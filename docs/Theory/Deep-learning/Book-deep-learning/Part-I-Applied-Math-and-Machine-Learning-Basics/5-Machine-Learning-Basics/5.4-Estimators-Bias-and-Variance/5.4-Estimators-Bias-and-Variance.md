# 5.4 Estimators, Bias and Variance

The field of statistics gives us many tools that can be used to achieve the machine learning goal of solving a task not only on the training set but also to generalize. Foundational concepts such as parameter estimation, bias and variance are useful to formally characterize notions of generalization, underfitting and overfitting.

***SUMMARY*** : 本节所描述的内容就是使用统计学的理论来描述deep learning中的generalization, underfitting and overfitting。





## 补充

### 维基百科[Bias of an estimator](https://en.wikipedia.org/wiki/Bias_of_an_estimator)



### [机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)有什么区别和联系？](https://www.zhihu.com/question/27068705)





### [偏差(Bias)和方差(Variance)——机器学习中的模型选择](https://www.jianshu.com/p/8c7f033be58a)

#### 模型性能的度量

在监督学习中，已知样本 ![(x_1, y_1),(x_2, y_2),...,(x_n, y_n)](https://math.jianshu.com/math?formula=(x_1%2C%20y_1)%2C(x_2%2C%20y_2)%2C...%2C(x_n%2C%20y_n))，要求拟合出一个模型（函数）![\hat{f}](https://math.jianshu.com/math?formula=%5Chat%7Bf%7D)，其预测值![\hat{f}(x)](https://math.jianshu.com/math?formula=%5Chat%7Bf%7D(x))与样本实际值![y](https://math.jianshu.com/math?formula=y)的**误差**最小。

考虑到**样本数据**其实是**采样**，![y](https://math.jianshu.com/math?formula=y)并不是真实值本身，假设真实模型（函数）是![f](https://math.jianshu.com/math?formula=f)，则采样值![y=f(x)+\varepsilon](https://math.jianshu.com/math?formula=y%3Df(x)%2B%5Cvarepsilon)，其中![\varepsilon](https://math.jianshu.com/math?formula=%5Cvarepsilon)代表噪音，其均值为0，方差为![\sigma^2](https://math.jianshu.com/math?formula=%5Csigma%5E2)。

拟合函数![\hat{f}](https://math.jianshu.com/math?formula=%5Chat%7Bf%7D)的主要目的是希望它能对新的样本进行预测，所以，拟合出函数![\hat{f}](https://math.jianshu.com/math?formula=%5Chat%7Bf%7D)后，需要在测试集（训练时未见过的数据）上检测其预测值与实际值![y](https://math.jianshu.com/math?formula=y)之间的**误差**。可以采用平方误差函数（mean squared error）来度量其拟合的好坏程度，即 $(y-\hat{f}(x))^2$

#### 误差期望值的分解

经过进一步的研究发现，对于某种特定的模型（下面还会进一步说明“特定模型”的含义），其**误差的期望值**可以分解为三个部分：样本**噪音**、模型预测值的**方差**、预测值相对真实值的**偏差**

公式为：
$$
E((y-\hat{f}(x))^2) = \sigma^2 + Var[\hat{f}(x))] + (Bias[\hat{f}(x)])^2
$$


其中 ![Bias[\hat{f}(x)] = E[\hat{f}(x) - f(x)]](https://math.jianshu.com/math?formula=Bias%5B%5Chat%7Bf%7D(x)%5D%20%3D%20E%5B%5Chat%7Bf%7D(x)%20-%20f(x)%5D)

即：**误差的期望值 = 噪音的方差 + 模型预测值的方差 + 预测值相对真实值的偏差的平方**
先看一个图比较直观。



![img](https://upload-images.jianshu.io/upload_images/2709767-38da68a134c01ee1.png?imageMogr2/auto-orient/strip|imageView2/2/w/731/format/webp)

图1 误差期望值的分解

使用特定模型对一个测试样本进行**预测**，就像打靶一样。

靶心（红点）是测试样本的真实值，测试样本的y（橙色点）是**真实值**加上**噪音**，特定模型重复多次训练会得到多个具体的模型，每一个具体模型对测试样本进行一次预测，就在靶上打出一个预测值（图上蓝色的点）。所有预测值的**平均**就是**预测值的期望**（较大的浅蓝色点），浅蓝色的圆圈表示预测值的离散程度，即**预测值的方差**。

所以，特定模型的预测值 与 真实值 的误差的 期望值，分解为上面公式中的三个部分，对应到图上的三条橙色线段：预测值的偏差、预测值的方差、样本噪音。

#### 理解误差期望值

回顾一下，**期望值**的含义是指在**同样的条件**下**重复多次**随机试验，得到的所有可能状态的**平均结果**（更详细的定义参考[维基百科-期望值](https://zh.wikipedia.org/wiki/期望值)）。对于机器学习来说，这种实验就是我们选择一种算法（并选定超参数），以及设置一个固定的训练集大小，这就是同样的条件，也就是上文所说的**特定的模型**。然后每次训练时从样本空间中选择一批样本作为训练集，但每次都随机抽取不同的样本，这样重复进行多次训练。每次训练会得到一个具体的模型，每个具体模型对同一个未见过的样本进行预测可以得到**预测值**。不断重复训练和预测，就能得到一系列预测值，根据样本和这些预测值计算出方差和偏差，就可以帮助我们考察该特定模型的**预测误差的期望值**，也就能衡量该特定模型的性能。对比多个特定模型的**误差的期望值**，可以帮助我们选择合适的模型。

#### 进一步理解误差期望值

再看一个更接近实际的例子，来自 [Bias-Variance in Machine Learning](http://www.cs.cmu.edu/~wcohen/10-601/bias-variance.pdf)

我们设置真实模型 ![f(x) = x + 2sin(1.5x)](https://math.jianshu.com/math?formula=f(x)%20%3D%20x%20%2B%202sin(1.5x))，函数图像如下图曲线所示。

样本值 y 就在**真实值**的基础上叠加一个随机噪音 N(0, 0.2)。

![img](https://upload-images.jianshu.io/upload_images/2709767-41bf0f141d2654d7.png?imageMogr2/auto-orient/strip|imageView2/2/w/873/format/webp)

图2 模型及样本

现在我们用线性函数来构建模型，训练样本来自随机采集的一组 y，经过多次重复，可以得到一系列具体的线性模型，如下图中那一组聚集在一起的黑色直线所示，其中间有一条红色线是这一组线性函数的平均（期望值）。这就是特定模型（线性函数）在同样条件下（每次取20个样本点）重复多次（得到50个线性函数）。

根据生成的50个具体的线性函数来考察该线性模型的预测性能，选取一个样本点，比如选择 x=5 时（下图中红色竖线位置），真实值 f(x) = 6.876，样本 ![y \approx 6.876](https://math.jianshu.com/math?formula=y%20%5Capprox%206.876)，y 与 f(x) 的偏差体现在图片右下方的**噪音（noise）** 部分。红色线性函数在 x=5 位置的值是这50个线性函数在该位置的期望值，黑色直线在 x=5 位置的一系列值的分布则反映了它们的**方差（Variance）**。50个预测的期望值与真实值 f(x) 之间的距离体现了**偏差（Bias）**。（参考下图右下部分的 variance 和 bias）。

![img](https://upload-images.jianshu.io/upload_images/2709767-2bd71832742a3838.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

图3 偏差、方差计算

总之，在机器学习中考察 偏差 和 方差，最重要的是要在不同数据集上训练出一组特定模型，这些模型对一个测试样本进行预测，考察这一组预测值的方差和偏差。

#### 误差的期望值公式推导

误差的期望值公式为什么可以分解为 噪音、偏差和方差，可以从数学上推导得来。先准备几个推导中需要用到的公式，为了方便，我们简化符号，记作
![f = f(x) \\ \hat{f} = \hat{f}(x)](https://math.jianshu.com/math?formula=f%20%3D%20f(x)%20%5C%5C%20%5Chat%7Bf%7D%20%3D%20%5Chat%7Bf%7D(x))

1. 方差的定义和计算公式
   ![Var[X] = E[X^2] - (E[X])^2](https://math.jianshu.com/math?formula=Var%5BX%5D%20%3D%20E%5BX%5E2%5D%20-%20(E%5BX%5D)%5E2)
   即 随机变量X的方差 = X平方的期望 - X期望的平方（参考 [维基百科-方差](https://zh.wikipedia.org/wiki/方差)），移项后得到
   ![E[X^2] = Var[X] + (E[X])^2 \qquad(1)](https://math.jianshu.com/math?formula=E%5BX%5E2%5D%20%3D%20Var%5BX%5D%20%2B%20(E%5BX%5D)%5E2%20%5Cqquad(1))

2. 测试样本y的期望值
   因为真实值![f](https://math.jianshu.com/math?formula=f)是一个确定的值，所以
   ![E[f] = f](https://math.jianshu.com/math?formula=E%5Bf%5D%20%3D%20f)
   另外根据上文测试样本值和噪音的定义
   ![y=f+\varepsilon \\ E[\varepsilon]=0 \\ Var[\varepsilon] = \sigma^2](https://math.jianshu.com/math?formula=y%3Df%2B%5Cvarepsilon%20%5C%5C%20E%5B%5Cvarepsilon%5D%3D0%20%5C%5C%20Var%5B%5Cvarepsilon%5D%20%3D%20%5Csigma%5E2)
   所以![E[y] = E[f+\varepsilon] = E[f] = f](https://math.jianshu.com/math?formula=E%5By%5D%20%3D%20E%5Bf%2B%5Cvarepsilon%5D%20%3D%20E%5Bf%5D%20%3D%20f)，即
   ![E[y] = f \qquad(2)](https://math.jianshu.com/math?formula=E%5By%5D%20%3D%20f%20%5Cqquad(2))

3. 测试样本y的方差

  
   $$
   Var[y] = E[(y - E[y])^2] = E[(y-f)^2] \\ = E[(f+\varepsilon-f)^2] = E[\varepsilon^2] \\ = Var[\varepsilon] + (E[\varepsilon])^2 = \sigma^2
   $$
   即
   ![Var[y] = \sigma^2 \qquad(3)](https://math.jianshu.com/math?formula=Var%5By%5D%20%3D%20%5Csigma%5E2%20%5Cqquad(3))

4. 样本噪音与预测值无关
   因为 ![\varepsilon](https://math.jianshu.com/math?formula=%5Cvarepsilon) 与 ![\hat{f}](https://math.jianshu.com/math?formula=%5Chat%7Bf%7D) 不相关，所以
   ![E[\varepsilon\hat{f}] = E[\varepsilon]E[\hat{f}] \qquad(4)](https://math.jianshu.com/math?formula=E%5B%5Cvarepsilon%5Chat%7Bf%7D%5D%20%3D%20E%5B%5Cvarepsilon%5DE%5B%5Chat%7Bf%7D%5D%20%5Cqquad(4))
   （参考[维基百科-期望值](https://zh.wikipedia.org/wiki/期望值))

5. 误差的期望
   公式推导如下
   $$
   E[(y-\hat{f})^2] = E[y^2 + \hat{f}^2 - 2y\hat{f}] \\ = E[y^2] + E[\hat{f}^2] - E[2y\hat{f}] \\ = \Big(Var[y] + (E[y]))^2 \Big) + \Big(Var[\hat{f}] + (E[\hat{f}])^2 \Big) - E[2(f+\varepsilon) \hat{f}] \\ = Var[y] + Var[\hat{f}] + (E[y])^2 + (E[\hat{f}])^2 - E[2f\hat{f} +2\varepsilon \hat{f}] \\ = Var[y] + Var[\hat{f}] + f^2 + (E[\hat{f}])^2 - E[2f\hat{f}] -E[2\varepsilon \hat{f}] \\ = Var[y] + Var[\hat{f}] + f^2 + (E[\hat{f}])^2 - 2fE[\hat{f}] -2E[\varepsilon]E[\hat{f}] \\ = Var[y] + Var[\hat{f}] + \Big(f^2 + (E[\hat{f}])^2 - 2fE[\hat{f}] \Big) \\ = Var[y] + Var[\hat{f}] + (f - E[\hat{f}])^2 \\ = \sigma^2 + Var[\hat{f}] + (Bias[\hat{f}])^2
   $$
   最后得到的三个项分别是：噪音的方差、模型预测值的方差、预测值相对真实值的偏差的平方。

#### 偏差 - 方差的选择

理想中，我们希望得到一个偏差和方差都很小的模型（下图左上），但实际上往往很困难。

![img](https://upload-images.jianshu.io/upload_images/2709767-374edf33dbd92974.png?imageMogr2/auto-orient/strip|imageView2/2/w/902/format/webp)

image



选择相对较好的模型的顺序：（方差小，偏差小） > （方差小，偏差大） > （方差大，偏差小） > （方差大，偏差大）。
方差小，偏差大 之所以在实际中排位相对靠前，是因为它比较**稳定**。很多时候实际中无法获得非常全面的**数据集**，那么，如果一个模型在可获得的样本上有较小的方差，说明它对不同数据集的敏感度不高，可以期望它对新数据集的预测效果比较稳定。



#### 选择假设集合

很多时候，机器学习所面临的问题，我们事先并不确切的知道要拟合的是一个怎样形式的函数，是几次多项式，是几层神经网络，选择样本的哪些特征，等等，都缺乏先验的知识来帮助我们选择。我们在一个基本上无穷大的**假设（模型）集合**中，凭借有限的经验进行尝试和选择。

机器学习有多种算法，以及每种算法中经常又可以选择不同的结构和超参数。它们所覆盖的假设集合有不同的大小。所以，选择一种算法（包括其结构和超参数），就是选择（限定）了一个**假设集合**。我们期望真实模型存在于我们所选定的**假设集合**范围内，并且该**假设集合**越小越好。

下面两幅图粗略表现了不同**假设集合**的关系

![img](https://upload-images.jianshu.io/upload_images/2709767-44d21b83ab9c2881.png?imageMogr2/auto-orient/strip|imageView2/2/w/812/format/webp)

不同的**假设集合**

![img](https://upload-images.jianshu.io/upload_images/2709767-2353bd4524bb9b72.png?imageMogr2/auto-orient/strip|imageView2/2/w/546/format/webp)

**正则化项**对假设集合的影响

我们思考一下监督学习的整个流程，其实就是一个不断缩小**假设集合**的过程。从大的方面看可以分为两个步骤。

1. 选择一个**假设集合**，包括模型及相关结构、超参数等。
2. 使用样本数据进行训练，使该模型尽量拟合样本，就是从上面选定的假设集合中找到一个特定的假设（模型）。

上面第一个步骤中，我们可以选择一些不同的假设集合，然后通过考察它们的**偏差方差**，对各**假设集合**的**性能**进行评估。比如多项式的次数，上图假设真实模型是一个二次多项式，那么线性函数集合中的模型会**欠拟合**（**方差低**，**偏差太高**），高次多项式集合中的模型容易**过拟合**（方差太高，偏差低），二项式集合中的模型能够有较好的折中（方差和偏差都相对较低），总体**误差**最小。

#### 偏差 - 方差权衡

1. 多项式回归
   多项式回归模型，我们可以选择不同的多项式的次数，对模型的影响如下。

![img](https://upload-images.jianshu.io/upload_images/2709767-0ae7d8325e3aa61b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

多项式次数对模型偏差方差的影响

| 多项式次数 | 模型复杂度 | 方差 | 偏差 | 过/欠拟合 |
| :--------: | :--------: | :--: | :--: | :-------: |
|     低     |     低     |  低  |  高  |  欠拟合   |
|     中     |     中     |  中  |  中  |   适度    |
|     高     |     高     |  高  |  低  |  过拟合   |

![img](https://upload-images.jianshu.io/upload_images/2709767-b7246236605df562.png?imageMogr2/auto-orient/strip|imageView2/2/w/625/format/webp)

多项式次数对训练误差/测试误差的影响

| 多项式次数 | 模型复杂度 | 训练误差 | 测试误差 |
| :--------: | :--------: | :------: | :------: |
|     低     |     低     |    高    |    高    |
|     中     |     中     |    中    |    低    |
|     高     |     高     |    低    |    高    |

2. 正则化项

   添加正则化项（Regularization）相当于对模型参数施加惩罚，压缩了参数的范围，限制了模型的复杂度，从而有助于缓解模型过拟合问题，选择不同的 正则化项权重λ 对模型的影响如下。

   ![img](https://upload-images.jianshu.io/upload_images/2709767-2a8a97bbb6eca42f.png?imageMogr2/auto-orient/strip|imageView2/2/w/876/format/webp)

   正则化项对模型偏差方差的影响

   | 正则化项权重λ | 模型复杂度 | 方差 | 偏差 | 过/欠拟合 |
   | :-----------: | :--------: | :--: | :--: | :-------: |
   |      大       |     低     |  低  |  高  |  欠拟合   |
   |      中       |     中     |  中  |  中  |   适度    |
   |      小       |     高     |  高  |  低  |  过拟合   |

![img](https://upload-images.jianshu.io/upload_images/2709767-0377b4c9df79ca7c.png?imageMogr2/auto-orient/strip|imageView2/2/w/349/format/webp)

正则化项对训练误差/测试误差的影响

| 正则化项权重λ | 模型复杂度 | 训练误差 | 测试误差 |
| :-----------: | :--------: | :------: | :------: |
|      大       |     低     |    高    |    高    |
|      中       |     中     |    中    |    低    |
|      小       |     高     |    低    |    高    |

3. 样本数量

   一般来说，我们希望**样本数量**越多越好。随着**样本数量**增加，训练误差会逐渐增长，测试误差会逐渐降低。

   ![img](https://upload-images.jianshu.io/upload_images/2709767-75bb399a3e66e6fa.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

   样本数量对训练误差/测试误差的影响

4. 神经网络



![img](https://upload-images.jianshu.io/upload_images/2709767-f86bb7a076aed457.png?imageMogr2/auto-orient/strip|imageView2/2/w/303/format/webp)

神经网络结构

| 神经网络结构 | 模型复杂度 | 方差 | 偏差 | 过/欠拟合 |
| :----------: | :--------: | :--: | :--: | :-------: |
|      小      |     低     |  低  |  高  |  欠拟合   |
|      中      |     中     |  中  |  中  |   适度    |
|      大      |     高     |  高  |  低  |  过拟合   |





#### K-Fold 交叉验证

计算偏差、方差可以帮助评估不同的假设集合，不过它需要较多的样本，以及重复多次拟合模型，需要比较多的数据和计算资源（参考上面图3）。

实际中，比较常用的方法是K-Fold交叉验证。它与标准的偏差、方差计算过程不太一样。简单的说，就是将训练样本分成k份，每次取其中一份作为验证集，另外 k-1 份作训练集。这样进行 k 次训练得到 k 个模型。这 k 个模型对各自的验证集进行预测，得到 k 个评估值（可以是误差、准确率，或按某种规则计算的得分等等）。注意到每个样本参与了 k-1 个模型的训练（导致模型之间存在关联），每个样本有一次被用作测试（没有用另外的从未见过的测试集数据），所以这与标准的计算过程是不一样的。

不过，K-Fold依然是很有价值的模型性能评估方法。可以直接针对这 k 个模型的评估值（误差、准确率，或按某种规则计算的得分等等）进行分析，取其平均可以体现该模型的预测准确性。对这 k 个值，比如k个误差值，计算**方差**，可以反应该模型的预测误差的离散程度，即后续用于未见过的样本数据时，模型的预测准确性是否**稳定**。

#### 参考

[维基百科 - Bias–variance tradeoff](https://en.wikipedia.org/wiki/Bias–variance_tradeoff)
[Bias-Variance in Machine Learning](http://www.cs.cmu.edu/~wcohen/10-601/bias-variance.pdf)
[维基百科 - 方差](https://zh.wikipedia.org/wiki/方差)
[维基百科 - 期望值](https://zh.wikipedia.org/wiki/期望值)
《Pattern Recognition and Machine Learning》之 3.2. The Bias-Variance Decomposition