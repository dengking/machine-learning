{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u5173\u4e8e\u672c\u5de5\u7a0b \u672c\u5de5\u7a0b\u6309\u7167\u7406\u8bba\u4e0e\u5b9e\u8df5\u76f8\u7ed3\u5408\u7684\u601d\u8def\u6765\u603b\u7ed3machine learning\u7684\u77e5\u8bc6\u3002 \u7406\u8bba\uff1a\u5728 Theory \u7ae0\u8282\u4ecb\u7ecd\uff1b \u5b9e\u8df5\uff1a\u5728 Programming \u7ae0\u8282\u4ecb\u7ecd\uff1b \u96f7\u950b\u7f51 \u8f83\u597d\u7684\u54a8\u8be2\u7f51\u7ad9 Google AI \u6ca1\u6709\u592a\u591a\u5185\u5bb9 Google Brain wikipedia Google Brain Google Brain Official site","title":"Home"},{"location":"#_1","text":"\u672c\u5de5\u7a0b\u6309\u7167\u7406\u8bba\u4e0e\u5b9e\u8df5\u76f8\u7ed3\u5408\u7684\u601d\u8def\u6765\u603b\u7ed3machine learning\u7684\u77e5\u8bc6\u3002 \u7406\u8bba\uff1a\u5728 Theory \u7ae0\u8282\u4ecb\u7ecd\uff1b \u5b9e\u8df5\uff1a\u5728 Programming \u7ae0\u8282\u4ecb\u7ecd\uff1b","title":"\u5173\u4e8e\u672c\u5de5\u7a0b"},{"location":"#_2","text":"\u8f83\u597d\u7684\u54a8\u8be2\u7f51\u7ad9","title":"\u96f7\u950b\u7f51"},{"location":"#google#ai","text":"\u6ca1\u6709\u592a\u591a\u5185\u5bb9","title":"Google AI"},{"location":"#google#brain","text":"wikipedia Google Brain Google Brain Official site","title":"Google Brain"},{"location":"AI-meeting/","text":"\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u9876\u7ea7\u4f1a\u8bae Conference on Neural Information Processing Systems NIPS International Conference on Computer Vision ICCV Conference on Computer Vision and Pattern Recognition CVPR International Conference on Learning Representations ICLR","title":"AI-meeting"},{"location":"AI-meeting/#_1","text":"","title":"\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u9876\u7ea7\u4f1a\u8bae"},{"location":"AI-meeting/#conference#on#neural#information#processing#systems","text":"NIPS","title":"Conference on Neural Information Processing Systems"},{"location":"AI-meeting/#international#conference#on#computer#vision","text":"ICCV","title":"International Conference on Computer Vision"},{"location":"AI-meeting/#conference#on#computer#vision#and#pattern#recognition","text":"CVPR","title":"Conference on Computer Vision and Pattern Recognition"},{"location":"AI-meeting/#international#conference#on#learning#representations","text":"ICLR","title":"International Conference on Learning Representations"},{"location":"TODO/","text":"AI Regularization https://en.wikipedia.org/wiki/Regularization_(mathematics ) https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-keras/ dropout https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/ https://stackoverflow.com/questions/35545798/keep-prob-in-tensorflow-mnist-tutorial TODO Machine learning Graphical model Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Helmholtz machine restricted Boltzmann machine http://cs230.stanford.edu/blog/createtrainmodel/ https://danijar.com/patterns-for-fast-prototyping-with-tensorflow/ https://hackernoon.com/towards-ai-how-long-does-it-take-you-to-go-from-idea-to-working-prototype-a-day-a-month-8a03ffecca0a tf.contrib.layers.xavier_initializer https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/layers/xavier_initializer?hl=cy https://stackoverflow.com/questions/42286426/what-is-the-difference-between-xavier-initializer-and-xavier-initializer-conv2d?rq=1 position embedding https://stackoverflow.com/questions/44614603/what-is-the-the-position-embedding-in-the-convolutional-sequence-to-sequence-lea time serial forecast https://www.tensorflow.org/tutorials/structured_data/time_series attention self attention Self-Attention Mechanisms in Natural Language Processing transformer https://glassboxmedicine.com/2019/08/15/the-transformer-attention-is-all-you-need/ attention and model architecture \u76ee\u524d\u6240\u9605\u8bfb\u7684\u5982\u4e0b\u8bba\u6587\u4e2d\uff0c\u4f7f\u7528attention\u7684model architecture\u90fd\u662fencoder-decoder 201409 Neural Machine Translation by Jointly Learning to Align and Translate 201502 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention \u5f53\u7136\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u6709\u8bba\u6587\u4e00\u79cdarchitecture\uff1atransformer\uff0c\u90a3transformer\u4e2d\u662f\u5982\u4f55\u7684\u5462\uff1f\u8fd8\u9700\u8981\u9605\u8bfb\u5b83\u7684paper\uff1b drop-out \u6784\u9020\u56fe\u7684\u8fc7\u7a0b\u548cFutures and promises\u4e4b\u95f4\u7684\u5173\u7cfb https://en.wikipedia.org/wiki/Futures_and_promises tensorflow\u7684\u6d4b\u8bd5 \u5728\u642d\u5efa\u540e\u6765computation graph\u540e\uff0c\u662f\u53ef\u4ee5\u4f7f\u7528numpy\u6570\u636e\u8fdb\u884c\u6d4b\u8bd5\u7684\uff0c\u5982\uff1a https://stackoverflow.com/questions/51443898/how-do-i-use-tf-reshape how to find tensorflow bottleneck \u6784\u5efa\u4e00\u4e2a\u5b8c\u6574\u7684AI\u5e94\u7528 \u6211\u76ee\u524d\u7684\u4e00\u4e2a\u95ee\u9898\u662f\u8fd8\u6ca1\u6709\u72ec\u7acb\u5730\u5b8c\u6210\u4e00\u4e2aAI\u4efb\u52a1\uff0c\u9700\u8981\u627e\u65f6\u95f4\u6765\u7ec3\u4e60\u3002 use knowledge graph to enhance semantic comprehension https://www.aminer.cn/research_report/5dd163d61ca12517163f032c?download=false \u6765\u52302019\u5e74\u7684\u4eca\u5929\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u8bf8\u591a\u5c40\u9650\u6027\u4e5f\u6162\u6162\u5f97\u5230\u5e7f\u6cdb\u8ba4\u77e5\u3002\u5bf9\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u800c\u8a00\uff0c\u8981\u505a\u5230\u7cbe\u7ec6\u6df1\u5ea6\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u5355\u7eaf\u4f9d\u9760\u6570\u636e\u6807\u6ce8\u4e0e\u7b97\u529b\u6295\u5165\u65e0\u6cd5\u89e3\u51b3\u672c\u8d28\u95ee\u9898\u3002\u5982\u679c\u6ca1\u6709\u5148\u9a8c\u77e5\u8bc6\u7684\u652f\u6301\uff0c\u201c\u4e2d\u56fd\u7684\u4e52\u4e53\u7403\u8c01\u90fd\u6253\u4e0d\u8fc7\u201d\u4e0e\u201c\u4e2d\u56fd\u7684\u8db3\u7403\u8c01\u90fd\u6253\u4e0d\u8fc7\u201d\uff0c\u5728\u8ba1\u7b97\u673a\u770b\u6765\u8bed\u4e49\u4e0a\u5e76\u6ca1\u6709\u5de8\u5927\u5dee\u5f02\uff0c\u800c\u5b9e\u9645\u4e0a\u4e24\u53e5\u4e2d\u7684\u201c\u6253\u4e0d\u8fc7\u201d\u610f\u601d\u6b63\u597d\u76f8\u53cd\u3002\u56e0\u6b64\uff0c\u878d\u5165\u77e5\u8bc6\u6765\u8fdb\u884c\u77e5\u8bc6\u6307\u5bfc\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u662f\u901a\u5411\u7cbe\u7ec6\u800c\u6df1\u5ea6\u7684\u8bed\u8a00\u7406\u89e3\u7684\u5fc5\u7531\u4e4b\u8def\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u53c8\u4ece\u54ea\u91cc\u6765\u5462\uff1f\u8fd9\u5c31\u6d89\u53ca\u5230\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u4e2a\u5173\u952e\u7814\u7a76\u95ee\u9898\u2014\u2014\u77e5\u8bc6\u83b7\u53d6\u3002 knowledge graph https://www.zhihu.com/topic/19551341/hot https://www.zhihu.com/org/hua-wei-yun-ji-zhu-zhai-ji-di/activities https://www.zhihu.com/people/ji-yi-chao/activities https://www.zhihu.com/question/354059866/answer/907009362 https://www.zhihu.com/topic/19838204/hot","title":"AI"},{"location":"TODO/#ai","text":"","title":"AI"},{"location":"TODO/#regularization","text":"https://en.wikipedia.org/wiki/Regularization_(mathematics ) https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-keras/","title":"Regularization"},{"location":"TODO/#dropout","text":"https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/ https://stackoverflow.com/questions/35545798/keep-prob-in-tensorflow-mnist-tutorial","title":"dropout"},{"location":"TODO/#todo","text":"","title":"TODO"},{"location":"TODO/#machine#learning","text":"","title":"Machine learning"},{"location":"TODO/#graphical#model","text":"Structured prediction Graphical models Bayes net Conditional random field Hidden Markov","title":"Graphical model"},{"location":"TODO/#helmholtz#machine","text":"restricted Boltzmann machine http://cs230.stanford.edu/blog/createtrainmodel/ https://danijar.com/patterns-for-fast-prototyping-with-tensorflow/ https://hackernoon.com/towards-ai-how-long-does-it-take-you-to-go-from-idea-to-working-prototype-a-day-a-month-8a03ffecca0a","title":"Helmholtz machine"},{"location":"TODO/#tfcontriblayersxavier_initializer","text":"https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/layers/xavier_initializer?hl=cy https://stackoverflow.com/questions/42286426/what-is-the-difference-between-xavier-initializer-and-xavier-initializer-conv2d?rq=1","title":"tf.contrib.layers.xavier_initializer"},{"location":"TODO/#position#embedding","text":"https://stackoverflow.com/questions/44614603/what-is-the-the-position-embedding-in-the-convolutional-sequence-to-sequence-lea","title":"position embedding"},{"location":"TODO/#time#serial#forecast","text":"https://www.tensorflow.org/tutorials/structured_data/time_series","title":"time serial forecast"},{"location":"TODO/#attention","text":"","title":"attention"},{"location":"TODO/#self#attention","text":"Self-Attention Mechanisms in Natural Language Processing","title":"self attention"},{"location":"TODO/#transformer","text":"https://glassboxmedicine.com/2019/08/15/the-transformer-attention-is-all-you-need/","title":"transformer"},{"location":"TODO/#attention#and#model#architecture","text":"\u76ee\u524d\u6240\u9605\u8bfb\u7684\u5982\u4e0b\u8bba\u6587\u4e2d\uff0c\u4f7f\u7528attention\u7684model architecture\u90fd\u662fencoder-decoder 201409 Neural Machine Translation by Jointly Learning to Align and Translate 201502 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention \u5f53\u7136\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u6709\u8bba\u6587\u4e00\u79cdarchitecture\uff1atransformer\uff0c\u90a3transformer\u4e2d\u662f\u5982\u4f55\u7684\u5462\uff1f\u8fd8\u9700\u8981\u9605\u8bfb\u5b83\u7684paper\uff1b","title":"attention and model architecture"},{"location":"TODO/#drop-out","text":"","title":"drop-out"},{"location":"TODO/#futures#and#promises","text":"https://en.wikipedia.org/wiki/Futures_and_promises","title":"\u6784\u9020\u56fe\u7684\u8fc7\u7a0b\u548cFutures and promises\u4e4b\u95f4\u7684\u5173\u7cfb"},{"location":"TODO/#tensorflow","text":"\u5728\u642d\u5efa\u540e\u6765computation graph\u540e\uff0c\u662f\u53ef\u4ee5\u4f7f\u7528numpy\u6570\u636e\u8fdb\u884c\u6d4b\u8bd5\u7684\uff0c\u5982\uff1a https://stackoverflow.com/questions/51443898/how-do-i-use-tf-reshape","title":"tensorflow\u7684\u6d4b\u8bd5"},{"location":"TODO/#how#to#find#tensorflow#bottleneck","text":"","title":"how to find tensorflow bottleneck"},{"location":"TODO/#ai_1","text":"\u6211\u76ee\u524d\u7684\u4e00\u4e2a\u95ee\u9898\u662f\u8fd8\u6ca1\u6709\u72ec\u7acb\u5730\u5b8c\u6210\u4e00\u4e2aAI\u4efb\u52a1\uff0c\u9700\u8981\u627e\u65f6\u95f4\u6765\u7ec3\u4e60\u3002","title":"\u6784\u5efa\u4e00\u4e2a\u5b8c\u6574\u7684AI\u5e94\u7528"},{"location":"TODO/#use#knowledge#graph#to#enhance#semantic#comprehension","text":"https://www.aminer.cn/research_report/5dd163d61ca12517163f032c?download=false \u6765\u52302019\u5e74\u7684\u4eca\u5929\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u8bf8\u591a\u5c40\u9650\u6027\u4e5f\u6162\u6162\u5f97\u5230\u5e7f\u6cdb\u8ba4\u77e5\u3002\u5bf9\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u800c\u8a00\uff0c\u8981\u505a\u5230\u7cbe\u7ec6\u6df1\u5ea6\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u5355\u7eaf\u4f9d\u9760\u6570\u636e\u6807\u6ce8\u4e0e\u7b97\u529b\u6295\u5165\u65e0\u6cd5\u89e3\u51b3\u672c\u8d28\u95ee\u9898\u3002\u5982\u679c\u6ca1\u6709\u5148\u9a8c\u77e5\u8bc6\u7684\u652f\u6301\uff0c\u201c\u4e2d\u56fd\u7684\u4e52\u4e53\u7403\u8c01\u90fd\u6253\u4e0d\u8fc7\u201d\u4e0e\u201c\u4e2d\u56fd\u7684\u8db3\u7403\u8c01\u90fd\u6253\u4e0d\u8fc7\u201d\uff0c\u5728\u8ba1\u7b97\u673a\u770b\u6765\u8bed\u4e49\u4e0a\u5e76\u6ca1\u6709\u5de8\u5927\u5dee\u5f02\uff0c\u800c\u5b9e\u9645\u4e0a\u4e24\u53e5\u4e2d\u7684\u201c\u6253\u4e0d\u8fc7\u201d\u610f\u601d\u6b63\u597d\u76f8\u53cd\u3002\u56e0\u6b64\uff0c\u878d\u5165\u77e5\u8bc6\u6765\u8fdb\u884c\u77e5\u8bc6\u6307\u5bfc\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u662f\u901a\u5411\u7cbe\u7ec6\u800c\u6df1\u5ea6\u7684\u8bed\u8a00\u7406\u89e3\u7684\u5fc5\u7531\u4e4b\u8def\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u53c8\u4ece\u54ea\u91cc\u6765\u5462\uff1f\u8fd9\u5c31\u6d89\u53ca\u5230\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u4e2a\u5173\u952e\u7814\u7a76\u95ee\u9898\u2014\u2014\u77e5\u8bc6\u83b7\u53d6\u3002","title":"use knowledge graph  to enhance semantic comprehension"},{"location":"TODO/#knowledge#graph","text":"https://www.zhihu.com/topic/19551341/hot https://www.zhihu.com/org/hua-wei-yun-ji-zhu-zhai-ji-di/activities https://www.zhihu.com/people/ji-yi-chao/activities https://www.zhihu.com/question/354059866/answer/907009362 https://www.zhihu.com/topic/19838204/hot","title":"knowledge graph"},{"location":"AI-papers/","text":"\u8bba\u6587 \u54ea\u91cc\u53bb\u627e\u8bba\u6587\uff1f\u54ea\u91cc\u53bb\u627e\u8fd9\u4e9b\u8bba\u6587\u7684\u5b9e\u73b0\uff1f paper with code \u7ed9\u51fa\u4e86\u8bba\u6587\u7684\u5b9e\u73b0\u3002 arXiv.org \u7269\u7406\u3001\u6570\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u751f\u7269\u5b66\u548c\u5b9a\u91cf\u91d1\u878d\u5b66\u7b49\u5b66\u672f\u8bba\u6587\u6587\u7ae0\u5e93 Aminer \u8ba1\u7b97\u673a\u79d1\u5b66\u8d44\u6e90\u7c7b\u7684\u77e5\u8bc6\u53d1\u73b0\u670d\u52a1\u7f51\u7ad9 Papers We Love \u901a\u8fc7Papers We Love(\u5b98\u65b9\u7b80\u79f0PWL)\u53ef\u4ee5\u627e\u5230\u5f88\u591a\u5173\u4e8e\u8ba1\u7b97\u673a\u79d1\u5b66\u7c7b\u7684\u5b66\u672f\u8bba\u6587 Scopus Web of Science \u7f8e\u56fd\u5b66\u672f\u8bba\u6587\u3001\u79d1\u5b66\u7814\u7a76\u7c7b\u7f51\u7ad9\u4f7f\u7528\u63a8\u8350 \u7c7b\u4f3c\u4e2d\u56fd\u77e5\u7f51\u4f46\u662f\u641c\u7d22\u82f1\u6587\u6587\u732e\u7684\u6743\u5a01\u7f51\u7ad9\u6709\u54ea\u4e9b\uff1f","title":"Introduction"},{"location":"AI-papers/#_1","text":"\u54ea\u91cc\u53bb\u627e\u8bba\u6587\uff1f\u54ea\u91cc\u53bb\u627e\u8fd9\u4e9b\u8bba\u6587\u7684\u5b9e\u73b0\uff1f","title":"\u8bba\u6587"},{"location":"AI-papers/#paper#with#code","text":"\u7ed9\u51fa\u4e86\u8bba\u6587\u7684\u5b9e\u73b0\u3002","title":"paper with code"},{"location":"AI-papers/#arxivorg","text":"\u7269\u7406\u3001\u6570\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u751f\u7269\u5b66\u548c\u5b9a\u91cf\u91d1\u878d\u5b66\u7b49\u5b66\u672f\u8bba\u6587\u6587\u7ae0\u5e93","title":"arXiv.org"},{"location":"AI-papers/#aminer","text":"\u8ba1\u7b97\u673a\u79d1\u5b66\u8d44\u6e90\u7c7b\u7684\u77e5\u8bc6\u53d1\u73b0\u670d\u52a1\u7f51\u7ad9","title":"Aminer"},{"location":"AI-papers/#papers#we#love","text":"\u901a\u8fc7Papers We Love(\u5b98\u65b9\u7b80\u79f0PWL)\u53ef\u4ee5\u627e\u5230\u5f88\u591a\u5173\u4e8e\u8ba1\u7b97\u673a\u79d1\u5b66\u7c7b\u7684\u5b66\u672f\u8bba\u6587","title":"Papers We Love"},{"location":"AI-papers/#scopus","text":"","title":"Scopus"},{"location":"AI-papers/#web#of#science","text":"","title":"Web of Science"},{"location":"AI-papers/#_2","text":"","title":"\u7f8e\u56fd\u5b66\u672f\u8bba\u6587\u3001\u79d1\u5b66\u7814\u7a76\u7c7b\u7f51\u7ad9\u4f7f\u7528\u63a8\u8350"},{"location":"AI-papers/#_3","text":"","title":"\u7c7b\u4f3c\u4e2d\u56fd\u77e5\u7f51\u4f46\u662f\u641c\u7d22\u82f1\u6587\u6587\u732e\u7684\u6743\u5a01\u7f51\u7ad9\u6709\u54ea\u4e9b\uff1f"},{"location":"AI-papers/Reading-record/","text":"Introduction Organize all carefully read papers, all papers are sorted by subject and time. RNN GRU \u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u9886\u57df \u8bc4\u4ef7 code 1412 201412 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling Junyoung Chung \uff0c Bengio, Yoshua Encoder\u2013Decoder architecture \u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u9886\u57df \u8bc4\u4ef7 code 1406 201406 Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation Kyunghyun Cho \uff0c Cho, Kyunghyun \uff0c Bengio, Yoshua NLP-machine translation \u9996\u6b21\u63d0\u51fa\u4e86RNN Encoder\u2013Decoder\uff1b \u8865\u5145\uff1a - Neural machine translation by jointly learning to align and translate - employing attention in machine translation - soft alignment 1409 201409 Sequence to Sequence Learning with Neural Networks Google NLP-machine translation \u8fd9\u7bc7\u8bba\u6587\u53c2\u8003\u4e86 Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation \uff0c\u6240\u4e0d\u540c\u7684\u662f\uff0c\u5b83\u4f7f\u7528\u7684\u662fLSTM\uff1b ### blog Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation attention \u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u9886\u57df \u8bc4\u4ef7 code 1409 201409 Neural Machine Translation by Jointly Learning to Align and Translate Bahdanau, Dzmitry \uff0c Cho, Kyunghyun \uff0c Bengio, Yoshua NLP-machine translation \u9996\u6b21\u63d0\u51fa\u4e86attention mechanism\uff1b \u8865\u51fa\uff1a - Neural machine translation by jointly learning to align and translate - employing attention in machine translation - soft alignment text_classification / a06_Seq2seqWithAttention / 1412 201412 MULTIPLE OBJECT RECOGNITION WITH VISUAL ATTENTION Google DeepMind University of Toronto - employing attention in OBJECT RECOGNITION 1502 201502 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention Kelvin Xu , Jimmy Ba , Ryan Kiros , Kyunghyun Cho , Aaron Courville , Ruslan Salakhutdinov , Richard Zemel , Yoshua Bengio image caption \u6bd4\u8f83\u5bb9\u6613\u9605\u8bfb\uff0c\u5bb9\u6613\u7406\u89e3\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u4e86\u89e3attention\u7684\u5165\u95e8\u8bfb\u7269 - \u53d71409\u548c1412\u7684\u542f\u53d1\uff0c\u5c06attention mechanism\u5e94\u7528\u4e8egenerating its caption - \u63d0\u51fa\u4e86soft attention\u548chard attention kelvinxu / arctic-captions 1601 201601 Long Short-Term Memory-Networks for Machine Reading Jianpeng Cheng University of Edinburgh Self-Attention 1706 201706 Attention Is All You Need Google Brain \u9996\u6b21\u63d0\u51fa\u4e86transformer--\u4e00\u79cd\u65b0\u7684model architecture \u8865\u5145\uff1a - \u300aattention is all you need\u300b\u89e3\u8bfb - huggingface / transformers - models / official / transformer / NLP \u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u8bc4\u4ef7 1810 201810 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding Google Brain \u8865\u51fa - TensorFlow code and pre-trained models for BERT distant supervision for relation extraction \u6807\u53f7 \u5e74\u4efd \u8bba\u6587 \u4f18\u70b9 \u5f31\u70b9 0911 200911 Distant supervision for relation extraction without labeled data \u5f88\u591a\uff0c\u6bd4\u5982\uff1a\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3001\u6210\u672c\u4f4e\u3001\u5927\u5bb9\u91cf\u6570\u636e\u96c6\u3001\u80fd\u591f\u89c4\u907f\u4e00\u4e9b\u56f0\u6270\u76d1\u7763\u5b66\u4e60\u7684\u95ee\u9898 1. \u566a\u58f0\u5927\uff0c\u6027\u80fd\u4e0d\u591f\u5f3a 2. \u9700\u8981\u4eba\u4e3a\u8bbe\u8ba1\u7279\u5f81 ... ... ... ... 15 2015 Distant supervisionfor relation extraction via piecewise convolutional neural networks. 1. \u4f7f\u7528**PCNNs**s\u795e\u7ecf\u7f51\u7edc\u9009\u62e9\u6700\u5927\u6982\u7387\u4e3avalid instance\u7684\u53e5\u5b50\u6765\u4ece\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u4f20\u7edf\u7684NLP\u5de5\u5177 1. \u6bcf\u4e2abag\u4e2d\u4ec5\u4ec5\u9009\u62e9\u4e00\u4e2a\u53e5\u5b50\uff08\u6700\u5927\u6982\u7387\uff09\u4f5c\u4e3avalid instance\uff0c\u5bfc\u81f4\u5b83\u672a\u80fd\u5145\u5206\u5229\u7528bag\u4e2d\u7684\u4fe1\u606f 17 2017 Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions 1. bag\u4e2d\u4f1a\u8003\u8651\u591a\u4e2a valid Instance 2. \u7531\u795e\u7ecf\u7f51\u7edc\u6765\u63d0\u53d6\u7279\u5f81 3. \u63d0\u51fa**entity descriptions**\u601d\u8def 1904 201904 Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions 1. \u9664\u4e86intra-bag\uff08\u5305\u5185\uff09 attentions\uff0c\u8fd8\u6dfb\u52a0\u4e86inter-bag\uff08\u5305\u95f4\uff09 attentions memory network \u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u8bc4\u4ef7 1410 201410 Memory Networks Jason Weston , Sumit Chopra , Antoine Bordes \u9996\u6b21\u63d0\u51famemory model 1503 201503 End-To-End Memory Networks Sainbayar Sukhbaatar , Arthur Szlam , Jason Weston , Rob Fergus","title":"Reading-record"},{"location":"AI-papers/Reading-record/#introduction","text":"Organize all carefully read papers, all papers are sorted by subject and time.","title":"Introduction"},{"location":"AI-papers/Reading-record/#rnn","text":"","title":"RNN"},{"location":"AI-papers/Reading-record/#gru","text":"\u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u9886\u57df \u8bc4\u4ef7 code 1412 201412 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling Junyoung Chung \uff0c Bengio, Yoshua","title":"GRU"},{"location":"AI-papers/Reading-record/#encoderdecoder#architecture","text":"\u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u9886\u57df \u8bc4\u4ef7 code 1406 201406 Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation Kyunghyun Cho \uff0c Cho, Kyunghyun \uff0c Bengio, Yoshua NLP-machine translation \u9996\u6b21\u63d0\u51fa\u4e86RNN Encoder\u2013Decoder\uff1b \u8865\u5145\uff1a - Neural machine translation by jointly learning to align and translate - employing attention in machine translation - soft alignment 1409 201409 Sequence to Sequence Learning with Neural Networks Google NLP-machine translation \u8fd9\u7bc7\u8bba\u6587\u53c2\u8003\u4e86 Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation \uff0c\u6240\u4e0d\u540c\u7684\u662f\uff0c\u5b83\u4f7f\u7528\u7684\u662fLSTM\uff1b ### blog Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation","title":"Encoder\u2013Decoder architecture"},{"location":"AI-papers/Reading-record/#attention","text":"\u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u9886\u57df \u8bc4\u4ef7 code 1409 201409 Neural Machine Translation by Jointly Learning to Align and Translate Bahdanau, Dzmitry \uff0c Cho, Kyunghyun \uff0c Bengio, Yoshua NLP-machine translation \u9996\u6b21\u63d0\u51fa\u4e86attention mechanism\uff1b \u8865\u51fa\uff1a - Neural machine translation by jointly learning to align and translate - employing attention in machine translation - soft alignment text_classification / a06_Seq2seqWithAttention / 1412 201412 MULTIPLE OBJECT RECOGNITION WITH VISUAL ATTENTION Google DeepMind University of Toronto - employing attention in OBJECT RECOGNITION 1502 201502 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention Kelvin Xu , Jimmy Ba , Ryan Kiros , Kyunghyun Cho , Aaron Courville , Ruslan Salakhutdinov , Richard Zemel , Yoshua Bengio image caption \u6bd4\u8f83\u5bb9\u6613\u9605\u8bfb\uff0c\u5bb9\u6613\u7406\u89e3\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u4e86\u89e3attention\u7684\u5165\u95e8\u8bfb\u7269 - \u53d71409\u548c1412\u7684\u542f\u53d1\uff0c\u5c06attention mechanism\u5e94\u7528\u4e8egenerating its caption - \u63d0\u51fa\u4e86soft attention\u548chard attention kelvinxu / arctic-captions 1601 201601 Long Short-Term Memory-Networks for Machine Reading Jianpeng Cheng University of Edinburgh Self-Attention 1706 201706 Attention Is All You Need Google Brain \u9996\u6b21\u63d0\u51fa\u4e86transformer--\u4e00\u79cd\u65b0\u7684model architecture \u8865\u5145\uff1a - \u300aattention is all you need\u300b\u89e3\u8bfb - huggingface / transformers - models / official / transformer /","title":"attention"},{"location":"AI-papers/Reading-record/#nlp","text":"\u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u8bc4\u4ef7 1810 201810 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding Google Brain \u8865\u51fa - TensorFlow code and pre-trained models for BERT","title":"NLP"},{"location":"AI-papers/Reading-record/#distant#supervision#for#relation#extraction","text":"\u6807\u53f7 \u5e74\u4efd \u8bba\u6587 \u4f18\u70b9 \u5f31\u70b9 0911 200911 Distant supervision for relation extraction without labeled data \u5f88\u591a\uff0c\u6bd4\u5982\uff1a\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3001\u6210\u672c\u4f4e\u3001\u5927\u5bb9\u91cf\u6570\u636e\u96c6\u3001\u80fd\u591f\u89c4\u907f\u4e00\u4e9b\u56f0\u6270\u76d1\u7763\u5b66\u4e60\u7684\u95ee\u9898 1. \u566a\u58f0\u5927\uff0c\u6027\u80fd\u4e0d\u591f\u5f3a 2. \u9700\u8981\u4eba\u4e3a\u8bbe\u8ba1\u7279\u5f81 ... ... ... ... 15 2015 Distant supervisionfor relation extraction via piecewise convolutional neural networks. 1. \u4f7f\u7528**PCNNs**s\u795e\u7ecf\u7f51\u7edc\u9009\u62e9\u6700\u5927\u6982\u7387\u4e3avalid instance\u7684\u53e5\u5b50\u6765\u4ece\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u4f20\u7edf\u7684NLP\u5de5\u5177 1. \u6bcf\u4e2abag\u4e2d\u4ec5\u4ec5\u9009\u62e9\u4e00\u4e2a\u53e5\u5b50\uff08\u6700\u5927\u6982\u7387\uff09\u4f5c\u4e3avalid instance\uff0c\u5bfc\u81f4\u5b83\u672a\u80fd\u5145\u5206\u5229\u7528bag\u4e2d\u7684\u4fe1\u606f 17 2017 Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions 1. bag\u4e2d\u4f1a\u8003\u8651\u591a\u4e2a valid Instance 2. \u7531\u795e\u7ecf\u7f51\u7edc\u6765\u63d0\u53d6\u7279\u5f81 3. \u63d0\u51fa**entity descriptions**\u601d\u8def 1904 201904 Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions 1. \u9664\u4e86intra-bag\uff08\u5305\u5185\uff09 attentions\uff0c\u8fd8\u6dfb\u52a0\u4e86inter-bag\uff08\u5305\u95f4\uff09 attentions","title":"distant supervision for relation extraction"},{"location":"AI-papers/Reading-record/#memory#network","text":"\u7f16\u53f7 \u65f6\u95f4 \u8bba\u6587 \u4f5c\u8005 \u8bc4\u4ef7 1410 201410 Memory Networks Jason Weston , Sumit Chopra , Antoine Bordes \u9996\u6b21\u63d0\u51famemory model 1503 201503 End-To-End Memory Networks Sainbayar Sukhbaatar , Arthur Szlam , Jason Weston , Rob Fergus","title":"memory network"},{"location":"Application/Computable-knowledge/Knowledge-representation-and-reasoning/","text":"Knowledge representation and reasoning","title":"Introduction"},{"location":"Application/Computable-knowledge/Knowledge-representation-and-reasoning/#knowledge#representation#and#reasoning","text":"","title":"Knowledge representation and reasoning"},{"location":"Application/NLP/","text":"\u5173\u4e8e\u672c\u7ae0 NLP\uff08natural language processing\uff09 \u987e\u540d\u601d\u4e49\uff0c\u6240\u7814\u7a76\u7684\u662f\u548c natural language \u76f8\u5173\u7684\u6280\u672f\u3002 \u5173\u4e8e formal language \u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u5de5\u7a0b automata-and-formal-language \uff0c\u4e24\u4e2a\u5de5\u7a0b\u90fd\u548clanguage\u76f8\u5173\uff0c\u6545\u5176\u4e2d\u7684\u5185\u5bb9\u662f\u5bc6\u5207\u76f8\u5173\u7684\u3002 \u4eba\u7c7b\u6240\u9762\u4e34\u7684\u95ee\u9898\u5206\u4e3a\u4e86\u4e24\u7c7b\uff1a problems that can be described by a list of formal, mathematical rules problems that can not be described by a list of formal, mathematical rules Language\u5176\u5b9e\u6709\u5bf9\u5e94\u7684\u4e24\u7c7b\uff1a formal language\uff0c\u6bd4\u5982programming language natural language \u663e\u7136\uff0c\u5bf9\u4e8eformal language\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7a0b\u5e8f\u5c31\u80fd\u591f\u641e\u5b9a\uff0c\u4f46\u662f\u5bf9\u4e8enatural language\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7a0b\u5e8f\u662f\u65e0\u6cd5\u89e3\u51b3\u7684\uff0c\u5f53\u4eca\u7684\u89e3\u51b3\u65b9\u6848\u5c31\u662f\u672c\u4e66\u6240\u63cf\u8ff0\u7684machine learning\uff0c\u672c\u7ae0\u6240\u8981\u63a2\u7d22\u7684\u6b63\u662f\u8fd9\u4e2a\u4e3b\u9898\uff0c\u5373\u5982\u4f55\u4f7f\u7528machine learning\u6765\u5b9e\u73b0NLP\u3002 \u5173\u4e8eNLP\uff0c\u53c2\u89c1\uff1a \u7ef4\u57fa\u767e\u79d1 Natural language processing","title":"Introduction"},{"location":"Application/NLP/#_1","text":"NLP\uff08natural language processing\uff09 \u987e\u540d\u601d\u4e49\uff0c\u6240\u7814\u7a76\u7684\u662f\u548c natural language \u76f8\u5173\u7684\u6280\u672f\u3002 \u5173\u4e8e formal language \u7684\u5185\u5bb9\uff0c\u53c2\u89c1\u5de5\u7a0b automata-and-formal-language \uff0c\u4e24\u4e2a\u5de5\u7a0b\u90fd\u548clanguage\u76f8\u5173\uff0c\u6545\u5176\u4e2d\u7684\u5185\u5bb9\u662f\u5bc6\u5207\u76f8\u5173\u7684\u3002 \u4eba\u7c7b\u6240\u9762\u4e34\u7684\u95ee\u9898\u5206\u4e3a\u4e86\u4e24\u7c7b\uff1a problems that can be described by a list of formal, mathematical rules problems that can not be described by a list of formal, mathematical rules Language\u5176\u5b9e\u6709\u5bf9\u5e94\u7684\u4e24\u7c7b\uff1a formal language\uff0c\u6bd4\u5982programming language natural language \u663e\u7136\uff0c\u5bf9\u4e8eformal language\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7a0b\u5e8f\u5c31\u80fd\u591f\u641e\u5b9a\uff0c\u4f46\u662f\u5bf9\u4e8enatural language\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7a0b\u5e8f\u662f\u65e0\u6cd5\u89e3\u51b3\u7684\uff0c\u5f53\u4eca\u7684\u89e3\u51b3\u65b9\u6848\u5c31\u662f\u672c\u4e66\u6240\u63cf\u8ff0\u7684machine learning\uff0c\u672c\u7ae0\u6240\u8981\u63a2\u7d22\u7684\u6b63\u662f\u8fd9\u4e2a\u4e3b\u9898\uff0c\u5373\u5982\u4f55\u4f7f\u7528machine learning\u6765\u5b9e\u73b0NLP\u3002 \u5173\u4e8eNLP\uff0c\u53c2\u89c1\uff1a \u7ef4\u57fa\u767e\u79d1 Natural language processing","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/NLP/","text":"NLP \u7ef4\u57fa\u767e\u79d1 Natural language processing Natural language processing ( NLP ) is a subfield of linguistics , computer science , information engineering , and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. NOTE: \u7efc\u5408\u5b66\u79d1 History Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules . Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law ) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar ), whose theoretical underpinnings\uff08\u57fa\u7840\uff09 discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[ 3] Some of the earliest-used machine learning algorithms, such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules. However, part-of-speech tagging \uff08\u8bcd\u6027\u6807\u6ce8\uff09 introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models. Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks. NOTE: \u4e0a\u8ff0rule\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1fgrammar rule\uff1f\u5e94\u8be5\u5c31\u662fgrammar rule\uff0c\u6bd4\u5982\u5728python\u7684Language Reference \u00b6 \u4e2d\u4e00\u822c\u4f1a\u4f7f\u7528 BNF \u6765\u63cf\u8ff0\u8fd9\u79cd\u8bed\u8a00\u7684grammar\uff1b NOTE: \u4e54\u59c6\u65af\u57fa\u8bed\u8a00\u5b66\u7684\u7406\u8bba\u57fa\u7840\u963b\u788d\u4e86 corpus linguistics \uff08\u8bed\u6599\u5e93\u8bed\u8a00\u5b66\uff09\uff0c corpus linguistics \u662fmachine-learning\u6784\u6210\u8bed\u8a00\u5904\u7406\u65b9\u6cd5\u7684\u57fa\u7840\u3002 Rule-based vs. statistical NLP In the early days, many language-processing systems were designed by hand-coding a set of rules:[ 9] [ 10] such as by writing grammars or devising heuristic rules for stemming . Since the so-called \"statistical revolution\"[ 11] [ 12] in the late 1980s and mid 1990s, much natural language processing research has relied heavily on machine learning . The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora of typical real-world examples (a corpus (plural, \"corpora\") is a set of documents, possibly with human or computer annotations). NOTE: \u673a\u5668\u5b66\u4e60\u8303\u5f0f\u8981\u6c42\u4f7f\u7528\u7edf\u8ba1\u63a8\u7406\uff0c\u901a\u8fc7\u5bf9\u5178\u578b\u7684\u771f\u5b9e\u4e16\u754c\u793a\u4f8b\u7684\u5927\u578b\u8bed\u6599\u5e93(\u8bed\u6599\u5e93(\u590d\u6570\uff0c\u201c\u8bed\u6599\u5e93\u201d)\u662f\u4e00\u7ec4\u6587\u6863\uff0c\u53ef\u80fd\u5e26\u6709\u4eba\u5de5\u6216\u8ba1\u7b97\u673a\u6ce8\u91ca)\u7684\u5206\u6790\u6765\u81ea\u52a8\u5b66\u4e60\u8fd9\u4e9b\u89c4\u5219\u3002 Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Some of the earliest-used algorithms, such as decision trees , produced systems of hard if-then rules similar to the systems of handwritten rules that were then common. Increasingly, however, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system. Systems based on machine-learning algorithms have many advantages over handproduced rules: The learning procedures used during machine learning automatically focus on the most common cases, whereas when writing rules by hand it is often not at all obvious where the effort should be directed. Automatic learning procedures can make use of statistical-inference algorithms to produce models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted). Generally, handling such input gracefully with handwritten rules, or, more generally, creating systems of handwritten rules that make soft decisions, is extremely difficult, error-prone and time-consuming. Systems based on automatically learning the rules can be made more accurate simply by supplying more input data. However, systems based on handwritten rules can only be made more accurate by increasing the complexity of the rules, which is a much more difficult task. In particular, there is a limit to the complexity of systems based on handcrafted rules, beyond which the systems become more and more unmanageable. However, creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked, generally without significant increases in the complexity of the annotation process. Major evaluations and tasks NOTE: \u5728 NLP\\NLP-progress \u7ae0\u8282\u5bf9\u8fd9\u90e8\u5206\u5185\u5bb9\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002 \u7ef4\u57fa\u767e\u79d1 Corpus linguistics NOTE: \u4f7f\u7528machine learning\u6280\u672f\u6765\u89e3\u51b3NLP\u95ee\u9898\uff0c\u5c31\u662f\u5c5e\u4e8e\u8fd9\u4e2a\u6d41\u6d3e Corpus linguistics is the study of language as expressed in corpora (samples) of \"real world\" text. Corpus linguistics proposes that reliable language analysis is more feasible with corpora collected in the field in its natural context (\"realia\"), and with minimal experimental-interference. The field of corpus linguistics features divergent views about the value of corpus annotation. These views range from John McHardy Sinclair , who advocates minimal annotation so texts speak for themselves,[ 1] to the Survey of English Usage team ( University College, London ), who advocate annotation as allowing greater linguistic understanding through rigorous recording.[ 2] The text-corpus method is a digestive approach that derives\uff08\u5bfc\u51fa\uff09 a set of abstract rules that govern a natural language from texts in that language, and explores how that language relates to other languages. Originally derived manually, corpora now are automatically derived from source texts. In addition to linguistics research, assembled corpora have been used to compile dictionaries (starting with The American Heritage Dictionary of the English Language in 1969) and grammar guides, such as A Comprehensive Grammar of the English Language , published in 1985. \u7ef4\u57fa\u767e\u79d1 Language model","title":"NLP"},{"location":"Application/NLP/NLP/#nlp","text":"","title":"NLP"},{"location":"Application/NLP/NLP/#natural#language#processing","text":"Natural language processing ( NLP ) is a subfield of linguistics , computer science , information engineering , and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. NOTE: \u7efc\u5408\u5b66\u79d1","title":"\u7ef4\u57fa\u767e\u79d1Natural language processing"},{"location":"Application/NLP/NLP/#history","text":"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules . Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law ) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar ), whose theoretical underpinnings\uff08\u57fa\u7840\uff09 discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[ 3] Some of the earliest-used machine learning algorithms, such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules. However, part-of-speech tagging \uff08\u8bcd\u6027\u6807\u6ce8\uff09 introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models. Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks. NOTE: \u4e0a\u8ff0rule\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1fgrammar rule\uff1f\u5e94\u8be5\u5c31\u662fgrammar rule\uff0c\u6bd4\u5982\u5728python\u7684Language Reference \u00b6 \u4e2d\u4e00\u822c\u4f1a\u4f7f\u7528 BNF \u6765\u63cf\u8ff0\u8fd9\u79cd\u8bed\u8a00\u7684grammar\uff1b NOTE: \u4e54\u59c6\u65af\u57fa\u8bed\u8a00\u5b66\u7684\u7406\u8bba\u57fa\u7840\u963b\u788d\u4e86 corpus linguistics \uff08\u8bed\u6599\u5e93\u8bed\u8a00\u5b66\uff09\uff0c corpus linguistics \u662fmachine-learning\u6784\u6210\u8bed\u8a00\u5904\u7406\u65b9\u6cd5\u7684\u57fa\u7840\u3002","title":"History"},{"location":"Application/NLP/NLP/#rule-based#vs#statistical#nlp","text":"In the early days, many language-processing systems were designed by hand-coding a set of rules:[ 9] [ 10] such as by writing grammars or devising heuristic rules for stemming . Since the so-called \"statistical revolution\"[ 11] [ 12] in the late 1980s and mid 1990s, much natural language processing research has relied heavily on machine learning . The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora of typical real-world examples (a corpus (plural, \"corpora\") is a set of documents, possibly with human or computer annotations). NOTE: \u673a\u5668\u5b66\u4e60\u8303\u5f0f\u8981\u6c42\u4f7f\u7528\u7edf\u8ba1\u63a8\u7406\uff0c\u901a\u8fc7\u5bf9\u5178\u578b\u7684\u771f\u5b9e\u4e16\u754c\u793a\u4f8b\u7684\u5927\u578b\u8bed\u6599\u5e93(\u8bed\u6599\u5e93(\u590d\u6570\uff0c\u201c\u8bed\u6599\u5e93\u201d)\u662f\u4e00\u7ec4\u6587\u6863\uff0c\u53ef\u80fd\u5e26\u6709\u4eba\u5de5\u6216\u8ba1\u7b97\u673a\u6ce8\u91ca)\u7684\u5206\u6790\u6765\u81ea\u52a8\u5b66\u4e60\u8fd9\u4e9b\u89c4\u5219\u3002 Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Some of the earliest-used algorithms, such as decision trees , produced systems of hard if-then rules similar to the systems of handwritten rules that were then common. Increasingly, however, research has focused on statistical models , which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system. Systems based on machine-learning algorithms have many advantages over handproduced rules: The learning procedures used during machine learning automatically focus on the most common cases, whereas when writing rules by hand it is often not at all obvious where the effort should be directed. Automatic learning procedures can make use of statistical-inference algorithms to produce models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted). Generally, handling such input gracefully with handwritten rules, or, more generally, creating systems of handwritten rules that make soft decisions, is extremely difficult, error-prone and time-consuming. Systems based on automatically learning the rules can be made more accurate simply by supplying more input data. However, systems based on handwritten rules can only be made more accurate by increasing the complexity of the rules, which is a much more difficult task. In particular, there is a limit to the complexity of systems based on handcrafted rules, beyond which the systems become more and more unmanageable. However, creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked, generally without significant increases in the complexity of the annotation process.","title":"Rule-based vs. statistical NLP"},{"location":"Application/NLP/NLP/#major#evaluations#and#tasks","text":"NOTE: \u5728 NLP\\NLP-progress \u7ae0\u8282\u5bf9\u8fd9\u90e8\u5206\u5185\u5bb9\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002","title":"Major evaluations and tasks"},{"location":"Application/NLP/NLP/#corpus#linguistics","text":"NOTE: \u4f7f\u7528machine learning\u6280\u672f\u6765\u89e3\u51b3NLP\u95ee\u9898\uff0c\u5c31\u662f\u5c5e\u4e8e\u8fd9\u4e2a\u6d41\u6d3e Corpus linguistics is the study of language as expressed in corpora (samples) of \"real world\" text. Corpus linguistics proposes that reliable language analysis is more feasible with corpora collected in the field in its natural context (\"realia\"), and with minimal experimental-interference. The field of corpus linguistics features divergent views about the value of corpus annotation. These views range from John McHardy Sinclair , who advocates minimal annotation so texts speak for themselves,[ 1] to the Survey of English Usage team ( University College, London ), who advocate annotation as allowing greater linguistic understanding through rigorous recording.[ 2] The text-corpus method is a digestive approach that derives\uff08\u5bfc\u51fa\uff09 a set of abstract rules that govern a natural language from texts in that language, and explores how that language relates to other languages. Originally derived manually, corpora now are automatically derived from source texts. In addition to linguistics research, assembled corpora have been used to compile dictionaries (starting with The American Heritage Dictionary of the English Language in 1969) and grammar guides, such as A Comprehensive Grammar of the English Language , published in 1985.","title":"\u7ef4\u57fa\u767e\u79d1Corpus linguistics"},{"location":"Application/NLP/NLP/#language#model","text":"","title":"\u7ef4\u57fa\u767e\u79d1Language model"},{"location":"Application/NLP/WordNet/","text":"WordNet","title":"WordNet"},{"location":"Application/NLP/WordNet/#wordnet","text":"","title":"WordNet"},{"location":"Application/NLP/Book-Natural-Language-Processing-with-Python/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u8bb0\u5f55\u5728\u9605\u8bfb Natural Language Processing with Python \u7684\u7b14\u8bb0\u3002 Natural Language Processing with Python \u662f\u4e00\u672c\u5f00\u6e90\u4e66\u7c4d\uff0c\u539f\u4e66\u5185\u5bb9\u6bd4\u8f83\u901a\u4fd7\u6613\u61c2\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u5165\u95e8NLP\u7684\u8bfb\u7269\u3002 \u5728\u9605\u8bfb\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5e94\u8be5\u9009\u62e9\u6027\u5730\u53bb\u9605\u8bfb\uff0c\u5bf9\u4e8e\u719f\u6089python\u7684\u4eba\uff0c\u53ef\u4ee5\u76f4\u63a5pass\u6389\u539f\u4e66\u4e2d\u5173\u4e8epython\u7684\u5185\u5bb9\u3002\u539f\u4e66\u4ecechapter 5\u5f00\u59cb\u8bb2\u8ff0NLP\u76f8\u5173\u5185\u5bb9\u3002 \u6211\u89c9\u5f97\u8fd9\u672c\u4e66\u7684\u6700\u5927\u4ef7\u503c\u5728\u4e8e\uff1a \u7ed3\u5408\u5177\u4f53\u4f8b\u5b50\u8bb2\u89e3\u4e86\u8bed\u8a00\u5b66\u4e2d\u7684\u7684\u4e00\u4e9b\u57fa\u7840\u6982\u5ff5 \u7ed9\u51fa\u4e86\u89e3\u51b3\u4e00\u4e9bNLP task\u7684Pipeline Architecture\uff0c\u8bfb\u8005\u53ef\u4ee5\u53c2\u8003\u8fdb\u884c\u5b9e\u8df5\uff0c\u4e0b\u9762\u5bf9\u6b64\u8fdb\u884c\u4e86\u603b\u7ed3\u3002 \u8bfb\u8005\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u867d\u7136\u4e66\u4e2d\u7ed9\u51fa\u4e86\u4e00\u4e9bNLP task\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u4f46\u662f\u968f\u7740\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u4e0d\u65ad\u6d8c\u73b0\u51fa\u4e86\u89e3\u51b3\u8fd9\u4e9b\u5df2\u77e5\u7684NLP task\u7684\u65b0\u6280\u672f\uff0c\u6240\u4ee5\u4e0d\u80fd\u591f\u62d8\u6ce5\u4e8e\u4e66\u4e2d\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u800c\u5e94\u8be5\u5b66\u4e60\u66f4\u52a0\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u5f0f\u3002 \u5185\u5bb9\u6982\u8981 \u53ef\u4ee5\u76f4\u63a5\u4ecechapter 5 Categorizing and Tagging Words \u5f00\u59cb\u9605\u8bfb\uff1bchapter 6 Learning to Classify Text \u8bb2\u6587\u672c\u5206\u7c7b\uff1bchapter 7 Extracting Information from Text \u8bb2\u5982\u4f55\u4ece\u6587\u672c\u4e2d\u62bd\u53d6\u4fe1\u606f\uff0c\u5176\u4e2d\u7ed9\u51fa\u7684 Information Extraction Architecture \u662f\u6bd4\u8f83\u5177\u6709\u542f\u53d1\u610f\u4e49\u7684\uff1bchapter 8 Analyzing Sentence Structure \u5176\u5b9e\u8bb2\u8ff0\u7684\u662fformal language\u4e2dparsing\u7684\u65b9\u6cd5\u3002 Pipeline Architecture Simple Pipeline Architecture for a Spoken Dialogue System \u5728 chapter 1. Language Processing and Python \u76845.5 Spoken Dialog Systems\u4e2d\u7ed9\u51fa\u4e86\u201c Simple Pipeline Architecture for a Spoken Dialogue System \u201d Figure 5.1 : Simple Pipeline Architecture for a Spoken Dialogue System: Spoken input (top left) is analyzed, words are recognized, sentences are parsed and interpreted in context, application-specific actions take place (top right); a response is planned, realized as a syntactic structure, then to suitably inflected words, and finally to spoken output; different types of linguistic knowledge inform each stage of the process.","title":"Introduction"},{"location":"Application/NLP/Book-Natural-Language-Processing-with-Python/#_1","text":"\u672c\u7ae0\u8bb0\u5f55\u5728\u9605\u8bfb Natural Language Processing with Python \u7684\u7b14\u8bb0\u3002 Natural Language Processing with Python \u662f\u4e00\u672c\u5f00\u6e90\u4e66\u7c4d\uff0c\u539f\u4e66\u5185\u5bb9\u6bd4\u8f83\u901a\u4fd7\u6613\u61c2\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u5165\u95e8NLP\u7684\u8bfb\u7269\u3002 \u5728\u9605\u8bfb\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5e94\u8be5\u9009\u62e9\u6027\u5730\u53bb\u9605\u8bfb\uff0c\u5bf9\u4e8e\u719f\u6089python\u7684\u4eba\uff0c\u53ef\u4ee5\u76f4\u63a5pass\u6389\u539f\u4e66\u4e2d\u5173\u4e8epython\u7684\u5185\u5bb9\u3002\u539f\u4e66\u4ecechapter 5\u5f00\u59cb\u8bb2\u8ff0NLP\u76f8\u5173\u5185\u5bb9\u3002 \u6211\u89c9\u5f97\u8fd9\u672c\u4e66\u7684\u6700\u5927\u4ef7\u503c\u5728\u4e8e\uff1a \u7ed3\u5408\u5177\u4f53\u4f8b\u5b50\u8bb2\u89e3\u4e86\u8bed\u8a00\u5b66\u4e2d\u7684\u7684\u4e00\u4e9b\u57fa\u7840\u6982\u5ff5 \u7ed9\u51fa\u4e86\u89e3\u51b3\u4e00\u4e9bNLP task\u7684Pipeline Architecture\uff0c\u8bfb\u8005\u53ef\u4ee5\u53c2\u8003\u8fdb\u884c\u5b9e\u8df5\uff0c\u4e0b\u9762\u5bf9\u6b64\u8fdb\u884c\u4e86\u603b\u7ed3\u3002 \u8bfb\u8005\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u867d\u7136\u4e66\u4e2d\u7ed9\u51fa\u4e86\u4e00\u4e9bNLP task\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u4f46\u662f\u968f\u7740\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u4e0d\u65ad\u6d8c\u73b0\u51fa\u4e86\u89e3\u51b3\u8fd9\u4e9b\u5df2\u77e5\u7684NLP task\u7684\u65b0\u6280\u672f\uff0c\u6240\u4ee5\u4e0d\u80fd\u591f\u62d8\u6ce5\u4e8e\u4e66\u4e2d\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u800c\u5e94\u8be5\u5b66\u4e60\u66f4\u52a0\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u5f0f\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/Book-Natural-Language-Processing-with-Python/#_2","text":"\u53ef\u4ee5\u76f4\u63a5\u4ecechapter 5 Categorizing and Tagging Words \u5f00\u59cb\u9605\u8bfb\uff1bchapter 6 Learning to Classify Text \u8bb2\u6587\u672c\u5206\u7c7b\uff1bchapter 7 Extracting Information from Text \u8bb2\u5982\u4f55\u4ece\u6587\u672c\u4e2d\u62bd\u53d6\u4fe1\u606f\uff0c\u5176\u4e2d\u7ed9\u51fa\u7684 Information Extraction Architecture \u662f\u6bd4\u8f83\u5177\u6709\u542f\u53d1\u610f\u4e49\u7684\uff1bchapter 8 Analyzing Sentence Structure \u5176\u5b9e\u8bb2\u8ff0\u7684\u662fformal language\u4e2dparsing\u7684\u65b9\u6cd5\u3002","title":"\u5185\u5bb9\u6982\u8981"},{"location":"Application/NLP/Book-Natural-Language-Processing-with-Python/#pipeline#architecture","text":"","title":"Pipeline Architecture"},{"location":"Application/NLP/Book-Natural-Language-Processing-with-Python/#simple#pipeline#architecture#for#a#spoken#dialogue#system","text":"\u5728 chapter 1. Language Processing and Python \u76845.5 Spoken Dialog Systems\u4e2d\u7ed9\u51fa\u4e86\u201c Simple Pipeline Architecture for a Spoken Dialogue System \u201d Figure 5.1 : Simple Pipeline Architecture for a Spoken Dialogue System: Spoken input (top left) is analyzed, words are recognized, sentences are parsed and interpreted in context, application-specific actions take place (top right); a response is planned, realized as a syntactic structure, then to suitably inflected words, and finally to spoken output; different types of linguistic knowledge inform each stage of the process.","title":"Simple Pipeline Architecture for a Spoken Dialogue System"},{"location":"Application/NLP/Lib/NLTK/","text":"\u5173\u4e8e\u672c\u7ae0 Natural Language Toolkit","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/Lib/NLTK/#_1","text":"Natural Language Toolkit","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/Lib/NLTK/docs/","text":"\u8fd9\u662f\u6211\u9605\u8bfb Natural Language Processing with Python \u7684\u7b14\u8bb0\u3002 \u6211\u662f\u5728\u6709\u4e00\u5b9a\u7684NLP\u77e5\u8bc6\u7684\u57fa\u7840\u540e\u6765\u9605\u8bfb\u8fd9\u672c\u4e66\u7684\uff0c\u8bfb\u540e\u7684\u6536\u83b7\u6709\uff1a \u8fd9\u4e2a\u4e66\u4e3a\u8bfb\u8005\u642d\u5efa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684NLP\u7cfb\u7edf\u7684\u6784\u6210\u90e8\u4ef6\uff0c\u5e76\u5206\u7ae0\u8282\u8fdb\u884c\u63cf\u8ff0\u3002\u6211\u89c9\u5f97\u4f5c\u8005\u7684\u8fd9\u79cd\u5b89\u6392\u8fd9\u662f\u975e\u5e38\u597d\u7684\uff0c\u8bfb\u5b8c\u540e\uff0c\u8bfb\u8005\u80fd\u591f\u6e05\u695a\u5730\u77e5\u9053\u9700\u8981\u505a\u54ea\u4e9b\u4e8b\u60c5\uff1b \u81f3\u4e8e\u6bcf\u4e00\u90e8\u4ef6\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u4e66\u4e2d\u5e76\u6ca1\u6709\u7ed9\u51fa\u5177\u4f53\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u8fd9\u662f\u53ef\u60f3\u800c\u77e5\u7684\u3002\u56e0\u4e3a\u968f\u7740\u6280\u672f\u7684\u6f14\u8fdb\uff0c\u4e0d\u65ad\u5730\u6709\u5168\u65b0\u7684\u6280\u672f\u51fa\u73b0\u3002\u4f46\u662f\u65e0\u8bba\u6280\u672f\u5982\u4f55\u66f4\u8fed\uff0c\u5b83\u6240\u8981\u5b9e\u73b0\u7684\u76ee\u6807\uff0c\u4f5c\u8005\u5df2\u7ecf\u544a\u8bc9\u4e86\u6211\u4eec\u3002","title":"Index"},{"location":"Application/NLP/Lib/NLTK/docs/10-Analyzing-the-Meaning-of-Sentences/10-Analyzing-the-Meaning-of-Sentences/","text":"10. Analyzing the Meaning of Sentences 10. Analyzing the Meaning of Sentences We have seen how useful it is to harness the power of a computer to process text on a large scale. However, now that we have the machinery of parsers and feature based grammars, can we do anything similarly useful by analyzing the meaning of sentences? The goal of this chapter is to answer the following questions: How can we represent natural language meaning so that a computer can process these representations ? How can we associate meaning representations with an unlimited set of sentences? How can we use programs that connect the meaning representations of sentences to stores of knowledge? Along the way we will learn some formal techniques in the field of logical semantics, and see how these can be used for interrogating databases that store facts about the world.","title":"10 Analyzing the Meaning of Sentences"},{"location":"Application/NLP/Lib/NLTK/docs/10-Analyzing-the-Meaning-of-Sentences/10-Analyzing-the-Meaning-of-Sentences/#10#analyzing#the#meaning#of#sentences","text":"We have seen how useful it is to harness the power of a computer to process text on a large scale. However, now that we have the machinery of parsers and feature based grammars, can we do anything similarly useful by analyzing the meaning of sentences? The goal of this chapter is to answer the following questions: How can we represent natural language meaning so that a computer can process these representations ? How can we associate meaning representations with an unlimited set of sentences? How can we use programs that connect the meaning representations of sentences to stores of knowledge? Along the way we will learn some formal techniques in the field of logical semantics, and see how these can be used for interrogating databases that store facts about the world.","title":"10. Analyzing the Meaning of Sentences"},{"location":"Application/NLP/Lib/NLTK/docs/5-Categorizing-and-Tagging-Words/5Categorizing-and-Tagging-Words/","text":"5. Categorizing and Tagging Words Back in elementary school you learnt the difference between nouns, verbs, adjectives, and adverbs. These \"word classes\" are not just the idle invention of grammarians, but are useful categories for many language processing tasks. As we will see, they arise from simple analysis of the distribution of words in text. The goal of this chapter is to answer the following questions: What are lexical categories and how are they used in natural language processing? What is a good Python data structure for storing words and their categories? How can we automatically tag each word of a text with its word class? Along the way, we'll cover some fundamental techniques in NLP, including sequence labeling , n-gram models, backoff, and evaluation. These techniques are useful in many areas, and tagging gives us a simple context in which to present them. We will also see how tagging is the second step in the typical NLP pipeline, following tokenization . NOTE: NLP pipeline: tokenization->tagging The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging , POS-tagging , or simply tagging . Parts of speech are also known as word classes or lexical categories . The collection of tags used for a particular task is known as a tagset . Our emphasis in this chapter is on exploiting tags, and tagging text automatically. NOTE: hierarchy: Parts of speech word classes 1 Using a Tagger A part-of-speech tagger, or POS-tagger , processes a sequence of words, and attaches a part of speech tag to each word (don't forget to import nltk ): >>> text = word_tokenize ( \"And now for something completely different\" ) >>> nltk . pos_tag ( text ) [( 'And' , 'CC' ), ( 'now' , 'RB' ), ( 'for' , 'IN' ), ( 'something' , 'NN' ), ( 'completely' , 'RB' ), ( 'different' , 'JJ' )] Here we see that and is CC , a coordinating conjunction; now and completely are RB , or adverbs; for is IN , a preposition; something is NN , a noun; and different is JJ , an adjective. Note NLTK provides documentation for each tag, which can be queried using the tag, e.g. nltk.help.upenn_tagset('RB') , or a regular expression, e.g. nltk.help.upenn_tagset('NN.*') . Some corpora have README files with tagset documentation, see nltk.corpus.???.readme() , substituting in the name of the corpus. Let's look at another example, this time including some homonyms: >>> text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\") >>> nltk.pos_tag(text) [('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')] Notice that refuse and permit both appear as a present tense verb ( VBP ) and a noun ( NN ). E.g. refUSE is a verb meaning \"deny,\" while REFuse is a noun meaning \"trash\" (i.e. they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)","title":"5. Categorizing and Tagging Words"},{"location":"Application/NLP/Lib/NLTK/docs/5-Categorizing-and-Tagging-Words/5Categorizing-and-Tagging-Words/#5#categorizing#and#tagging#words","text":"Back in elementary school you learnt the difference between nouns, verbs, adjectives, and adverbs. These \"word classes\" are not just the idle invention of grammarians, but are useful categories for many language processing tasks. As we will see, they arise from simple analysis of the distribution of words in text. The goal of this chapter is to answer the following questions: What are lexical categories and how are they used in natural language processing? What is a good Python data structure for storing words and their categories? How can we automatically tag each word of a text with its word class? Along the way, we'll cover some fundamental techniques in NLP, including sequence labeling , n-gram models, backoff, and evaluation. These techniques are useful in many areas, and tagging gives us a simple context in which to present them. We will also see how tagging is the second step in the typical NLP pipeline, following tokenization . NOTE: NLP pipeline: tokenization->tagging The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging , POS-tagging , or simply tagging . Parts of speech are also known as word classes or lexical categories . The collection of tags used for a particular task is known as a tagset . Our emphasis in this chapter is on exploiting tags, and tagging text automatically. NOTE: hierarchy: Parts of speech word classes","title":"5. Categorizing and Tagging Words"},{"location":"Application/NLP/Lib/NLTK/docs/5-Categorizing-and-Tagging-Words/5Categorizing-and-Tagging-Words/#1#using#a#tagger","text":"A part-of-speech tagger, or POS-tagger , processes a sequence of words, and attaches a part of speech tag to each word (don't forget to import nltk ): >>> text = word_tokenize ( \"And now for something completely different\" ) >>> nltk . pos_tag ( text ) [( 'And' , 'CC' ), ( 'now' , 'RB' ), ( 'for' , 'IN' ), ( 'something' , 'NN' ), ( 'completely' , 'RB' ), ( 'different' , 'JJ' )] Here we see that and is CC , a coordinating conjunction; now and completely are RB , or adverbs; for is IN , a preposition; something is NN , a noun; and different is JJ , an adjective. Note NLTK provides documentation for each tag, which can be queried using the tag, e.g. nltk.help.upenn_tagset('RB') , or a regular expression, e.g. nltk.help.upenn_tagset('NN.*') . Some corpora have README files with tagset documentation, see nltk.corpus.???.readme() , substituting in the name of the corpus. Let's look at another example, this time including some homonyms: >>> text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\") >>> nltk.pos_tag(text) [('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')] Notice that refuse and permit both appear as a present tense verb ( VBP ) and a noun ( NN ). E.g. refUSE is a verb meaning \"deny,\" while REFuse is a noun meaning \"trash\" (i.e. they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)","title":"1  Using a Tagger"},{"location":"Application/NLP/Lib/NLTK/docs/5-Categorizing-and-Tagging-Words/wikipedia-Part-of-speech-tagging/","text":"Part-of-speech tagging Part-of-speech tagging In corpus linguistics , part-of-speech tagging ( POS tagging or PoS tagging or POST ), also called grammatical tagging or word-categorydisambiguation , is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech ,[ 1] based on both its definition and its context\u2014i.e., its relationship with adjacent and related words in a phrase , sentence , or paragraph . A simplified form of this is commonly taught to school-age children, in the identification of words as nouns , verbs , adjectives , adverbs , etc. Once performed by hand, POS tagging is now done in the context of computational linguistics , using algorithms which associate discrete terms, as well as hidden parts of speech, in accordance with a set of descriptive tags. POS-tagging algorithms fall into two distinctive groups: rule-based and stochastic. E. Brill's tagger , one of the first and most widely used English POS-taggers, employs rule-based algorithms.","title":"wikipedia Part of speech tagging"},{"location":"Application/NLP/Lib/NLTK/docs/5-Categorizing-and-Tagging-Words/wikipedia-Part-of-speech-tagging/#part-of-speech#tagging","text":"In corpus linguistics , part-of-speech tagging ( POS tagging or PoS tagging or POST ), also called grammatical tagging or word-categorydisambiguation , is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech ,[ 1] based on both its definition and its context\u2014i.e., its relationship with adjacent and related words in a phrase , sentence , or paragraph . A simplified form of this is commonly taught to school-age children, in the identification of words as nouns , verbs , adjectives , adverbs , etc. Once performed by hand, POS tagging is now done in the context of computational linguistics , using algorithms which associate discrete terms, as well as hidden parts of speech, in accordance with a set of descriptive tags. POS-tagging algorithms fall into two distinctive groups: rule-based and stochastic. E. Brill's tagger , one of the first and most widely used English POS-taggers, employs rule-based algorithms.","title":"Part-of-speech tagging"},{"location":"Application/NLP/Lib/NLTK/docs/7-Extracting-Information-from-Text/7-Extracting-Information-from-Text/","text":"7. Extracting Information from Text 1 Information Extraction 1.1 Information Extraction Architecture 2 Chunking 2.1 Noun Phrase Chunking 2.2 Tag Patterns 7. Extracting Information from Text For any given question, it's likely that someone has written the answer down somewhere. The amount of natural language text that is available in electronic form is truly staggering, and is increasing every day. However, the complexity of natural language can make it very difficult to access the information in that text. The state of the art in NLP is still a long way from being able to build general-purpose representations of meaning from unrestricted text. If we instead focus our efforts on a limited set of questions or \"entity relations,\" such as \"where are different facilities located,\" or \"who is employed by what company,\" we can make significant progress. The goal of this chapter is to answer the following questions: How can we build a system that extracts structured data, such as tables, from unstructured text? What are some robust methods for identifying the entities and relationships described in a text? Which corpora are appropriate for this work, and how do we use them for training and evaluating our models? Along the way, we'll apply techniques from the last two chapters to the problems of chunking and named-entity recognition . 1 Information Extraction Information comes in many shapes and sizes. One important form is structured data , where there is a regular and predictable organization of entities and relationships . For example, we might be interested in the relation between companies and locations. Given a particular company, we would like to be able to identify the locations where it does business; conversely, given a location, we would like to discover which companies do business in that location. If our data is in tabular form, such as the example in 1.1 , then answering these queries is straightforward. Table 1.1 : Locations data OrgName LocationName Omnicom New York DDB Needham New York Kaplan Thaler Group New York BBDO South Atlanta Georgia-Pacific Atlanta Things are more tricky if we try to get similar information out of text. For example, consider the following snippet (from nltk.corpus.ieer, for fileid NYT19980315.0085). (1) The fourth Wells account moving to another agency is the packaged paper-products division of Georgia-Pacific Corp., which arrived at Wells only last fall. Like Hertz and the History Channel, it is also leaving for an Omnicom-owned agency, the BBDO South unit of BBDO Worldwide. BBDO South in Atlanta, which handles corporate advertising for Georgia-Pacific, will assume additional duties for brands like Angel Soft toilet tissue and Sparkle paper towels, said Ken Haldin, a spokesman for Georgia-Pacific in Atlanta. If you read through (1) , you will glean the information required to answer the example question. But how do we get a machine to understand enough about (1) to return the answers in 1.2 ? This is obviously a much harder task. Unlike 1.1 , (1) contains no structure that links organization names with location names. One approach to this problem involves building a very general representation of meaning ( 10. ). In this chapter we take a different approach, deciding in advance that we will only look for very specific kinds of information in text, such as the relation between organizations and locations. Rather than trying to use text like (1) to answer the question directly, we first convert the unstructured data of natural language sentences into the structured data of 1.1 . Then we reap the benefits of powerful query tools such as SQL. This method of getting meaning from text is called Information Extraction . Information Extraction has many applications, including business intelligence, resume harvesting, media analysis, sentiment detection, patent search, and email scanning. A particularly important area of current research involves the attempt to extract structured data out of electronically-available scientific literature, especially in the domain of biology and medicine. 1.1 Information Extraction Architecture 1.1 shows the architecture for a simple information extraction system . It begins by processing a document using several of the procedures discussed in 3 and 5. : first, the raw text of the document is split into sentences using a sentence segmenter , and each sentence is further subdivided into words using a tokenizer . Next, each sentence is tagged with part-of-speech tags , which will prove very helpful in the next step, named entity detection . In this step, we search for mentions of potentially interesting entities in each sentence. Finally, we use relation detection to search for likely relations between different entities in the text. Figure 1.1 : Simple Pipeline Architecture for an Information Extraction System. This system takes the raw text of a document as its input, and generates a list of (entity, relation, entity) tuples as its output. For example, given a document that indicates that the company Georgia-Pacific is located in Atlanta, it might generate the tuple ([ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']) . To perform the first three tasks, we can define a simple function that simply connects together NLTK's default sentence segmenter [1], word tokenizer [2], and part-of-speech tagger [3]: >>> def ie_preprocess ( document ): ... sentences = nltk . sent_tokenize ( document ) [ 1 ] ... sentences = [ nltk . word_tokenize ( sent ) for sent in sentences ] [ 2 ] ... sentences = [ nltk . pos_tag ( sent ) for sent in sentences ] [ 3 ] Next, in named entity detection , we segment and label the entities that might participate in interesting relations with one another. Typically, these will be definite noun phrases such as the knights who say \"ni\" , or proper names such as Monty Python . In some tasks it is useful to also consider indefinite nouns or noun chunks, such as every student or cats, and these do not necessarily refer to entities in the same way as definite NP s and proper names. Finally, in relation extraction, we search for specific patterns between pairs of entities that occur near one another in the text, and use those patterns to build tuples recording the relationships between the entities. 2 Chunking The basic technique we will use for entity detection is chunking , which segments and labels multi-token sequences as illustrated in 2.1 . The smaller boxes show the word-level tokenization and part-of-speech tagging, while the large boxes show higher-level chunking. Each of these larger boxes is called a chunk . Like tokenization, which omits whitespace, chunking usually selects a subset of the tokens. Also like tokenization, the pieces produced by a chunker do not overlap in the source text. Figure 2.1 : Segmentation and Labeling at both the Token and Chunk Levels In this section, we will explore chunking in some depth, beginning with the definition and representation of chunks. We will see regular expression and n-gram approaches to chunking, and will develop and evaluate chunkers using the CoNLL-2000 chunking corpus. We will then return in (5) and 6 to the tasks of named entity recognition and relation extraction. 2.1 Noun Phrase Chunking We will begin by considering the task of noun phrase chunking , or NP-chunking , where we search for chunks corresponding to individual noun phrases. For example, here is some Wall Street Journal text with NP -chunks marked using brackets: (2) [ The/DT market/NN ] for/IN [ system-management/NN software/NN ] for/IN [ Digital/NNP ] [ 's/POS hardware/NN ] is/VBZ fragmented/JJ enough/RB that/IN [ a/DT giant/NN ] such/JJ as/IN [ Computer/NNP Associates/NNPS ] should/MD do/VB well/RB there/RB ./. As we can see, NP -chunks are often smaller pieces than complete noun phrases. For example, the market for system-management software for Digital's hardware is a single noun phrase (containing two nested noun phrases), but it is captured in NP -chunks by the simpler chunk the market . One of the motivations for this difference is that NP -chunks are defined so as not to contain other NP -chunks. Consequently, any prepositional phrases or subordinate clauses that modify a nominal will not be included in the corresponding NP -chunk, since they almost certainly contain further noun phrases. One of the most useful sources of information for NP -chunking is part-of-speech tags . This is one of the motivations for performing part-of-speech tagging in our information extraction system. We demonstrate this approach using an example sentence that has been part-of-speech tagged in 2.2 . In order to create an NP -chunker, we will first define a chunk grammar , consisting of rules that indicate how sentences should be chunked. In this case, we will define a simple grammar with a single regular-expression rule. This rule says that an NP chunk should be formed whenever the chunker finds an optional determiner ( DT ) followed by any number of adjectives ( JJ ) and then a noun ( NN ). Using this grammar, we create a chunk parser, and test it on our example sentence. The result is a tree, which we can either print, or display graphically. sentence = [( \"the\" , \"DT\" ), ( \"little\" , \"JJ\" ), ( \"yellow\" , \"JJ\" ), ( \"dog\" , \"NN\" ), ( \"barked\" , \"VBD\" ), ( \"at\" , \"IN\" ), ( \"the\" , \"DT\" ), ( \"cat\" , \"NN\" )] grammar = \"NP: {<DT>?<JJ>*<NN>}\" cp = nltk . RegexpParser ( grammar ) result = cp . parse ( sentence ) print ( result ) ( S ( NP the / DT little / JJ yellow / JJ dog / NN ) barked / VBD at / IN ( NP the / DT cat / NN )) result . draw () Example 2.2 (code_chunkex.py) : Figure 2.2 : Example of a Simple Regular Expression Based NP Chunker. NOTE: In fact, this is a parse tree. 2.2 Tag Patterns The rules that make up a chunk grammar use tag patterns to describe sequences of tagged words. A tag pattern is a sequence of part-of-speech tags delimited using angle brackets, e.g. ?* . Tag patterns are similar to regular expression patterns ( 3.4 ). Now, consider the following noun phrases from the Wall Street Journal: another/DT sharp/JJ dive/NN trade/NN figures/NNS any/DT new/JJ policy/NN measures/NNS earlier/JJR stages/NNS Panamanian/JJ dictator/NN Manuel/NNP Noriega/NNP We can match these noun phrases using a slight refinement of the first tag pattern above, i.e. ?*+ . This will chunk any sequence of tokens beginning with an optional determiner, followed by zero or more adjectives of any type (including relative adjectives like earlier/JJR ), followed by one or more nouns of any type. However, it is easy to find many more complicated examples which this rule will not cover: his/PRP$ Mansion/NNP House/NNP speech/NN the/DT price/NN cutting/VBG 3/CD %/NN to/TO 4/CD %/NN more/JJR than/IN 10/CD %/NN the/DT fastest/JJS developing/VBG trends/NNS 's/POS skill/NN Note Your Turn: Try to come up with tag patterns to cover these cases. Test them using the graphical interface nltk.app.chunkparser() . Continue to refine your tag patterns with the help of the feedback given by this tool.","title":"7 Extracting Information from Text"},{"location":"Application/NLP/Lib/NLTK/docs/7-Extracting-Information-from-Text/7-Extracting-Information-from-Text/#7#extracting#information#from#text","text":"For any given question, it's likely that someone has written the answer down somewhere. The amount of natural language text that is available in electronic form is truly staggering, and is increasing every day. However, the complexity of natural language can make it very difficult to access the information in that text. The state of the art in NLP is still a long way from being able to build general-purpose representations of meaning from unrestricted text. If we instead focus our efforts on a limited set of questions or \"entity relations,\" such as \"where are different facilities located,\" or \"who is employed by what company,\" we can make significant progress. The goal of this chapter is to answer the following questions: How can we build a system that extracts structured data, such as tables, from unstructured text? What are some robust methods for identifying the entities and relationships described in a text? Which corpora are appropriate for this work, and how do we use them for training and evaluating our models? Along the way, we'll apply techniques from the last two chapters to the problems of chunking and named-entity recognition .","title":"7. Extracting Information from Text"},{"location":"Application/NLP/Lib/NLTK/docs/7-Extracting-Information-from-Text/7-Extracting-Information-from-Text/#1#information#extraction","text":"Information comes in many shapes and sizes. One important form is structured data , where there is a regular and predictable organization of entities and relationships . For example, we might be interested in the relation between companies and locations. Given a particular company, we would like to be able to identify the locations where it does business; conversely, given a location, we would like to discover which companies do business in that location. If our data is in tabular form, such as the example in 1.1 , then answering these queries is straightforward. Table 1.1 : Locations data OrgName LocationName Omnicom New York DDB Needham New York Kaplan Thaler Group New York BBDO South Atlanta Georgia-Pacific Atlanta Things are more tricky if we try to get similar information out of text. For example, consider the following snippet (from nltk.corpus.ieer, for fileid NYT19980315.0085). (1) The fourth Wells account moving to another agency is the packaged paper-products division of Georgia-Pacific Corp., which arrived at Wells only last fall. Like Hertz and the History Channel, it is also leaving for an Omnicom-owned agency, the BBDO South unit of BBDO Worldwide. BBDO South in Atlanta, which handles corporate advertising for Georgia-Pacific, will assume additional duties for brands like Angel Soft toilet tissue and Sparkle paper towels, said Ken Haldin, a spokesman for Georgia-Pacific in Atlanta. If you read through (1) , you will glean the information required to answer the example question. But how do we get a machine to understand enough about (1) to return the answers in 1.2 ? This is obviously a much harder task. Unlike 1.1 , (1) contains no structure that links organization names with location names. One approach to this problem involves building a very general representation of meaning ( 10. ). In this chapter we take a different approach, deciding in advance that we will only look for very specific kinds of information in text, such as the relation between organizations and locations. Rather than trying to use text like (1) to answer the question directly, we first convert the unstructured data of natural language sentences into the structured data of 1.1 . Then we reap the benefits of powerful query tools such as SQL. This method of getting meaning from text is called Information Extraction . Information Extraction has many applications, including business intelligence, resume harvesting, media analysis, sentiment detection, patent search, and email scanning. A particularly important area of current research involves the attempt to extract structured data out of electronically-available scientific literature, especially in the domain of biology and medicine.","title":"1  Information Extraction"},{"location":"Application/NLP/Lib/NLTK/docs/7-Extracting-Information-from-Text/7-Extracting-Information-from-Text/#11#information#extraction#architecture","text":"1.1 shows the architecture for a simple information extraction system . It begins by processing a document using several of the procedures discussed in 3 and 5. : first, the raw text of the document is split into sentences using a sentence segmenter , and each sentence is further subdivided into words using a tokenizer . Next, each sentence is tagged with part-of-speech tags , which will prove very helpful in the next step, named entity detection . In this step, we search for mentions of potentially interesting entities in each sentence. Finally, we use relation detection to search for likely relations between different entities in the text. Figure 1.1 : Simple Pipeline Architecture for an Information Extraction System. This system takes the raw text of a document as its input, and generates a list of (entity, relation, entity) tuples as its output. For example, given a document that indicates that the company Georgia-Pacific is located in Atlanta, it might generate the tuple ([ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']) . To perform the first three tasks, we can define a simple function that simply connects together NLTK's default sentence segmenter [1], word tokenizer [2], and part-of-speech tagger [3]: >>> def ie_preprocess ( document ): ... sentences = nltk . sent_tokenize ( document ) [ 1 ] ... sentences = [ nltk . word_tokenize ( sent ) for sent in sentences ] [ 2 ] ... sentences = [ nltk . pos_tag ( sent ) for sent in sentences ] [ 3 ] Next, in named entity detection , we segment and label the entities that might participate in interesting relations with one another. Typically, these will be definite noun phrases such as the knights who say \"ni\" , or proper names such as Monty Python . In some tasks it is useful to also consider indefinite nouns or noun chunks, such as every student or cats, and these do not necessarily refer to entities in the same way as definite NP s and proper names. Finally, in relation extraction, we search for specific patterns between pairs of entities that occur near one another in the text, and use those patterns to build tuples recording the relationships between the entities.","title":"1.1  Information Extraction Architecture"},{"location":"Application/NLP/Lib/NLTK/docs/7-Extracting-Information-from-Text/7-Extracting-Information-from-Text/#2#chunking","text":"The basic technique we will use for entity detection is chunking , which segments and labels multi-token sequences as illustrated in 2.1 . The smaller boxes show the word-level tokenization and part-of-speech tagging, while the large boxes show higher-level chunking. Each of these larger boxes is called a chunk . Like tokenization, which omits whitespace, chunking usually selects a subset of the tokens. Also like tokenization, the pieces produced by a chunker do not overlap in the source text. Figure 2.1 : Segmentation and Labeling at both the Token and Chunk Levels In this section, we will explore chunking in some depth, beginning with the definition and representation of chunks. We will see regular expression and n-gram approaches to chunking, and will develop and evaluate chunkers using the CoNLL-2000 chunking corpus. We will then return in (5) and 6 to the tasks of named entity recognition and relation extraction.","title":"2  Chunking"},{"location":"Application/NLP/Lib/NLTK/docs/7-Extracting-Information-from-Text/7-Extracting-Information-from-Text/#21#noun#phrase#chunking","text":"We will begin by considering the task of noun phrase chunking , or NP-chunking , where we search for chunks corresponding to individual noun phrases. For example, here is some Wall Street Journal text with NP -chunks marked using brackets: (2) [ The/DT market/NN ] for/IN [ system-management/NN software/NN ] for/IN [ Digital/NNP ] [ 's/POS hardware/NN ] is/VBZ fragmented/JJ enough/RB that/IN [ a/DT giant/NN ] such/JJ as/IN [ Computer/NNP Associates/NNPS ] should/MD do/VB well/RB there/RB ./. As we can see, NP -chunks are often smaller pieces than complete noun phrases. For example, the market for system-management software for Digital's hardware is a single noun phrase (containing two nested noun phrases), but it is captured in NP -chunks by the simpler chunk the market . One of the motivations for this difference is that NP -chunks are defined so as not to contain other NP -chunks. Consequently, any prepositional phrases or subordinate clauses that modify a nominal will not be included in the corresponding NP -chunk, since they almost certainly contain further noun phrases. One of the most useful sources of information for NP -chunking is part-of-speech tags . This is one of the motivations for performing part-of-speech tagging in our information extraction system. We demonstrate this approach using an example sentence that has been part-of-speech tagged in 2.2 . In order to create an NP -chunker, we will first define a chunk grammar , consisting of rules that indicate how sentences should be chunked. In this case, we will define a simple grammar with a single regular-expression rule. This rule says that an NP chunk should be formed whenever the chunker finds an optional determiner ( DT ) followed by any number of adjectives ( JJ ) and then a noun ( NN ). Using this grammar, we create a chunk parser, and test it on our example sentence. The result is a tree, which we can either print, or display graphically. sentence = [( \"the\" , \"DT\" ), ( \"little\" , \"JJ\" ), ( \"yellow\" , \"JJ\" ), ( \"dog\" , \"NN\" ), ( \"barked\" , \"VBD\" ), ( \"at\" , \"IN\" ), ( \"the\" , \"DT\" ), ( \"cat\" , \"NN\" )] grammar = \"NP: {<DT>?<JJ>*<NN>}\" cp = nltk . RegexpParser ( grammar ) result = cp . parse ( sentence ) print ( result ) ( S ( NP the / DT little / JJ yellow / JJ dog / NN ) barked / VBD at / IN ( NP the / DT cat / NN )) result . draw () Example 2.2 (code_chunkex.py) : Figure 2.2 : Example of a Simple Regular Expression Based NP Chunker. NOTE: In fact, this is a parse tree.","title":"2.1  Noun Phrase Chunking"},{"location":"Application/NLP/Lib/NLTK/docs/7-Extracting-Information-from-Text/7-Extracting-Information-from-Text/#22#tag#patterns","text":"The rules that make up a chunk grammar use tag patterns to describe sequences of tagged words. A tag pattern is a sequence of part-of-speech tags delimited using angle brackets, e.g. ?* . Tag patterns are similar to regular expression patterns ( 3.4 ). Now, consider the following noun phrases from the Wall Street Journal: another/DT sharp/JJ dive/NN trade/NN figures/NNS any/DT new/JJ policy/NN measures/NNS earlier/JJR stages/NNS Panamanian/JJ dictator/NN Manuel/NNP Noriega/NNP We can match these noun phrases using a slight refinement of the first tag pattern above, i.e. ?*+ . This will chunk any sequence of tokens beginning with an optional determiner, followed by zero or more adjectives of any type (including relative adjectives like earlier/JJR ), followed by one or more nouns of any type. However, it is easy to find many more complicated examples which this rule will not cover: his/PRP$ Mansion/NNP House/NNP speech/NN the/DT price/NN cutting/VBG 3/CD %/NN to/TO 4/CD %/NN more/JJR than/IN 10/CD %/NN the/DT fastest/JJS developing/VBG trends/NNS 's/POS skill/NN Note Your Turn: Try to come up with tag patterns to cover these cases. Test them using the graphical interface nltk.app.chunkparser() . Continue to refine your tag patterns with the help of the feedback given by this tool.","title":"2.2  Tag Patterns"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/","text":"8. Analyzing Sentence Structure 1 Some Grammatical Dilemmas 1.1 Linguistic Data and Unlimited Possibilities 1.2 Ubiquitous Ambiguity 2 What's the Use of Syntax? 3 Context Free Grammar 3.1 A Simple Grammar 3.2 Writing Your Own Grammars 3.3 Recursion in Syntactic Structure 4 Parsing With Context Free Grammar 4.1 Recursive Descent Parsing 4.2 Shift-Reduce Parsing 4.3 The Left-Corner Parser 4.4 Well-Formed Substring Tables 5 Dependencies and Dependency Grammar 6 Grammar Development 6.1 Treebanks and Grammars 6.2 Pernicious Ambiguity 6.3 Weighted Grammar 7 Summary 8. Analyzing Sentence Structure Earlier chapters focused on words: how to identify them, analyze their structure, assign them to lexical categories, and access their meanings. We have also seen how to identify patterns in word sequences or n-grams. However, these methods only scratch the surface of the complex constraints that govern sentences. We need a way to deal with the ambiguity that natural language is famous for. We also need to be able to cope with the fact that there are an unlimited number of possible sentences, and we can only write finite programs to analyze their structures and discover their meanings. NOTE: As far as grammar is concerned, formal language is much simpler than natural language The goal of this chapter is to answer the following questions: How can we use a formal grammar to describe the structure of an unlimited set of sentences? How do we represent the structure of sentences using syntax trees ? How do parsers analyze a sentence and automatically build a syntax tree ? Along the way, we will cover the fundamentals of English syntax, and see that there are systematic aspects of meaning that are much easier to capture once we have identified the structure of sentences. NOTE: My GitHub project automata-and-formal-language summary the knowledge related to formal language. 1 Some Grammatical Dilemmas 1.1 Linguistic Data and Unlimited Possibilities In this chapter, we will adopt the formal framework of \"generative grammar\", in which a \"language\" is considered to be nothing more than an enormous collection of all grammatical sentences, and a grammar is a formal notation that can be used for \"generating\" the members of this set. Grammars use recursive productions of the form S \u2192 S and S , as we will explore in 3 . In 10. we will extend this, to automatically build up the meaning of a sentence out of the meanings of its parts. 1.2 Ubiquitous Ambiguity A well-known example of ambiguity is shown in (2) , from the Groucho Marx movie, Animal Crackers (1930): (2) While hunting in Africa, I shot an elephant in my pajamas. How he got into my pajamas, I don't know. Let's take a closer look at the ambiguity in the phrase: I shot an elephant in my pajamas . First we need to define a simple grammar: groucho_grammar = nltk . CFG . fromstring ( \"\"\"S -> NP VP PP -> P NP NP -> Det N | Det N PP | 'I' VP -> V NP | VP PP Det -> 'an' | 'my' N -> 'elephant' | 'pajamas' V -> 'shot' P -> 'in' \"\"\" ) NOTE: What dose NP, VP mean? see 2 What's the Use of Syntax? 3 Context Free Grammar This grammar permits the sentence to be analyzed in two ways, depending on whether the prepositional phrase in my pajamas describes the elephant or the shooting event. sent = [ 'I' , 'shot' , 'an' , 'elephant' , 'in' , 'my' , 'pajamas' ] parser = nltk . ChartParser ( groucho_grammar ) for tree in parser . parse ( sent ): print ( tree ) The program produces two bracketed structures, which we can depict as trees, as shown in (3b) : (3) a. b. Notice that there's no ambiguity concerning the meaning of any of the words; This chapter presents grammars and parsing, as the formal and computational methods for investigating and modeling the linguistic phenomena we have been discussing. As we shall see, patterns of well-formedness and ill-formedness in a sequence of words can be understood with respect to the phrase structure and dependencies. We can develop formal models of these structures using grammars and parsers. As before, a key motivation is natural language understanding . How much more of the meaning of a text can we access when we can reliably recognize the linguistic structures it contains? Having read in a text, can a program \"understand\" it enough to be able to answer simple questions about \"what happened\" or \"who did what to whom\"? Also as before, we will develop simple programs to process annotated corpora and perform useful tasks. 2 What's the Use of Syntax? In 2.2 , we have added grammatical category labels to the words we saw in the earlier figure. The labels NP , VP , and PP stand for noun phrase , verb phrase and prepositional phrase respectively. Figure 2.2 : Substitution of Word Sequences Plus Grammatical Categories: This diagram reproduces 2.1 along with grammatical categories corresponding to noun phrases ( NP ), verb phrases ( VP ), prepositional phrases ( PP ), and nominals ( Nom ). If we now strip out the words apart from the topmost row, add an S node, and flip the figure over, we end up with a standard phrase structure tree, shown in (8) . Each node in this tree (including the words) is called a constituent . The immediate constituents of S are NP and VP . (8) As we will see in the next section, a grammar specifies how the sentence can be subdivided into its immediate constituents, and how these can be further subdivided until we reach the level of individual words. Note As we saw in 1 , sentences can have arbitrary length. Consequently, phrase structure trees can have arbitrary depth . The cascaded chunk parsers we saw in 4 can only produce structures of bounded depth, so chunking methods aren't applicable here. 3 Context Free Grammar 3.1 A Simple Grammar Let's start off by looking at a simple context-free grammar. By convention, the left-hand-side of the first production is the start-symbol of the grammar, typically S , and all well-formed trees must have this symbol as their root label. In NLTK, context-free grammars are defined in the nltk.grammar module. In 3.1 we define a grammar and show how to parse a simple sentence admitted by the grammar. grammar1 = nltk . CFG . fromstring ( \"\"\" S -> NP VP VP -> V NP | V NP PP PP -> P NP V -> \"saw\" | \"ate\" | \"walked\" NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP Det -> \"a\" | \"an\" | \"the\" | \"my\" N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\" P -> \"in\" | \"on\" | \"by\" | \"with\" \"\"\" ) sent = \"Mary saw Bob\" . split () rd_parser = nltk . RecursiveDescentParser ( grammar1 ) for tree in rd_parser . parse ( sent ): print ( tree ) The grammar in 3.1 contains productions involving various syntactic categories, as laid out in 3.1 . Table 3.1 : Syntactic Categories Symbol Meaning Example S sentence the man walked NP noun phrase a dog VP verb phrase saw a park PP prepositional phrase with a telescope Det determiner the N noun dog V verb walked P preposition in A production like VP -> V NP | V NP PP has a disjunction on the righthand side, shown by the | and is an abbreviation for the two productions VP -> V NP and VP -> V NP PP . Figure 3.2 : Recursive Descent Parser Demo: This tool allows you to watch the operation of a recursive descent parser as it grows the parse tree and matches it against the input words. Note Your Turn: Try developing a simple grammar of your own, using the recursive descent parser application, nltk.app.rdparser() , shown in 3.2 . It comes already loaded with a sample grammar, but you can edit this as you please (using the Edit menu). Change the grammar, and the sentence to be parsed, and run the parser using the autostep button. If we parse the sentence The dog saw a man in the park using the grammar shown in 3.1 , we end up with two trees, similar to those we saw for (3b) : a. b. 3.2 Writing Your Own Grammars If you are interested in experimenting with writing CFGs, you will find it helpful to create and edit your grammar in a text file, say mygrammar.cfg . You can then load it into NLTK and parse with it as follows: grammar1 = nltk . data . load ( 'file:mygrammar.cfg' ) sent = \"Mary saw Bob\" . split () rd_parser = nltk . RecursiveDescentParser ( grammar1 ) for tree in rd_parser . parse ( sent ): print ( tree ) 3.3 Recursion in Syntactic Structure A grammar is said to be recursive if a category occurring on the left hand side of a production also appears on the righthand side of a production, as illustrated in 3.3 . The production Nom -> Adj Nom (where Nom is the category of nominals) involves direct recursion on the category Nom , whereas indirect recursion on S arises from the combination of two productions, namely S -> NP VP and VP -> V S . grammar2 = nltk . CFG . fromstring ( \"\"\" S -> NP VP NP -> Det Nom | PropN Nom -> Adj Nom | N VP -> V Adj | V NP | V S | V NP PP PP -> P NP PropN -> 'Buster' | 'Chatterer' | 'Joe' Det -> 'the' | 'a' N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log' Adj -> 'angry' | 'frightened' | 'little' | 'tall' V -> 'chased' | 'saw' | 'said' | 'thought' | 'was' | 'put' P -> 'on' \"\"\" ) Example 3.3 (code_cfg2.py) : Figure 3.3 : A Recursive Context-Free Grammar To see how recursion arises from this grammar, consider the following trees. (10a) involves nested nominal phrases, while (10b) contains nested sentences. (10) a. b. We've only illustrated two levels of recursion here, but there's no upper limit on the depth. You can experiment with parsing sentences that involve more deeply nested structures. Beware that the RecursiveDescentParser is unable to handle left-recursive productions of the form X -> X Y ; we will return to this in 4 . 4 Parsing With Context Free Grammar A parser processes input sentences according to the productions of a grammar, and builds one or more constituent structures that conform to the grammar. A grammar is a declarative specification of well-formedness \u2014 it is actually just a string, not a program. A parser is a procedural interpretation of the grammar. It searches through the space of trees licensed by a grammar to find one that has the required sentence along its fringe. A parser permits a grammar to be evaluated against a collection of test sentences, helping linguists to discover mistakes in their grammatical analysis. A parser can serve as a model of psycholinguistic processing, helping to explain the difficulties that humans have with processing certain syntactic constructions. Many natural language applications involve parsing at some point; for example, we would expect the natural language questions submitted to a question-answering system to undergo parsing as an initial step.In this section we see two simple parsing algorithms, a top-down method called recursive descent parsing, and a bottom-up method called shift-reduce parsing. We also see some more sophisticated algorithms, a top-down method with bottom-up filtering called left-corner parsing , and a dynamic programming technique called chart parsing . 4.1 Recursive Descent Parsing 4.2 Shift-Reduce Parsing 4.3 The Left-Corner Parser 4.4 Well-Formed Substring Tables 5 Dependencies and Dependency Grammar 6 Grammar Development Parsing builds trees over sentences, according to a phrase structure grammar. Now, all the examples we gave above only involved toy grammars containing a handful of productions. What happens if we try to scale up this approach to deal with realistic corpora of language? In this section we will see how to access treebanks, and look at the challenge of developing broad-coverage grammars. 6.1 Treebanks and Grammars 6.2 Pernicious Ambiguity 6.3 Weighted Grammar 7 Summary","title":"8 Analyzing Sentence Structure"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#8#analyzing#sentence#structure","text":"Earlier chapters focused on words: how to identify them, analyze their structure, assign them to lexical categories, and access their meanings. We have also seen how to identify patterns in word sequences or n-grams. However, these methods only scratch the surface of the complex constraints that govern sentences. We need a way to deal with the ambiguity that natural language is famous for. We also need to be able to cope with the fact that there are an unlimited number of possible sentences, and we can only write finite programs to analyze their structures and discover their meanings. NOTE: As far as grammar is concerned, formal language is much simpler than natural language The goal of this chapter is to answer the following questions: How can we use a formal grammar to describe the structure of an unlimited set of sentences? How do we represent the structure of sentences using syntax trees ? How do parsers analyze a sentence and automatically build a syntax tree ? Along the way, we will cover the fundamentals of English syntax, and see that there are systematic aspects of meaning that are much easier to capture once we have identified the structure of sentences. NOTE: My GitHub project automata-and-formal-language summary the knowledge related to formal language.","title":"8. Analyzing Sentence Structure"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#1#some#grammatical#dilemmas","text":"","title":"1  Some Grammatical Dilemmas"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#11#linguistic#data#and#unlimited#possibilities","text":"In this chapter, we will adopt the formal framework of \"generative grammar\", in which a \"language\" is considered to be nothing more than an enormous collection of all grammatical sentences, and a grammar is a formal notation that can be used for \"generating\" the members of this set. Grammars use recursive productions of the form S \u2192 S and S , as we will explore in 3 . In 10. we will extend this, to automatically build up the meaning of a sentence out of the meanings of its parts.","title":"1.1  Linguistic Data and Unlimited Possibilities"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#12#ubiquitous#ambiguity","text":"A well-known example of ambiguity is shown in (2) , from the Groucho Marx movie, Animal Crackers (1930): (2) While hunting in Africa, I shot an elephant in my pajamas. How he got into my pajamas, I don't know. Let's take a closer look at the ambiguity in the phrase: I shot an elephant in my pajamas . First we need to define a simple grammar: groucho_grammar = nltk . CFG . fromstring ( \"\"\"S -> NP VP PP -> P NP NP -> Det N | Det N PP | 'I' VP -> V NP | VP PP Det -> 'an' | 'my' N -> 'elephant' | 'pajamas' V -> 'shot' P -> 'in' \"\"\" ) NOTE: What dose NP, VP mean? see 2 What's the Use of Syntax? 3 Context Free Grammar This grammar permits the sentence to be analyzed in two ways, depending on whether the prepositional phrase in my pajamas describes the elephant or the shooting event. sent = [ 'I' , 'shot' , 'an' , 'elephant' , 'in' , 'my' , 'pajamas' ] parser = nltk . ChartParser ( groucho_grammar ) for tree in parser . parse ( sent ): print ( tree ) The program produces two bracketed structures, which we can depict as trees, as shown in (3b) : (3) a. b. Notice that there's no ambiguity concerning the meaning of any of the words; This chapter presents grammars and parsing, as the formal and computational methods for investigating and modeling the linguistic phenomena we have been discussing. As we shall see, patterns of well-formedness and ill-formedness in a sequence of words can be understood with respect to the phrase structure and dependencies. We can develop formal models of these structures using grammars and parsers. As before, a key motivation is natural language understanding . How much more of the meaning of a text can we access when we can reliably recognize the linguistic structures it contains? Having read in a text, can a program \"understand\" it enough to be able to answer simple questions about \"what happened\" or \"who did what to whom\"? Also as before, we will develop simple programs to process annotated corpora and perform useful tasks.","title":"1.2  Ubiquitous Ambiguity"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#2#whats#the#use#of#syntax","text":"In 2.2 , we have added grammatical category labels to the words we saw in the earlier figure. The labels NP , VP , and PP stand for noun phrase , verb phrase and prepositional phrase respectively. Figure 2.2 : Substitution of Word Sequences Plus Grammatical Categories: This diagram reproduces 2.1 along with grammatical categories corresponding to noun phrases ( NP ), verb phrases ( VP ), prepositional phrases ( PP ), and nominals ( Nom ). If we now strip out the words apart from the topmost row, add an S node, and flip the figure over, we end up with a standard phrase structure tree, shown in (8) . Each node in this tree (including the words) is called a constituent . The immediate constituents of S are NP and VP . (8) As we will see in the next section, a grammar specifies how the sentence can be subdivided into its immediate constituents, and how these can be further subdivided until we reach the level of individual words. Note As we saw in 1 , sentences can have arbitrary length. Consequently, phrase structure trees can have arbitrary depth . The cascaded chunk parsers we saw in 4 can only produce structures of bounded depth, so chunking methods aren't applicable here.","title":"2  What's the Use of Syntax?"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#3#context#free#grammar","text":"","title":"3  Context Free Grammar"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#31#a#simple#grammar","text":"Let's start off by looking at a simple context-free grammar. By convention, the left-hand-side of the first production is the start-symbol of the grammar, typically S , and all well-formed trees must have this symbol as their root label. In NLTK, context-free grammars are defined in the nltk.grammar module. In 3.1 we define a grammar and show how to parse a simple sentence admitted by the grammar. grammar1 = nltk . CFG . fromstring ( \"\"\" S -> NP VP VP -> V NP | V NP PP PP -> P NP V -> \"saw\" | \"ate\" | \"walked\" NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP Det -> \"a\" | \"an\" | \"the\" | \"my\" N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\" P -> \"in\" | \"on\" | \"by\" | \"with\" \"\"\" ) sent = \"Mary saw Bob\" . split () rd_parser = nltk . RecursiveDescentParser ( grammar1 ) for tree in rd_parser . parse ( sent ): print ( tree ) The grammar in 3.1 contains productions involving various syntactic categories, as laid out in 3.1 . Table 3.1 : Syntactic Categories Symbol Meaning Example S sentence the man walked NP noun phrase a dog VP verb phrase saw a park PP prepositional phrase with a telescope Det determiner the N noun dog V verb walked P preposition in A production like VP -> V NP | V NP PP has a disjunction on the righthand side, shown by the | and is an abbreviation for the two productions VP -> V NP and VP -> V NP PP . Figure 3.2 : Recursive Descent Parser Demo: This tool allows you to watch the operation of a recursive descent parser as it grows the parse tree and matches it against the input words. Note Your Turn: Try developing a simple grammar of your own, using the recursive descent parser application, nltk.app.rdparser() , shown in 3.2 . It comes already loaded with a sample grammar, but you can edit this as you please (using the Edit menu). Change the grammar, and the sentence to be parsed, and run the parser using the autostep button. If we parse the sentence The dog saw a man in the park using the grammar shown in 3.1 , we end up with two trees, similar to those we saw for (3b) : a. b.","title":"3.1  A Simple Grammar"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#32#writing#your#own#grammars","text":"If you are interested in experimenting with writing CFGs, you will find it helpful to create and edit your grammar in a text file, say mygrammar.cfg . You can then load it into NLTK and parse with it as follows: grammar1 = nltk . data . load ( 'file:mygrammar.cfg' ) sent = \"Mary saw Bob\" . split () rd_parser = nltk . RecursiveDescentParser ( grammar1 ) for tree in rd_parser . parse ( sent ): print ( tree )","title":"3.2  Writing Your Own Grammars"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#33#recursion#in#syntactic#structure","text":"A grammar is said to be recursive if a category occurring on the left hand side of a production also appears on the righthand side of a production, as illustrated in 3.3 . The production Nom -> Adj Nom (where Nom is the category of nominals) involves direct recursion on the category Nom , whereas indirect recursion on S arises from the combination of two productions, namely S -> NP VP and VP -> V S . grammar2 = nltk . CFG . fromstring ( \"\"\" S -> NP VP NP -> Det Nom | PropN Nom -> Adj Nom | N VP -> V Adj | V NP | V S | V NP PP PP -> P NP PropN -> 'Buster' | 'Chatterer' | 'Joe' Det -> 'the' | 'a' N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log' Adj -> 'angry' | 'frightened' | 'little' | 'tall' V -> 'chased' | 'saw' | 'said' | 'thought' | 'was' | 'put' P -> 'on' \"\"\" ) Example 3.3 (code_cfg2.py) : Figure 3.3 : A Recursive Context-Free Grammar To see how recursion arises from this grammar, consider the following trees. (10a) involves nested nominal phrases, while (10b) contains nested sentences. (10) a. b. We've only illustrated two levels of recursion here, but there's no upper limit on the depth. You can experiment with parsing sentences that involve more deeply nested structures. Beware that the RecursiveDescentParser is unable to handle left-recursive productions of the form X -> X Y ; we will return to this in 4 .","title":"3.3  Recursion in Syntactic Structure"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#4#parsing#with#context#free#grammar","text":"A parser processes input sentences according to the productions of a grammar, and builds one or more constituent structures that conform to the grammar. A grammar is a declarative specification of well-formedness \u2014 it is actually just a string, not a program. A parser is a procedural interpretation of the grammar. It searches through the space of trees licensed by a grammar to find one that has the required sentence along its fringe. A parser permits a grammar to be evaluated against a collection of test sentences, helping linguists to discover mistakes in their grammatical analysis. A parser can serve as a model of psycholinguistic processing, helping to explain the difficulties that humans have with processing certain syntactic constructions. Many natural language applications involve parsing at some point; for example, we would expect the natural language questions submitted to a question-answering system to undergo parsing as an initial step.In this section we see two simple parsing algorithms, a top-down method called recursive descent parsing, and a bottom-up method called shift-reduce parsing. We also see some more sophisticated algorithms, a top-down method with bottom-up filtering called left-corner parsing , and a dynamic programming technique called chart parsing .","title":"4  Parsing With Context Free Grammar"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#41#recursive#descent#parsing","text":"","title":"4.1  Recursive Descent Parsing"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#42#shift-reduce#parsing","text":"","title":"4.2  Shift-Reduce Parsing"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#43#the#left-corner#parser","text":"","title":"4.3  The Left-Corner Parser"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#44#well-formed#substring#tables","text":"","title":"4.4  Well-Formed Substring Tables"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#5#dependencies#and#dependency#grammar","text":"","title":"5  Dependencies and Dependency Grammar"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#6#grammar#development","text":"Parsing builds trees over sentences, according to a phrase structure grammar. Now, all the examples we gave above only involved toy grammars containing a handful of productions. What happens if we try to scale up this approach to deal with realistic corpora of language? In this section we will see how to access treebanks, and look at the challenge of developing broad-coverage grammars.","title":"6  Grammar Development"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#61#treebanks#and#grammars","text":"","title":"6.1  Treebanks and Grammars"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#62#pernicious#ambiguity","text":"","title":"6.2  Pernicious Ambiguity"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#63#weighted#grammar","text":"","title":"6.3  Weighted Grammar"},{"location":"Application/NLP/Lib/NLTK/docs/8-Analyzing-Sentence-Structure/8-Analyzing-Sentence-Structure/#7#summary","text":"","title":"7  Summary"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/","text":"parser\u7684\u5b9e\u73b0\u5206\u6790 tree.py probability.py grammar.py parse \u529f\u80fd\u5206\u6790 \u6839\u636e\u7528\u6237\u6307\u5b9a\u7684grammar\uff0c\u6784\u9020parser\u3002 \u652f\u6301\u7684\u8bed\u6cd5 CFG PCFG( probabilistic context free grammar ) \u9996\u5148\u9700\u8981\u8003\u8651\u7684\u5982\u4f55\u6765\u8868\u793a CFG ? \u7531 grammar.py \u5b9e\u73b0\u3002 Nonterminal class Nonterminal A non-terminal symbol for a context free grammar, immutable and hashable class FeatStructNonterminal Productions class Production class DependencyProduction(Production) A dependency grammar production class ProbabilisticProduction Grammars class CFG A context-free grammar. A grammar consists of a start state and a set of productions. class FeatureGrammar(CFG) A dependency grammar production class DependencyGrammar class ProbabilisticDependencyGrammar grammar class RecursiveDescentParser(ParserI) class TransitionParser(ParserI) class BottomUpProbabilisticChartParser(ParserI) class MaltParser(ParserI) class GenericStanfordParser(ParserI) class ViterbiParser(ParserI) class ChartParser(ParserI) class GenericCoreNLPParser(ParserI, TokenizerI, TaggerI) class BllipParser(ParserI) class ShiftReduceParser(ParserI)","title":"parser\u7684\u5b9e\u73b0\u5206\u6790"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#parser","text":"tree.py probability.py grammar.py parse","title":"parser\u7684\u5b9e\u73b0\u5206\u6790"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#_1","text":"\u6839\u636e\u7528\u6237\u6307\u5b9a\u7684grammar\uff0c\u6784\u9020parser\u3002","title":"\u529f\u80fd\u5206\u6790"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#_2","text":"CFG PCFG( probabilistic context free grammar ) \u9996\u5148\u9700\u8981\u8003\u8651\u7684\u5982\u4f55\u6765\u8868\u793a CFG ? \u7531 grammar.py \u5b9e\u73b0\u3002","title":"\u652f\u6301\u7684\u8bed\u6cd5"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#nonterminal","text":"class Nonterminal A non-terminal symbol for a context free grammar, immutable and hashable class FeatStructNonterminal","title":"Nonterminal"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#productions","text":"class Production class DependencyProduction(Production) A dependency grammar production class ProbabilisticProduction","title":"Productions"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#grammars","text":"class CFG A context-free grammar. A grammar consists of a start state and a set of productions. class FeatureGrammar(CFG) A dependency grammar production class DependencyGrammar class ProbabilisticDependencyGrammar","title":"Grammars"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#grammar","text":"","title":"grammar"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#recursivedescentparserparseri","text":"","title":"class RecursiveDescentParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#transitionparserparseri","text":"","title":"class TransitionParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#bottomupprobabilisticchartparserparseri","text":"","title":"class BottomUpProbabilisticChartParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#maltparserparseri","text":"","title":"class MaltParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#genericstanfordparserparseri","text":"","title":"class GenericStanfordParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#viterbiparserparseri","text":"","title":"class ViterbiParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#chartparserparseri","text":"","title":"class ChartParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#genericcorenlpparserparseri#tokenizeri#taggeri","text":"","title":"class GenericCoreNLPParser(ParserI, TokenizerI, TaggerI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#bllipparserparseri","text":"","title":"class BllipParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/#class#shiftreduceparserparseri","text":"","title":"class ShiftReduceParser(ParserI)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/nltk.parser/","text":"Grammar Parsing http://www.nltk.org/howto/grammar.html https://github.com/nltk/nltk/tree/develop/nltk/parse http://www.nltk.org/book/ch08.html","title":"[Grammar Parsing](http://www.nltk.org/howto/grammar.html)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/nltk.parser/#grammar#parsing","text":"http://www.nltk.org/howto/grammar.html https://github.com/nltk/nltk/tree/develop/nltk/parse http://www.nltk.org/book/ch08.html","title":"Grammar Parsing"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/nltk.tree/","text":"nltk.tree.Tree \u76f8\u5173\u6587\u6863\u6709\uff1a Unit tests for nltk.tree.Tree \u770b\u4e86\u5b83\u7684\u5b9e\u73b0\u540e\uff0c\u53d1\u73b0\u5b83\u7684\u5b9e\u73b0\u65b9\u5f0f\u548c\u666e\u901a\u7684\u5b9e\u73b0\u6811\u7684\u65b9\u5f0f\u4e0d\u540c\uff1a \u666e\u901a\u7684\u5b9e\u73b0\u65b9\u5f0f\u90fd\u662f\u5b9a\u4e49 class Node \uff0c\u7136\u540e Node \u4e2d\u5305\u542b\u6307\u5411\u5b50\u8282\u70b9\u7684\u6307\u9488\uff0c\u8fd9\u79cd\u65b9\u5f0f\u662f\u5c06\u6811\u7684\u6784\u6210\u770b\u505a\u662f Node \u4e4b\u95f4\u7684\u5173\u8054\uff1b \u800c\u5b83\u663e\u793a\u5730\u5b9a\u4e49 class Node \uff0c\u76f4\u63a5\u5b9a\u4e49 class Tree \uff0c\u5b83\u5c06\u6811\u7684\u6784\u6210\u770b\u505a\u662f Tree \u4e4b\u95f4\u7684\u5173\u8054\u3002 class Tree ( list ): def __init__ ( self , node , children = None ): if children is None : raise TypeError ( \" %s : Expected a node value and child list \" % type ( self ) . __name__ ) elif isinstance ( children , string_types ): raise TypeError ( \" %s () argument 2 should be a list, not a \" \"string\" % type ( self ) . __name__ ) else : list . __init__ ( self , children ) self . _label = node \u663e\u7136\uff0c\u867d\u7136 class Tree \u53eb\u505a Tree \uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\uff0c\u5b83\u7684\u529f\u80fd\u975e\u5e38\u7c7b\u4f3c\u4e8e Node \u3002 \u53ef\u4ee5\u770b\u5230\uff0c class Tree \u7ee7\u627f\u4e86 list \uff0c\u5b83\u5c06\u548c\u5b50\u6811\u4e4b\u95f4\u7684\u5173\u8054\u5168\u90e8\u4fdd\u5b58\u4e0e list \u4e2d\u3002 \u53e6\u5916\u5b83\u53ea\u6709\u4e00\u4e2a\u6210\u5458\u53d8\u91cf _label \uff0c\u8fd9\u662f\u56e0\u4e3a class Tree \u4e3b\u8981\u7528\u4f5cparse tree\uff0cparse tree\u4e2d\u7684\u6bcf\u4e2anode\u53ea\u6709\u4e00\u4e2alabel\u3002 \u4e0b\u9762\u662f\u4ee3\u7801\u4e2d\u7ed9\u51fa\u7684\u8be5\u7c7b\u7684\u6587\u6863\uff1a A Tree represents a hierarchical grouping of leaves and subtrees. For example, each constituent in a syntax tree is represented by a single Tree. A tree's children are encoded as a list of leaves and subtrees, where a leaf is a basic (non-tree) value; and a subtree is a nested Tree. \u4ece\u4e0a\u8ff0\u6587\u6863\u4e2d\uff0c\u53ef\u4ee5\u770b\u51fa class Tree \u548c\u666e\u901a\u7684\u6811\u7684\u5b9e\u73b0\u65b9\u5f0f\u4e4b\u95f4\u7684\u4e00\u4e2a\u5dee\u5f02\uff1a \u5728\u666e\u901a\u7684\u5b9e\u73b0\u4e2d\uff0c\u6811\u4e2d\u8282\u70b9\u7684\u7c7b\u578b\u90fd\u662f\u76f8\u540c\u7684\uff0c\u8fd9\u91cc\u628a\u5b83\u79f0\u4e3a class Node \uff0c\u65e0\u8bba\u662f\u5185\u8282\u70b9\u8fd8\u662f\u53f6\u5b50\u8282\u70b9\uff1b \u4f46\u662f\u5728 class Tree \u4e2d\uff0c\u6ca1\u6709\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u5b9e\u73b0\uff0c\u800c\u662f\u6240\u6709\u7684\u5185\u8282\u70b9\u7684\u5185\u7701\u90fd\u662f class Tree \uff0c\u800c\u53f6\u5b50\u8282\u70b9\u7684\u7c7b\u578b\u662fbasic (non-tree) type\u3002","title":"[nltk.tree.Tree](https://github.com/nltk/nltk/blob/develop/nltk/tree.py)"},{"location":"Application/NLP/Lib/NLTK/implementation/parse/nltk.tree/#nltktreetree","text":"\u76f8\u5173\u6587\u6863\u6709\uff1a Unit tests for nltk.tree.Tree \u770b\u4e86\u5b83\u7684\u5b9e\u73b0\u540e\uff0c\u53d1\u73b0\u5b83\u7684\u5b9e\u73b0\u65b9\u5f0f\u548c\u666e\u901a\u7684\u5b9e\u73b0\u6811\u7684\u65b9\u5f0f\u4e0d\u540c\uff1a \u666e\u901a\u7684\u5b9e\u73b0\u65b9\u5f0f\u90fd\u662f\u5b9a\u4e49 class Node \uff0c\u7136\u540e Node \u4e2d\u5305\u542b\u6307\u5411\u5b50\u8282\u70b9\u7684\u6307\u9488\uff0c\u8fd9\u79cd\u65b9\u5f0f\u662f\u5c06\u6811\u7684\u6784\u6210\u770b\u505a\u662f Node \u4e4b\u95f4\u7684\u5173\u8054\uff1b \u800c\u5b83\u663e\u793a\u5730\u5b9a\u4e49 class Node \uff0c\u76f4\u63a5\u5b9a\u4e49 class Tree \uff0c\u5b83\u5c06\u6811\u7684\u6784\u6210\u770b\u505a\u662f Tree \u4e4b\u95f4\u7684\u5173\u8054\u3002 class Tree ( list ): def __init__ ( self , node , children = None ): if children is None : raise TypeError ( \" %s : Expected a node value and child list \" % type ( self ) . __name__ ) elif isinstance ( children , string_types ): raise TypeError ( \" %s () argument 2 should be a list, not a \" \"string\" % type ( self ) . __name__ ) else : list . __init__ ( self , children ) self . _label = node \u663e\u7136\uff0c\u867d\u7136 class Tree \u53eb\u505a Tree \uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\uff0c\u5b83\u7684\u529f\u80fd\u975e\u5e38\u7c7b\u4f3c\u4e8e Node \u3002 \u53ef\u4ee5\u770b\u5230\uff0c class Tree \u7ee7\u627f\u4e86 list \uff0c\u5b83\u5c06\u548c\u5b50\u6811\u4e4b\u95f4\u7684\u5173\u8054\u5168\u90e8\u4fdd\u5b58\u4e0e list \u4e2d\u3002 \u53e6\u5916\u5b83\u53ea\u6709\u4e00\u4e2a\u6210\u5458\u53d8\u91cf _label \uff0c\u8fd9\u662f\u56e0\u4e3a class Tree \u4e3b\u8981\u7528\u4f5cparse tree\uff0cparse tree\u4e2d\u7684\u6bcf\u4e2anode\u53ea\u6709\u4e00\u4e2alabel\u3002 \u4e0b\u9762\u662f\u4ee3\u7801\u4e2d\u7ed9\u51fa\u7684\u8be5\u7c7b\u7684\u6587\u6863\uff1a A Tree represents a hierarchical grouping of leaves and subtrees. For example, each constituent in a syntax tree is represented by a single Tree. A tree's children are encoded as a list of leaves and subtrees, where a leaf is a basic (non-tree) value; and a subtree is a nested Tree. \u4ece\u4e0a\u8ff0\u6587\u6863\u4e2d\uff0c\u53ef\u4ee5\u770b\u51fa class Tree \u548c\u666e\u901a\u7684\u6811\u7684\u5b9e\u73b0\u65b9\u5f0f\u4e4b\u95f4\u7684\u4e00\u4e2a\u5dee\u5f02\uff1a \u5728\u666e\u901a\u7684\u5b9e\u73b0\u4e2d\uff0c\u6811\u4e2d\u8282\u70b9\u7684\u7c7b\u578b\u90fd\u662f\u76f8\u540c\u7684\uff0c\u8fd9\u91cc\u628a\u5b83\u79f0\u4e3a class Node \uff0c\u65e0\u8bba\u662f\u5185\u8282\u70b9\u8fd8\u662f\u53f6\u5b50\u8282\u70b9\uff1b \u4f46\u662f\u5728 class Tree \u4e2d\uff0c\u6ca1\u6709\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u5b9e\u73b0\uff0c\u800c\u662f\u6240\u6709\u7684\u5185\u8282\u70b9\u7684\u5185\u7701\u90fd\u662f class Tree \uff0c\u800c\u53f6\u5b50\u8282\u70b9\u7684\u7c7b\u578b\u662fbasic (non-tree) type\u3002","title":"nltk.tree.Tree"},{"location":"Application/NLP/Lib/spaCy/","text":"\u5173\u4e8e\u672c\u7ae0 spaCy Speech and Language Processing","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/Lib/spaCy/#_1","text":"spaCy Speech and Language Processing","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/Linguistics/","text":"\u5173\u4e8e\u672c\u7ae0 NLP\u662f\u4e00\u95e8\u4ea4\u53c9\u5b66\u79d1\uff0c\u9664\u4e86computer science\u5916\uff0c\u5b83\u8fd8\u6d89\u53ca Linguistics \uff08\u8bed\u8a00\u5b66\uff09\u7684\u5f88\u591a\u5185\u5bb9\u3002\u672c\u7ae0\u5c31\u68b3\u7406\u4e00\u4e0b\u5728\u4ece\u4e8bNLP\u65f6\u5019\uff0c\u9700\u8981\u7684\u4e00\u4e9b Linguistics \u7684\u57fa\u7840\u77e5\u8bc6\u3002 Language \u53c2\u89c1\uff1a \u7ef4\u57fa\u767e\u79d1 Language \u5de5\u7a0b automata-and-formal-language \u7684 Formal-language \u7ae0\u8282 \u6587\u7ae0 Language and program Grammar \u53c2\u89c1\uff1a \u7ef4\u57fa\u767e\u79d1 Grammar \u5de5\u7a0b automata-and-formal-language \u7684 Formal-language \u7ae0\u8282 \u8bfb\u8005\u9700\u8981\u81f3\u5c11\u5bf9Grammatical theories\u7684\u51e0\u4e2a\u6d41\u6d3e\u6709\u4e00\u4e9b\u8ba4\u77e5\uff0c\u5c24\u5176\u662f Generative grammar \u6d41\u6d3e\u3002 Phrase structure grammar VS Dependency grammar \u5728NLP\u9886\u57df\uff0c\u8fd9\u4e24\u79cdgrammar\u662f\u6700\u4e3a\u5e38\u89c1\u7684\uff0c\u4e24\u8005\u672c\u8d28\u7684\u5dee\u5f02\u5728\u4e8e\u63cf\u8ff0\u8bed\u8a00\u7684\u7ed3\u6784\u65f6\u91c7\u7528\u7684relation\u4e0d\u540c\uff0c Phrase structure grammar \u6240\u91c7\u7528\u7684\u662f Constituency relation \uff0c\u800c Dependency grammar \u6240\u91c7\u7528\u7684\u662f Dependency relation \u3002","title":"Introduction"},{"location":"Application/NLP/Linguistics/#_1","text":"NLP\u662f\u4e00\u95e8\u4ea4\u53c9\u5b66\u79d1\uff0c\u9664\u4e86computer science\u5916\uff0c\u5b83\u8fd8\u6d89\u53ca Linguistics \uff08\u8bed\u8a00\u5b66\uff09\u7684\u5f88\u591a\u5185\u5bb9\u3002\u672c\u7ae0\u5c31\u68b3\u7406\u4e00\u4e0b\u5728\u4ece\u4e8bNLP\u65f6\u5019\uff0c\u9700\u8981\u7684\u4e00\u4e9b Linguistics \u7684\u57fa\u7840\u77e5\u8bc6\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/Linguistics/#language","text":"\u53c2\u89c1\uff1a \u7ef4\u57fa\u767e\u79d1 Language \u5de5\u7a0b automata-and-formal-language \u7684 Formal-language \u7ae0\u8282 \u6587\u7ae0 Language and program","title":"Language"},{"location":"Application/NLP/Linguistics/#grammar","text":"\u53c2\u89c1\uff1a \u7ef4\u57fa\u767e\u79d1 Grammar \u5de5\u7a0b automata-and-formal-language \u7684 Formal-language \u7ae0\u8282 \u8bfb\u8005\u9700\u8981\u81f3\u5c11\u5bf9Grammatical theories\u7684\u51e0\u4e2a\u6d41\u6d3e\u6709\u4e00\u4e9b\u8ba4\u77e5\uff0c\u5c24\u5176\u662f Generative grammar \u6d41\u6d3e\u3002","title":"Grammar"},{"location":"Application/NLP/Linguistics/#phrase#structure#grammar#vs#dependency#grammar","text":"\u5728NLP\u9886\u57df\uff0c\u8fd9\u4e24\u79cdgrammar\u662f\u6700\u4e3a\u5e38\u89c1\u7684\uff0c\u4e24\u8005\u672c\u8d28\u7684\u5dee\u5f02\u5728\u4e8e\u63cf\u8ff0\u8bed\u8a00\u7684\u7ed3\u6784\u65f6\u91c7\u7528\u7684relation\u4e0d\u540c\uff0c Phrase structure grammar \u6240\u91c7\u7528\u7684\u662f Constituency relation \uff0c\u800c Dependency grammar \u6240\u91c7\u7528\u7684\u662f Dependency relation \u3002","title":"Phrase structure grammar VS Dependency grammar"},{"location":"Application/NLP/Linguistics/Part-of-speech/","text":"Part of speech \u672c\u6587\u7684\u5185\u5bb9\u57fa\u4e8e\uff1a \u7ef4\u57fa\u767e\u79d1 Part of speech Natural Language Processing with Python \u7684 5. Categorizing and Tagging Words What is \u201cpart of speech\u201d\uff1f \"part of speech\"\u5373\u8bcd\u6027\uff0c\u5982\u679c\u4ee5machine learning\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u201cpart of speech\u201d\u975e\u5e38\u7c7b\u4f3c\u4e8e\u201clabel\u201d\uff0c\u5373\u5b83\u8868\u793a\u7684\u662f\u8bcd\u8bed\u7684**\u7c7b\u522b**\uff08\u540e\u6587\u4e2d\u4f1a\u51fa\u73b0\u201dword class\u201c\u8fd9\u4e2a\u8bcd\uff0c\u663e\u7136\u8fd9\u4e2a\u8bcd\u662f\u66f4\u52a0\u80fd\u591f\u4f53\u73b0\u5b83\u7684\u542b\u4e49\u7684\uff09\uff0c\u8fd9\u4e00\u70b9\u5728 Natural Language Processing with Python \u7684 5. Categorizing and Tagging Words \u7684\u540d\u79f0\u4e2d\u7684\u201cCategorizing\"\uff08\u5206\u7c7b\uff09\u4e2d\u4f53\u73b0\u51fa\u6765\u4e86\u3002\u663e\u7136\uff0c\u65e2\u7136\u80fd\u591f\u8fdb\u884c\u5206\u7c7b\uff0c\u90a3\u4e48\u5404\u79cdpart of speech\uff08word class\uff09\u80af\u5b9a\u6709\u7740\u663e\u8457\u7684\u7279\u5f81\u3002 \u6709\u4e86\u8fd9\u4e9b\u8ba4\u77e5\uff0c\u5c31\u80fd\u591f\u7406\u89e3\u7ef4\u57fa\u767e\u79d1\u7684 Part of speech \u4e2d\u7684\u5b9a\u4e49\u4e86\uff1a In traditional grammar , a part of speech (abbreviated form: PoS or POS ) is a category of words (or, more generally, of lexical items ) that have similar grammatical properties. Words that are assigned to the same part of speech generally display similar syntactic behavior\u2014they play similar roles within the grammatical structure of sentences\u2014and sometimes similar morphology in that they undergo inflection for similar properties. \u4e0b\u9762\u7ed9\u51fa\u4e86part of speech\u7684\u4e00\u4e2a\u4f8b\u5b50\uff1a Commonly listed English parts of speech are noun , verb , adjective , adverb , pronoun , preposition , conjunction , interjection , and sometimes numeral , article , or determiner . Other terms than part of speech \u2014particularly in modern linguistic classifications, which often make more precise distinctions than the traditional scheme does\u2014include word class , lexical class , and lexical category . \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0d\u540c\u7684\u8bed\u8a00\u6709\u7740\u4e0d\u540c\u7684part of speech Because of such variation in the number of categories and their identifying properties, analysis of parts of speech must be done for each individual language. \u5982\u4f55\u5b9a\u4e49\uff08\u521b\u9020\uff09part of speech\uff1f \u4e00\u95e8\u8bed\u8a00\u7684\u53ef\u7528\u4f7f\u7528\u7684Part of speech\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u7814\u7a76\u4eba\u5458\u662f\u53ef\u4ee5\u6839\u636e\u9700\u6c42\u6765\u521b\u9020\u9002\u5408\u4e8e\u7279\u5b9a\u95ee\u9898\u7684part of speech\uff08\u5176\u5b9e\u5c31\u662f\u5b9a\u4e49\u7c7b\u522b\uff0c\u4f46\u662f\u663e\u7136\u5728\u8fdb\u884c\u5b9a\u4e49\u7684\u65f6\u5019\uff0c\u5e94\u8be5\u662f\u9700\u8981\u8003\u8651\u8bed\u8a00\u5b66\u7684\u7406\u8bba\u7684\uff09\uff0c\u8fd9\u4e9bpart of speech\u79f0\u4e3a\u201c Tag sets \u201d\u3002\u90a3\u5982\u4f55\u6765\u8fdb\u884c\u521b\u9020\u5462\uff1f\u4e0b\u9762\u7ed9\u51fa\u4e86\u4e00\u4e9b\u6709\u53c2\u8003\u4ef7\u503c\u7684\u5185\u5bb9\uff1a Functional classification 7 How to Determine the Category of a Word \u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u6765\u81ea\u52a8\u5730\u8fdb\u884c\u201c\u5206\u7c7b\u201d\uff1f \u6211\u4eec\u5df2\u7ecf\u4e86\u89e3\u4e86part of speech\u7684\u542b\u4e49\uff0c\u77e5\u9053\u5b83\u672c\u8d28\u4e0a\u5c31\u662f\u7c7b\u522b\u3002\u7ed9\u5b9a\u4e00\u6bb5\u8bdd\uff0c\u6211\u4eec\u4eba\u7c7b\u662f\u53ef\u4ee5\u975e\u5e38\u8f7b\u677e\u5730\u6307\u51fa\u54ea\u4e9b\u8bcd\u662f\u5c5e\u4e8e\u54ea\u79cdpart of speech\uff0c\u90a3\u5982\u4f55\u8ba9computer\u4e5f\u83b7\u5f97\u8fd9\u79cd\u80fd\u529b\u5462\uff1f\u8fd9\u5c31\u662f\u672c\u8282\u6807\u9898\u7684\u6240\u63d0\u51fa\u7684\u95ee\u9898,\uff0c\u8fd9\u4e2a\u95ee\u9898\u662fNLP\u9886\u57df\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u53eb\u505a Part-of-speech tagging \uff0c\u5728\u4e0b\u4e00\u7ae0\u8282\u7684 Part-of-speech-tagging \u4e2d\u5bf9\u6b64\u8fdb\u884c\u4e13\u95e8\u8ba8\u8bba\u3002","title":"Part-of-speech"},{"location":"Application/NLP/Linguistics/Part-of-speech/#part#of#speech","text":"\u672c\u6587\u7684\u5185\u5bb9\u57fa\u4e8e\uff1a \u7ef4\u57fa\u767e\u79d1 Part of speech Natural Language Processing with Python \u7684 5. Categorizing and Tagging Words","title":"Part of speech"},{"location":"Application/NLP/Linguistics/Part-of-speech/#what#is#part#of#speech","text":"\"part of speech\"\u5373\u8bcd\u6027\uff0c\u5982\u679c\u4ee5machine learning\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u201cpart of speech\u201d\u975e\u5e38\u7c7b\u4f3c\u4e8e\u201clabel\u201d\uff0c\u5373\u5b83\u8868\u793a\u7684\u662f\u8bcd\u8bed\u7684**\u7c7b\u522b**\uff08\u540e\u6587\u4e2d\u4f1a\u51fa\u73b0\u201dword class\u201c\u8fd9\u4e2a\u8bcd\uff0c\u663e\u7136\u8fd9\u4e2a\u8bcd\u662f\u66f4\u52a0\u80fd\u591f\u4f53\u73b0\u5b83\u7684\u542b\u4e49\u7684\uff09\uff0c\u8fd9\u4e00\u70b9\u5728 Natural Language Processing with Python \u7684 5. Categorizing and Tagging Words \u7684\u540d\u79f0\u4e2d\u7684\u201cCategorizing\"\uff08\u5206\u7c7b\uff09\u4e2d\u4f53\u73b0\u51fa\u6765\u4e86\u3002\u663e\u7136\uff0c\u65e2\u7136\u80fd\u591f\u8fdb\u884c\u5206\u7c7b\uff0c\u90a3\u4e48\u5404\u79cdpart of speech\uff08word class\uff09\u80af\u5b9a\u6709\u7740\u663e\u8457\u7684\u7279\u5f81\u3002 \u6709\u4e86\u8fd9\u4e9b\u8ba4\u77e5\uff0c\u5c31\u80fd\u591f\u7406\u89e3\u7ef4\u57fa\u767e\u79d1\u7684 Part of speech \u4e2d\u7684\u5b9a\u4e49\u4e86\uff1a In traditional grammar , a part of speech (abbreviated form: PoS or POS ) is a category of words (or, more generally, of lexical items ) that have similar grammatical properties. Words that are assigned to the same part of speech generally display similar syntactic behavior\u2014they play similar roles within the grammatical structure of sentences\u2014and sometimes similar morphology in that they undergo inflection for similar properties. \u4e0b\u9762\u7ed9\u51fa\u4e86part of speech\u7684\u4e00\u4e2a\u4f8b\u5b50\uff1a Commonly listed English parts of speech are noun , verb , adjective , adverb , pronoun , preposition , conjunction , interjection , and sometimes numeral , article , or determiner . Other terms than part of speech \u2014particularly in modern linguistic classifications, which often make more precise distinctions than the traditional scheme does\u2014include word class , lexical class , and lexical category . \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0d\u540c\u7684\u8bed\u8a00\u6709\u7740\u4e0d\u540c\u7684part of speech Because of such variation in the number of categories and their identifying properties, analysis of parts of speech must be done for each individual language.","title":"What is \u201cpart of speech\u201d\uff1f"},{"location":"Application/NLP/Linguistics/Part-of-speech/#part#of#speech_1","text":"\u4e00\u95e8\u8bed\u8a00\u7684\u53ef\u7528\u4f7f\u7528\u7684Part of speech\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u7814\u7a76\u4eba\u5458\u662f\u53ef\u4ee5\u6839\u636e\u9700\u6c42\u6765\u521b\u9020\u9002\u5408\u4e8e\u7279\u5b9a\u95ee\u9898\u7684part of speech\uff08\u5176\u5b9e\u5c31\u662f\u5b9a\u4e49\u7c7b\u522b\uff0c\u4f46\u662f\u663e\u7136\u5728\u8fdb\u884c\u5b9a\u4e49\u7684\u65f6\u5019\uff0c\u5e94\u8be5\u662f\u9700\u8981\u8003\u8651\u8bed\u8a00\u5b66\u7684\u7406\u8bba\u7684\uff09\uff0c\u8fd9\u4e9bpart of speech\u79f0\u4e3a\u201c Tag sets \u201d\u3002\u90a3\u5982\u4f55\u6765\u8fdb\u884c\u521b\u9020\u5462\uff1f\u4e0b\u9762\u7ed9\u51fa\u4e86\u4e00\u4e9b\u6709\u53c2\u8003\u4ef7\u503c\u7684\u5185\u5bb9\uff1a Functional classification 7 How to Determine the Category of a Word","title":"\u5982\u4f55\u5b9a\u4e49\uff08\u521b\u9020\uff09part of speech\uff1f"},{"location":"Application/NLP/Linguistics/Part-of-speech/#_1","text":"\u6211\u4eec\u5df2\u7ecf\u4e86\u89e3\u4e86part of speech\u7684\u542b\u4e49\uff0c\u77e5\u9053\u5b83\u672c\u8d28\u4e0a\u5c31\u662f\u7c7b\u522b\u3002\u7ed9\u5b9a\u4e00\u6bb5\u8bdd\uff0c\u6211\u4eec\u4eba\u7c7b\u662f\u53ef\u4ee5\u975e\u5e38\u8f7b\u677e\u5730\u6307\u51fa\u54ea\u4e9b\u8bcd\u662f\u5c5e\u4e8e\u54ea\u79cdpart of speech\uff0c\u90a3\u5982\u4f55\u8ba9computer\u4e5f\u83b7\u5f97\u8fd9\u79cd\u80fd\u529b\u5462\uff1f\u8fd9\u5c31\u662f\u672c\u8282\u6807\u9898\u7684\u6240\u63d0\u51fa\u7684\u95ee\u9898,\uff0c\u8fd9\u4e2a\u95ee\u9898\u662fNLP\u9886\u57df\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u53eb\u505a Part-of-speech tagging \uff0c\u5728\u4e0b\u4e00\u7ae0\u8282\u7684 Part-of-speech-tagging \u4e2d\u5bf9\u6b64\u8fdb\u884c\u4e13\u95e8\u8ba8\u8bba\u3002","title":"\u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u6765\u81ea\u52a8\u5730\u8fdb\u884c\u201c\u5206\u7c7b\u201d\uff1f"},{"location":"Application/NLP/Model/BERT/BERT-implementation/","text":"","title":"BERT-implementation"},{"location":"Application/NLP/Model/BERT/BERT-paper/","text":"","title":"BERT-paper"},{"location":"Application/NLP/Model/BERT/BERT/","text":"BERT \u7ef4\u57fa\u767e\u79d1 BERT","title":"BERT"},{"location":"Application/NLP/Model/BERT/BERT/#bert","text":"","title":"BERT"},{"location":"Application/NLP/Model/BERT/BERT/#bert_1","text":"","title":"\u7ef4\u57fa\u767e\u79d1BERT"},{"location":"Application/NLP/Model/GPT/openai-GPT-2/","text":"https://github.com/openai/gpt-2 https://openai.com/blog/better-language-models/","title":"openai-GPT-2"},{"location":"Application/NLP/NLP-progress/Task-of-NLP/","text":"Task of NLP \u672c\u8282\u5bf9 NLP-progress \u4e2d\u6240\u603b\u7ed3\u7684NLP task\u8fdb\u884c\u603b\u7ed3\uff0c\u5206\u6790\u3002\u539f\u6587\u94fe\u63a5\uff1a https://coggle.it/diagram/W01z0KfTAjJ-vuxw/t/nlp-progress-repo Syntax/sentence analysis \u672c\u8282\u7684\u8fd9\u4e9btask\u90fd\u662fsentence\u7ea7\u522b\u7684\uff0c\u4e0e\u6b64\u76f8\u5bf9\u7684\u662fdocument\u7ea7\u522b\u7684\u3002\u5728sentence\u7ea7\u522b\uff0c\u4e00\u7c7b\u91cd\u8981\u7684task\u5c31\u662f\u5206\u6790sentence\u7684syntax\uff0c\u5728\u4e0b\u9762\u6240\u5217\u7684\u8fd9\u4e9bsentence\u7ea7\u522b\u7684task\u4e2d\uff0c\u540d\u5b57\u4e2d\u5305\u542b\u6709syntax\u6216parsing\u7684\u548c\u6b64\u7c7btask\u5bc6\u5207\u76f8\u5173\uff0c\u6709\u4e00\u4e2a\u95ee\u9898\u662f\uff0c\u8fd9\u4e9btask\u80fd\u5426\u5904\u7406\u590d\u5408\u53e5\uff1f Task name Explanation CCG Shallow syntax/Chunking Chunking, also known as shallow parsing, identifies continuous spans of tokens that form syntactic units such as noun phrases or verb phrases. Constituency parsing Constituency parsing aims to extract a constituency-based parse tree from a sentence that represents its syntactic structure according to a phrase structure grammar . Dependency parsing Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between \u201chead\u201d words and words, which modify those heads. Part-of-speech tagging Semantic parsing \u5305\u62ec\uff1a - AMR parsing - SQL parsing Semantic role labeling Coreference resolution Named entity recognition Named entity recognition (NER) is the task of tagging entities in text with their corresponding type. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens. \u5728 \u8bed\u8a00\u5b66 \u4e2d\uff0c\u4f7f\u7528 Grammar \u6765\u63cf\u8ff0\u8bed\u8a00\uff0c\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\uff0c parsing \u5f80\u5f80\u6307\u8fdb\u884c\u8bed\u6cd5\u5206\u6790\uff0c\u6240\u4ee5\u4e0b\u9762\u540d\u79f0\u4e2d\u5e26\u6709parsing\u7684\u90fd\u5177\u6709\u6b64\u542b\u4e49\u3002 Document analysis \u987e\u540d\u601d\u4e49\uff0c\u672c\u8282\u6240\u63cf\u8ff0\u7684task\u90fd\u662f\u6587\u6863\u7ea7\u522b\u7684\u3002 Task name Explanation Sentiment analysis Sentiment analysis is the task of classifying the polarity of a given text. Temporal processing Question answering Semantic textual similarity Open Information extraction Open Information Extraction approaches leads to creation of large Knowledge bases (KB) from the web. Text classification Summarization \u548c\u8bed\u97f3\u76f8\u5173\u7684NLP task Automatic speech recognition \u5176\u4ed6 Language modeling Common sense Natural language inference See also \u7ef4\u57fa\u767e\u79d1 Tasks of natural language processing","title":"Task-of-NLP"},{"location":"Application/NLP/NLP-progress/Task-of-NLP/#task#of#nlp","text":"\u672c\u8282\u5bf9 NLP-progress \u4e2d\u6240\u603b\u7ed3\u7684NLP task\u8fdb\u884c\u603b\u7ed3\uff0c\u5206\u6790\u3002\u539f\u6587\u94fe\u63a5\uff1a https://coggle.it/diagram/W01z0KfTAjJ-vuxw/t/nlp-progress-repo","title":"Task of NLP"},{"location":"Application/NLP/NLP-progress/Task-of-NLP/#syntaxsentence#analysis","text":"\u672c\u8282\u7684\u8fd9\u4e9btask\u90fd\u662fsentence\u7ea7\u522b\u7684\uff0c\u4e0e\u6b64\u76f8\u5bf9\u7684\u662fdocument\u7ea7\u522b\u7684\u3002\u5728sentence\u7ea7\u522b\uff0c\u4e00\u7c7b\u91cd\u8981\u7684task\u5c31\u662f\u5206\u6790sentence\u7684syntax\uff0c\u5728\u4e0b\u9762\u6240\u5217\u7684\u8fd9\u4e9bsentence\u7ea7\u522b\u7684task\u4e2d\uff0c\u540d\u5b57\u4e2d\u5305\u542b\u6709syntax\u6216parsing\u7684\u548c\u6b64\u7c7btask\u5bc6\u5207\u76f8\u5173\uff0c\u6709\u4e00\u4e2a\u95ee\u9898\u662f\uff0c\u8fd9\u4e9btask\u80fd\u5426\u5904\u7406\u590d\u5408\u53e5\uff1f Task name Explanation CCG Shallow syntax/Chunking Chunking, also known as shallow parsing, identifies continuous spans of tokens that form syntactic units such as noun phrases or verb phrases. Constituency parsing Constituency parsing aims to extract a constituency-based parse tree from a sentence that represents its syntactic structure according to a phrase structure grammar . Dependency parsing Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between \u201chead\u201d words and words, which modify those heads. Part-of-speech tagging Semantic parsing \u5305\u62ec\uff1a - AMR parsing - SQL parsing Semantic role labeling Coreference resolution Named entity recognition Named entity recognition (NER) is the task of tagging entities in text with their corresponding type. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens. \u5728 \u8bed\u8a00\u5b66 \u4e2d\uff0c\u4f7f\u7528 Grammar \u6765\u63cf\u8ff0\u8bed\u8a00\uff0c\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\uff0c parsing \u5f80\u5f80\u6307\u8fdb\u884c\u8bed\u6cd5\u5206\u6790\uff0c\u6240\u4ee5\u4e0b\u9762\u540d\u79f0\u4e2d\u5e26\u6709parsing\u7684\u90fd\u5177\u6709\u6b64\u542b\u4e49\u3002","title":"Syntax/sentence analysis"},{"location":"Application/NLP/NLP-progress/Task-of-NLP/#document#analysis","text":"\u987e\u540d\u601d\u4e49\uff0c\u672c\u8282\u6240\u63cf\u8ff0\u7684task\u90fd\u662f\u6587\u6863\u7ea7\u522b\u7684\u3002 Task name Explanation Sentiment analysis Sentiment analysis is the task of classifying the polarity of a given text. Temporal processing Question answering Semantic textual similarity Open Information extraction Open Information Extraction approaches leads to creation of large Knowledge bases (KB) from the web. Text classification Summarization","title":"Document analysis"},{"location":"Application/NLP/NLP-progress/Task-of-NLP/#nlp#task","text":"Automatic speech recognition","title":"\u548c\u8bed\u97f3\u76f8\u5173\u7684NLP task"},{"location":"Application/NLP/NLP-progress/Task-of-NLP/#_1","text":"Language modeling Common sense Natural language inference","title":"\u5176\u4ed6"},{"location":"Application/NLP/NLP-progress/Task-of-NLP/#see#also","text":"\u7ef4\u57fa\u767e\u79d1 Tasks of natural language processing","title":"See also"},{"location":"Application/NLP/NLP-progress/Distant-supervision/Distant-supervision/","text":"what is distant supervision? According to my understanding, Distant Supervisio**n is the process of specifying the **concept which the individual words of a passage, usually a sentence, are trying to convey. For example, a database maintains the structured relationship concerns( NLP, this sentence). Our distant supervision system would take as input the sentence: \"This is a sentence about NLP.\" Based on this sentence it would recognize the entities, since as a pre-processing step the sentence would have been passed through a named-entity recognizer, NLP & this sentence . Since our database has it that NLP and this sentence are related by the bond of concern(s) it would identify the input sentence as expressing the relationship Concerns(NLP, this sentence) . My questions is two fold: 1) What is the use of that? Is it that later our system might see a sentence in \"the wild\" such as That sentence is about OPP and realize that it's seen something similar to that before and thereby realize the novel relationship such that concerns(OPP, that sentence). , based only on the words/ individual tokens? 2) Does it take into account the actual words of the sentence? The verb 'is' and the adverb 'about' for instance, realizing (through WordNet or some other hyponymy system) that this is somehow similar to the higher-order concept \"concerns\"? Does anyone have some code used to generate a distant supervision system that I could look at, i.e. a system that cross references a KB, such as Freebase, and a corpus, such as the NYTimes, and produces a distant supervision database? I think that would go a long way in clarifying my conception of distant supervision. Distant supervision: supervised, semi-supervised, or both? \"Distant supervision\" is a learning scheme in which a classifier is learned given a weakly labeled training set (training data is labeled automatically based on heuristics / rules ). I think that both supervised learning, and semi-supervised learning can include such \"distant supervision\" if their labeled data is heuristically/automatically labeled. However, in this page , \"distant supervision\" is defined as \"semi-supervised learning\" (i.e., limited to \"semi-supervision\"). So my question is, does \"distant supervision\" exclusively refer to semi-supervision? In my opinion it can be applied to both supervised and semi-supervised learning. Please provide any reliable references if any. A A Distant supervision algorithm usually has the following steps: 1] It may have some labeled training data 2] It \"has\" access to a pool of unlabeled data 3] It has an operator that allows it to sample from this unlabeled data and label them and this operator is expected to be noisy in its labels 4] The algorithm then collectively utilizes the original labeled training data if it had and this new noisily labeled data to give the final output. Now, to answer your question, you as well as the site both are correct. You are looking at the 4 th step of the algorithm and notice that at the 4 th step one can use any algorithm that the user has access to. Hence your point, \"it can be applied to both supervised and semi-supervised learning\" . Whereas the site is looking at all the steps 1-4 collectively and notices that the noisily labeled data is obtained from a pool of unlabeled data (with or without the use of some pre-existing labeled training data) and this process of obtaining noisy labels is an essential component for any distant supervision algorithm, hence it is a semi-supervised algorithm. Distant supervision Most machine learning techniques require a set of training data . A traditional approach for collecting training data is to have humans label a set of documents. For example, for the marriage relation, human annotators may label the pair \"Bill Clinton\" and \"Hillary Clinton\" as a positive training example. This approach is expensive in terms of both time and money, and if our corpus is large, will not yield enough data for our algorithms to work with. And because humans make errors, the resulting training data will most likely be noisy. An alternative approach to generating training data is distant supervision . In distant supervision, we make use of an already existing database , such as Freebase or a domain-specific database, to collect examples for the relation we want to extract. We then use these examples to automatically generate our training data. For example, Freebase contains the fact that Barack Obama and Michelle Obama are married. We take this fact, and then label each pair of \"Barack Obama\" and \"Michelle Obama\" that appear in the same sentence as a positive example for our marriage relation. This way we can easily generate a large amount of (possibly noisy) training data. Applying distant supervision to get positive examples for a particular relation is easy, but generating negative examples is more of an art than a science. \u8fdc\u7a0b\u76d1\u7763\u6d45\u8c08 \u5173\u7cfb\u62bd\u53d6\u662fNER\u57fa\u7840\u4e0a\u7684\u4e00\u4e2a\u4efb\u52a1\uff0c\u5c31\u662f\u62bd\u53d6\u4e00\u4e2a\u53e5\u5b50\u4e2d\u5b9e\u4f53\u5bf9\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u5173\u7cfb\u62bd\u53d6\u5668\uff0c\u7ed9\u5b83\u4e00\u4e2a\u53e5\u5b50\u4fe9\u5b9e\u4f53\uff0c\u9996\u5148\u5b83\u9700\u8981\u77e5\u9053\u7ed9\u8fd9\u4fe9\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u6253\u4e2a\u4ec0\u4e48\u6807\u7b7e\uff0c\u6a21\u578b\u4e0d\u53ef\u80fd\u81ea\u5df1\u7ed9\u5173\u7cfb\u53d6\u540d\u5b57\uff0c\u6240\u4ee5\u80af\u5b9a\u9700\u8981\u4eba\u7528\u6807\u6ce8\u597d\u7684\u8bed\u6599\u544a\u8bc9\u4ed6\uff0c\u8fd9\u4fe9\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u53eb\u5565\u3002\u7136\u540e\u6a21\u578b\u8bad\u7ec3\u597d\u4e86\uff0c\u518d\u9047\u5230\u54ea\u4e2a\u53e5\u5b50\u91cc\u6709\u8fd9\u79cd\u5b9e\u4f53\u5bf9\uff0c\u4ed6\u5c31\u4f1a\u77e5\u9053\u662f\u8fd9\u4e2a\u5173\u7cfb\u5e76\u62bd\u51fa\u6765\u3002 \u90a3\u4e48\u95ee\u9898\u6765\u4e86\u3002\u4eba\u5de5\u6807\u6ce8\u597d\u7684\u8bed\u6599\u54ea\u91cc\u53bb\u627e\u3002\u8fd9\u662fNLP\u65b9\u5411\u4e00\u4e2a\u5de8\u5927\u7684\u6311\u6218\u3002\u81ea\u5df1\u6807\u8d39\u65f6\u8d39\u529b\uff0c\u800c\u4e14\u6570\u91cf\u5b9e\u5728\u6709\u9650\uff0c\u6570\u636e\u89c4\u6a21\u5927\u5927\u9650\u5236\u4e86\u6a21\u578b\u8bad\u7ec3\u3002 \u8fd9\u4e2a\u65f6\u5019mintz\u5927\u4f6c\u9996\u6b21\u63d0\u51fa\u4e86\u4e0d\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u5173\u7cfb\u62bd\u53d6\uff0c\u4e5f\u5c31\u662f\u628a\u8fdc\u7a0b\u76d1\u7763\u5e94\u7528\u5230\u4e86\u5173\u7cfb\u62bd\u53d6\u4e0a\u3002\u90a3\u4e48\u5230\u5e95\u4ec0\u4e48\u53eb\u505a\u8fdc\u7a0b\u76d1\u7763\uff1f\u5b83\u65e2\u4e0d\u662f\u5355\u7eaf\u7684\u4f20\u7edf\u610f\u4e49\u4e0a\u7684\u76d1\u7763\u8bed\u6599\uff0c\u5f53\u7136\u4e5f\u4e0d\u662f\u65e0\u76d1\u7763\u3002\u5b83\u662f\u4e00\u79cd\u7528KB\u53bb\u5bf9\u9f50\u6734\u7d20\u6587\u672c\u7684\u6807\u6ce8\u65b9\u6cd5\u3002 KB\u4e2d\u5df2\u7ecf\u6709\u5173\u7cfb\u540d\u548c\u5b9e\u4f53\u5bf9\u7684\u4e09\u5143\u7ec4\uff0c\u53ea\u9700\u8981\u628a\u8fd9**\u4e09\u5143\u7ec4**\u4ed8\u7ed9**\u6734\u7d20\u6587\u672c**\u4e2d\u76f8\u5e94\u7684\u53e5\u5b50\u5c31\u53ef\u4ee5\u4e86\uff0c\u90a3\u6309\u7167\u4ec0\u4e48\u539f\u5219\u4ed8\uff1f\u8fd9\u65f6\u5019z\u5927\u4f6c\u5c31\u63d0\u51fa\u4e86\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u5047\u8bbe\uff1a\u5982\u679c\u4e00\u4e2a\u53e5\u5b50\u4e2d\u542b\u6709\u4e00\u4e2a\u5173\u7cfb\u6d89\u53ca\u7684\u5b9e\u4f53\u5bf9\uff0c\u90a3\u8fd9\u4e2a\u53e5\u5b50\u5c31\u662f\u63cf\u8ff0\u7684\u8fd9\u4e2a\u5173\u7cfb\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u62a5\u7eb8\u91cc\u6240\u6709\u542b\u6709\u4e2d\u56fd\u548c\u5317\u4eac\u7684\u53e5\u5b50\uff0c\u5168\u90fd\u5047\u8bbe\u8bf4\u7684\u662f\u5317\u4eac\u662f\u4e2d\u56fd\u7684\u9996\u90fd\u3002\u7136\u540e\u628a\u8fd9\u4e9b\u53e5\u5b50\u5168\u90fd\u63d0\u53d6\u51fa\u6765\u4f5c\u4e3a\u9996\u90fd\u8fd9\u4e2a\u5173\u7cfb\u7684\u8bad\u7ec3\u8bed\u6599\uff0c\u76f4\u63a5\u6279\u91cf\u6253\u4e2a**\u6807\u7b7e**\uff0c \u5b9e\u4f53\u8bc6\u522b**\u548c**\u6807\u6ce8**\u4e00\u4e3e\u4e24\u5f97\u3002\u7136\u540e\u628a\u4e00\u4e2a**\u5173\u7cfb**\u5bf9\u5e94\u7684\u6240\u6709\u53e5\u5b50\u6253\u4e2a\u5305\uff0c\u79f0\u4f5c\u4e00\u4e2a**bag ,\u5e72\u8106\u4e00\u4e2a**bag**\u4e00\u4e2a**\u6807\u7b7e**\u3002\u8fd9\u5c31\u662f\u540e\u6765\u53c8\u6709\u7684\u5de5\u4f5c\uff0c\u88ab\u53eb\u505a**\u591a\u793a\u4f8b\u5b66\u4e60**\u3002 \u8bf4\u5230\u8fd9\u5c31\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u65b9\u6cd5\u6709\u5f88\u591a\u4e0d\u4e25\u8c28\u7684\u5730\u65b9\uff0c\u4e00\u662f\u627e\u53e5\u5b50\u65f6\u5019\uff0c\u8c01\u8bf4\u542b\u6709\u4e2d\u56fd\u548c\u5317\u4eac\u7684\u53e5\u5b50\u5168\u90fd\u662f\u9996\u90fd\u7684\u5173\u7cfb\uff0c\u6bd4\u5982\u6211\u8bf4\u4e2d\u56fd\u7684\u9762\u79ef\u6bd4\u5317\u4eac\u7684\u9762\u79ef\u5927\uff0c\u5c31\u4e0d\u662f\u3002\u5728\u4e3e\u4e2a\u901a\u7528\u7684\u4f8b\u5b50\uff0c\u4e54\u5e03\u65af\u662f\u82f9\u679c\u7684\u521b\u59cb\u4eba\uff0c\u548c\u4e54\u5e03\u65af\u5403\u4e86\u4e00\u4e2a\u82f9\u679c\uff0c\u8868\u8fbe\u7684\u5b8c\u5168\u4e0d\u662f\u4e00\u4e2a\u5173\u7cfb\u3002\u8fd9\u5c31\u8bf4\u660e\u8fdc\u7a0b\u76d1\u7763\u7684\u6570\u636e\u91cc\u5b58\u5728\u5927\u91cf\u7684\u566a\u58f0\uff0c\u6211\u4eec\u628a\u771f\u6b63\u542b\u6709\u6307\u5b9a\u5173\u7cfb\u7684\u53e5\u5b50\u53eb\u505areal instance \uff0c\u5b9e\u9645\u4e0a\u4e0d\u542b\u4efb\u4f55\u5173\u7cfb\u7684\u53e5\u5b50\u53ebNA\uff0c\u5176\u4f59\u7684\u5c31\u90fd\u662f\u53cd\u4f8b\u3002\u8fd9\u4e2a\u566a\u58f0\u95ee\u9898\u88ab\u53eb\u505awrong label \u95ee\u9898\u3002\u8fd9\u662f\u8fdc\u7a0b\u76d1\u7763\u65b9\u6cd5\u7b2c\u4e00\u4e2a\u9700\u8981\u89e3\u51b3\u7684\u5927\u95ee\u9898\u3002 \u5176\u6b21\uff0c\u7ed9bag\u6253\u6807\u7b7e\u65f6\u5019\u6839\u636e\u4ec0\u4e48\u6253\uff1f\u6309\u90a3\u4e2a\u5173\u7cfb\u62bd\u7684\u53e5\u5b50\u5c31\u51a0\u90a3\u4e2a\u5173\u7cfb\u7684\u540d\uff1f\u90a3\u4e07\u4e00\u91cc\u9762\u53ea\u6709\u4e00\u4e2areal sentence \u5176\u4f59\u5168\u662f\u53cd\u4f8b\u6216\u8005NA\u548b\u529e\uff1f\u6240\u4ee5\u7ed9\u5305\u6253\u6807\u7b7e\u7684\u7b56\u7565\u4e5f\u6709\u5f88\u591a\u79cd\uff0c\u6700\u7ecf\u5178\u7684\u5c31\u662f\u5f53\u91cc\u9762\u6240\u6709\u53e5\u5b50\u90fd\u662fNA\u7684\u65f6\u5019\uff0c\u5305\u4e5fNA\uff0c\u91cc\u9762\u53ea\u8981\u6709\u5e26\u5173\u7cfb\u7684\u53e5\u5b50\uff0c\u5c31\u628a\u5360\u6bd4\u6700\u5927\u7684\u5173\u7cfb\u6253\u7ed9\u8fd9\u4e2abag\u3002\u7136\u540e\u62ff\u53bb\u4f5c\u4e3a\u8bad\u7ec3\u8bed\u6599\u3002\u5176\u5b9e\u4e5f\u53ef\u4ee5\u5bf9bag\u91cc\u7684\u53e5\u5b50\u505a\u4e00\u4e9b\u9884\u5904\u7406\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u679c\uff0c\u6bd4\u5982\u4e24\u4e2a\u5b9e\u4f53\u5728\u53e5\u5b50\u91cc\u7684\u8ddd\u79bb\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c\u5c31\u5220\u6389\uff0c\u5b9e\u4f53\u7adf\u7136\u662f\u5176\u4ed6\u5b9e\u4f53\u7684\u5b50\u5b57\u7b26\u4e32\uff0c\u90a3\u4e0d\u662f\u778e\u5bf9\u5e94\u5417\uff0c\u4e5f\u5220\u6389\u3002\u7b49\u7b49\u3002 \u5f53\u7136\u8fdc\u7a0b\u76d1\u7763\u8fd8\u6709\u4e00\u4e9b\u5176\u4ed6\u95ee\u9898\uff0c\u6bd4\u5982\u4f60\u627e\u4e0d\u5230\u4f60\u60f3\u505a\u7684\u9886\u57df\u7684\u5408\u9002\u7684KB\u3002\u90a3\u8fd9\u79cd\u60c5\u51b5\u6211\u4e5f\u4e0d\u77e5\u9053\u80fd\u6709\u4ec0\u4e48\u529e\u6cd5\u4e86\uff0c\u5982\u679c\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u8fd8\u9700\u8981\u5177\u4f53\u95ee\u9898\u5177\u4f53\u5206\u6790\uff0cDS\u4e5f\u4e0d\u80fd\u5904\u5904\u9002\u7528\u3002 \u90a3\u4e48\u7efc\u4e0a\uff0c\u5927\u5bb6\u77e5\u9053\u4e86\u4ec0\u4e48\u662f\u5173\u7cfb\u62bd\u53d6 \uff0c\u4ec0\u4e48\u662f\u8fdc\u7a0b\u76d1\u7763\u3002\u63a5\u4e0b\u6765\u5c31\u8981\u9762\u5bf9\u521a\u624d\u63d0\u5230\u7684\u90a3\u4e9b\u6311\u6218\u4e86\uff0c\u4e3a\u4e86\u627e\u5230\u66f4\u4f18\u7684\u5173\u7cfb\u62bd\u53d6\u5668\u3002\u4e4b\u540e\u7684\u5de5\u4f5c\u4e3b\u8981\u4e5f\u96c6\u4e2d\u5728\u5bf9\u6570\u636e\u7684\u964d\u566a\uff0c\u5bf9\u6a21\u578b\u7684\u6539\u9020\u4e0a\u3002 \u8fd1\u4e9b\u5e74\u9646\u7eed\u63d0\u51fa\u4e86\u5f88\u591a\u4f18\u79c0\u7684\u65b9\u6cd5\uff0c\u5177\u4f53\u4ecb\u7ecd\u5728review\u91cc\u3002","title":"Distant-supervision"},{"location":"Application/NLP/NLP-progress/Distant-supervision/Distant-supervision/#what#is#distant#supervision","text":"According to my understanding, Distant Supervisio**n is the process of specifying the **concept which the individual words of a passage, usually a sentence, are trying to convey. For example, a database maintains the structured relationship concerns( NLP, this sentence). Our distant supervision system would take as input the sentence: \"This is a sentence about NLP.\" Based on this sentence it would recognize the entities, since as a pre-processing step the sentence would have been passed through a named-entity recognizer, NLP & this sentence . Since our database has it that NLP and this sentence are related by the bond of concern(s) it would identify the input sentence as expressing the relationship Concerns(NLP, this sentence) . My questions is two fold: 1) What is the use of that? Is it that later our system might see a sentence in \"the wild\" such as That sentence is about OPP and realize that it's seen something similar to that before and thereby realize the novel relationship such that concerns(OPP, that sentence). , based only on the words/ individual tokens? 2) Does it take into account the actual words of the sentence? The verb 'is' and the adverb 'about' for instance, realizing (through WordNet or some other hyponymy system) that this is somehow similar to the higher-order concept \"concerns\"? Does anyone have some code used to generate a distant supervision system that I could look at, i.e. a system that cross references a KB, such as Freebase, and a corpus, such as the NYTimes, and produces a distant supervision database? I think that would go a long way in clarifying my conception of distant supervision.","title":"what is distant supervision?"},{"location":"Application/NLP/NLP-progress/Distant-supervision/Distant-supervision/#distant#supervision#supervised#semi-supervised#or#both","text":"\"Distant supervision\" is a learning scheme in which a classifier is learned given a weakly labeled training set (training data is labeled automatically based on heuristics / rules ). I think that both supervised learning, and semi-supervised learning can include such \"distant supervision\" if their labeled data is heuristically/automatically labeled. However, in this page , \"distant supervision\" is defined as \"semi-supervised learning\" (i.e., limited to \"semi-supervision\"). So my question is, does \"distant supervision\" exclusively refer to semi-supervision? In my opinion it can be applied to both supervised and semi-supervised learning. Please provide any reliable references if any.","title":"Distant supervision: supervised, semi-supervised, or both?"},{"location":"Application/NLP/NLP-progress/Distant-supervision/Distant-supervision/#a","text":"A Distant supervision algorithm usually has the following steps: 1] It may have some labeled training data 2] It \"has\" access to a pool of unlabeled data 3] It has an operator that allows it to sample from this unlabeled data and label them and this operator is expected to be noisy in its labels 4] The algorithm then collectively utilizes the original labeled training data if it had and this new noisily labeled data to give the final output. Now, to answer your question, you as well as the site both are correct. You are looking at the 4 th step of the algorithm and notice that at the 4 th step one can use any algorithm that the user has access to. Hence your point, \"it can be applied to both supervised and semi-supervised learning\" . Whereas the site is looking at all the steps 1-4 collectively and notices that the noisily labeled data is obtained from a pool of unlabeled data (with or without the use of some pre-existing labeled training data) and this process of obtaining noisy labels is an essential component for any distant supervision algorithm, hence it is a semi-supervised algorithm.","title":"A"},{"location":"Application/NLP/NLP-progress/Distant-supervision/Distant-supervision/#distant#supervision","text":"Most machine learning techniques require a set of training data . A traditional approach for collecting training data is to have humans label a set of documents. For example, for the marriage relation, human annotators may label the pair \"Bill Clinton\" and \"Hillary Clinton\" as a positive training example. This approach is expensive in terms of both time and money, and if our corpus is large, will not yield enough data for our algorithms to work with. And because humans make errors, the resulting training data will most likely be noisy. An alternative approach to generating training data is distant supervision . In distant supervision, we make use of an already existing database , such as Freebase or a domain-specific database, to collect examples for the relation we want to extract. We then use these examples to automatically generate our training data. For example, Freebase contains the fact that Barack Obama and Michelle Obama are married. We take this fact, and then label each pair of \"Barack Obama\" and \"Michelle Obama\" that appear in the same sentence as a positive example for our marriage relation. This way we can easily generate a large amount of (possibly noisy) training data. Applying distant supervision to get positive examples for a particular relation is easy, but generating negative examples is more of an art than a science.","title":"Distant supervision"},{"location":"Application/NLP/NLP-progress/Distant-supervision/Distant-supervision/#_1","text":"\u5173\u7cfb\u62bd\u53d6\u662fNER\u57fa\u7840\u4e0a\u7684\u4e00\u4e2a\u4efb\u52a1\uff0c\u5c31\u662f\u62bd\u53d6\u4e00\u4e2a\u53e5\u5b50\u4e2d\u5b9e\u4f53\u5bf9\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u5173\u7cfb\u62bd\u53d6\u5668\uff0c\u7ed9\u5b83\u4e00\u4e2a\u53e5\u5b50\u4fe9\u5b9e\u4f53\uff0c\u9996\u5148\u5b83\u9700\u8981\u77e5\u9053\u7ed9\u8fd9\u4fe9\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u6253\u4e2a\u4ec0\u4e48\u6807\u7b7e\uff0c\u6a21\u578b\u4e0d\u53ef\u80fd\u81ea\u5df1\u7ed9\u5173\u7cfb\u53d6\u540d\u5b57\uff0c\u6240\u4ee5\u80af\u5b9a\u9700\u8981\u4eba\u7528\u6807\u6ce8\u597d\u7684\u8bed\u6599\u544a\u8bc9\u4ed6\uff0c\u8fd9\u4fe9\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u53eb\u5565\u3002\u7136\u540e\u6a21\u578b\u8bad\u7ec3\u597d\u4e86\uff0c\u518d\u9047\u5230\u54ea\u4e2a\u53e5\u5b50\u91cc\u6709\u8fd9\u79cd\u5b9e\u4f53\u5bf9\uff0c\u4ed6\u5c31\u4f1a\u77e5\u9053\u662f\u8fd9\u4e2a\u5173\u7cfb\u5e76\u62bd\u51fa\u6765\u3002 \u90a3\u4e48\u95ee\u9898\u6765\u4e86\u3002\u4eba\u5de5\u6807\u6ce8\u597d\u7684\u8bed\u6599\u54ea\u91cc\u53bb\u627e\u3002\u8fd9\u662fNLP\u65b9\u5411\u4e00\u4e2a\u5de8\u5927\u7684\u6311\u6218\u3002\u81ea\u5df1\u6807\u8d39\u65f6\u8d39\u529b\uff0c\u800c\u4e14\u6570\u91cf\u5b9e\u5728\u6709\u9650\uff0c\u6570\u636e\u89c4\u6a21\u5927\u5927\u9650\u5236\u4e86\u6a21\u578b\u8bad\u7ec3\u3002 \u8fd9\u4e2a\u65f6\u5019mintz\u5927\u4f6c\u9996\u6b21\u63d0\u51fa\u4e86\u4e0d\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u5173\u7cfb\u62bd\u53d6\uff0c\u4e5f\u5c31\u662f\u628a\u8fdc\u7a0b\u76d1\u7763\u5e94\u7528\u5230\u4e86\u5173\u7cfb\u62bd\u53d6\u4e0a\u3002\u90a3\u4e48\u5230\u5e95\u4ec0\u4e48\u53eb\u505a\u8fdc\u7a0b\u76d1\u7763\uff1f\u5b83\u65e2\u4e0d\u662f\u5355\u7eaf\u7684\u4f20\u7edf\u610f\u4e49\u4e0a\u7684\u76d1\u7763\u8bed\u6599\uff0c\u5f53\u7136\u4e5f\u4e0d\u662f\u65e0\u76d1\u7763\u3002\u5b83\u662f\u4e00\u79cd\u7528KB\u53bb\u5bf9\u9f50\u6734\u7d20\u6587\u672c\u7684\u6807\u6ce8\u65b9\u6cd5\u3002 KB\u4e2d\u5df2\u7ecf\u6709\u5173\u7cfb\u540d\u548c\u5b9e\u4f53\u5bf9\u7684\u4e09\u5143\u7ec4\uff0c\u53ea\u9700\u8981\u628a\u8fd9**\u4e09\u5143\u7ec4**\u4ed8\u7ed9**\u6734\u7d20\u6587\u672c**\u4e2d\u76f8\u5e94\u7684\u53e5\u5b50\u5c31\u53ef\u4ee5\u4e86\uff0c\u90a3\u6309\u7167\u4ec0\u4e48\u539f\u5219\u4ed8\uff1f\u8fd9\u65f6\u5019z\u5927\u4f6c\u5c31\u63d0\u51fa\u4e86\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u5047\u8bbe\uff1a\u5982\u679c\u4e00\u4e2a\u53e5\u5b50\u4e2d\u542b\u6709\u4e00\u4e2a\u5173\u7cfb\u6d89\u53ca\u7684\u5b9e\u4f53\u5bf9\uff0c\u90a3\u8fd9\u4e2a\u53e5\u5b50\u5c31\u662f\u63cf\u8ff0\u7684\u8fd9\u4e2a\u5173\u7cfb\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u62a5\u7eb8\u91cc\u6240\u6709\u542b\u6709\u4e2d\u56fd\u548c\u5317\u4eac\u7684\u53e5\u5b50\uff0c\u5168\u90fd\u5047\u8bbe\u8bf4\u7684\u662f\u5317\u4eac\u662f\u4e2d\u56fd\u7684\u9996\u90fd\u3002\u7136\u540e\u628a\u8fd9\u4e9b\u53e5\u5b50\u5168\u90fd\u63d0\u53d6\u51fa\u6765\u4f5c\u4e3a\u9996\u90fd\u8fd9\u4e2a\u5173\u7cfb\u7684\u8bad\u7ec3\u8bed\u6599\uff0c\u76f4\u63a5\u6279\u91cf\u6253\u4e2a**\u6807\u7b7e**\uff0c \u5b9e\u4f53\u8bc6\u522b**\u548c**\u6807\u6ce8**\u4e00\u4e3e\u4e24\u5f97\u3002\u7136\u540e\u628a\u4e00\u4e2a**\u5173\u7cfb**\u5bf9\u5e94\u7684\u6240\u6709\u53e5\u5b50\u6253\u4e2a\u5305\uff0c\u79f0\u4f5c\u4e00\u4e2a**bag ,\u5e72\u8106\u4e00\u4e2a**bag**\u4e00\u4e2a**\u6807\u7b7e**\u3002\u8fd9\u5c31\u662f\u540e\u6765\u53c8\u6709\u7684\u5de5\u4f5c\uff0c\u88ab\u53eb\u505a**\u591a\u793a\u4f8b\u5b66\u4e60**\u3002 \u8bf4\u5230\u8fd9\u5c31\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u65b9\u6cd5\u6709\u5f88\u591a\u4e0d\u4e25\u8c28\u7684\u5730\u65b9\uff0c\u4e00\u662f\u627e\u53e5\u5b50\u65f6\u5019\uff0c\u8c01\u8bf4\u542b\u6709\u4e2d\u56fd\u548c\u5317\u4eac\u7684\u53e5\u5b50\u5168\u90fd\u662f\u9996\u90fd\u7684\u5173\u7cfb\uff0c\u6bd4\u5982\u6211\u8bf4\u4e2d\u56fd\u7684\u9762\u79ef\u6bd4\u5317\u4eac\u7684\u9762\u79ef\u5927\uff0c\u5c31\u4e0d\u662f\u3002\u5728\u4e3e\u4e2a\u901a\u7528\u7684\u4f8b\u5b50\uff0c\u4e54\u5e03\u65af\u662f\u82f9\u679c\u7684\u521b\u59cb\u4eba\uff0c\u548c\u4e54\u5e03\u65af\u5403\u4e86\u4e00\u4e2a\u82f9\u679c\uff0c\u8868\u8fbe\u7684\u5b8c\u5168\u4e0d\u662f\u4e00\u4e2a\u5173\u7cfb\u3002\u8fd9\u5c31\u8bf4\u660e\u8fdc\u7a0b\u76d1\u7763\u7684\u6570\u636e\u91cc\u5b58\u5728\u5927\u91cf\u7684\u566a\u58f0\uff0c\u6211\u4eec\u628a\u771f\u6b63\u542b\u6709\u6307\u5b9a\u5173\u7cfb\u7684\u53e5\u5b50\u53eb\u505areal instance \uff0c\u5b9e\u9645\u4e0a\u4e0d\u542b\u4efb\u4f55\u5173\u7cfb\u7684\u53e5\u5b50\u53ebNA\uff0c\u5176\u4f59\u7684\u5c31\u90fd\u662f\u53cd\u4f8b\u3002\u8fd9\u4e2a\u566a\u58f0\u95ee\u9898\u88ab\u53eb\u505awrong label \u95ee\u9898\u3002\u8fd9\u662f\u8fdc\u7a0b\u76d1\u7763\u65b9\u6cd5\u7b2c\u4e00\u4e2a\u9700\u8981\u89e3\u51b3\u7684\u5927\u95ee\u9898\u3002 \u5176\u6b21\uff0c\u7ed9bag\u6253\u6807\u7b7e\u65f6\u5019\u6839\u636e\u4ec0\u4e48\u6253\uff1f\u6309\u90a3\u4e2a\u5173\u7cfb\u62bd\u7684\u53e5\u5b50\u5c31\u51a0\u90a3\u4e2a\u5173\u7cfb\u7684\u540d\uff1f\u90a3\u4e07\u4e00\u91cc\u9762\u53ea\u6709\u4e00\u4e2areal sentence \u5176\u4f59\u5168\u662f\u53cd\u4f8b\u6216\u8005NA\u548b\u529e\uff1f\u6240\u4ee5\u7ed9\u5305\u6253\u6807\u7b7e\u7684\u7b56\u7565\u4e5f\u6709\u5f88\u591a\u79cd\uff0c\u6700\u7ecf\u5178\u7684\u5c31\u662f\u5f53\u91cc\u9762\u6240\u6709\u53e5\u5b50\u90fd\u662fNA\u7684\u65f6\u5019\uff0c\u5305\u4e5fNA\uff0c\u91cc\u9762\u53ea\u8981\u6709\u5e26\u5173\u7cfb\u7684\u53e5\u5b50\uff0c\u5c31\u628a\u5360\u6bd4\u6700\u5927\u7684\u5173\u7cfb\u6253\u7ed9\u8fd9\u4e2abag\u3002\u7136\u540e\u62ff\u53bb\u4f5c\u4e3a\u8bad\u7ec3\u8bed\u6599\u3002\u5176\u5b9e\u4e5f\u53ef\u4ee5\u5bf9bag\u91cc\u7684\u53e5\u5b50\u505a\u4e00\u4e9b\u9884\u5904\u7406\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u679c\uff0c\u6bd4\u5982\u4e24\u4e2a\u5b9e\u4f53\u5728\u53e5\u5b50\u91cc\u7684\u8ddd\u79bb\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c\u5c31\u5220\u6389\uff0c\u5b9e\u4f53\u7adf\u7136\u662f\u5176\u4ed6\u5b9e\u4f53\u7684\u5b50\u5b57\u7b26\u4e32\uff0c\u90a3\u4e0d\u662f\u778e\u5bf9\u5e94\u5417\uff0c\u4e5f\u5220\u6389\u3002\u7b49\u7b49\u3002 \u5f53\u7136\u8fdc\u7a0b\u76d1\u7763\u8fd8\u6709\u4e00\u4e9b\u5176\u4ed6\u95ee\u9898\uff0c\u6bd4\u5982\u4f60\u627e\u4e0d\u5230\u4f60\u60f3\u505a\u7684\u9886\u57df\u7684\u5408\u9002\u7684KB\u3002\u90a3\u8fd9\u79cd\u60c5\u51b5\u6211\u4e5f\u4e0d\u77e5\u9053\u80fd\u6709\u4ec0\u4e48\u529e\u6cd5\u4e86\uff0c\u5982\u679c\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u8fd8\u9700\u8981\u5177\u4f53\u95ee\u9898\u5177\u4f53\u5206\u6790\uff0cDS\u4e5f\u4e0d\u80fd\u5904\u5904\u9002\u7528\u3002 \u90a3\u4e48\u7efc\u4e0a\uff0c\u5927\u5bb6\u77e5\u9053\u4e86\u4ec0\u4e48\u662f\u5173\u7cfb\u62bd\u53d6 \uff0c\u4ec0\u4e48\u662f\u8fdc\u7a0b\u76d1\u7763\u3002\u63a5\u4e0b\u6765\u5c31\u8981\u9762\u5bf9\u521a\u624d\u63d0\u5230\u7684\u90a3\u4e9b\u6311\u6218\u4e86\uff0c\u4e3a\u4e86\u627e\u5230\u66f4\u4f18\u7684\u5173\u7cfb\u62bd\u53d6\u5668\u3002\u4e4b\u540e\u7684\u5de5\u4f5c\u4e3b\u8981\u4e5f\u96c6\u4e2d\u5728\u5bf9\u6570\u636e\u7684\u964d\u566a\uff0c\u5bf9\u6a21\u578b\u7684\u6539\u9020\u4e0a\u3002 \u8fd1\u4e9b\u5e74\u9646\u7eed\u63d0\u51fa\u4e86\u5f88\u591a\u4f18\u79c0\u7684\u65b9\u6cd5\uff0c\u5177\u4f53\u4ecb\u7ecd\u5728review\u91cc\u3002","title":"\u8fdc\u7a0b\u76d1\u7763\u6d45\u8c08"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/","text":"Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks Abstract Two problems arise when using distant supervision for relation extraction . First, in this method, an already existing knowledge base is heuristically aligned to texts, and the alignment results are treated as labeled data. However, the heuristic alignment can fail, resulting in wrong label problem. In addition, in previous approaches, statistical models have typically been applied to ad hoc\uff08\u7279\u5b9a\u7684\uff09 features. The noise that originates from the feature extraction process can cause poor performance. In this paper, we propose a novel model dubbed the Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address these two problems. To solve the first problem, distant supervised relation extraction is treated as a multi-instance problem in which the uncertainty of instance labels is taken into account. To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features. Experiments show that our method is effective and outperforms several competitive baseline methods. 1 Introduction In relation extraction, one challenge that is faced when building a machine learning system is the generation of training examples. One common technique for coping with this difficulty is distant supervision (Mintz et al., 2009) which assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way. Figure 1 shows an example of the automatic labeling of data through distant supervision. In this example, Apple and Steve Jobs are two related entities in Freebase 1 . All sentences that contain these two entities are selected as training instances. The distant supervision strategy is an effective method of automatically labeling training data. However, it has two major shortcomings when used for relation extraction. First, the distant supervision assumption is too strong and causes the wrong label problem. A sentence that mentions two entities does not necessarily express their relation in a knowledge base. It is possible that these two entities may simply share the same topic. For instance, the upper sentence indeed expresses the \u201ccompany/founders\u201d relation in Figure1. The lower sentence, however, does not express this relation but is still selected as a training instance. This will hinder the performance of a model trained on such noisy data. Second, previous methods (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011) have typically applied supervised models to elaborately designed features when obtained the labeled data through distant supervision. These features are often derived from preexisting Natural Language Processing (NLP) tools. Since errors inevitably\uff08\u4e0d\u53ef\u907f\u514d\u7684\uff09 exist in NLP tools, the use of traditional features leads to error propagation or accumulation. Distant supervised relation extraction generally addresses corpora from the Web, including many informal texts. Figure 2 shows the sentence length distribution of a benchmark distant supervision dataset that was developed by Riedel et al. (2010). Approximately half of the sentences are longer than 40 words. McDonald and Nivre (2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem , the training set consists of many bags , and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level . In the learning process, the uncertainty of instance labels can be taken into account; this alleviates\uff08\u51cf\u8f7b\uff09 the wrong label problem . To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features . Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Applein Figure1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information . These approaches usually consider both internal and external contexts . A sentence is inherently divided into three segments according to the two given entities. The internal context includes the characters inside the two entities, and the external context involves the characters around the two entities (Zhang et al., 2006). Clearly, single max pooling is not sufficient to capture such structural information . To capture structural and other latent\uff08\u9690\u85cf\u7684\uff0c\u6f5c\u5728\u7684\uff09 information, we divide the convolution results into three segments based on the positions of the two given entities and devise a piecewise max pooling layer instead of the single max pooling layer. The piecewise max pooling procedure returns the maximum value in each segment instead of a single maximum value over the entire sentence. Thus, it is expected to exhibit superior performance compared with traditional methods. The contributions of this paper can be summarized as follows. We explore the feasibility of performing distant supervised relation extraction without hand-designed features. PCNNS are proposed to automatically learn features without complicated NLP preprocessing. To address the wrong label problem, we develop innovative solutions that incorporate multi-instance learning into the PCNNS for distant supervised relation extraction . In the proposed network, we devise a piecewise max pooling layer , which aims to capture structural information between two entities. 2 Related Work Relation extraction is one of the most important topics in NLP. Many approaches to relation extraction have been developed, such as bootstrapping, unsupervised relation discovery and supervised classification. Supervised approaches are the most commonly used methods for relation extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm , relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning . The term \u2018multi-instance learning was coined by (Dietterich et al., 1997) while investigating the problem of predicting drug activity. In multi-instance learning, the uncertainty of instance labels can be taken into account. The focus of multi-instance learning is to discriminate among the bags. These methods have been shown to be effective for relation extraction. However, their performance depends strongly on the quality of the designed features. Most existing studies have concentrated on extracting features to identify the relations between two entities. Previous methods can be generally categorized into two types: feature-based methods and kernel-based methods . In feature-based methods, a diverse set of strategies is exploited to convert classification clues (e.g., sequences, parse trees) into feature vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernel-based methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel(Qianetal., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival\uff08\u590d\u5174\uff09 of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction . Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a particularly interesting topic. Zhang and Zhou (2006) successfully incorporated multi-instance learning into traditional Backpropagation (BP) and Radial Basis Function (RBF) networks and optimized these networks by minimizing a sum-of-squares error function. In contrast to their method, we define the objective function based on the cross-entropy principle. 3 Methodology Distant supervised relation extraction is formulated as multi-instance problem. In this section, we present innovative solutions that incorporate multi-instance learning into a convolutional neural network to fulfill this task. PCNNs are proposed for the automatic learning of features without complicated NLP preprocessing. Figure 3 shows our neural network architecture for distant supervised relation extraction. It illustrates the procedure that handles one instance of a bag. This procedure includes four main parts: Vector Representation, Convolution, Piecewise Max Pooling and Softmax Output. We describe these parts in detail below. Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extrac- tion, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. 3.1 Vector Representation The inputs of our network are raw word tokens. When using neural networks , we typically transform word tokens into low-dimensional vectors . In our method, each input word token is transformed into a vector by looking up pre-trained word embeddings . Moreover, we use position features (PFs) to specify entity pairs, which are also transformed into vectors by looking up position embeddings . 3.1.1 Word Embeddings Word embeddings are distributed representations of words that map each word in a text to a \u2018k\u2019- dimensional real-valued vector. They have recently been shown to capture both semantic\uff08\u8bed\u4e49\uff09 and syntactic\uff08\u53e5\u6cd5\uff09 information about words very well, setting performance records in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori\uff08\u5148\u9a8c\uff09 has become common practice for enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings . Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence\uff08\u540c\u73b0\uff09 structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013). In this paper, we use the Skip-gram model (Mikolov et al., 2013) to train word embeddings . 3.1.2 Position Embeddings In relation extraction, we focus on assigning labels to entity pairs . Similar to Zeng et al. (2014), we use PFs to specify entity pairs. A PF is defined as the combination of the relative distances from the current word to e_1 e_1 and e_2 e_2 . For instance, in the following example, the relative distances from son to e_1 e_1 (Kojo Annan) and e_2 e_2 (Kofi Annan) are 3 and -2, respectively. Two position embedding matrixes ( PF_1 PF_1 and PF_2 PF_2 ) are randomly initialized. We then transform the relative distances into real valued vectors by looking up the position embedding matrixes . In the example shown in Figure 3, it is assumed that the size of the word embedding is d_w = 4 d_w = 4 and that the size of the position embedding is d_p = 1 d_p = 1 . In combined word embeddings and position embeddings , the vector representation part transforms an instance into a matrix S \\in \\mathbb R^{ s \\times d} S \\in \\mathbb R^{ s \\times d} , where s s is the sentence length and d = d_w + d_p \u2217 2 d = d_w + d_p \u2217 2 . The matrix S S is subsequently fed into the convolution part. SUMMARY : \u5c06\u4e00\u4e2asentence\u8f6c\u6362\u4e3a\u4e00\u4e2amatrix\uff1b 3.2 Convolution In relation extraction, an input sentence that is marked as containing the target entities corresponds only to a relation type ; it does not predict labels for each word. Thus, it might be necessary to utilize all local features and perform this prediction globally. When using a neural network, the convolution approach is a natural means of merging all these features (Collobert et al., 2011). Convolution is an operation between a vector of weights, w , and a vector of inputs that is treated as a sequence q . The weights matrix w is regarded as the filter for the convolution. In the example shown in Figure 3, we assume that the length of the filter is w (w = 3) w (w = 3) ; thus, w $ \\in \\mathbb R^m (m = w \\times d) \uff08 \uff08 w \\times d \u8868\u793a\u7684\u662f \u8868\u793a\u7684\u662f w \u884c \u884c d \u5217\uff0c\u5b83\u8868\u793a \u5217\uff0c\u5b83\u8868\u793a w$\u662f\u4e00\u4e2a\u77e9\u9635\uff09. We consider S to be a sequence \\{ \\textbf q_1 , \\textbf q_2 ,\u00b7\u00b7\u00b7 , \\textbf q_s \\} \\{ \\textbf q_1 , \\textbf q_2 ,\u00b7\u00b7\u00b7 , \\textbf q_s \\} , where $ \\textbf q_i \\in \\mathbb R^d$ . In general, let q_{i:j} q_{i:j} refer to the concatenation of q_i q_i to q_j q_j . The convolution operation involves taking the dot product of w with each w w -gram in the sequence q to obtain another sequence \\textbf c \\in \\mathbb R^{s+w\u22121} \\textbf c \\in \\mathbb R^{s+w\u22121} $$ c_j = \\textbf w \\textbf q_{j\u2212w+1:j} \\tag 1\\ $$ where the index j j ranges from 1 to s+w\u22121 s+w\u22121 . Out-of-range input values q_i q_i , where i < 1 i < 1 or i > s i > s , are taken to be zero. SUMMARY : dot produce\u610f\u5473\u7740\u7ed3\u679c\u662f\u4e00\u4e2a\u5f20\u91cf\uff1b SUMMARY : \u6ce8\u610f\uff0c j - (j - w + 1) = w j - (j - w + 1) = w SUMMARY : **filter**\u7684\u957f\u5ea6 w w \u8868\u793a\u7684\u662f\u5b83\u4e00\u6b21\u626b\u63cf w w \u4e2a\u8bcd SUMMARY : **c**\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u5b83\u7684\u957f\u5ea6\u662f s+w\u22121 s+w\u22121 \uff0c\u6211\u731c\u6d4b\u5b83\u7684\u542b\u4e49\u662ffilter\u6cbf\u7740**q**\u8fdb\u884c\u6ed1\u52a8\uff0c\u7b2c\u4e00\u6b21\u5b83\u4ec5\u4ec5\u5403\u4e0b\u4e00\u4e2aword\uff0c\u7b2c\u4e8c\u6b21\u5403\u4e0b\u4e24\u4e2aword\uff0c\u7b2c\u4e09\u6b21\u5403\u4e0b3\u4e2aword\uff0c\u540e\u9762\u6bcf\u4e00\u6b21\u90fd\u5403\u4e0b3\u4e2aword\u3002 The ability to capture different features typically requires the use of multiple filters (or feature maps ) in the convolution . Under the assumption that we use n filters ($\\textbf W = {\\textbf w_1 ,\\textbf w_2 ,\u00b7\u00b7\u00b7 ,\\textbf w_n } $), the convolution operation can be expressed as follows: $$ c_{ij} = \\textbf w_i \\textbf q_{j\u2212w+1:j} \\space \\space \\space 1 \u2264 i \u2264 n \\tag 2 $$ The convolution result is a matrix C = \\{\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n \\} \\in \\mathbb R^{n \\times (s+w\u22121)} C = \\{\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n \\} \\in \\mathbb R^{n \\times (s+w\u22121)} . Figure 3 shows an example in which we use 3 different filters in the convolution procedure. SUMMARY : \u8fd9\u5c31\u662f\u5178\u578b\u7684 Conv1D 3.3 Piecewise Max Pooling The size of the convolution output matrix C \\in \\mathbb R^{n \\times (s+w\u22121)} C \\in \\mathbb R^{n \\times (s+w\u22121)} depends on the number of tokens s s in the sentence that is fed into the network. To apply subsequent layers, the features that are extracted by the convolution layer must be combined such that they are independent of the sentence length . In traditional Convolution Neural Networks (CNNs), max pooling operations are often applied for this purpose (Collobert et al., 2011; Zeng et al., 2014). This type of pooling scheme naturally addresses variable sentence lengths. The idea is to capture the most significant features (with the highest values) in each feature map . However, despite the widespread use of single max pooling , this approach is insufficient for relation extraction . As described in the first section, single max pooling reduces the size of the hidden layers too rapidly and is too coarse to capture fine-grained features for relation extraction. In addition, single max pooling is not sufficient to capture the structural information between two entities. In relation extraction, an input sentence can be divided into three segments based on the two selected entities. Therefore, we propose a piecewise max pooling procedure that returns the maximum value in each segment instead of a single maximum value. As shown in Figure 3, the output of each convolutional filter c_i c_i is divided into three segments {c_{i1} ,c_{i2} ,c_{i3} } {c_{i1} ,c_{i2} ,c_{i3} } by Kojo Annan and KofiA nnan. The piecewise max pooling procedure can be expressed as follows: $$ p_{ij}=max(c_{ij}) \\space \\space 1 \u2264 i \u2264 n \\space \\space 1 \u2264 j \u2264 3 \\tag 3 $$ SUMMARY : p_{ij} p_{ij} \u662f\u4e00\u4e2a\u5f20\u91cf SUMMARY : \u5b9e\u73b0\u4e0a\u7684\u4e00\u4e2a\u95ee\u9898\uff0c C = {\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n } \\in \\mathbb R^{n \\times (s+w\u22121)} C = {\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n } \\in \\mathbb R^{n \\times (s+w\u22121)} \uff0c\u663e\u7136 p_{ij} \\in \\mathbb R^{(s+w\u22121)} p_{ij} \\in \\mathbb R^{(s+w\u22121)} \uff0c\u5b83\u7684\u7ef4\u5ea6\u548c\u8f93\u5165\u7684\u53e5\u5b50\u7684\u7ef4\u5ea6\u5e76\u4e0d\u76f8\u540c\uff0c\u90a3\u5b83\u5982\u4f55\u5b9e\u73b0each convolutional filter c_i c_i is divided into three segments {c_{i1} ,c_{i2} ,c_{i3} } {c_{i1} ,c_{i2} ,c_{i3} } by Kojo Annan and KofiA nnan\uff1f For the output of each convolutional filter , we can obtain a 3-dimensional vector $ \\textbf p_i = {p_{i1} ,p_{i2} ,p_{i3} }$. We then concatenate all vectors \\textbf p_{1:n} \\textbf p_{1:n} and apply a non-linear function, such as the hyperbolic tangent. Finally, the piecewise max pooling procedure outputs a vector: $$ \\textbf g = tanh(\\textbf p_{1:n}) \\tag 4 $$ where g \\in R^{3n} g \\in R^{3n} . The size of g g is fixed and is no longer related to the sentence length. SUMMARY : g \\in R^{3n} g \\in R^{3n} \u4e2d3\u7684\u542b\u4e49\u662f\u4e09\u6bb5\uff0c n n \u8868\u793a\u7684\u662ffilter\u7684\u4e2a\u6570\uff1b 3.4 Softmax Output To compute the confidence of each relation, the feature vector g g is fed into a softmax classifier. $$ \\textbf o = \\textbf W_1 \\textbf g + b \\tag 5 $$ \\textbf W_1 \\in \\mathbb R^{n1 \\times 3n} \\textbf W_1 \\in \\mathbb R^{n1 \\times 3n} is the transformation matrix, and \\textbf o \\in \\mathbb R^{n1} \\textbf o \\in \\mathbb R^{n1} is the final output of the network, where n_1 n_1 is equal to the number of possible relation types for the relation extraction system. We employ dropout (Hinton et al., 2012) on the penultimate\uff08\u5012\u6570\u7b2c\u4e8c\uff09 layer for regularization. Dropout prevents the co-adaptation of hidden units by randomly dropping out a proportion p p of the hidden units during forward computing. We first apply a \u201cmasking\u201d operation (\\textbf g \\circ \\textbf r) (\\textbf g \\circ \\textbf r) on g , where r is a vector of Bernoulli random variables with probability p p of being 1. Eq.(5) becomes: $$ \\textbf o = \\textbf W_1 (\\textbf g \\circ \\textbf r) + b \\tag 6 $$ Each output can then be interpreted as the confidence score of the corresponding relation. This score can be interpreted as a conditional probability by applying a softmax operation (see Section 3.5). In the test procedure, the learned weight vectors are scaled by p p such that $ \\hat{\\textbf W_1} = p \\textbf W_1$ and are used (without dropout) to score unseen instances. 3.5 Multi-instance Learning In order to alleviate the wrong label problem, we use multi-instance learning for PCNNs. The PCNNs-based relation extraction can be stated as a quintuple \\theta = (\\textbf E, \\textbf {PF_1} , \\textbf {PF_2} , \\textbf W, \\textbf W_1 ) \\theta = (\\textbf E, \\textbf {PF_1} , \\textbf {PF_2} , \\textbf W, \\textbf W_1 ) \uff08 \\textbf E \\textbf E represents the word embeddings\uff09 . The input to the network is a bag . Suppose that there are T bags {M_1 ,M_2 ,\u00b7\u00b7\u00b7 ,M_T } {M_1 ,M_2 ,\u00b7\u00b7\u00b7 ,M_T } and that the i i -th bag contains q_i q_i instances M_i = \\{m_i^1 ,m_i^2 ,\u00b7\u00b7\u00b7 ,m_i^{q_i}\\} M_i = \\{m_i^1 ,m_i^2 ,\u00b7\u00b7\u00b7 ,m_i^{q_i}\\} . The objective of multi-instance learning is to predict the labels of the unseen bags. In this paper, all instances in a bag are considered independently. Given an input instance m_i^j m_i^j , the network with the parameter \\theta \\theta outputs a vector \\textbf o \\textbf o , where the r r -th component o_r o_r corresponds to the score associated with relation r r . To obtain the conditional probability p(r \\mid m,\\theta) p(r \\mid m,\\theta) , we apply a softmax operation over all relation types: $$ p(r \\mid m_i^j;\\theta)=\\frac {e^{o_r}} {\\sum_{k=1}^{n1} e^{o_k}} \\tag 7 $$ The objective of multi-instance learning is to discriminate bags rather than instances. To do so, we must define the objective function on the bags. Given all ( T T ) training bags (M_i ,y_i ) (M_i ,y_i ) , we can define the objective function using cross-entropy at the bag level as follows: J(\\theta)=\\sum_{i=1}^T \\log {p(y_i \\mid m_i^j; \\theta)} \\tag 8 J(\\theta)=\\sum_{i=1}^T \\log {p(y_i \\mid m_i^j; \\theta)} \\tag 8 where j j is constrained as follows: $$ j^\\star = \\arg \\max \\limits_{w_1} p(y_i \\mid m_i^j ; \\theta) \\space \\space 1 \u2264 j \u2264 q_i \\tag 9 $$ Using this defined objective function, we maximize J(\\theta) J(\\theta) through stochastic gradient descent over shuffled mini-batches with the Adadelta (Zeiler, 2012) update rule. The entire training procedure is described in Algorithm 1. Algorithm 1 Multi-instance learning 1: Initialize \\theta \\theta . Partition the bags into mini-batches of size b_s b_s . 2: Randomly choose a mini-batch, and feed the bags into the network one by one. 3: Find the j j -th instance $m_i^j \\space (1 \u2264 i \u2264 b_s ) $ in each bag according to Eq. (9). 4: Update \\theta \\theta based on the gradients of m_i^j (1 \u2264i \u2264 b_s ) m_i^j (1 \u2264i \u2264 b_s ) via Adadelta. 5: Repeat steps 2-4 until either convergence or the maximum number of epochs is reached. From the introduction presented above, we know that the traditional backpropagation algorithm modifies a network in accordance with all training instances, whereas backpropagation with multi-instance learning modifies a network based on bags. Thus, our method captures the nature of distant supervised relation extraction, in which some training instances will inevitably be incorrectly labeled. When a trained PCNN is used for prediction, a bag is positively labeled if and only if the output of the network on at least one of its instances is assigned a positive label. SUMMARY : \u5728\u6a21\u578b\u8fdb\u884c\u4f7f\u7528\u7684\u65f6\u5019\uff0c\u96be\u9053\u4e5f\u662f\u6309\u7167bag\u7684\u65b9\u5f0f\u6765\u8fdb\u884c\u8f93\u5165\u7684\uff1f\u7136\u540e\u4ece\u6bcf\u4e2abag\u4e2d\u9009\u62e9\u51fa\u4e00\u4e2avalid instance\uff1b 4 Experiments Our experiments are intended to provide evidence that supports the following hypothesis: automat- ically learning features using PCNNs with multiinstance learning can lead to an increase in performance. To this end, we first introduce the dataset and evaluation metrics used. Next, we test several variants via cross-validation to determine the parameters to be used in our experiments. We then compare the performance of our method to those of several traditional methods. Finally, we evaluate the effects of piecewise max pooling and multi-instance learning ^3 ^3 . With regard to the position feature, our experiments yield the same positive results described in Zeng et al. (2014). Because the position feature is not the main contribution of this paper, we do not present the results without the position feature.","title":"[Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks](http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP203.pdf)"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#distant#supervision#for#relation#extraction#via#piecewise#convolutional#neural#networks","text":"","title":"Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#abstract","text":"Two problems arise when using distant supervision for relation extraction . First, in this method, an already existing knowledge base is heuristically aligned to texts, and the alignment results are treated as labeled data. However, the heuristic alignment can fail, resulting in wrong label problem. In addition, in previous approaches, statistical models have typically been applied to ad hoc\uff08\u7279\u5b9a\u7684\uff09 features. The noise that originates from the feature extraction process can cause poor performance. In this paper, we propose a novel model dubbed the Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address these two problems. To solve the first problem, distant supervised relation extraction is treated as a multi-instance problem in which the uncertainty of instance labels is taken into account. To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features. Experiments show that our method is effective and outperforms several competitive baseline methods.","title":"Abstract"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#1#introduction","text":"In relation extraction, one challenge that is faced when building a machine learning system is the generation of training examples. One common technique for coping with this difficulty is distant supervision (Mintz et al., 2009) which assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way. Figure 1 shows an example of the automatic labeling of data through distant supervision. In this example, Apple and Steve Jobs are two related entities in Freebase 1 . All sentences that contain these two entities are selected as training instances. The distant supervision strategy is an effective method of automatically labeling training data. However, it has two major shortcomings when used for relation extraction. First, the distant supervision assumption is too strong and causes the wrong label problem. A sentence that mentions two entities does not necessarily express their relation in a knowledge base. It is possible that these two entities may simply share the same topic. For instance, the upper sentence indeed expresses the \u201ccompany/founders\u201d relation in Figure1. The lower sentence, however, does not express this relation but is still selected as a training instance. This will hinder the performance of a model trained on such noisy data. Second, previous methods (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011) have typically applied supervised models to elaborately designed features when obtained the labeled data through distant supervision. These features are often derived from preexisting Natural Language Processing (NLP) tools. Since errors inevitably\uff08\u4e0d\u53ef\u907f\u514d\u7684\uff09 exist in NLP tools, the use of traditional features leads to error propagation or accumulation. Distant supervised relation extraction generally addresses corpora from the Web, including many informal texts. Figure 2 shows the sentence length distribution of a benchmark distant supervision dataset that was developed by Riedel et al. (2010). Approximately half of the sentences are longer than 40 words. McDonald and Nivre (2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem , the training set consists of many bags , and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level . In the learning process, the uncertainty of instance labels can be taken into account; this alleviates\uff08\u51cf\u8f7b\uff09 the wrong label problem . To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features . Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Applein Figure1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information . These approaches usually consider both internal and external contexts . A sentence is inherently divided into three segments according to the two given entities. The internal context includes the characters inside the two entities, and the external context involves the characters around the two entities (Zhang et al., 2006). Clearly, single max pooling is not sufficient to capture such structural information . To capture structural and other latent\uff08\u9690\u85cf\u7684\uff0c\u6f5c\u5728\u7684\uff09 information, we divide the convolution results into three segments based on the positions of the two given entities and devise a piecewise max pooling layer instead of the single max pooling layer. The piecewise max pooling procedure returns the maximum value in each segment instead of a single maximum value over the entire sentence. Thus, it is expected to exhibit superior performance compared with traditional methods. The contributions of this paper can be summarized as follows. We explore the feasibility of performing distant supervised relation extraction without hand-designed features. PCNNS are proposed to automatically learn features without complicated NLP preprocessing. To address the wrong label problem, we develop innovative solutions that incorporate multi-instance learning into the PCNNS for distant supervised relation extraction . In the proposed network, we devise a piecewise max pooling layer , which aims to capture structural information between two entities.","title":"1 Introduction"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#2#related#work","text":"Relation extraction is one of the most important topics in NLP. Many approaches to relation extraction have been developed, such as bootstrapping, unsupervised relation discovery and supervised classification. Supervised approaches are the most commonly used methods for relation extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm , relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning . The term \u2018multi-instance learning was coined by (Dietterich et al., 1997) while investigating the problem of predicting drug activity. In multi-instance learning, the uncertainty of instance labels can be taken into account. The focus of multi-instance learning is to discriminate among the bags. These methods have been shown to be effective for relation extraction. However, their performance depends strongly on the quality of the designed features. Most existing studies have concentrated on extracting features to identify the relations between two entities. Previous methods can be generally categorized into two types: feature-based methods and kernel-based methods . In feature-based methods, a diverse set of strategies is exploited to convert classification clues (e.g., sequences, parse trees) into feature vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernel-based methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel(Qianetal., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival\uff08\u590d\u5174\uff09 of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction . Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a particularly interesting topic. Zhang and Zhou (2006) successfully incorporated multi-instance learning into traditional Backpropagation (BP) and Radial Basis Function (RBF) networks and optimized these networks by minimizing a sum-of-squares error function. In contrast to their method, we define the objective function based on the cross-entropy principle.","title":"2 Related Work"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#3#methodology","text":"Distant supervised relation extraction is formulated as multi-instance problem. In this section, we present innovative solutions that incorporate multi-instance learning into a convolutional neural network to fulfill this task. PCNNs are proposed for the automatic learning of features without complicated NLP preprocessing. Figure 3 shows our neural network architecture for distant supervised relation extraction. It illustrates the procedure that handles one instance of a bag. This procedure includes four main parts: Vector Representation, Convolution, Piecewise Max Pooling and Softmax Output. We describe these parts in detail below. Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extrac- tion, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan.","title":"3 Methodology"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#31#vector#representation","text":"The inputs of our network are raw word tokens. When using neural networks , we typically transform word tokens into low-dimensional vectors . In our method, each input word token is transformed into a vector by looking up pre-trained word embeddings . Moreover, we use position features (PFs) to specify entity pairs, which are also transformed into vectors by looking up position embeddings .","title":"3.1 Vector Representation"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#311#word#embeddings","text":"Word embeddings are distributed representations of words that map each word in a text to a \u2018k\u2019- dimensional real-valued vector. They have recently been shown to capture both semantic\uff08\u8bed\u4e49\uff09 and syntactic\uff08\u53e5\u6cd5\uff09 information about words very well, setting performance records in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori\uff08\u5148\u9a8c\uff09 has become common practice for enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings . Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence\uff08\u540c\u73b0\uff09 structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013). In this paper, we use the Skip-gram model (Mikolov et al., 2013) to train word embeddings .","title":"3.1.1 Word Embeddings"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#312#position#embeddings","text":"In relation extraction, we focus on assigning labels to entity pairs . Similar to Zeng et al. (2014), we use PFs to specify entity pairs. A PF is defined as the combination of the relative distances from the current word to e_1 e_1 and e_2 e_2 . For instance, in the following example, the relative distances from son to e_1 e_1 (Kojo Annan) and e_2 e_2 (Kofi Annan) are 3 and -2, respectively. Two position embedding matrixes ( PF_1 PF_1 and PF_2 PF_2 ) are randomly initialized. We then transform the relative distances into real valued vectors by looking up the position embedding matrixes . In the example shown in Figure 3, it is assumed that the size of the word embedding is d_w = 4 d_w = 4 and that the size of the position embedding is d_p = 1 d_p = 1 . In combined word embeddings and position embeddings , the vector representation part transforms an instance into a matrix S \\in \\mathbb R^{ s \\times d} S \\in \\mathbb R^{ s \\times d} , where s s is the sentence length and d = d_w + d_p \u2217 2 d = d_w + d_p \u2217 2 . The matrix S S is subsequently fed into the convolution part. SUMMARY : \u5c06\u4e00\u4e2asentence\u8f6c\u6362\u4e3a\u4e00\u4e2amatrix\uff1b","title":"3.1.2 Position Embeddings"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#32#convolution","text":"In relation extraction, an input sentence that is marked as containing the target entities corresponds only to a relation type ; it does not predict labels for each word. Thus, it might be necessary to utilize all local features and perform this prediction globally. When using a neural network, the convolution approach is a natural means of merging all these features (Collobert et al., 2011). Convolution is an operation between a vector of weights, w , and a vector of inputs that is treated as a sequence q . The weights matrix w is regarded as the filter for the convolution. In the example shown in Figure 3, we assume that the length of the filter is w (w = 3) w (w = 3) ; thus, w $ \\in \\mathbb R^m (m = w \\times d) \uff08 \uff08 w \\times d \u8868\u793a\u7684\u662f \u8868\u793a\u7684\u662f w \u884c \u884c d \u5217\uff0c\u5b83\u8868\u793a \u5217\uff0c\u5b83\u8868\u793a w$\u662f\u4e00\u4e2a\u77e9\u9635\uff09. We consider S to be a sequence \\{ \\textbf q_1 , \\textbf q_2 ,\u00b7\u00b7\u00b7 , \\textbf q_s \\} \\{ \\textbf q_1 , \\textbf q_2 ,\u00b7\u00b7\u00b7 , \\textbf q_s \\} , where $ \\textbf q_i \\in \\mathbb R^d$ . In general, let q_{i:j} q_{i:j} refer to the concatenation of q_i q_i to q_j q_j . The convolution operation involves taking the dot product of w with each w w -gram in the sequence q to obtain another sequence \\textbf c \\in \\mathbb R^{s+w\u22121} \\textbf c \\in \\mathbb R^{s+w\u22121} $$ c_j = \\textbf w \\textbf q_{j\u2212w+1:j} \\tag 1\\ $$ where the index j j ranges from 1 to s+w\u22121 s+w\u22121 . Out-of-range input values q_i q_i , where i < 1 i < 1 or i > s i > s , are taken to be zero. SUMMARY : dot produce\u610f\u5473\u7740\u7ed3\u679c\u662f\u4e00\u4e2a\u5f20\u91cf\uff1b SUMMARY : \u6ce8\u610f\uff0c j - (j - w + 1) = w j - (j - w + 1) = w SUMMARY : **filter**\u7684\u957f\u5ea6 w w \u8868\u793a\u7684\u662f\u5b83\u4e00\u6b21\u626b\u63cf w w \u4e2a\u8bcd SUMMARY : **c**\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u5b83\u7684\u957f\u5ea6\u662f s+w\u22121 s+w\u22121 \uff0c\u6211\u731c\u6d4b\u5b83\u7684\u542b\u4e49\u662ffilter\u6cbf\u7740**q**\u8fdb\u884c\u6ed1\u52a8\uff0c\u7b2c\u4e00\u6b21\u5b83\u4ec5\u4ec5\u5403\u4e0b\u4e00\u4e2aword\uff0c\u7b2c\u4e8c\u6b21\u5403\u4e0b\u4e24\u4e2aword\uff0c\u7b2c\u4e09\u6b21\u5403\u4e0b3\u4e2aword\uff0c\u540e\u9762\u6bcf\u4e00\u6b21\u90fd\u5403\u4e0b3\u4e2aword\u3002 The ability to capture different features typically requires the use of multiple filters (or feature maps ) in the convolution . Under the assumption that we use n filters ($\\textbf W = {\\textbf w_1 ,\\textbf w_2 ,\u00b7\u00b7\u00b7 ,\\textbf w_n } $), the convolution operation can be expressed as follows: $$ c_{ij} = \\textbf w_i \\textbf q_{j\u2212w+1:j} \\space \\space \\space 1 \u2264 i \u2264 n \\tag 2 $$ The convolution result is a matrix C = \\{\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n \\} \\in \\mathbb R^{n \\times (s+w\u22121)} C = \\{\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n \\} \\in \\mathbb R^{n \\times (s+w\u22121)} . Figure 3 shows an example in which we use 3 different filters in the convolution procedure. SUMMARY : \u8fd9\u5c31\u662f\u5178\u578b\u7684 Conv1D","title":"3.2 Convolution"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#33#piecewise#max#pooling","text":"The size of the convolution output matrix C \\in \\mathbb R^{n \\times (s+w\u22121)} C \\in \\mathbb R^{n \\times (s+w\u22121)} depends on the number of tokens s s in the sentence that is fed into the network. To apply subsequent layers, the features that are extracted by the convolution layer must be combined such that they are independent of the sentence length . In traditional Convolution Neural Networks (CNNs), max pooling operations are often applied for this purpose (Collobert et al., 2011; Zeng et al., 2014). This type of pooling scheme naturally addresses variable sentence lengths. The idea is to capture the most significant features (with the highest values) in each feature map . However, despite the widespread use of single max pooling , this approach is insufficient for relation extraction . As described in the first section, single max pooling reduces the size of the hidden layers too rapidly and is too coarse to capture fine-grained features for relation extraction. In addition, single max pooling is not sufficient to capture the structural information between two entities. In relation extraction, an input sentence can be divided into three segments based on the two selected entities. Therefore, we propose a piecewise max pooling procedure that returns the maximum value in each segment instead of a single maximum value. As shown in Figure 3, the output of each convolutional filter c_i c_i is divided into three segments {c_{i1} ,c_{i2} ,c_{i3} } {c_{i1} ,c_{i2} ,c_{i3} } by Kojo Annan and KofiA nnan. The piecewise max pooling procedure can be expressed as follows: $$ p_{ij}=max(c_{ij}) \\space \\space 1 \u2264 i \u2264 n \\space \\space 1 \u2264 j \u2264 3 \\tag 3 $$ SUMMARY : p_{ij} p_{ij} \u662f\u4e00\u4e2a\u5f20\u91cf SUMMARY : \u5b9e\u73b0\u4e0a\u7684\u4e00\u4e2a\u95ee\u9898\uff0c C = {\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n } \\in \\mathbb R^{n \\times (s+w\u22121)} C = {\\textbf c_1 ,\\textbf c_2 ,\u00b7\u00b7\u00b7 ,\\textbf c_n } \\in \\mathbb R^{n \\times (s+w\u22121)} \uff0c\u663e\u7136 p_{ij} \\in \\mathbb R^{(s+w\u22121)} p_{ij} \\in \\mathbb R^{(s+w\u22121)} \uff0c\u5b83\u7684\u7ef4\u5ea6\u548c\u8f93\u5165\u7684\u53e5\u5b50\u7684\u7ef4\u5ea6\u5e76\u4e0d\u76f8\u540c\uff0c\u90a3\u5b83\u5982\u4f55\u5b9e\u73b0each convolutional filter c_i c_i is divided into three segments {c_{i1} ,c_{i2} ,c_{i3} } {c_{i1} ,c_{i2} ,c_{i3} } by Kojo Annan and KofiA nnan\uff1f For the output of each convolutional filter , we can obtain a 3-dimensional vector $ \\textbf p_i = {p_{i1} ,p_{i2} ,p_{i3} }$. We then concatenate all vectors \\textbf p_{1:n} \\textbf p_{1:n} and apply a non-linear function, such as the hyperbolic tangent. Finally, the piecewise max pooling procedure outputs a vector: $$ \\textbf g = tanh(\\textbf p_{1:n}) \\tag 4 $$ where g \\in R^{3n} g \\in R^{3n} . The size of g g is fixed and is no longer related to the sentence length. SUMMARY : g \\in R^{3n} g \\in R^{3n} \u4e2d3\u7684\u542b\u4e49\u662f\u4e09\u6bb5\uff0c n n \u8868\u793a\u7684\u662ffilter\u7684\u4e2a\u6570\uff1b","title":"3.3 Piecewise Max Pooling"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#34#softmax#output","text":"To compute the confidence of each relation, the feature vector g g is fed into a softmax classifier. $$ \\textbf o = \\textbf W_1 \\textbf g + b \\tag 5 $$ \\textbf W_1 \\in \\mathbb R^{n1 \\times 3n} \\textbf W_1 \\in \\mathbb R^{n1 \\times 3n} is the transformation matrix, and \\textbf o \\in \\mathbb R^{n1} \\textbf o \\in \\mathbb R^{n1} is the final output of the network, where n_1 n_1 is equal to the number of possible relation types for the relation extraction system. We employ dropout (Hinton et al., 2012) on the penultimate\uff08\u5012\u6570\u7b2c\u4e8c\uff09 layer for regularization. Dropout prevents the co-adaptation of hidden units by randomly dropping out a proportion p p of the hidden units during forward computing. We first apply a \u201cmasking\u201d operation (\\textbf g \\circ \\textbf r) (\\textbf g \\circ \\textbf r) on g , where r is a vector of Bernoulli random variables with probability p p of being 1. Eq.(5) becomes: $$ \\textbf o = \\textbf W_1 (\\textbf g \\circ \\textbf r) + b \\tag 6 $$ Each output can then be interpreted as the confidence score of the corresponding relation. This score can be interpreted as a conditional probability by applying a softmax operation (see Section 3.5). In the test procedure, the learned weight vectors are scaled by p p such that $ \\hat{\\textbf W_1} = p \\textbf W_1$ and are used (without dropout) to score unseen instances.","title":"3.4 Softmax Output"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#35#multi-instance#learning","text":"In order to alleviate the wrong label problem, we use multi-instance learning for PCNNs. The PCNNs-based relation extraction can be stated as a quintuple \\theta = (\\textbf E, \\textbf {PF_1} , \\textbf {PF_2} , \\textbf W, \\textbf W_1 ) \\theta = (\\textbf E, \\textbf {PF_1} , \\textbf {PF_2} , \\textbf W, \\textbf W_1 ) \uff08 \\textbf E \\textbf E represents the word embeddings\uff09 . The input to the network is a bag . Suppose that there are T bags {M_1 ,M_2 ,\u00b7\u00b7\u00b7 ,M_T } {M_1 ,M_2 ,\u00b7\u00b7\u00b7 ,M_T } and that the i i -th bag contains q_i q_i instances M_i = \\{m_i^1 ,m_i^2 ,\u00b7\u00b7\u00b7 ,m_i^{q_i}\\} M_i = \\{m_i^1 ,m_i^2 ,\u00b7\u00b7\u00b7 ,m_i^{q_i}\\} . The objective of multi-instance learning is to predict the labels of the unseen bags. In this paper, all instances in a bag are considered independently. Given an input instance m_i^j m_i^j , the network with the parameter \\theta \\theta outputs a vector \\textbf o \\textbf o , where the r r -th component o_r o_r corresponds to the score associated with relation r r . To obtain the conditional probability p(r \\mid m,\\theta) p(r \\mid m,\\theta) , we apply a softmax operation over all relation types: $$ p(r \\mid m_i^j;\\theta)=\\frac {e^{o_r}} {\\sum_{k=1}^{n1} e^{o_k}} \\tag 7 $$ The objective of multi-instance learning is to discriminate bags rather than instances. To do so, we must define the objective function on the bags. Given all ( T T ) training bags (M_i ,y_i ) (M_i ,y_i ) , we can define the objective function using cross-entropy at the bag level as follows: J(\\theta)=\\sum_{i=1}^T \\log {p(y_i \\mid m_i^j; \\theta)} \\tag 8 J(\\theta)=\\sum_{i=1}^T \\log {p(y_i \\mid m_i^j; \\theta)} \\tag 8 where j j is constrained as follows: $$ j^\\star = \\arg \\max \\limits_{w_1} p(y_i \\mid m_i^j ; \\theta) \\space \\space 1 \u2264 j \u2264 q_i \\tag 9 $$ Using this defined objective function, we maximize J(\\theta) J(\\theta) through stochastic gradient descent over shuffled mini-batches with the Adadelta (Zeiler, 2012) update rule. The entire training procedure is described in Algorithm 1. Algorithm 1 Multi-instance learning 1: Initialize \\theta \\theta . Partition the bags into mini-batches of size b_s b_s . 2: Randomly choose a mini-batch, and feed the bags into the network one by one. 3: Find the j j -th instance $m_i^j \\space (1 \u2264 i \u2264 b_s ) $ in each bag according to Eq. (9). 4: Update \\theta \\theta based on the gradients of m_i^j (1 \u2264i \u2264 b_s ) m_i^j (1 \u2264i \u2264 b_s ) via Adadelta. 5: Repeat steps 2-4 until either convergence or the maximum number of epochs is reached. From the introduction presented above, we know that the traditional backpropagation algorithm modifies a network in accordance with all training instances, whereas backpropagation with multi-instance learning modifies a network based on bags. Thus, our method captures the nature of distant supervised relation extraction, in which some training instances will inevitably be incorrectly labeled. When a trained PCNN is used for prediction, a bag is positively labeled if and only if the output of the network on at least one of its instances is assigned a positive label. SUMMARY : \u5728\u6a21\u578b\u8fdb\u884c\u4f7f\u7528\u7684\u65f6\u5019\uff0c\u96be\u9053\u4e5f\u662f\u6309\u7167bag\u7684\u65b9\u5f0f\u6765\u8fdb\u884c\u8f93\u5165\u7684\uff1f\u7136\u540e\u4ece\u6bcf\u4e2abag\u4e2d\u9009\u62e9\u51fa\u4e00\u4e2avalid instance\uff1b","title":"3.5 Multi-instance Learning"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2015-Distant%20Supervision%20for%20Relation%20Extraction%20via%20Piecewise%20Convolutio/#4#experiments","text":"Our experiments are intended to provide evidence that supports the following hypothesis: automat- ically learning features using PCNNs with multiinstance learning can lead to an increase in performance. To this end, we first introduce the dataset and evaluation metrics used. Next, we test several variants via cross-validation to determine the parameters to be used in our experiments. We then compare the performance of our method to those of several traditional methods. Finally, we evaluate the effects of piecewise max pooling and multi-instance learning ^3 ^3 . With regard to the position feature, our experiments yield the same positive results described in Zeng et al. (2014). Because the position feature is not the main contribution of this paper, we do not present the results without the position feature.","title":"4 Experiments"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/","text":"Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions Abstract Distant supervision for relation extraction is an efficient method to scale relation extraction to very large corpora which contains thousands of relations. However, the existing approaches have flaws on selecting valid instances and lack of background knowledge about the entities . In this paper, we propose a sentence-level attention model to select the valid instances , which makes full use of the supervision information from knowledge bases . And we extract entity descriptions from Freebase and Wikipedia pages to supplement background knowledge for our task. The background knowledge not only provides more information for predicting relations, but also brings better entity representations for the attention module. We conduct three experiments on a widely used dataset and the experimental results show that our approach outperforms all the baseline systems significantly. SUMMARY : \u63d0\u51fa\u4e24\u4e2a\u60f3\u6cd5\uff1a a sentence-level attention model to select the valid instances extract entity descriptions from Freebase and Wikipedia pages to supplement background knowledge for our task SUMMARY : \u5982\u4f55\u7406\u89e3**supervision information**\uff1f\u5176\u5b9e\u4ed6\u5c31\u662f\u540e\u9762\u6240\u5c5e\u7684valid sentence\uff0c\u4e5f\u5c31\u662f\u6b63\u786e\u63cf\u8ff0\u4e86\u5173\u7cfb\u7684\u53e5\u5b50\uff1b Introduction Relation extraction (RE) under distant supervision aims to predict semantic relations between pairs of entities in texts supervised by knowledge bases (KBs). It heuristically\uff08\u542f\u53d1\u5f0f\u5730\uff09 aligns entities in texts to a given KB and uses this alignment to learn a relation extractor . The training data are labelled automatically as follows: for a triplet r(e_1 ,e_2 )^1 r(e_1 ,e_2 )^1 in the KB, all sentences that mention both entities e_1 e_1 and e_2 e_2 are regarded as the training instances of relation r r . Figure 1 shows the training instances of triplet /location/location/contains (Nevada, Las Vegas) . The sentences from S_1 S_1 to S_4 S_4 all mention entities Nevada and Las Vegas, so they are all training instances of the relation /location/location/contains . The task is crucial for many Natural Language Processing (NLP) applications such as automatic knowledge completion and question-answering. SUMMARY : \u5728attention\u4e2d\uff0calign\u662f\u4e5f\u7ecf\u5e38\u88ab\u63d0\u53ca\u7684\u8bcd\uff1b Figure 1: Training instances of the triplet /location/location/contains (Nevada, Las Vegas). The low part shows the descriptions of Nevada and Las Vegas. Distant supervision strategy is an effective method of automatically labeling training data, however, it is plagued by the wrong label problem (Riedel,Yao,and McCallum 2010). A sentence that mentions two entities may not express the relation which links them in a KB. It is possible that the two entities may just appear in the same sentence because they are related to the same topic. For example, in Figure 1, sentences S_2 S_2 and S_4 S_4 both mention Nevada and Las Vegas , but they do not express the relation /location/location/contains . Mintz et al., (2009) ignored the problem and extracted features from all\uff08\u6240\u6709\u7684\uff0c\u65e0\u8bba\u5b83\u4eec\u662f\u5426\u8868\u8fbe\u4e86\u8fd9\u79cd\u5173\u7cfb\uff09 the sentences to feed a relation classifier . Riedel, Yao, and McCallum, (2010) proposed the expressed- at-least-once^2 expressed- at-least-once^2 \uff08 If two entities participate in a relation , at least one sentence that mentions these two entities might express that relation.\uff09 assumption, and used an undirected graphical model to predict which sentences express the relation . Based on the Multi-Instance Learning (Dietterich, Lathrop, and Lozano-P\u00e9rez 1997), Hoffmann et al., (2011) and Surdeanu et al., (2012) also used a probabilistic, graphical model to select sentences and added overlapping relations to their relation extraction systems. Zeng et al., (2015) combined multi-instance learning (MIL) and piecewise convolutional neuraln etworks (PCNNs) to choose the most likely valid sentence and predict relations, which achieved state-of-the-art performance on the dataset developed by (Riedel, Yao, and McCallum 2010). In multi-instance learning paradigm, for the triplet r(e_1 ,e_2 ) r(e_1 ,e_2 ) , all the sentences which mention both e_1 e_1 and e_2 e_2 constitute a bag and the relation r r is the label of the bag. Although the above approaches have achieved high performance on RE under distant supervision , they have two main flaws. More specifically, (1) A bag may contain multiple valid sentences . For example, in Figure 1, sentences S_1 S_1 and S_3 S_3 both express the relation /location/location/contains . The probabilistic, graphical models (Riedel, Yao, and McCallum 2010; Hoffmann et al. 2011; Surdeanu et al. 2012) had considered the observation, but the features they designed to choose valid sentences are often derived from preexisting NLP tools which suffer from error propagation and accumulation (Bach and Badaskar 2007). Zeng et al., (2015) extracted sentence features by PCNNs instead of relying on the traditional NLP tools and achieved state-of-the-art performance. However, in the learning process, its MIL module only selected one sentence which has the maximum probability to be a valid candidate . This strategy doesn\u2019t make full use of the supervision information . Therefore, integrating the merits\uff08\u4f18\u70b9\uff09 (considering multiple valid sentences and extracting features by neural networks) of the two approaches may be promising; (2) The entity descriptions , which can provide helpful background knowledge , are useful resources for our task. For example, in Figure 1, it\u2019s difficult to decide which relation the sentence S_1 S_1 expresses without the information that Nevada is a state and Las Vegas is a city. When lacking the background knowledge , Nevada may be a government official\u2019s name and S_1 S_1 doesn\u2019t express the relation /location/location/contains . Therefore, the descriptions are beneficial for the task. Unfortunately, none of the existing work uses them for RE under distant supervision . To select multiple valid sentences, we propose a sentence-level attention model based on PCNNs (denoted by APCNNs ), which extracts sentence features using PCNNs and learns the weights of sentences by the attention module . We hope that the attention mechanism is able to selectively focus on the relevant sentences through assigning higher weights for valid sentences and lower weights for the invalid ones . In this way, APCNNs could recognize multiple valid sentences in a bag . Concretely, motivated by TransE (Bordes et al. 2013) which modeled a triplet r(e_1 ,e_2 ) r(e_1 ,e_2 ) with e_1 + r \\approx e_2 e_1 + r \\approx e_2 (the bold, italic letters represent vectors ), we use (e_1 \u2212 e_2 ) (e_1 \u2212 e_2 ) to represent the relation between e_1 e_1 and e_2 e_2 in sentences (we will show more explanations later). For a bag , we first use PCNNs to extract each sentence\u2019s feature vector v_ {sen} v_ {sen} , then compute the attention weight for each sentence through a hidden layer with the concatenation\uff08\u4e32\u8054\uff09 way [ v_{sen} ;e_1 \u2212 e_2 ] [ v_{sen} ;e_1 \u2212 e_2 ] (Luong, Pham, and Manning 2015). At last, the weighted sum of all sentence feature vectors is the bag\u2019s features. In addition, to encode more background knowledge into our model , we use convolutional neural networks (CNNs) to extract entity descriptions\u2019 feature vectors and let them be close to the corresponding entity vectors via adding constraints on the objective function of APCNNs (called APCNNs+D, where \u201cD\u201d refers to descriptions). The background knowledge not only provides more information for predicting relations , but also brings better entity representations for the attention module . Therefore, our main contributions in this paper are: (1)We introduce a sentence-level attention model to select multiple valid sentences in a bag. This strategy makes full use of the supervision information; (2) We use entity descriptions to provide background knowledge for predicting relations and improving entity representations; (3) We conduct experiments on a widely used dataset^3 dataset^3 and achieve state-of-the-art performance. Task Definition In multi-instance learning paradigm , all sentences labeled by a triplet constitute a bag and each sentence is called an instance. Suppose that there are N N bags {B_1 ,B_2 ,\u00b7\u00b7\u00b7 , B_N } {B_1 ,B_2 ,\u00b7\u00b7\u00b7 , B_N } in the training set and that the i i -th bag contains q_i q_i instances B_i = {b_1^i ,b_2^i ,\u00b7\u00b7\u00b7 ,b_{q_i}^i } (i = 1,\u00b7\u00b7\u00b7 ,N) B_i = {b_1^i ,b_2^i ,\u00b7\u00b7\u00b7 ,b_{q_i}^i } (i = 1,\u00b7\u00b7\u00b7 ,N) . The objective of multi-instance learning is to predict the labels of the unseen bags . We need to learn a relation extractor based on the training data and then use it to predict relations for test set. Specifically, for a bag in B_j = {b_1^j ,b_2^j ,\u00b7\u00b7\u00b7 ,b_{q_j}^j } (j = 1,\u00b7\u00b7\u00b7 ,N) B_j = {b_1^j ,b_2^j ,\u00b7\u00b7\u00b7 ,b_{q_j}^j } (j = 1,\u00b7\u00b7\u00b7 ,N) training set, we need to extract features from the bag (from one or several valid instances) and then use them to train a classifier. For a bag in test set , we also need to extract features in the same way and use the classifier to predict the relation between the given entity pair. Methodology In this section, we present the main innovative solutions including sentence-level attention and entity descriptions . Sentence-level attention makes our model be able to select multiple valid instances for training, so that we can make full use of the supervision information . Entity descriptions provide more background knowledge about the entities , which could improve the performance of our model and bring better entity representations for attention module . Figure 2 shows the neural network architecture of our model APCNNs . It consists of two parts: PCNNs Module and Sentence-level Attention Module . PCNNs Module includes Vector Representation, Convolution Piecewise Max-pooling. Sentence-level Attention Module is composed of Attention Layer Softmax Classifier. We describe these parts in details below. PCNNs Module This module is used to extract feature vector of an instance (sentence) in a bag. Vector Representation Word Embeddings Position Embeddings Convolution Piecewise Max-pooling Sentence-level Attention Module Experiments Dataset Evaluation Metrics Experimental Results and Analysis Conclusions and Future Work","title":"[Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions](https://pdfs.semanticscholar.org/b8da/823ad81e3b8e5b80d82f86129fdb1d9132e7.pdf?_ga=2.78898385.436512546.1571998669-788894272.1569305268)"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#distant#supervision#for#relation#extraction#with#sentence-level#attention#and#entity#descriptions","text":"","title":"Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#abstract","text":"Distant supervision for relation extraction is an efficient method to scale relation extraction to very large corpora which contains thousands of relations. However, the existing approaches have flaws on selecting valid instances and lack of background knowledge about the entities . In this paper, we propose a sentence-level attention model to select the valid instances , which makes full use of the supervision information from knowledge bases . And we extract entity descriptions from Freebase and Wikipedia pages to supplement background knowledge for our task. The background knowledge not only provides more information for predicting relations, but also brings better entity representations for the attention module. We conduct three experiments on a widely used dataset and the experimental results show that our approach outperforms all the baseline systems significantly. SUMMARY : \u63d0\u51fa\u4e24\u4e2a\u60f3\u6cd5\uff1a a sentence-level attention model to select the valid instances extract entity descriptions from Freebase and Wikipedia pages to supplement background knowledge for our task SUMMARY : \u5982\u4f55\u7406\u89e3**supervision information**\uff1f\u5176\u5b9e\u4ed6\u5c31\u662f\u540e\u9762\u6240\u5c5e\u7684valid sentence\uff0c\u4e5f\u5c31\u662f\u6b63\u786e\u63cf\u8ff0\u4e86\u5173\u7cfb\u7684\u53e5\u5b50\uff1b","title":"Abstract"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#introduction","text":"Relation extraction (RE) under distant supervision aims to predict semantic relations between pairs of entities in texts supervised by knowledge bases (KBs). It heuristically\uff08\u542f\u53d1\u5f0f\u5730\uff09 aligns entities in texts to a given KB and uses this alignment to learn a relation extractor . The training data are labelled automatically as follows: for a triplet r(e_1 ,e_2 )^1 r(e_1 ,e_2 )^1 in the KB, all sentences that mention both entities e_1 e_1 and e_2 e_2 are regarded as the training instances of relation r r . Figure 1 shows the training instances of triplet /location/location/contains (Nevada, Las Vegas) . The sentences from S_1 S_1 to S_4 S_4 all mention entities Nevada and Las Vegas, so they are all training instances of the relation /location/location/contains . The task is crucial for many Natural Language Processing (NLP) applications such as automatic knowledge completion and question-answering. SUMMARY : \u5728attention\u4e2d\uff0calign\u662f\u4e5f\u7ecf\u5e38\u88ab\u63d0\u53ca\u7684\u8bcd\uff1b Figure 1: Training instances of the triplet /location/location/contains (Nevada, Las Vegas). The low part shows the descriptions of Nevada and Las Vegas. Distant supervision strategy is an effective method of automatically labeling training data, however, it is plagued by the wrong label problem (Riedel,Yao,and McCallum 2010). A sentence that mentions two entities may not express the relation which links them in a KB. It is possible that the two entities may just appear in the same sentence because they are related to the same topic. For example, in Figure 1, sentences S_2 S_2 and S_4 S_4 both mention Nevada and Las Vegas , but they do not express the relation /location/location/contains . Mintz et al., (2009) ignored the problem and extracted features from all\uff08\u6240\u6709\u7684\uff0c\u65e0\u8bba\u5b83\u4eec\u662f\u5426\u8868\u8fbe\u4e86\u8fd9\u79cd\u5173\u7cfb\uff09 the sentences to feed a relation classifier . Riedel, Yao, and McCallum, (2010) proposed the expressed- at-least-once^2 expressed- at-least-once^2 \uff08 If two entities participate in a relation , at least one sentence that mentions these two entities might express that relation.\uff09 assumption, and used an undirected graphical model to predict which sentences express the relation . Based on the Multi-Instance Learning (Dietterich, Lathrop, and Lozano-P\u00e9rez 1997), Hoffmann et al., (2011) and Surdeanu et al., (2012) also used a probabilistic, graphical model to select sentences and added overlapping relations to their relation extraction systems. Zeng et al., (2015) combined multi-instance learning (MIL) and piecewise convolutional neuraln etworks (PCNNs) to choose the most likely valid sentence and predict relations, which achieved state-of-the-art performance on the dataset developed by (Riedel, Yao, and McCallum 2010). In multi-instance learning paradigm, for the triplet r(e_1 ,e_2 ) r(e_1 ,e_2 ) , all the sentences which mention both e_1 e_1 and e_2 e_2 constitute a bag and the relation r r is the label of the bag. Although the above approaches have achieved high performance on RE under distant supervision , they have two main flaws. More specifically, (1) A bag may contain multiple valid sentences . For example, in Figure 1, sentences S_1 S_1 and S_3 S_3 both express the relation /location/location/contains . The probabilistic, graphical models (Riedel, Yao, and McCallum 2010; Hoffmann et al. 2011; Surdeanu et al. 2012) had considered the observation, but the features they designed to choose valid sentences are often derived from preexisting NLP tools which suffer from error propagation and accumulation (Bach and Badaskar 2007). Zeng et al., (2015) extracted sentence features by PCNNs instead of relying on the traditional NLP tools and achieved state-of-the-art performance. However, in the learning process, its MIL module only selected one sentence which has the maximum probability to be a valid candidate . This strategy doesn\u2019t make full use of the supervision information . Therefore, integrating the merits\uff08\u4f18\u70b9\uff09 (considering multiple valid sentences and extracting features by neural networks) of the two approaches may be promising; (2) The entity descriptions , which can provide helpful background knowledge , are useful resources for our task. For example, in Figure 1, it\u2019s difficult to decide which relation the sentence S_1 S_1 expresses without the information that Nevada is a state and Las Vegas is a city. When lacking the background knowledge , Nevada may be a government official\u2019s name and S_1 S_1 doesn\u2019t express the relation /location/location/contains . Therefore, the descriptions are beneficial for the task. Unfortunately, none of the existing work uses them for RE under distant supervision . To select multiple valid sentences, we propose a sentence-level attention model based on PCNNs (denoted by APCNNs ), which extracts sentence features using PCNNs and learns the weights of sentences by the attention module . We hope that the attention mechanism is able to selectively focus on the relevant sentences through assigning higher weights for valid sentences and lower weights for the invalid ones . In this way, APCNNs could recognize multiple valid sentences in a bag . Concretely, motivated by TransE (Bordes et al. 2013) which modeled a triplet r(e_1 ,e_2 ) r(e_1 ,e_2 ) with e_1 + r \\approx e_2 e_1 + r \\approx e_2 (the bold, italic letters represent vectors ), we use (e_1 \u2212 e_2 ) (e_1 \u2212 e_2 ) to represent the relation between e_1 e_1 and e_2 e_2 in sentences (we will show more explanations later). For a bag , we first use PCNNs to extract each sentence\u2019s feature vector v_ {sen} v_ {sen} , then compute the attention weight for each sentence through a hidden layer with the concatenation\uff08\u4e32\u8054\uff09 way [ v_{sen} ;e_1 \u2212 e_2 ] [ v_{sen} ;e_1 \u2212 e_2 ] (Luong, Pham, and Manning 2015). At last, the weighted sum of all sentence feature vectors is the bag\u2019s features. In addition, to encode more background knowledge into our model , we use convolutional neural networks (CNNs) to extract entity descriptions\u2019 feature vectors and let them be close to the corresponding entity vectors via adding constraints on the objective function of APCNNs (called APCNNs+D, where \u201cD\u201d refers to descriptions). The background knowledge not only provides more information for predicting relations , but also brings better entity representations for the attention module . Therefore, our main contributions in this paper are: (1)We introduce a sentence-level attention model to select multiple valid sentences in a bag. This strategy makes full use of the supervision information; (2) We use entity descriptions to provide background knowledge for predicting relations and improving entity representations; (3) We conduct experiments on a widely used dataset^3 dataset^3 and achieve state-of-the-art performance.","title":"Introduction"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#task#definition","text":"In multi-instance learning paradigm , all sentences labeled by a triplet constitute a bag and each sentence is called an instance. Suppose that there are N N bags {B_1 ,B_2 ,\u00b7\u00b7\u00b7 , B_N } {B_1 ,B_2 ,\u00b7\u00b7\u00b7 , B_N } in the training set and that the i i -th bag contains q_i q_i instances B_i = {b_1^i ,b_2^i ,\u00b7\u00b7\u00b7 ,b_{q_i}^i } (i = 1,\u00b7\u00b7\u00b7 ,N) B_i = {b_1^i ,b_2^i ,\u00b7\u00b7\u00b7 ,b_{q_i}^i } (i = 1,\u00b7\u00b7\u00b7 ,N) . The objective of multi-instance learning is to predict the labels of the unseen bags . We need to learn a relation extractor based on the training data and then use it to predict relations for test set. Specifically, for a bag in B_j = {b_1^j ,b_2^j ,\u00b7\u00b7\u00b7 ,b_{q_j}^j } (j = 1,\u00b7\u00b7\u00b7 ,N) B_j = {b_1^j ,b_2^j ,\u00b7\u00b7\u00b7 ,b_{q_j}^j } (j = 1,\u00b7\u00b7\u00b7 ,N) training set, we need to extract features from the bag (from one or several valid instances) and then use them to train a classifier. For a bag in test set , we also need to extract features in the same way and use the classifier to predict the relation between the given entity pair.","title":"Task Definition"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#methodology","text":"In this section, we present the main innovative solutions including sentence-level attention and entity descriptions . Sentence-level attention makes our model be able to select multiple valid instances for training, so that we can make full use of the supervision information . Entity descriptions provide more background knowledge about the entities , which could improve the performance of our model and bring better entity representations for attention module . Figure 2 shows the neural network architecture of our model APCNNs . It consists of two parts: PCNNs Module and Sentence-level Attention Module . PCNNs Module includes Vector Representation, Convolution Piecewise Max-pooling. Sentence-level Attention Module is composed of Attention Layer Softmax Classifier. We describe these parts in details below.","title":"Methodology"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#pcnns#module","text":"This module is used to extract feature vector of an instance (sentence) in a bag.","title":"PCNNs Module"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#vector#representation","text":"","title":"Vector Representation"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#word#embeddings","text":"","title":"Word Embeddings"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#position#embeddings","text":"","title":"Position Embeddings"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#convolution","text":"","title":"Convolution"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#piecewise#max-pooling","text":"","title":"Piecewise Max-pooling"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#sentence-level#attention#module","text":"","title":"Sentence-level Attention Module"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#experiments","text":"","title":"Experiments"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#dataset","text":"","title":"Dataset"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#evaluation#metrics","text":"","title":"Evaluation Metrics"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#experimental#results#and#analysis","text":"","title":"Experimental Results and Analysis"},{"location":"Application/NLP/NLP-progress/Distant-supervision/TODO-Papers/paper-2017-Distant%20Supervision%20for%20Relation%20Extraction%20with%20Sentence-Level%20Atten/#conclusions#and#future#work","text":"","title":"Conclusions and Future Work"},{"location":"Application/NLP/NLP-progress/Entity-Linking/Entity-Linking/","text":"Entity Linking Entity Linking (EL) is the task of recognizing (cf. Named Entity Recognition ) and disambiguating (Named Entity Disambiguation) named entities to a knowledge base (e.g. Wikidata, DBpedia, or YAGO). It is sometimes also simply known as Named Entity Recognition and Disambiguation. EL can be split into two classes of approaches: End-to-End : processing a piece of text to extract the entities (i.e. Named Entity Recognition) and then disambiguate\uff08\u6d88\u9664\u6b67\u4e49\uff09 these extracted entities to the correct entry in a given knowledge base (e.g. Wikidata, DBpedia, YAGO). Disambiguation-Only : contrary to the first approach, this one directly takes gold standard named entities as input and only disambiguates them to the correct entry in a given knowledge base. wikipedia Entity linking","title":"Entity-Linking"},{"location":"Application/NLP/NLP-progress/Entity-Linking/Entity-Linking/#entity#linking","text":"Entity Linking (EL) is the task of recognizing (cf. Named Entity Recognition ) and disambiguating (Named Entity Disambiguation) named entities to a knowledge base (e.g. Wikidata, DBpedia, or YAGO). It is sometimes also simply known as Named Entity Recognition and Disambiguation. EL can be split into two classes of approaches: End-to-End : processing a piece of text to extract the entities (i.e. Named Entity Recognition) and then disambiguate\uff08\u6d88\u9664\u6b67\u4e49\uff09 these extracted entities to the correct entry in a given knowledge base (e.g. Wikidata, DBpedia, YAGO). Disambiguation-Only : contrary to the first approach, this one directly takes gold standard named entities as input and only disambiguates them to the correct entry in a given knowledge base.","title":"Entity Linking"},{"location":"Application/NLP/NLP-progress/Entity-Linking/Entity-Linking/#wikipedia#entity#linking","text":"","title":"wikipedia Entity linking"},{"location":"Application/NLP/NLP-progress/Neural-machine-translation/Neural-machine-translation/","text":"Neural machine translation Neural machine translation (NMT) is an approach to machine translation that uses an artificial neural network to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model. Properties They require only a fraction of the memory needed by traditional statistical machine translation (SMT) models. Furthermore, unlike conventional translation systems, all parts of the neural translation model are trained jointly (end-to-end) to maximize the translation performance.[ 1] [ 2] [ 3] History Deep learning applications appeared first in speech recognition in the 1990s. The first scientific paper on using neural networks in machine translation appeared in 2014, followed by a lot of advances in the following few years. (Large-vocabulary NMT, application to Image captioning, Subword-NMT, Multilingual NMT, Multi-Source NMT, Character-dec NMT, Zero-Resource NMT, Google, Fully Character-NMT, Zero-Shot NMT in 2017) In 2015 there was the first appearance of a NMT system in a public machine translation competition (OpenMT'15). WMT'15 also for the first time had a NMT contender; the following year it already had 90% of NMT systems among its winners.[ 4] The popularity of NMT also owes to the events such as the introducing of NMT section (NMT [ 5] and Neural MT Training [ 6] of Annual WMT (Workshop of Machine Translation), and the first independent workshop\uff08\u7814\u8ba8\u4f1a\uff09 on NMT by Google [ 7] which continued afterwards each year. Workings NMT departs from phrase-based statistical approaches that use separately engineered subcomponents.[ 8] Neural machine translation (NMT) is not a drastic step beyond what has been traditionally done in statistical machine translation (SMT). Its main departure is the use of vector representations (\"embeddings\", \"continuous space representations\") for words and internal states. The structure of the models is simpler than phrase-based models. There is no separate language model, translation model, and reordering model, but just a single sequence model that predicts one word at a time. However, this sequence prediction is conditioned on the entire source sentence and the entire already produced target sequence . NMT models use deep learning and representation learning . The word sequence modeling was at first typically done using a recurrent neural network (RNN). A bidirectional recurrent neural network, known as an encoder , is used by the neural network to encode a source sentence for a second RNN, known as a decoder , that is used to predict words in the target language .[ 9] Convolutional Neural Networks (Convnets) are in principle somewhat better for long continuous sequences, but were initially not used due to several weaknesses that were successfully compensated for by 2017 by using so-called \"attention\"-based approaches.[ 10] [ 11] There are further Coverage Models addressing the issues in traditional attention mechanism, such as ignoring of past alignment information leading to over-translation and under-translation [ 12] . \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08Convnets\uff09\u539f\u5219\u4e0a\u5bf9\u4e8e\u8f83\u957f\u7684\u8fde\u7eed\u5e8f\u5217\u8981\u597d\u4e00\u4e9b\uff0c\u4f46\u6700\u521d\u7531\u4e8e\u51e0\u4e2a\u5f31\u70b9\u800c\u6ca1\u6709\u4f7f\u7528\uff0c\u8fd9\u4e9b\u5f31\u70b9\u5df2\u57282017\u5e74\u901a\u8fc7\u4f7f\u7528\u6240\u8c13\u7684\u201c\u57fa\u4e8e\u6ce8\u610f\u529b\u201d\u7684\u65b9\u6cd5\u6210\u529f\u5730\u5f97\u5230\u4e86\u5f25\u8865\u3002 \u8fd8\u6709\u5176\u4ed6\u6db5\u76d6\u6a21\u578b\u53ef\u89e3\u51b3\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u95ee\u9898\uff0c\u4f8b\u5982\u5ffd\u7565\u8fc7\u53bb\u7684\u5bf9\u9f50\u4fe1\u606f\uff0c\u4ece\u800c\u5bfc\u81f4\u7ffb\u8bd1\u8fc7\u5ea6\u548c\u7ffb\u8bd1\u4e0d\u8db3 Usages By 2016, most of the best MT systems were using neural networks.[ 4] Google , Microsoft , Yandex [ 13] and PROMT [ 14] translation services now use NMT. Google uses Google Neural Machine Translation (GNMT) in preference to its previous statistical methods.[ 15] Microsoft uses a similar technology for its speech translations (including Microsoft Translator live and Skype Translator ).[ 16] An open source neural machine translation system, OpenNMT, has been released by the Harvard NLP group.[ 17] The NMT technology can be used outside the scope of natural language. For instance, it has been shown that NMT can also work on source code of computer programs. With careful encoding of source code, the SequenceR automatic bug fixing system is trained on past commits mined in Git repositories and is able to generate correct one-line patches.[ 18]","title":"Neural-machine-translation"},{"location":"Application/NLP/NLP-progress/Neural-machine-translation/Neural-machine-translation/#neural#machine#translation","text":"Neural machine translation (NMT) is an approach to machine translation that uses an artificial neural network to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model.","title":"Neural machine translation"},{"location":"Application/NLP/NLP-progress/Neural-machine-translation/Neural-machine-translation/#properties","text":"They require only a fraction of the memory needed by traditional statistical machine translation (SMT) models. Furthermore, unlike conventional translation systems, all parts of the neural translation model are trained jointly (end-to-end) to maximize the translation performance.[ 1] [ 2] [ 3]","title":"Properties"},{"location":"Application/NLP/NLP-progress/Neural-machine-translation/Neural-machine-translation/#history","text":"Deep learning applications appeared first in speech recognition in the 1990s. The first scientific paper on using neural networks in machine translation appeared in 2014, followed by a lot of advances in the following few years. (Large-vocabulary NMT, application to Image captioning, Subword-NMT, Multilingual NMT, Multi-Source NMT, Character-dec NMT, Zero-Resource NMT, Google, Fully Character-NMT, Zero-Shot NMT in 2017) In 2015 there was the first appearance of a NMT system in a public machine translation competition (OpenMT'15). WMT'15 also for the first time had a NMT contender; the following year it already had 90% of NMT systems among its winners.[ 4] The popularity of NMT also owes to the events such as the introducing of NMT section (NMT [ 5] and Neural MT Training [ 6] of Annual WMT (Workshop of Machine Translation), and the first independent workshop\uff08\u7814\u8ba8\u4f1a\uff09 on NMT by Google [ 7] which continued afterwards each year.","title":"History"},{"location":"Application/NLP/NLP-progress/Neural-machine-translation/Neural-machine-translation/#workings","text":"NMT departs from phrase-based statistical approaches that use separately engineered subcomponents.[ 8] Neural machine translation (NMT) is not a drastic step beyond what has been traditionally done in statistical machine translation (SMT). Its main departure is the use of vector representations (\"embeddings\", \"continuous space representations\") for words and internal states. The structure of the models is simpler than phrase-based models. There is no separate language model, translation model, and reordering model, but just a single sequence model that predicts one word at a time. However, this sequence prediction is conditioned on the entire source sentence and the entire already produced target sequence . NMT models use deep learning and representation learning . The word sequence modeling was at first typically done using a recurrent neural network (RNN). A bidirectional recurrent neural network, known as an encoder , is used by the neural network to encode a source sentence for a second RNN, known as a decoder , that is used to predict words in the target language .[ 9] Convolutional Neural Networks (Convnets) are in principle somewhat better for long continuous sequences, but were initially not used due to several weaknesses that were successfully compensated for by 2017 by using so-called \"attention\"-based approaches.[ 10] [ 11] There are further Coverage Models addressing the issues in traditional attention mechanism, such as ignoring of past alignment information leading to over-translation and under-translation [ 12] . \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08Convnets\uff09\u539f\u5219\u4e0a\u5bf9\u4e8e\u8f83\u957f\u7684\u8fde\u7eed\u5e8f\u5217\u8981\u597d\u4e00\u4e9b\uff0c\u4f46\u6700\u521d\u7531\u4e8e\u51e0\u4e2a\u5f31\u70b9\u800c\u6ca1\u6709\u4f7f\u7528\uff0c\u8fd9\u4e9b\u5f31\u70b9\u5df2\u57282017\u5e74\u901a\u8fc7\u4f7f\u7528\u6240\u8c13\u7684\u201c\u57fa\u4e8e\u6ce8\u610f\u529b\u201d\u7684\u65b9\u6cd5\u6210\u529f\u5730\u5f97\u5230\u4e86\u5f25\u8865\u3002 \u8fd8\u6709\u5176\u4ed6\u6db5\u76d6\u6a21\u578b\u53ef\u89e3\u51b3\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u95ee\u9898\uff0c\u4f8b\u5982\u5ffd\u7565\u8fc7\u53bb\u7684\u5bf9\u9f50\u4fe1\u606f\uff0c\u4ece\u800c\u5bfc\u81f4\u7ffb\u8bd1\u8fc7\u5ea6\u548c\u7ffb\u8bd1\u4e0d\u8db3","title":"Workings"},{"location":"Application/NLP/NLP-progress/Neural-machine-translation/Neural-machine-translation/#usages","text":"By 2016, most of the best MT systems were using neural networks.[ 4] Google , Microsoft , Yandex [ 13] and PROMT [ 14] translation services now use NMT. Google uses Google Neural Machine Translation (GNMT) in preference to its previous statistical methods.[ 15] Microsoft uses a similar technology for its speech translations (including Microsoft Translator live and Skype Translator ).[ 16] An open source neural machine translation system, OpenNMT, has been released by the Harvard NLP group.[ 17] The NMT technology can be used outside the scope of natural language. For instance, it has been shown that NMT can also work on source code of computer programs. With careful encoding of source code, the SequenceR automatic bug fixing system is trained on past commits mined in Git repositories and is able to generate correct one-line patches.[ 18]","title":"Usages"},{"location":"Application/NLP/NLP-progress/Part-of-speech-tagging/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u63cf\u8ff0NLP\u4efb\u52a1Part-of-speech tagging\uff0c\u53c2\u8003\u5185\u5bb9\u5982\u4e0b\uff1a \u7ef4\u57fa\u767e\u79d1 Part-of-speech tagging NLP-progress \u7684 Part-of-speech tagging Natural Language Processing with Python \u5173\u4e8epart of speech\uff0c\u53c2\u89c1Linguistics\u7ae0\u8282\u3002","title":"Introduction"},{"location":"Application/NLP/NLP-progress/Part-of-speech-tagging/#_1","text":"\u672c\u7ae0\u63cf\u8ff0NLP\u4efb\u52a1Part-of-speech tagging\uff0c\u53c2\u8003\u5185\u5bb9\u5982\u4e0b\uff1a \u7ef4\u57fa\u767e\u79d1 Part-of-speech tagging NLP-progress \u7684 Part-of-speech tagging Natural Language Processing with Python \u5173\u4e8epart of speech\uff0c\u53c2\u89c1Linguistics\u7ae0\u8282\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Application/NLP/NLP-progress/Relationship-Extraction/Relationship-Extraction/","text":"Relationship Extraction Relationship extraction is the task of extracting semantic relationships from a text. Extracted relationships usually occur between two or more entities of a certain type (e.g. Person, Organisation, Location) and fall into a number of semantic categories (e.g. married to, employed by, lives in). SUMMARY : entity\u662f\u5426\u9700\u8981\u7279\u522b\u5730\u8fdb\u884c\u6807\u6ce8\uff1f Capturing discriminative attributes (SemEval 2018 Task 10) \u6355\u6349\u6709\u533a\u522b\u6027\u7684\u5c5e\u6027 Capturing discriminative attributes (SemEval 2018 Task 10) is a binary classification task where participants were asked to identify whether an attribute could help discriminate between two concepts. Unlike other word similarity prediction tasks, this task focuses on the semantic differences between words. e.g. red(attribute) can be used to discriminate apple (concept1) from banana (concept2) -> label 1 FewRel The Few-Shot Relation Classification Dataset (FewRel) is a different setting from the previous datasets. This dataset consists of 70K sentences expressing 100 relations annotated by crowdworkers on Wikipedia corpus. The few-shot learning task follows the N-way K-shot meta learning setting. It is both the largest supervised relation classification dataset as well as the largest few-shot learning dataset till now. The public leaderboard is available on the FewRel website . Multi-Way Classification of Semantic Relations Between Pairs of Nominals (SemEval 2010 Task 8) SemEval-2010 introduced \u2018Task 8 - Multi-Way Classification of Semantic Relations Between Pairs of Nominals\u2019. The task is, given a sentence and two tagged nominals, to predict the relation between those nominals and the direction of the relation. The dataset contains nine general semantic relations together with a tenth \u2018OTHER\u2019 relation. Example: There were apples, pears and oranges in the bowl . (content-container, pears, bowl) The main evaluation metric used is macro-averaged F1, averaged across the nine proper relationships (i.e. excluding the OTHER relation), taking directionality of the relation into account. Several papers have used additional data (e.g. pre-trained word embeddings, WordNet) to improve performance. The figures reported here are the highest achieved by the model using any external resources. End-to-End Models Model F1 Paper / Source Code BERT-based Models Matching-the-Blanks (Baldini Soares et al., 2019) 89.5 Matching the Blanks: Distributional Similarity for Relation Learning R-BERT (Wu et al. 2019) 89.25 Enriching Pre-trained Language Model with Entity Information for Relation Classification CNN-based Models Multi-Attention CNN (Wang et al. 2016) 88.0 Relation Classification via Multi-Level Attention CNNs lawlietAi\u2019s Reimplementation Attention CNN (Huang and Y Shen, 2016) 84.3 85.9 * Attention-Based Convolutional Neural Network for Semantic Relation Extraction CR-CNN (dos Santos et al., 2015) 84.1 Classifying Relations by Ranking with Convolutional Neural Network pratapbhanu\u2019s Reimplementation CNN (Zeng et al., 2014) 82.7 Relation Classification via Convolutional Deep Neural Network roomylee\u2019s Reimplementation RNN-based Models Entity Attention Bi-LSTM (Lee et al., 2019) 85.2 Semantic Relation Classification via Bidirectional LSTM Networks with Entity-aware Attention using Latent Entity Typing Official Hierarchical Attention Bi-LSTM (Xiao and C Liu, 2016) 84.3 Semantic Relation Classification via Hierarchical Recurrent Neural Network with Attention Attention Bi-LSTM (Zhou et al., 2016) 84.0 Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification SeoSangwoo\u2019s Reimplementation Bi-LSTM (Zhang et al., 2015) 82.7 84.3 * Bidirectional long short-term memory networks for relation classification *: It uses external lexical resources, such as WordNet, part-of-speech tags, dependency tags, and named entity tags.","title":"Relationship-Extraction"},{"location":"Application/NLP/NLP-progress/Relationship-Extraction/Relationship-Extraction/#relationship#extraction","text":"Relationship extraction is the task of extracting semantic relationships from a text. Extracted relationships usually occur between two or more entities of a certain type (e.g. Person, Organisation, Location) and fall into a number of semantic categories (e.g. married to, employed by, lives in). SUMMARY : entity\u662f\u5426\u9700\u8981\u7279\u522b\u5730\u8fdb\u884c\u6807\u6ce8\uff1f","title":"Relationship Extraction"},{"location":"Application/NLP/NLP-progress/Relationship-Extraction/Relationship-Extraction/#capturing#discriminative#attributes#semeval#2018#task#10","text":"\u6355\u6349\u6709\u533a\u522b\u6027\u7684\u5c5e\u6027 Capturing discriminative attributes (SemEval 2018 Task 10) is a binary classification task where participants were asked to identify whether an attribute could help discriminate between two concepts. Unlike other word similarity prediction tasks, this task focuses on the semantic differences between words. e.g. red(attribute) can be used to discriminate apple (concept1) from banana (concept2) -> label 1","title":"Capturing discriminative attributes (SemEval 2018 Task 10)"},{"location":"Application/NLP/NLP-progress/Relationship-Extraction/Relationship-Extraction/#fewrel","text":"The Few-Shot Relation Classification Dataset (FewRel) is a different setting from the previous datasets. This dataset consists of 70K sentences expressing 100 relations annotated by crowdworkers on Wikipedia corpus. The few-shot learning task follows the N-way K-shot meta learning setting. It is both the largest supervised relation classification dataset as well as the largest few-shot learning dataset till now. The public leaderboard is available on the FewRel website .","title":"FewRel"},{"location":"Application/NLP/NLP-progress/Relationship-Extraction/Relationship-Extraction/#multi-way#classification#of#semantic#relations#between#pairs#of#nominals#semeval#2010#task#8","text":"SemEval-2010 introduced \u2018Task 8 - Multi-Way Classification of Semantic Relations Between Pairs of Nominals\u2019. The task is, given a sentence and two tagged nominals, to predict the relation between those nominals and the direction of the relation. The dataset contains nine general semantic relations together with a tenth \u2018OTHER\u2019 relation. Example: There were apples, pears and oranges in the bowl . (content-container, pears, bowl) The main evaluation metric used is macro-averaged F1, averaged across the nine proper relationships (i.e. excluding the OTHER relation), taking directionality of the relation into account. Several papers have used additional data (e.g. pre-trained word embeddings, WordNet) to improve performance. The figures reported here are the highest achieved by the model using any external resources.","title":"Multi-Way Classification of Semantic Relations Between Pairs of Nominals (SemEval 2010 Task 8)"},{"location":"Application/NLP/NLP-progress/Relationship-Extraction/Relationship-Extraction/#end-to-end#models","text":"Model F1 Paper / Source Code BERT-based Models Matching-the-Blanks (Baldini Soares et al., 2019) 89.5 Matching the Blanks: Distributional Similarity for Relation Learning R-BERT (Wu et al. 2019) 89.25 Enriching Pre-trained Language Model with Entity Information for Relation Classification CNN-based Models Multi-Attention CNN (Wang et al. 2016) 88.0 Relation Classification via Multi-Level Attention CNNs lawlietAi\u2019s Reimplementation Attention CNN (Huang and Y Shen, 2016) 84.3 85.9 * Attention-Based Convolutional Neural Network for Semantic Relation Extraction CR-CNN (dos Santos et al., 2015) 84.1 Classifying Relations by Ranking with Convolutional Neural Network pratapbhanu\u2019s Reimplementation CNN (Zeng et al., 2014) 82.7 Relation Classification via Convolutional Deep Neural Network roomylee\u2019s Reimplementation RNN-based Models Entity Attention Bi-LSTM (Lee et al., 2019) 85.2 Semantic Relation Classification via Bidirectional LSTM Networks with Entity-aware Attention using Latent Entity Typing Official Hierarchical Attention Bi-LSTM (Xiao and C Liu, 2016) 84.3 Semantic Relation Classification via Hierarchical Recurrent Neural Network with Attention Attention Bi-LSTM (Zhou et al., 2016) 84.0 Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification SeoSangwoo\u2019s Reimplementation Bi-LSTM (Zhang et al., 2015) 82.7 84.3 * Bidirectional long short-term memory networks for relation classification *: It uses external lexical resources, such as WordNet, part-of-speech tags, dependency tags, and named entity tags.","title":"End-to-End Models"},{"location":"Application/NLP/NLP-progress/Shallow-parsing/Shallow-parsing/","text":"Shallow parsing Shallow parsing","title":"Shallow-parsing"},{"location":"Application/NLP/NLP-progress/Shallow-parsing/Shallow-parsing/#shallow#parsing","text":"","title":"Shallow parsing"},{"location":"Application/NLP/NLP-progress/Shallow-parsing/paper-Shallow-Parsing-with-Conditional-Random-Fields/","text":"Shallow Parsing with Conditional Random Fields Shallow Parsing with Conditional Random Fields","title":"paper Shallow Parsing with Conditional Random Fields"},{"location":"Application/NLP/NLP-progress/Shallow-parsing/paper-Shallow-Parsing-with-Conditional-Random-Fields/#shallow#parsing#with#conditional#random#fields","text":"","title":"Shallow Parsing with Conditional Random Fields"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Named-entity-recognition/","text":"Named entity recognition Named entity recognition (NER) is the task of tagging\uff08\u6807\u8bb0\uff09 entities in text with their corresponding type. Approaches typically use BIO notation\uff08\u8bb0\u53f7\uff09, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens. Example: Mark Watney visited Mars B-PER I-PER O B-LOC","title":"[Named entity recognition](http://nlpprogress.com/english/named_entity_recognition.html)"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Named-entity-recognition/#named#entity#recognition","text":"Named entity recognition (NER) is the task of tagging\uff08\u6807\u8bb0\uff09 entities in text with their corresponding type. Approaches typically use BIO notation\uff08\u8bb0\u53f7\uff09, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens. Example: Mark Watney visited Mars B-PER I-PER O B-LOC","title":"Named entity recognition"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Paper/","text":"Named Entity Recognition with Bidirectional LSTM-CNNs https://aclweb.org/anthology/Q16-1026 https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs A Survey on Deep Learning for Named Entity Recognition https://arxiv.org/abs/1812.09449 DEEP ACTIVE LEARNING FOR NAMED ENTITY https://openreview.net/pdf?id=ry018WZAZ","title":"Paper"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Paper/#named#entity#recognition#with#bidirectional#lstm-cnns","text":"https://aclweb.org/anthology/Q16-1026 https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs","title":"Named Entity Recognition with Bidirectional LSTM-CNNs"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Paper/#a#survey#on#deep#learning#for#named#entity#recognition","text":"https://arxiv.org/abs/1812.09449","title":"A Survey on Deep Learning for Named Entity Recognition"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Paper/#deep#active#learning#for#named#entity","text":"https://openreview.net/pdf?id=ry018WZAZ","title":"DEEP ACTIVE LEARNING FOR NAMED ENTITY"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Example-named-entity-recognition/","text":"","title":"Example named entity recognition"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/","text":"MedicalNamedEntityRecognition CCKS2017\u4e2d\u6587\u7535\u5b50\u75c5\u4f8b\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u9879\u76ee,\u4e3b\u8981\u5b9e\u73b0\u4f7f\u7528\u4e86\u57fa\u4e8e\u5b57\u5411\u91cf( char embedding)\u7684\u56db\u5c42\u53cc\u5411LSTM\uff08 bi-directional lstm \uff09\u4e0e CRF \u6a21\u578b\u7684\u7f51\u7edc.\u8be5\u9879\u76ee\u63d0\u4f9b\u4e86\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u6837\u672c(\u4e00\u822c\u9192\u76ee,\u51fa\u9662\u60c5\u51b5,\u75c5\u53f2\u60c5\u51b5,\u75c5\u53f2\u7279\u70b9,\u8bca\u7597\u7ecf\u8fc7)\u4e0e\u8f6c\u6362\u7248\u672c,\u8bad\u7ec3\u811a\u672c,\u9884\u8bad\u7ec3\u6a21\u578b,\u53ef\u7528\u4e8e\u5e8f\u5217\u6807\u6ce8\u7814\u7a76.\u628a\u73a9\u548cPK\u4f7f\u7528. \u9879\u76ee\u4ecb\u7ecd \u7535\u5b50\u75c5\u5386\u7ed3\u6784\u5316\u662f\u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u75c5\u5386\u3001\u5e94\u7528\u75c5\u5386\u7684\u57fa\u7840\u3002\u57fa\u4e8e\u5bf9\u75c5\u5386\u7684\u7ed3\u6784\u5316\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u75c7\u72b6\u3001\u75be\u75c5\u3001\u836f\u54c1\u3001\u68c0\u67e5\u68c0\u9a8c\u7b49\u591a\u4e2a\u77e5\u8bc6\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u6982\u7387\uff0c\u6784\u5efa\u533b\u7597\u9886\u57df\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u533b\u751f\u7684\u5de5\u4f5c. CCKS2018\u7684\u7535\u5b50\u75c5\u5386\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u8bc4\u6d4b\u4efb\u52a1\uff0c\u662f\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u4e00\u7ec4\u7535\u5b50\u75c5\u5386\u7eaf\u6587\u672c\u6587\u6863\uff0c\u8bc6\u522b\u5e76\u62bd\u53d6\u51fa\u5176\u4e2d\u4e0e\u533b\u5b66\u4e34\u5e8a\u76f8\u5173\u7684**\u5b9e\u4f53**\uff0c\u5e76\u5c06\u5b83\u4eec**\u5f52\u7c7b**\u5230\u9884\u5148\u5b9a\u4e49\u597d\u7684\u7c7b\u522b\u4e2d\u3002\u7ec4\u59d4\u4f1a\u9488\u5bf9\u8fd9\u4e2a\u8bc4\u6d4b\u4efb\u52a1\uff0c\u63d0\u4f9b\u4e86600\u4efd\u6807\u6ce8\u597d\u7684\u7535\u5b50\u75c5\u5386\u6587\u672c\uff0c\u5171\u9700\u8bc6\u522b\u542b\u89e3\u5256\u90e8\u4f4d\u3001\u72ec\u7acb\u75c7\u72b6\u3001\u75c7\u72b6\u63cf\u8ff0\u3001\u624b\u672f\u548c\u836f\u7269\u4e94\u7c7b\u5b9e\u4f53\u3002 **\u9886\u57df\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u95ee\u9898**\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7ecf\u5178\u7684\u5e8f\u5217\u6807\u6ce8\u95ee\u9898, \u672c\u9879\u76ee\u662f\u8fd0\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c**\u547d\u540d\u5b9e\u4f53\u8bc6\u522b**\u7684\u4e00\u4e2a\u5c1d\u8bd5. \u5b9e\u9a8c\u6570\u636e \u4e00, \u76ee\u6807\u5e8f\u5217\u6807\u8bb0\u96c6\u5408 O \u975e\u5b9e\u4f53\u90e8\u5206, TREATMENT \u6cbb\u7597\u65b9\u5f0f, BODY \u8eab\u4f53\u90e8\u4f4d, SIGN \u75be\u75c5\u75c7\u72b6, CHECK \u533b\u5b66\u68c0\u67e5, DISEASE \u75be\u75c5\u5b9e\u4f53, \u4e8c, \u5e8f\u5217\u6807\u8bb0\u65b9\u6cd5 \u91c7\u7528 BIO \u4e09\u5143\u6807\u8bb0 self . class_dict = { 'O' : 0 , 'TREATMENT-I' : 1 , 'TREATMENT-B' : 2 , 'BODY-B' : 3 , 'BODY-I' : 4 , 'SIGNS-I' : 5 , 'SIGNS-B' : 6 , 'CHECK-B' : 7 , 'CHECK-I' : 8 , 'DISEASE-I' : 9 , 'DISEASE-B' : 10 } \u4e09, \u6570\u636e\u8f6c\u6362 \u8bc4\u6d4b\u65b9\u63d0\u4f9b\u4e86\u56db\u4e2a\u76ee\u5f55(\u4e00\u822c\u9879\u76ee, \u51fa\u9662\u9879\u76ee, \u75c5\u53f2\u7279\u70b9, \u8bca\u7597\u7ecf\u8fc7),\u56db\u4e2a\u76ee\u5f55\u4e0b\u6709txt original\u6587\u4ef6**\u548ct**xt\u6807\u6ce8\u6587\u4ef6 ,\u5185\u5bb9\u6837\u5f0f\u5982\u4e0b: \u4e00\u822c\u9879\u76ee-1.txtoriginal.txt \u5973\u6027\uff0c88\u5c81\uff0c\u519c\u6c11\uff0c\u53cc\u6ee6\u533a\u5e94\u8425\u5b50\u6751\u4eba\uff0c\u4e3b\u56e0\u53f3\u9acb\u90e8\u6454\u4f24\u540e\u75bc\u75db\u80bf\u80c0\uff0c\u6d3b\u52a8\u53d7\u96505\u5c0f\u65f6\u4e8e2016-10-29\uff1b11\uff1a12\u5165\u9662\u3002 \u4e00\u822c\u9879\u76ee-1.txt: \u53f3\u9acb\u90e8 21 23 \u8eab\u4f53\u90e8\u4f4d \u75bc\u75db 27 28 \u75c7\u72b6\u548c\u4f53\u5f81 \u80bf\u80c0 29 30 \u75c7\u72b6\u548c\u4f53\u5f81 \u8f6c\u6362\u811a\u672c\u51fd\u6570: def transfer ( self ): f = open ( self . train_filepath , 'w+' ) count = 0 for root , dirs , files in os . walk ( self . origin_path ): for file in files : filepath = os . path . join ( root , file ) if 'original' not in filepath : continue label_filepath = filepath . replace ( '.txtoriginal' , '' ) print ( filepath , ' \\t\\t ' , label_filepath ) content = open ( filepath ) . read () . strip () res_dict = {} for line in open ( label_filepath ): res = line . strip () . split ( ' ' ) start = int ( res [ 1 ]) end = int ( res [ 2 ]) label = res [ 3 ] label_id = self . label_dict . get ( label ) for i in range ( start , end + 1 ): if i == start : label_cate = label_id + '-B' else : label_cate = label_id + '-I' res_dict [ i ] = label_cate for indx , char in enumerate ( content ): char_label = res_dict . get ( indx , 'O' ) print ( char , char_label ) f . write ( char + ' \\t ' + char_label + ' \\n ' ) f . close () return \u6a21\u578b\u8f93\u51fa\u6837\u5f0f: \uff0c O \u7537 O \uff0c O \u53cc O \u5854 O \u5c71 O \u4eba O \uff0c O \u4e3b O \u56e0 O \u54b3 SIGNS-B \u55fd SIGNS-I \u3001 O \u5c11 SIGNS-B \u75f0 SIGNS-I 1 O \u4e2a O \u6708 O \uff0c O \u52a0 O \u91cd O 3 O \u5929 O \uff0c O \u62bd SIGNS-B \u6410 SIGNS-I \u6a21\u578b\u642d\u5efa \u672c\u6a21\u578b\u4f7f\u7528**\u9884\u8bad\u7ec3\u5b57\u5411\u91cf**,\u4f5c\u4e3a**embedding\u5c42**\u8f93\u5165,\u7136\u540e\u7ecf\u8fc7\u4e24\u4e2a\u53cc\u5411LSTM\u5c42\u8fdb\u884c\u7f16\u7801,\u7f16\u7801\u540e\u52a0\u5165dense\u5c42,\u6700\u540e\u9001\u5165CRF\u5c42\u8fdb\u884c\u5e8f\u5217\u6807\u6ce8. '''\u4f7f\u7528\u9884\u8bad\u7ec3\u5411\u91cf\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3''' def tokenvec_bilstm2_crf_model ( self ): model = Sequential () embedding_layer = Embedding ( self . VOCAB_SIZE + 1 , self . EMBEDDING_DIM , weights = [ self . embedding_matrix ], input_length = self . TIME_STAMPS , trainable = False , mask_zero = True ) model . add ( embedding_layer ) model . add ( Bidirectional ( LSTM ( 128 , return_sequences = True ))) model . add ( Dropout ( 0.5 )) model . add ( Bidirectional ( LSTM ( 64 , return_sequences = True ))) model . add ( Dropout ( 0.5 )) model . add ( TimeDistributed ( Dense ( self . NUM_CLASSES ))) crf_layer = CRF ( self . NUM_CLASSES , sparse_target = True ) model . add ( crf_layer ) model . compile ( 'adam' , loss = crf_layer . loss_function , metrics = [ crf_layer . accuracy ]) model . summary () return model \u6a21\u578b\u6548\u679c 1, \u6a21\u578b\u7684\u8bad\u7ec3: \u6a21\u578b \u8bad\u7ec3\u96c6 \u6d4b\u8bd5\u96c6 \u8bad\u7ec3\u96c6\u51c6\u786e\u7387 \u6d4b\u8bd5\u96c6\u51c6\u786e\u7387 \u5907\u6ce8 \u533b\u7597\u5b9e\u4f53\u8bc6\u522b 6268 1571 0.9649 0.8451 5\u4e2aepcho 2, \u6a21\u578b\u7684\u6d4b\u8bd5: python lstm_predict.py , \u5bf9\u8bad\u7ec3\u597d\u7684\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5,\u6d4b\u8bd5\u6548\u679c\u5982\u4e0b: enter an sent:\u4ed6\u6700\u8fd1\u5934\u75db,\u6d41\u9f3b\u6d95,\u4f30\u8ba1\u662f\u53d1\u70e7\u4e86 [('\u4ed6', 'O'), ('\u6700', 'O'), ('\u8fd1', 'O'), ('\u5934', 'SIGNS-B'), ('\u75db', 'SIGNS-I'), (',', 'O'), ('\u6d41', 'O'), ('\u9f3b', 'O'), ('\u6d95', 'O'), (',', 'O'), ('\u4f30', 'O'), ('\u8ba1', 'O'), ('\u662f', 'O'), ('\u53d1', 'SIGNS-B'), ('\u70e7', 'SIGNS-I'), ('\u4e86', 'SIGNS-I')] enter an sent:\u53e3\u8154\u6e83\u75a1\u53ef\u80fd\u9700\u8981\u591a\u5403\u7ef4\u751f\u7d20 [('\u53e3', 'BODY-B'), ('\u8154', 'BODY-I'), ('\u6e83', 'O'), ('\u75a1', 'O'), ('\u53ef', 'O'), ('\u80fd', 'O'), ('\u9700', 'O'), ('\u8981', 'O'), ('\u591a', 'O'), ('\u5403', 'O'), ('\u7ef4', 'CHECK-B'), ('\u751f', 'CHECK-B'), ('\u7d20', 'TREATMENT-I')] enter an sent:\u4ed6\u9aa8\u6298\u4e86,\u53ef\u80fd\u9700\u8981\u62cd\u7247 [('\u4ed6', 'O'), ('\u9aa8', 'SIGNS-B'), ('\u6298', 'SIGNS-I'), ('\u4e86', 'O'), (',', 'O'), ('\u53ef', 'O'), ('\u80fd', 'O'), ('\u9700', 'O'), ('\u8981', \u603b\u7ed3 1,\u672c\u9879\u76ee\u9488\u5bf9\u4e2d\u6587\u7535\u5b50\u75c5\u4f8b\u547d\u540d\u5b9e\u4f53\u4efb\u52a1,\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eBilstm+CRF\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b 2,\u672c\u9879\u76ee\u4f7f\u7528charembedding\u4f5c\u4e3a\u539f\u59cb\u7279\u5f81,\u8bad\u7ec3\u96c6\u51c6\u786e\u7387\u4e3a0.9649,\u6d4b\u8bd5\u96c6\u51c6\u786e\u8fbe\u52300.8451 3,\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u53ef\u4ee5\u52a0\u5165\u66f4\u591a\u7684\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3,\u540e\u671f\u5c06\u9010\u6b65\u5b9e\u9a8c\u5176\u4ed6\u65b9\u5f0f.","title":"[MedicalNamedEntityRecognition](https://github.com/liuhuanyong/MedicalNamedEntityRecognition)"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#medicalnamedentityrecognition","text":"CCKS2017\u4e2d\u6587\u7535\u5b50\u75c5\u4f8b\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u9879\u76ee,\u4e3b\u8981\u5b9e\u73b0\u4f7f\u7528\u4e86\u57fa\u4e8e\u5b57\u5411\u91cf( char embedding)\u7684\u56db\u5c42\u53cc\u5411LSTM\uff08 bi-directional lstm \uff09\u4e0e CRF \u6a21\u578b\u7684\u7f51\u7edc.\u8be5\u9879\u76ee\u63d0\u4f9b\u4e86\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u6837\u672c(\u4e00\u822c\u9192\u76ee,\u51fa\u9662\u60c5\u51b5,\u75c5\u53f2\u60c5\u51b5,\u75c5\u53f2\u7279\u70b9,\u8bca\u7597\u7ecf\u8fc7)\u4e0e\u8f6c\u6362\u7248\u672c,\u8bad\u7ec3\u811a\u672c,\u9884\u8bad\u7ec3\u6a21\u578b,\u53ef\u7528\u4e8e\u5e8f\u5217\u6807\u6ce8\u7814\u7a76.\u628a\u73a9\u548cPK\u4f7f\u7528.","title":"MedicalNamedEntityRecognition"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_1","text":"\u7535\u5b50\u75c5\u5386\u7ed3\u6784\u5316\u662f\u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u75c5\u5386\u3001\u5e94\u7528\u75c5\u5386\u7684\u57fa\u7840\u3002\u57fa\u4e8e\u5bf9\u75c5\u5386\u7684\u7ed3\u6784\u5316\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u75c7\u72b6\u3001\u75be\u75c5\u3001\u836f\u54c1\u3001\u68c0\u67e5\u68c0\u9a8c\u7b49\u591a\u4e2a\u77e5\u8bc6\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u6982\u7387\uff0c\u6784\u5efa\u533b\u7597\u9886\u57df\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u533b\u751f\u7684\u5de5\u4f5c. CCKS2018\u7684\u7535\u5b50\u75c5\u5386\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u8bc4\u6d4b\u4efb\u52a1\uff0c\u662f\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u4e00\u7ec4\u7535\u5b50\u75c5\u5386\u7eaf\u6587\u672c\u6587\u6863\uff0c\u8bc6\u522b\u5e76\u62bd\u53d6\u51fa\u5176\u4e2d\u4e0e\u533b\u5b66\u4e34\u5e8a\u76f8\u5173\u7684**\u5b9e\u4f53**\uff0c\u5e76\u5c06\u5b83\u4eec**\u5f52\u7c7b**\u5230\u9884\u5148\u5b9a\u4e49\u597d\u7684\u7c7b\u522b\u4e2d\u3002\u7ec4\u59d4\u4f1a\u9488\u5bf9\u8fd9\u4e2a\u8bc4\u6d4b\u4efb\u52a1\uff0c\u63d0\u4f9b\u4e86600\u4efd\u6807\u6ce8\u597d\u7684\u7535\u5b50\u75c5\u5386\u6587\u672c\uff0c\u5171\u9700\u8bc6\u522b\u542b\u89e3\u5256\u90e8\u4f4d\u3001\u72ec\u7acb\u75c7\u72b6\u3001\u75c7\u72b6\u63cf\u8ff0\u3001\u624b\u672f\u548c\u836f\u7269\u4e94\u7c7b\u5b9e\u4f53\u3002 **\u9886\u57df\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u95ee\u9898**\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7ecf\u5178\u7684\u5e8f\u5217\u6807\u6ce8\u95ee\u9898, \u672c\u9879\u76ee\u662f\u8fd0\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c**\u547d\u540d\u5b9e\u4f53\u8bc6\u522b**\u7684\u4e00\u4e2a\u5c1d\u8bd5.","title":"\u9879\u76ee\u4ecb\u7ecd"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_2","text":"","title":"\u5b9e\u9a8c\u6570\u636e"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_3","text":"O \u975e\u5b9e\u4f53\u90e8\u5206, TREATMENT \u6cbb\u7597\u65b9\u5f0f, BODY \u8eab\u4f53\u90e8\u4f4d, SIGN \u75be\u75c5\u75c7\u72b6, CHECK \u533b\u5b66\u68c0\u67e5, DISEASE \u75be\u75c5\u5b9e\u4f53,","title":"\u4e00, \u76ee\u6807\u5e8f\u5217\u6807\u8bb0\u96c6\u5408"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_4","text":"\u91c7\u7528 BIO \u4e09\u5143\u6807\u8bb0 self . class_dict = { 'O' : 0 , 'TREATMENT-I' : 1 , 'TREATMENT-B' : 2 , 'BODY-B' : 3 , 'BODY-I' : 4 , 'SIGNS-I' : 5 , 'SIGNS-B' : 6 , 'CHECK-B' : 7 , 'CHECK-I' : 8 , 'DISEASE-I' : 9 , 'DISEASE-B' : 10 }","title":"\u4e8c, \u5e8f\u5217\u6807\u8bb0\u65b9\u6cd5"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_5","text":"\u8bc4\u6d4b\u65b9\u63d0\u4f9b\u4e86\u56db\u4e2a\u76ee\u5f55(\u4e00\u822c\u9879\u76ee, \u51fa\u9662\u9879\u76ee, \u75c5\u53f2\u7279\u70b9, \u8bca\u7597\u7ecf\u8fc7),\u56db\u4e2a\u76ee\u5f55\u4e0b\u6709txt original\u6587\u4ef6**\u548ct**xt\u6807\u6ce8\u6587\u4ef6 ,\u5185\u5bb9\u6837\u5f0f\u5982\u4e0b: \u4e00\u822c\u9879\u76ee-1.txtoriginal.txt \u5973\u6027\uff0c88\u5c81\uff0c\u519c\u6c11\uff0c\u53cc\u6ee6\u533a\u5e94\u8425\u5b50\u6751\u4eba\uff0c\u4e3b\u56e0\u53f3\u9acb\u90e8\u6454\u4f24\u540e\u75bc\u75db\u80bf\u80c0\uff0c\u6d3b\u52a8\u53d7\u96505\u5c0f\u65f6\u4e8e2016-10-29\uff1b11\uff1a12\u5165\u9662\u3002 \u4e00\u822c\u9879\u76ee-1.txt: \u53f3\u9acb\u90e8 21 23 \u8eab\u4f53\u90e8\u4f4d \u75bc\u75db 27 28 \u75c7\u72b6\u548c\u4f53\u5f81 \u80bf\u80c0 29 30 \u75c7\u72b6\u548c\u4f53\u5f81 \u8f6c\u6362\u811a\u672c\u51fd\u6570: def transfer ( self ): f = open ( self . train_filepath , 'w+' ) count = 0 for root , dirs , files in os . walk ( self . origin_path ): for file in files : filepath = os . path . join ( root , file ) if 'original' not in filepath : continue label_filepath = filepath . replace ( '.txtoriginal' , '' ) print ( filepath , ' \\t\\t ' , label_filepath ) content = open ( filepath ) . read () . strip () res_dict = {} for line in open ( label_filepath ): res = line . strip () . split ( ' ' ) start = int ( res [ 1 ]) end = int ( res [ 2 ]) label = res [ 3 ] label_id = self . label_dict . get ( label ) for i in range ( start , end + 1 ): if i == start : label_cate = label_id + '-B' else : label_cate = label_id + '-I' res_dict [ i ] = label_cate for indx , char in enumerate ( content ): char_label = res_dict . get ( indx , 'O' ) print ( char , char_label ) f . write ( char + ' \\t ' + char_label + ' \\n ' ) f . close () return \u6a21\u578b\u8f93\u51fa\u6837\u5f0f: \uff0c O \u7537 O \uff0c O \u53cc O \u5854 O \u5c71 O \u4eba O \uff0c O \u4e3b O \u56e0 O \u54b3 SIGNS-B \u55fd SIGNS-I \u3001 O \u5c11 SIGNS-B \u75f0 SIGNS-I 1 O \u4e2a O \u6708 O \uff0c O \u52a0 O \u91cd O 3 O \u5929 O \uff0c O \u62bd SIGNS-B \u6410 SIGNS-I","title":"\u4e09, \u6570\u636e\u8f6c\u6362"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_6","text":"\u672c\u6a21\u578b\u4f7f\u7528**\u9884\u8bad\u7ec3\u5b57\u5411\u91cf**,\u4f5c\u4e3a**embedding\u5c42**\u8f93\u5165,\u7136\u540e\u7ecf\u8fc7\u4e24\u4e2a\u53cc\u5411LSTM\u5c42\u8fdb\u884c\u7f16\u7801,\u7f16\u7801\u540e\u52a0\u5165dense\u5c42,\u6700\u540e\u9001\u5165CRF\u5c42\u8fdb\u884c\u5e8f\u5217\u6807\u6ce8. '''\u4f7f\u7528\u9884\u8bad\u7ec3\u5411\u91cf\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3''' def tokenvec_bilstm2_crf_model ( self ): model = Sequential () embedding_layer = Embedding ( self . VOCAB_SIZE + 1 , self . EMBEDDING_DIM , weights = [ self . embedding_matrix ], input_length = self . TIME_STAMPS , trainable = False , mask_zero = True ) model . add ( embedding_layer ) model . add ( Bidirectional ( LSTM ( 128 , return_sequences = True ))) model . add ( Dropout ( 0.5 )) model . add ( Bidirectional ( LSTM ( 64 , return_sequences = True ))) model . add ( Dropout ( 0.5 )) model . add ( TimeDistributed ( Dense ( self . NUM_CLASSES ))) crf_layer = CRF ( self . NUM_CLASSES , sparse_target = True ) model . add ( crf_layer ) model . compile ( 'adam' , loss = crf_layer . loss_function , metrics = [ crf_layer . accuracy ]) model . summary () return model","title":"\u6a21\u578b\u642d\u5efa"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_7","text":"1, \u6a21\u578b\u7684\u8bad\u7ec3: \u6a21\u578b \u8bad\u7ec3\u96c6 \u6d4b\u8bd5\u96c6 \u8bad\u7ec3\u96c6\u51c6\u786e\u7387 \u6d4b\u8bd5\u96c6\u51c6\u786e\u7387 \u5907\u6ce8 \u533b\u7597\u5b9e\u4f53\u8bc6\u522b 6268 1571 0.9649 0.8451 5\u4e2aepcho 2, \u6a21\u578b\u7684\u6d4b\u8bd5: python lstm_predict.py , \u5bf9\u8bad\u7ec3\u597d\u7684\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5,\u6d4b\u8bd5\u6548\u679c\u5982\u4e0b: enter an sent:\u4ed6\u6700\u8fd1\u5934\u75db,\u6d41\u9f3b\u6d95,\u4f30\u8ba1\u662f\u53d1\u70e7\u4e86 [('\u4ed6', 'O'), ('\u6700', 'O'), ('\u8fd1', 'O'), ('\u5934', 'SIGNS-B'), ('\u75db', 'SIGNS-I'), (',', 'O'), ('\u6d41', 'O'), ('\u9f3b', 'O'), ('\u6d95', 'O'), (',', 'O'), ('\u4f30', 'O'), ('\u8ba1', 'O'), ('\u662f', 'O'), ('\u53d1', 'SIGNS-B'), ('\u70e7', 'SIGNS-I'), ('\u4e86', 'SIGNS-I')] enter an sent:\u53e3\u8154\u6e83\u75a1\u53ef\u80fd\u9700\u8981\u591a\u5403\u7ef4\u751f\u7d20 [('\u53e3', 'BODY-B'), ('\u8154', 'BODY-I'), ('\u6e83', 'O'), ('\u75a1', 'O'), ('\u53ef', 'O'), ('\u80fd', 'O'), ('\u9700', 'O'), ('\u8981', 'O'), ('\u591a', 'O'), ('\u5403', 'O'), ('\u7ef4', 'CHECK-B'), ('\u751f', 'CHECK-B'), ('\u7d20', 'TREATMENT-I')] enter an sent:\u4ed6\u9aa8\u6298\u4e86,\u53ef\u80fd\u9700\u8981\u62cd\u7247 [('\u4ed6', 'O'), ('\u9aa8', 'SIGNS-B'), ('\u6298', 'SIGNS-I'), ('\u4e86', 'O'), (',', 'O'), ('\u53ef', 'O'), ('\u80fd', 'O'), ('\u9700', 'O'), ('\u8981',","title":"\u6a21\u578b\u6548\u679c"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Medical-Named-Entity-Recognition/#_8","text":"1,\u672c\u9879\u76ee\u9488\u5bf9\u4e2d\u6587\u7535\u5b50\u75c5\u4f8b\u547d\u540d\u5b9e\u4f53\u4efb\u52a1,\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eBilstm+CRF\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b 2,\u672c\u9879\u76ee\u4f7f\u7528charembedding\u4f5c\u4e3a\u539f\u59cb\u7279\u5f81,\u8bad\u7ec3\u96c6\u51c6\u786e\u7387\u4e3a0.9649,\u6d4b\u8bd5\u96c6\u51c6\u786e\u8fbe\u52300.8451 3,\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u53ef\u4ee5\u52a0\u5165\u66f4\u591a\u7684\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3,\u540e\u671f\u5c06\u9010\u6b65\u5b9e\u9a8c\u5176\u4ed6\u65b9\u5f0f.","title":"\u603b\u7ed3"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Sequence-tagging/","text":"sequence_tagging","title":"[sequence_tagging](https://github.com/guillaumegenthial/sequence_tagging)"},{"location":"Application/NLP/NLP-progress/TODO-Named-entity-recognition/Example/Sequence-tagging/#sequence_tagging","text":"","title":"sequence_tagging"},{"location":"Application/NLP/NLP-progress/Text-Classification/Text-Classification/","text":"Text-Classification","title":"Text-Classification"},{"location":"Application/NLP/NLP-progress/Text-Classification/Text-Classification/#text-classification","text":"","title":"Text-Classification"},{"location":"Application/NLP/NLP-progress/Text-Classification/paper-Bidirectional-LSTM-with-attention-mechanism-and-convolutional-layer/","text":"","title":"paper-Bidirectional-LSTM-with-attention-mechanism-and-convolutional-layer"},{"location":"Application/NLP/Representation-of-word/Representation-of-image-VS--word/","text":"\u524d\u8a00 \u5bf9word\u7684representation\u8981\u6bd4\u5bf9image\u7684representation\u96be\uff0c\u56e0\u4e3aword\u662f\u5177\u6709\u975e\u5e38\u5e7f\u6cdb\u7684distribution\uff0c\u5b83\u7684\u7ec4\u5408\u662f\u975e\u5e38\u4e4b\u591a\u7684\uff0c\u4f46\u662fimage\u5219\u975e\u5e38\u96c6\u4e2d\uff1b \u5728NLP\u9886\u57df\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u6765\u5ea6\u91cf\u8bed\u4e49\u7684\u76f8\u4f3c\u6027\uff1b representation of word Vector space model Distributional semantics \u5728 Word embedding \u4e2d\u6709\u8fd9\u6837\u7684\u4e00\u6bb5\u8bdd\uff1a In 2000 Bengio et al. provided in a series of papers the \"Neural probabilistic language models\" to reduce the high dimensionality of words representations in contexts by \"learning a distributed representation for words\". (Bengio et al., 2003).[ 12]","title":"Representation-of-image-VS--word"},{"location":"Application/NLP/Representation-of-word/Representation-of-image-VS--word/#_1","text":"\u5bf9word\u7684representation\u8981\u6bd4\u5bf9image\u7684representation\u96be\uff0c\u56e0\u4e3aword\u662f\u5177\u6709\u975e\u5e38\u5e7f\u6cdb\u7684distribution\uff0c\u5b83\u7684\u7ec4\u5408\u662f\u975e\u5e38\u4e4b\u591a\u7684\uff0c\u4f46\u662fimage\u5219\u975e\u5e38\u96c6\u4e2d\uff1b \u5728NLP\u9886\u57df\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u6765\u5ea6\u91cf\u8bed\u4e49\u7684\u76f8\u4f3c\u6027\uff1b","title":"\u524d\u8a00"},{"location":"Application/NLP/Representation-of-word/Representation-of-image-VS--word/#representation#of#word","text":"Vector space model Distributional semantics \u5728 Word embedding \u4e2d\u6709\u8fd9\u6837\u7684\u4e00\u6bb5\u8bdd\uff1a In 2000 Bengio et al. provided in a series of papers the \"Neural probabilistic language models\" to reduce the high dimensionality of words representations in contexts by \"learning a distributed representation for words\". (Bengio et al., 2003).[ 12]","title":"representation of word"},{"location":"Application/NRE/","text":"Neural Relation Extraction (NRE) This is my repository about neural relation extraction . distant supervision for relation extraction papers No Time Paper Pros Cons 0911 200911 Distant supervision for relation extraction without labeled data \u5f88\u591a\uff0c\u6bd4\u5982\uff1a\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3001\u6210\u672c\u4f4e\u3001\u5927\u5bb9\u91cf\u6570\u636e\u96c6\u3001\u80fd\u591f\u89c4\u907f\u4e00\u4e9b\u56f0\u6270\u76d1\u7763\u5b66\u4e60\u7684\u95ee\u9898 1. \u566a\u58f0\u5927\uff0c\u6027\u80fd\u4e0d\u591f\u5f3a 2. \u9700\u8981\u4eba\u4e3a\u8bbe\u8ba1\u7279\u5f81 ... ... ... ... 15 2015 Distant supervisionfor relation extraction via piecewise convolutional neural networks. 1. \u4f7f\u7528**PCNNs**s\u795e\u7ecf\u7f51\u7edc\u9009\u62e9\u6700\u5927\u6982\u7387\u4e3avalid instance\u7684\u53e5\u5b50\u6765\u4ece\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u4f20\u7edf\u7684NLP\u5de5\u5177 1. \u6bcf\u4e2abag\u4e2d\u4ec5\u4ec5\u9009\u62e9\u4e00\u4e2a\u53e5\u5b50\uff08\u6700\u5927\u6982\u7387\uff09\u4f5c\u4e3avalid instance\uff0c\u5bfc\u81f4\u5b83\u672a\u80fd\u5145\u5206\u5229\u7528bag\u4e2d\u7684\u4fe1\u606f 17 2017 Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions 1. bag\u4e2d\u4f1a\u8003\u8651\u591a\u4e2a valid Instance 2. \u7531\u795e\u7ecf\u7f51\u7edc\u6765\u63d0\u53d6\u7279\u5f81 3. \u63d0\u51fa**entity descriptions**\u601d\u8def 1904 201904 Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions 1. \u9664\u4e86intra-bag\uff08\u5305\u5185\uff09 attentions\uff0c\u8fd8\u6dfb\u52a0\u4e86inter-bag\uff08\u5305\u95f4\uff09 attentions","title":"Introduction"},{"location":"Application/NRE/#neural#relation#extraction#nre","text":"This is my repository about neural relation extraction .","title":"Neural Relation Extraction (NRE)"},{"location":"Application/NRE/#distant#supervision#for#relation#extraction","text":"","title":"distant supervision for relation extraction"},{"location":"Application/NRE/#papers","text":"No Time Paper Pros Cons 0911 200911 Distant supervision for relation extraction without labeled data \u5f88\u591a\uff0c\u6bd4\u5982\uff1a\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3001\u6210\u672c\u4f4e\u3001\u5927\u5bb9\u91cf\u6570\u636e\u96c6\u3001\u80fd\u591f\u89c4\u907f\u4e00\u4e9b\u56f0\u6270\u76d1\u7763\u5b66\u4e60\u7684\u95ee\u9898 1. \u566a\u58f0\u5927\uff0c\u6027\u80fd\u4e0d\u591f\u5f3a 2. \u9700\u8981\u4eba\u4e3a\u8bbe\u8ba1\u7279\u5f81 ... ... ... ... 15 2015 Distant supervisionfor relation extraction via piecewise convolutional neural networks. 1. \u4f7f\u7528**PCNNs**s\u795e\u7ecf\u7f51\u7edc\u9009\u62e9\u6700\u5927\u6982\u7387\u4e3avalid instance\u7684\u53e5\u5b50\u6765\u4ece\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u4f20\u7edf\u7684NLP\u5de5\u5177 1. \u6bcf\u4e2abag\u4e2d\u4ec5\u4ec5\u9009\u62e9\u4e00\u4e2a\u53e5\u5b50\uff08\u6700\u5927\u6982\u7387\uff09\u4f5c\u4e3avalid instance\uff0c\u5bfc\u81f4\u5b83\u672a\u80fd\u5145\u5206\u5229\u7528bag\u4e2d\u7684\u4fe1\u606f 17 2017 Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions 1. bag\u4e2d\u4f1a\u8003\u8651\u591a\u4e2a valid Instance 2. \u7531\u795e\u7ecf\u7f51\u7edc\u6765\u63d0\u53d6\u7279\u5f81 3. \u63d0\u51fa**entity descriptions**\u601d\u8def 1904 201904 Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions 1. \u9664\u4e86intra-bag\uff08\u5305\u5185\uff09 attentions\uff0c\u8fd8\u6dfb\u52a0\u4e86inter-bag\uff08\u5305\u95f4\uff09 attentions","title":"papers"},{"location":"Application/Sequence/Sequence/","text":"Sequence machine learning\u4e2d\uff0c\u89e3\u51b3sequence\u95ee\u9898\u7684\u4e00\u4e9b\u65b9\u5f0f\uff1a Markov-model","title":"Sequence"},{"location":"Application/Sequence/Sequence/#sequence","text":"machine learning\u4e2d\uff0c\u89e3\u51b3sequence\u95ee\u9898\u7684\u4e00\u4e9b\u65b9\u5f0f\uff1a Markov-model","title":"Sequence"},{"location":"Data-set/","text":"\u4ece\u4e8b\u673a\u5668\u5b66\u4e60\uff0c\u4e0d\u80fd\u591f\u7f3a\u5c11\u6570\u636e\u7684\u652f\u6301\uff0c\u8fd9\u91cc\u624b\u673a\u4e86\u4e00\u4e9b\u63d0\u4f9b\u4e86\u8f83\u597d\u7684\u6570\u636e\u96c6\u7684\u7f51\u7ad9\u3002 https://www.tensorflow.org/tutorials/keras/basic_regressionon","title":"Introduction"},{"location":"Data-set/Auto-MPG-Data-Set/AUTO-MPG-example/","text":"","title":"AUTO MPG example"},{"location":"Programming/VS-pytorch-vs-tensorflow/","text":"https://towardsdatascience.com/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b","title":"VS-pytorch-vs-tensorflow"},{"location":"Programming/Keras/Getting-started-with-the-Keras-Sequential-model/","text":"Getting started with the Keras Sequential model Multilayer Perceptron (MLP) for multi-class softmax classification: import keras from keras.models import Sequential from keras.layers import Dense , Dropout , Activation from keras.optimizers import SGD # Generate dummy data import numpy as np x_train = np . random . random (( 1000 , 20 )) y_train = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 1000 , 1 )), num_classes = 10 ) x_test = np . random . random (( 100 , 20 )) y_test = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 100 , 1 )), num_classes = 10 ) model = Sequential () # Dense(64) is a fully-connected layer with 64 hidden units. # in the first layer, you must specify the expected input data shape: # here, 20-dimensional vectors. model . add ( Dense ( 64 , activation = 'relu' , input_dim = 20 )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 64 , activation = 'relu' )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 10 , activation = 'softmax' )) sgd = SGD ( lr = 0.01 , decay = 1e-6 , momentum = 0.9 , nesterov = True ) model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'accuracy' ]) model . fit ( x_train , y_train , epochs = 20 , batch_size = 128 ) score = model . evaluate ( x_test , y_test , batch_size = 128 ) NOTE: \u601d\u8003\uff1a\u4e0a\u8ff0\u6743\u91cd\u77e9\u9635\u662f\u4ec0\u4e48\uff1f\u4e00\u822c\u8f93\u5165\u77e9\u9635\u7684shape\u662f [batch_size, feature_num] \uff0c\u5219\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f [feature_num, hidden_layer_node_num_1] \uff1b \u663e\u7136\uff0c\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\u548c batch_size \u65e0\u5173\u7684\uff1b \u4e00\u822c\uff0c\u6211\u4eec\u5728\u9605\u8bfb\u4e66\u7c4d\u7684\u65f6\u5019\uff0c\u4e66\u4e2d\u6240\u63cf\u8ff0\u7684\u6d41\u7a0b\u90fd\u662f\u4e00\u6b21\u8f93\u5165\u4e00\u6761\u8bb0\u5f55\uff0c\u8fd9\u79cd\u505a\u6cd5\u662f\u7406\u8bba\u4e0a\u7684\uff0c\u5b9e\u9645\u4e0a\u5982\u679c\u771f\u6ef4\u4e00\u6b21\u4ec5\u4ec5\u5582\u5165\u4e00\u6761\u6570\u636e\u7684\u8bdd\uff0c\u4f1a\u975e\u5e38\u7f13\u6162\uff1b\u5b9e\u9645\u7684\u5b9e\u73b0\u662f\u4e00\u6b21\u5582\u5165\u4e00\u4e2abatch\u7684\uff0c\u5373\u662f\u4e0a\u9762\u6240\u63cf\u8ff0\u7684\u8f93\u5165\u77e9\u9635\uff0c\u73b0\u4ee3\u7684GPU\u5904\u7406\u77e9\u9635\u8fd0\u7b97\u7684\u901f\u5ea6\u975e\u5e38\u5feb\uff1b\u5176\u5b9e\u4e00\u6b21\u5582\u5165\u4e00\u6761\u8bb0\u5f55\u4e5f\u53ef\u4ee5\u5957\u7528\u4e0a\u9762\u7684\u77e9\u9635\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u5373 batch_size=1 \uff1b\u6839\u636e\u77e9\u9635\u7684\u4e58\u6cd5\u539f\u7406\u53ef\u4ee5\u4ece\u77e5\u9053\u6bcf\u4e00\u6761\u6570\u636e\u4f1a\u6d41\u5165\u5230\u7b2c\u4e00\u9690\u85cf\u5c42\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8282\u70b9\uff0c\u4e00\u6761\u8bb0\u5f55\u6d41\u5165\u4e00\u4e2a\u8282\u70b9\u4ea7\u751f\u7684\u8f93\u51fa\u5176\u5b9e\u662f\u4e00\u4e2a\u6807\u91cf\uff1b \u65e0\u8bba\u5bf9\u4e8e\u4ec0\u4e48\u6a21\u578b\uff0c\u4e0a\u8ff0\u539f\u7406\u90fd\u662f\u901a\u7528\u7684\uff1b\u6240\u4ee5\uff0c\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684\u8282\u70b9\u6570\u548c\u7279\u5f81\u7684\u4e2a\u6570\u662f\u6ca1\u6709\u5173\u8054\u7684\uff1b\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b [ [1,1,1], [1,1,1], [1,1,1], [1,1,1], [1,1,1], ] 4*3 \u7b2c\u4e00\u9690\u85cf\u5c42\u670910\u4e2anode\uff0c\u5219\u5b83\u7684\u6743\u91cd\u77e9\u9635\u662f[3 * 10] [ [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], ] \u6bcf\u4e00\u5217\u8868\u793a\u7684\u662f \u7b2c\u4e8c\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\uff1a [hidden_layer_node_num_1, hidden_layer_node_num_2] \uff0c\u4f9d\u6b21\u7c7b\u63a8\uff0c\u6240\u4ee5\u6700\u7ec8\u6700\u540e\u4e00\u5c42\u5373\u8f93\u51fa\u5c42\u7684\u4e0e\u524d\u4e00\u5c42\u4e4b\u95f4\u7684\u6743\u91cd\u77e9\u9635 [hidden_layer_node_num_-1, n_class] \uff08 -1 \u8868\u793a\u6700\u540e\u4e00\u5c42\uff09\u3002 \u6240\u4ee5\uff0c\u6700\u7ec8\u4e00\u4e2abatch_size\u7684\u6570\u636e\u6d41\u7ecfMLP\u4e4b\u540e\uff0c\u5f97\u5230\u7684\u6570\u636e\u7684shape\u662f [batch_size, n_classes] \u3002 \u5176\u5b9e\u4ece\u8fd9\u4e2a\u6570\u5b66\u5173\u7cfb\u4e5f\u53ef\u4ee5\u770b\u51fa\u4e3a\u4ec0\u4e48\u8981\u5c06label\u4ee5one-hot\u7684\u65b9\u5f0f\u8868\u793a\u4e86\uff1b","title":"Getting-started-with-the-Keras-Sequential-model"},{"location":"Programming/Keras/Getting-started-with-the-Keras-Sequential-model/#getting#started#with#the#keras#sequential#model","text":"","title":"Getting started with the Keras Sequential model"},{"location":"Programming/Keras/Getting-started-with-the-Keras-Sequential-model/#multilayer#perceptron#mlp#for#multi-class#softmax#classification","text":"import keras from keras.models import Sequential from keras.layers import Dense , Dropout , Activation from keras.optimizers import SGD # Generate dummy data import numpy as np x_train = np . random . random (( 1000 , 20 )) y_train = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 1000 , 1 )), num_classes = 10 ) x_test = np . random . random (( 100 , 20 )) y_test = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 100 , 1 )), num_classes = 10 ) model = Sequential () # Dense(64) is a fully-connected layer with 64 hidden units. # in the first layer, you must specify the expected input data shape: # here, 20-dimensional vectors. model . add ( Dense ( 64 , activation = 'relu' , input_dim = 20 )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 64 , activation = 'relu' )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 10 , activation = 'softmax' )) sgd = SGD ( lr = 0.01 , decay = 1e-6 , momentum = 0.9 , nesterov = True ) model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'accuracy' ]) model . fit ( x_train , y_train , epochs = 20 , batch_size = 128 ) score = model . evaluate ( x_test , y_test , batch_size = 128 ) NOTE: \u601d\u8003\uff1a\u4e0a\u8ff0\u6743\u91cd\u77e9\u9635\u662f\u4ec0\u4e48\uff1f\u4e00\u822c\u8f93\u5165\u77e9\u9635\u7684shape\u662f [batch_size, feature_num] \uff0c\u5219\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f [feature_num, hidden_layer_node_num_1] \uff1b \u663e\u7136\uff0c\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\u548c batch_size \u65e0\u5173\u7684\uff1b \u4e00\u822c\uff0c\u6211\u4eec\u5728\u9605\u8bfb\u4e66\u7c4d\u7684\u65f6\u5019\uff0c\u4e66\u4e2d\u6240\u63cf\u8ff0\u7684\u6d41\u7a0b\u90fd\u662f\u4e00\u6b21\u8f93\u5165\u4e00\u6761\u8bb0\u5f55\uff0c\u8fd9\u79cd\u505a\u6cd5\u662f\u7406\u8bba\u4e0a\u7684\uff0c\u5b9e\u9645\u4e0a\u5982\u679c\u771f\u6ef4\u4e00\u6b21\u4ec5\u4ec5\u5582\u5165\u4e00\u6761\u6570\u636e\u7684\u8bdd\uff0c\u4f1a\u975e\u5e38\u7f13\u6162\uff1b\u5b9e\u9645\u7684\u5b9e\u73b0\u662f\u4e00\u6b21\u5582\u5165\u4e00\u4e2abatch\u7684\uff0c\u5373\u662f\u4e0a\u9762\u6240\u63cf\u8ff0\u7684\u8f93\u5165\u77e9\u9635\uff0c\u73b0\u4ee3\u7684GPU\u5904\u7406\u77e9\u9635\u8fd0\u7b97\u7684\u901f\u5ea6\u975e\u5e38\u5feb\uff1b\u5176\u5b9e\u4e00\u6b21\u5582\u5165\u4e00\u6761\u8bb0\u5f55\u4e5f\u53ef\u4ee5\u5957\u7528\u4e0a\u9762\u7684\u77e9\u9635\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u5373 batch_size=1 \uff1b\u6839\u636e\u77e9\u9635\u7684\u4e58\u6cd5\u539f\u7406\u53ef\u4ee5\u4ece\u77e5\u9053\u6bcf\u4e00\u6761\u6570\u636e\u4f1a\u6d41\u5165\u5230\u7b2c\u4e00\u9690\u85cf\u5c42\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8282\u70b9\uff0c\u4e00\u6761\u8bb0\u5f55\u6d41\u5165\u4e00\u4e2a\u8282\u70b9\u4ea7\u751f\u7684\u8f93\u51fa\u5176\u5b9e\u662f\u4e00\u4e2a\u6807\u91cf\uff1b \u65e0\u8bba\u5bf9\u4e8e\u4ec0\u4e48\u6a21\u578b\uff0c\u4e0a\u8ff0\u539f\u7406\u90fd\u662f\u901a\u7528\u7684\uff1b\u6240\u4ee5\uff0c\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684\u8282\u70b9\u6570\u548c\u7279\u5f81\u7684\u4e2a\u6570\u662f\u6ca1\u6709\u5173\u8054\u7684\uff1b\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b [ [1,1,1], [1,1,1], [1,1,1], [1,1,1], [1,1,1], ] 4*3 \u7b2c\u4e00\u9690\u85cf\u5c42\u670910\u4e2anode\uff0c\u5219\u5b83\u7684\u6743\u91cd\u77e9\u9635\u662f[3 * 10] [ [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], ] \u6bcf\u4e00\u5217\u8868\u793a\u7684\u662f \u7b2c\u4e8c\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\uff1a [hidden_layer_node_num_1, hidden_layer_node_num_2] \uff0c\u4f9d\u6b21\u7c7b\u63a8\uff0c\u6240\u4ee5\u6700\u7ec8\u6700\u540e\u4e00\u5c42\u5373\u8f93\u51fa\u5c42\u7684\u4e0e\u524d\u4e00\u5c42\u4e4b\u95f4\u7684\u6743\u91cd\u77e9\u9635 [hidden_layer_node_num_-1, n_class] \uff08 -1 \u8868\u793a\u6700\u540e\u4e00\u5c42\uff09\u3002 \u6240\u4ee5\uff0c\u6700\u7ec8\u4e00\u4e2abatch_size\u7684\u6570\u636e\u6d41\u7ecfMLP\u4e4b\u540e\uff0c\u5f97\u5230\u7684\u6570\u636e\u7684shape\u662f [batch_size, n_classes] \u3002 \u5176\u5b9e\u4ece\u8fd9\u4e2a\u6570\u5b66\u5173\u7cfb\u4e5f\u53ef\u4ee5\u770b\u51fa\u4e3a\u4ec0\u4e48\u8981\u5c06label\u4ee5one-hot\u7684\u65b9\u5f0f\u8868\u793a\u4e86\uff1b","title":"Multilayer Perceptron (MLP) for multi-class softmax classification:"},{"location":"Programming/Keras/intro-Keras/","text":"Keras: The Python Deep Learning library You have just found Keras. Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow , CNTK , or Theano . It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research. Use Keras if you need a deep learning library that: Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility). Supports both convolutional networks and recurrent networks, as well as combinations of the two. Runs seamlessly on CPU and GPU. Read the documentation at Keras.io . Keras is compatible with: Python 2.7-3.6 . Guiding principles User friendliness. Keras is an API designed for human beings, not machines. It puts user experience front and center. Keras follows best practices for reducing cognitive\uff08\u8ba4\u77e5\uff09 load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error. Modularity. A model is understood as a sequence or a graph of standalone, fully configurable modules that can be plugged together with as few restrictions as possible. In particular, neural layers , cost functions , optimizers , initialization schemes , activation functions and regularization schemes are all standalone modules that you can combine to create new models. Easy extensibility. New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research. Work with Python . No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility. NOTE: \u597d\u7684software\u5c31\u5e94\u5f53\u63d0\u4f9b\u5982Keras\u8fd9\u6837\u7684API\uff1b Getting started: 30 seconds to Keras The core data structure of Keras is a model , a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. For more complex architectures, you should use the Keras functional API , which allows to build arbitrary graphs of layers. SUMMARY : \u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\uff0cmodel\uff0cnetwork\uff0cgraph\u53ef\u4ee5\u770b\u505a\u662f\u540c\u4e49\u8bcd\uff1b Here is the Sequential model: from keras.models import Sequential model = Sequential () Stacking\uff08\u5806\uff09 layers is as easy as .add() : from keras.layers import Dense model . add ( Dense ( units = 64 , activation = 'relu' , input_dim = 100 )) model . add ( Dense ( units = 10 , activation = 'softmax' )) Once your model looks good, configure its learning process with .compile() : model . compile ( loss = 'categorical_crossentropy' , optimizer = 'sgd' , metrics = [ 'accuracy' ]) If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code). model . compile ( loss = keras . losses . categorical_crossentropy , optimizer = keras . optimizers . SGD ( lr = 0.01 , momentum = 0.9 , nesterov = True )) You can now iterate on your training data in batches: # x_train and y_train are Numpy arrays --just like in the Scikit-Learn API. model . fit ( x_train , y_train , epochs = 5 , batch_size = 32 ) Alternatively, you can feed batches to your model manually: model . train_on_batch ( x_batch , y_batch ) Evaluate your performance in one line: loss_and_metrics = model . evaluate ( x_test , y_test , batch_size = 128 ) Or generate predictions on new data: classes = model . predict ( x_test , batch_size = 128 ) Building a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful? For a more in-depth tutorial about Keras, you can check out: Getting started with the Sequential model Getting started with the functional API In the examples folder of the repository, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, etc. Installation Before installing Keras, please install one of its backend engines: TensorFlow, Theano, or CNTK. We recommend the TensorFlow backend. TensorFlow installation instructions . Theano installation instructions . CNTK installation instructions . You may also consider installing the following optional dependencies : cuDNN (recommended if you plan on running Keras on GPU). HDF5 and h5py (required if you plan on saving Keras models to disk). graphviz and pydot (used by visualization utilities to plot model graphs). Then, you can install Keras itself. There are two ways to install Keras: Configuring your Keras backend By default, Keras will use TensorFlow as its tensor manipulation library. Follow these instructions to configure the Keras backend.","title":"intro-Keras"},{"location":"Programming/Keras/intro-Keras/#keras#the#python#deep#learning#library","text":"","title":"Keras: The Python Deep Learning library"},{"location":"Programming/Keras/intro-Keras/#you#have#just#found#keras","text":"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow , CNTK , or Theano . It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research. Use Keras if you need a deep learning library that: Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility). Supports both convolutional networks and recurrent networks, as well as combinations of the two. Runs seamlessly on CPU and GPU. Read the documentation at Keras.io . Keras is compatible with: Python 2.7-3.6 .","title":"You have just found Keras."},{"location":"Programming/Keras/intro-Keras/#guiding#principles","text":"User friendliness. Keras is an API designed for human beings, not machines. It puts user experience front and center. Keras follows best practices for reducing cognitive\uff08\u8ba4\u77e5\uff09 load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error. Modularity. A model is understood as a sequence or a graph of standalone, fully configurable modules that can be plugged together with as few restrictions as possible. In particular, neural layers , cost functions , optimizers , initialization schemes , activation functions and regularization schemes are all standalone modules that you can combine to create new models. Easy extensibility. New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research. Work with Python . No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility. NOTE: \u597d\u7684software\u5c31\u5e94\u5f53\u63d0\u4f9b\u5982Keras\u8fd9\u6837\u7684API\uff1b","title":"Guiding principles"},{"location":"Programming/Keras/intro-Keras/#getting#started#30#seconds#to#keras","text":"The core data structure of Keras is a model , a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. For more complex architectures, you should use the Keras functional API , which allows to build arbitrary graphs of layers. SUMMARY : \u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\uff0cmodel\uff0cnetwork\uff0cgraph\u53ef\u4ee5\u770b\u505a\u662f\u540c\u4e49\u8bcd\uff1b Here is the Sequential model: from keras.models import Sequential model = Sequential () Stacking\uff08\u5806\uff09 layers is as easy as .add() : from keras.layers import Dense model . add ( Dense ( units = 64 , activation = 'relu' , input_dim = 100 )) model . add ( Dense ( units = 10 , activation = 'softmax' )) Once your model looks good, configure its learning process with .compile() : model . compile ( loss = 'categorical_crossentropy' , optimizer = 'sgd' , metrics = [ 'accuracy' ]) If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code). model . compile ( loss = keras . losses . categorical_crossentropy , optimizer = keras . optimizers . SGD ( lr = 0.01 , momentum = 0.9 , nesterov = True )) You can now iterate on your training data in batches: # x_train and y_train are Numpy arrays --just like in the Scikit-Learn API. model . fit ( x_train , y_train , epochs = 5 , batch_size = 32 ) Alternatively, you can feed batches to your model manually: model . train_on_batch ( x_batch , y_batch ) Evaluate your performance in one line: loss_and_metrics = model . evaluate ( x_test , y_test , batch_size = 128 ) Or generate predictions on new data: classes = model . predict ( x_test , batch_size = 128 ) Building a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful? For a more in-depth tutorial about Keras, you can check out: Getting started with the Sequential model Getting started with the functional API In the examples folder of the repository, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, etc.","title":"Getting started: 30 seconds to Keras"},{"location":"Programming/Keras/intro-Keras/#installation","text":"Before installing Keras, please install one of its backend engines: TensorFlow, Theano, or CNTK. We recommend the TensorFlow backend. TensorFlow installation instructions . Theano installation instructions . CNTK installation instructions . You may also consider installing the following optional dependencies : cuDNN (recommended if you plan on running Keras on GPU). HDF5 and h5py (required if you plan on saving Keras models to disk). graphviz and pydot (used by visualization utilities to plot model graphs). Then, you can install Keras itself. There are two ways to install Keras:","title":"Installation"},{"location":"Programming/Keras/intro-Keras/#configuring#your#keras#backend","text":"By default, Keras will use TensorFlow as its tensor manipulation library. Follow these instructions to configure the Keras backend.","title":"Configuring your Keras backend"},{"location":"Programming/Keras/keras-Layers-Convolutional-Layers/","text":"Convolutional Layers Conv1D keras . layers . Conv1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = 'channels_last' , dilation_rate = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None ) 1D convolution layer (e.g. temporal convolution ). This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None , it is applied to the outputs as well. When using this layer as the first layer in a model, provide an input_shape argument (tuple of integers or None , does not include the batch axis), e.g. input_shape=(10, 128) for time series sequences of 10 time steps with 128 features per step in data_format=\"channels_last\" , or (None, 128) for variable-length sequences with 128 features per step. Arguments filters : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). kernel_size : An integer or tuple/list of a single integer, specifying the length of the 1D convolution window. strides : An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1. data_format : A string, one of \"channels_last\" (default) or \"channels_first\" . The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, channels) (default format for temporal data in Keras) while \"channels_first\" corresponds to inputs with shape (batch, channels, steps) . NOTE: \u5173\u4e8e**filters**\u548c**kernel_size**\uff0c\u53c2\u89c1\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\uff1a Keras conv1d layer parameters: filters and kernel_size NOTE : \u5173\u4e8echannel-last\u548cchannel-first\uff0c\u53c2\u89c1\u8fd9\u7bc7\u6587\u7ae0\uff1a A Gentle Introduction to Channels-First and Channels-Last Image Formats Input shape 3D tensor with shape: (batch, steps, channels) NOTE: \u8981\u60f3\u7406\u89e3\u8fd9\u6bb5\u8bdd\u4e2d steps \u3001 channels \u7684\u542b\u4e49\uff0c\u9996\u5148\u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\u4e0a\u9762\u7684\u7b2c\u4e09\u6bb5\uff0c\u5176\u4e2d\u5df2\u7ecf\u7ed9\u51fa\u4e86\u4e00\u4e2aexample\uff1b\u8fd9\u91cc\u6211\u518d\u8865\u5145\u4e00\u4e2a\u4f8b\u5b50\uff1a \u5982\u679c\u4ee5 Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks \u4e2d\u7684sentence\u4e3a\u4f8b\uff0c\u90a3\u4e48 steps \u5219\u8868\u793a\u7684sentence\u7684\u957f\u5ea6\uff0c\u5373sentence\u4e2dword\u7684\u4e2a\u6570\uff1b channels \u5219\u8868\u793aword embedding+position embedding\u7684\u957f\u5ea6\uff1b Output shape 3D tensor with shape: (batch, new_steps, filters) steps value might have changed due to padding or strides. NOTE: \u4e0a\u8ff0output shape\u548c Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks \u4e2d\u63cf\u8ff0\u7684\u4e0d\u540c\uff1b NOTE: \u4e00\u822c\u5728\u8bb2\u89e3model\u7684\u539f\u7406\u65f6\u5019\u90fd\u662f\u4e0d\u4f1a\u6d89\u53ca\u5230 batch_size \u7684\uff0c\u800c\u662f\u4ec5\u4ec5\u4e00\u4e00\u6761\u8f93\u5165\u6570\u636e\u4e3a\u4f8b\u6765\u8fdb\u884c\u8bf4\u660e\uff0c\u4f46\u662f\u5b9e\u73b0\u5e93\u4e2d\u5219\u5fc5\u987b\u8981\u6d89\u53ca\u5230 batch_size \uff0c\u8fd9\u91cc\u4fbf\u662f\u8fd9\u6837\uff1b\u5176\u5b9e\u6211\u89c9\u5f97\u5e94\u8be5\u8fd9\u6837\u6765\u7406\u89e3\uff1aConv1D\u80af\u5b9a\u4f1a\u5bf9\u8f93\u5165\u7684 batch_size \u6761\u8bb0\u5f55\u4e2d\u7684\u6bcf\u4e00\u6761\u90fd\u6267\u884c\u7cfb\u7edf\u7684\u5377\u79ef\u8fc7\u7a0b\uff1b","title":"keras-Layers-Convolutional-Layers"},{"location":"Programming/Keras/keras-Layers-Convolutional-Layers/#convolutional#layers","text":"","title":"Convolutional Layers"},{"location":"Programming/Keras/keras-Layers-Convolutional-Layers/#conv1d","text":"keras . layers . Conv1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = 'channels_last' , dilation_rate = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None ) 1D convolution layer (e.g. temporal convolution ). This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None , it is applied to the outputs as well. When using this layer as the first layer in a model, provide an input_shape argument (tuple of integers or None , does not include the batch axis), e.g. input_shape=(10, 128) for time series sequences of 10 time steps with 128 features per step in data_format=\"channels_last\" , or (None, 128) for variable-length sequences with 128 features per step. Arguments filters : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). kernel_size : An integer or tuple/list of a single integer, specifying the length of the 1D convolution window. strides : An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1. data_format : A string, one of \"channels_last\" (default) or \"channels_first\" . The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, channels) (default format for temporal data in Keras) while \"channels_first\" corresponds to inputs with shape (batch, channels, steps) . NOTE: \u5173\u4e8e**filters**\u548c**kernel_size**\uff0c\u53c2\u89c1\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\uff1a Keras conv1d layer parameters: filters and kernel_size NOTE : \u5173\u4e8echannel-last\u548cchannel-first\uff0c\u53c2\u89c1\u8fd9\u7bc7\u6587\u7ae0\uff1a A Gentle Introduction to Channels-First and Channels-Last Image Formats","title":"Conv1D"},{"location":"Programming/Keras/keras-Layers-Convolutional-Layers/#input#shape","text":"3D tensor with shape: (batch, steps, channels) NOTE: \u8981\u60f3\u7406\u89e3\u8fd9\u6bb5\u8bdd\u4e2d steps \u3001 channels \u7684\u542b\u4e49\uff0c\u9996\u5148\u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\u4e0a\u9762\u7684\u7b2c\u4e09\u6bb5\uff0c\u5176\u4e2d\u5df2\u7ecf\u7ed9\u51fa\u4e86\u4e00\u4e2aexample\uff1b\u8fd9\u91cc\u6211\u518d\u8865\u5145\u4e00\u4e2a\u4f8b\u5b50\uff1a \u5982\u679c\u4ee5 Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks \u4e2d\u7684sentence\u4e3a\u4f8b\uff0c\u90a3\u4e48 steps \u5219\u8868\u793a\u7684sentence\u7684\u957f\u5ea6\uff0c\u5373sentence\u4e2dword\u7684\u4e2a\u6570\uff1b channels \u5219\u8868\u793aword embedding+position embedding\u7684\u957f\u5ea6\uff1b","title":"Input  shape"},{"location":"Programming/Keras/keras-Layers-Convolutional-Layers/#output#shape","text":"3D tensor with shape: (batch, new_steps, filters) steps value might have changed due to padding or strides. NOTE: \u4e0a\u8ff0output shape\u548c Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks \u4e2d\u63cf\u8ff0\u7684\u4e0d\u540c\uff1b NOTE: \u4e00\u822c\u5728\u8bb2\u89e3model\u7684\u539f\u7406\u65f6\u5019\u90fd\u662f\u4e0d\u4f1a\u6d89\u53ca\u5230 batch_size \u7684\uff0c\u800c\u662f\u4ec5\u4ec5\u4e00\u4e00\u6761\u8f93\u5165\u6570\u636e\u4e3a\u4f8b\u6765\u8fdb\u884c\u8bf4\u660e\uff0c\u4f46\u662f\u5b9e\u73b0\u5e93\u4e2d\u5219\u5fc5\u987b\u8981\u6d89\u53ca\u5230 batch_size \uff0c\u8fd9\u91cc\u4fbf\u662f\u8fd9\u6837\uff1b\u5176\u5b9e\u6211\u89c9\u5f97\u5e94\u8be5\u8fd9\u6837\u6765\u7406\u89e3\uff1aConv1D\u80af\u5b9a\u4f1a\u5bf9\u8f93\u5165\u7684 batch_size \u6761\u8bb0\u5f55\u4e2d\u7684\u6bcf\u4e00\u6761\u90fd\u6267\u884c\u7cfb\u7edf\u7684\u5377\u79ef\u8fc7\u7a0b\uff1b","title":"Output shape"},{"location":"Programming/Programming-paradigm/","text":"Programming model/paradigm Symbolic VS imperative \u5728 ./Symbolic-and-imperative \u4e2d\u8fdb\u884c\u4e86\u603b\u7ed3\u3002 TensorFlow Programming Model \u5728 TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems \u4e2d\u5bf9TensorFlow\u7684programming model\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 \u7ecf\u9a8c\u603b\u7ed3 Rule one: separation of model and dataset \u5c06model\u548cdataset\u5206\u9694\u5f00\u6765 Use trainer to connect dataset and model Feedforward and feedback \u524d\u9988\u8fc7\u7a0b\uff1a\u8ba1\u7b97\u5f97\u5230loss \u53cd\u9988\u8fc7\u7a0b\uff1abackpropagation to compute gradient and then adjust parameter\uff1b","title":"Introduction"},{"location":"Programming/Programming-paradigm/#programming#modelparadigm","text":"","title":"Programming model/paradigm"},{"location":"Programming/Programming-paradigm/#symbolic#vs#imperative","text":"\u5728 ./Symbolic-and-imperative \u4e2d\u8fdb\u884c\u4e86\u603b\u7ed3\u3002","title":"Symbolic VS imperative"},{"location":"Programming/Programming-paradigm/#tensorflow#programming#model","text":"\u5728 TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems \u4e2d\u5bf9TensorFlow\u7684programming model\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002","title":"TensorFlow Programming Model"},{"location":"Programming/Programming-paradigm/#_1","text":"","title":"\u7ecf\u9a8c\u603b\u7ed3"},{"location":"Programming/Programming-paradigm/#rule#one#separation#of#model#and#dataset","text":"\u5c06model\u548cdataset\u5206\u9694\u5f00\u6765","title":"Rule one: separation of model and dataset"},{"location":"Programming/Programming-paradigm/#use#trainer#to#connect#dataset#and#model","text":"","title":"Use trainer to connect dataset and model"},{"location":"Programming/Programming-paradigm/#feedforward#and#feedback","text":"\u524d\u9988\u8fc7\u7a0b\uff1a\u8ba1\u7b97\u5f97\u5230loss \u53cd\u9988\u8fc7\u7a0b\uff1abackpropagation to compute gradient and then adjust parameter\uff1b","title":"Feedforward and feedback"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/","text":"Symbolic and imperative symbolic programming\u548cimperative programming\u662f\u5f53\u524dDL\u9886\u57df\u7684\u4e24\u79cd\u4e3b\u6d41programming paradigm\u3002 mxnet Deep Learning Programming Paradigm Writing clear, intuitive deep learning code can be challenging, and the first thing any practitioner must deal with is the language syntax itself. Complicating matters, of the many deep learning libraries out there, each has its own approach to programming style. \u590d\u6742\u7684\u95ee\u9898\u662f\uff0c\u5728\u4f17\u591a\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\u4e2d\uff0c\u6bcf\u4e2a\u5e93\u90fd\u6709\u81ea\u5df1\u7684\u7f16\u7a0b\u98ce\u683c\u3002 In this document, we focus on two of the most important high-level design decisions: 1) Whether to embrace(\u62e5\u62b1) the symbolic or imperative paradigm for mathematical computation . NOTE: \u5173\u4e8esymbolic programming\uff0c\u53c2\u89c1\u5de5\u7a0bprogramming-language\u7684 Theory\\Programming-paradigm\\Symbolic-programming \u7ae0\u8282 2) Whether to build networks with bigger (more abstract) or more atomic operations. Throughout, we\u2019ll focus on the programming models themselves. When programming style decisions may impact performance, we point this out, but we don\u2019t dwell on specific implementation details. NOTE: \"dwell on\"\u7684\u610f\u601d\u662f\"\u601d\u60f3\u5c40\u9650\u4e8e\" Symbolic vs. Imperative Programs If you are a Python or C++ programmer, then you\u2019re already familiar with imperative programs . Imperative-style programs perform computation as you run them. Most code you write in Python is imperative, as is the following NumPy snippet. import numpy as np a = np . ones ( 10 ) b = np . ones ( 10 ) * 2 c = b * a d = c + 1 When the program executes c = b * a , it runs the actual numerical computation . Symbolic programs are a bit different. With symbolic-style programs, we first define a (potentially complex) function abstractly. When defining the function, no actual numerical computation takes place. We define the abstract function in terms of placeholder values. Then we can compile the function, and evaluate it given real inputs. In the following example, we rewrite the imperative program from above as a symbolic-style program: A = Variable ( 'A' ) B = Variable ( 'B' ) C = B * A D = C + Constant ( 1 ) # compiles the function f = compile ( D ) d = f ( A = np . ones ( 10 ), B = np . ones ( 10 ) * 2 ) As you can see, in the symbolic version, when C = B * A is executed, no computation occurs. Instead, this operation generates a computation graph (also called a symbolic graph ) that represents the computation . The following figure shows a computation graph to compute D . Most symbolic-style programs contain, either explicitly or implicitly, a compile step. This converts the computation graph into a function that we can later call. In the above example, numerical computation only occurs in the last line of code. The defining characteristic of symbolic programs is their clear separation between building the computation graph and executing it. For neural networks, we typically define the entire model as a single compute graph . Deep learning libraries Among other popular deep learning libraries, Torch, Chainer, and Minerva embrace the imperative style . Examples of symbolic-style deep learning libraries include Theano, CGT, and TensorFlow. We might also view libraries like CXXNet and Caffe, which rely on configuration files, as symbolic-style libraries. In this interpretation, we\u2019d consider the content of the configuration file as defining the computation graph. Now that you understand the difference between these two programming models, let\u2019s compare the advantages of each. Imperative Programs Tend to be More Flexible When you\u2019re using an imperative-style library from Python, you are writing in Python. Nearly anything that would be intuitive to write in Python, you could accelerate by calling down in the appropriate places to the imperative deep learning library. On the other hand, when you write a symbolic program , you may not have access to all the familiar Python constructs, like iteration. Consider the following imperative program , and think about how you can translate this into a symbolic program. a = 2 b = a + 1 d = np . zeros ( 10 ) for i in range ( d ): d += np . zeros ( 10 ) This wouldn\u2019t be so easy if the Python for-loop weren\u2019t supported by the symbolic API . When you write a symbolic program in Python, you\u2019re not writing in Python. Instead, you\u2019re writing in a domain-specific language (DSL) defined by the symbolic API . The symbolic APIs found in deep learning libraries are powerful DSLs that generate callable computation graphs for neural networks. Symbolic Programs Tend to be More Efficient As we\u2019ve seen, imperative programs tend to be flexible and fit nicely into the programming flow of a host language . So you might wonder, why do so many deep learning libraries embrace the symbolic paradigm ? The main reason is efficiency , both in terms of memory and speed . Let\u2019s revisit our toy example from before. NOTE: \u5173\u4e8ehost language\u548cDSL\u7684\u5185\u5bb9\uff0c\u53c2\u89c1 Theory\\Programming-language\\Host-language \u7ae0\u8282\u3002 import numpy as np a = np . ones ( 10 ) b = np . ones ( 10 ) * 2 c = b * a d = c + 1 Assume that each cell in the array occupies 8 bytes of memory. How much memory do you need to execute this program in the Python console? Assume that each cell in the array occupies 8 bytes of memory. How much memory do you need to execute this program in the Python console? As an imperative program we need to allocate memory at each line. That leaves us allocating 4 arrays of size 10. So we\u2019ll need 4 * 10 * 8 = 320 bytes. On the other hand, if we built a computation graph , and knew in advance that we only needed d , we could reuse the memory originally allocated for intermediate values . For example, by performing computations in-place, we might recycle the bits allocated for b to store c . And we might recycle the bits allocated for c to store d . In the end we could cut our memory requirement in half, requiring just 2 * 10 * 8 = 160 bytes. Symbolic programs are more restricted . When we call compile on D, we tell the system that only the value of d is needed. The intermediate values of the computation, in this case c , is then invisible to us. We benefit because the symbolic programs can then safely reuse the memory for in-place computation . But on the other hand, if we later decide that we need to access c , we\u2019re out of luck. So imperative programs are better prepared to encounter all possible demands. If we ran the imperative version of the code in a Python console, we could inspect any of the intermediate variables in the future. Symbolic programs can also perform another kind of optimization, called operation folding . Returning to our toy example, the multiplication and addition operations can be folded into one operation, as shown in the following graph. If the computation runs on a GPU processor, one GPU kernel will be executed, instead of two. In fact, this is one way we hand-craft operations in optimized libraries, such as CXXNet and Caffe. Operation folding improves computation efficiency. Note, you can\u2019t perform operation folding in imperative programs, because the intermediate values might be referenced in the future. Operation folding is possible in symbolic programs because you get the entire computation graph , and a clear specification of which values will be needed and which are not. Expression Template and Statically Typed Language NOTE: \u5173\u4e8eExpression Template \uff0c\u53c2\u89c1\u5de5\u7a0bprogramming language\u7684 C-family-language\\C++\\Idiom\\TMP\\Expression-Template \u7ae0\u8282\u3002 tensorflow What are Symbolic and Imperative APIs in TensorFlow 2.0?","title":"Symbolic-and-imperative"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#symbolic#and#imperative","text":"symbolic programming\u548cimperative programming\u662f\u5f53\u524dDL\u9886\u57df\u7684\u4e24\u79cd\u4e3b\u6d41programming paradigm\u3002","title":"Symbolic and imperative"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#mxnet#deep#learning#programming#paradigm","text":"Writing clear, intuitive deep learning code can be challenging, and the first thing any practitioner must deal with is the language syntax itself. Complicating matters, of the many deep learning libraries out there, each has its own approach to programming style. \u590d\u6742\u7684\u95ee\u9898\u662f\uff0c\u5728\u4f17\u591a\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\u4e2d\uff0c\u6bcf\u4e2a\u5e93\u90fd\u6709\u81ea\u5df1\u7684\u7f16\u7a0b\u98ce\u683c\u3002 In this document, we focus on two of the most important high-level design decisions: 1) Whether to embrace(\u62e5\u62b1) the symbolic or imperative paradigm for mathematical computation . NOTE: \u5173\u4e8esymbolic programming\uff0c\u53c2\u89c1\u5de5\u7a0bprogramming-language\u7684 Theory\\Programming-paradigm\\Symbolic-programming \u7ae0\u8282 2) Whether to build networks with bigger (more abstract) or more atomic operations. Throughout, we\u2019ll focus on the programming models themselves. When programming style decisions may impact performance, we point this out, but we don\u2019t dwell on specific implementation details. NOTE: \"dwell on\"\u7684\u610f\u601d\u662f\"\u601d\u60f3\u5c40\u9650\u4e8e\"","title":"mxnet Deep Learning Programming Paradigm"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#symbolic#vs#imperative#programs","text":"If you are a Python or C++ programmer, then you\u2019re already familiar with imperative programs . Imperative-style programs perform computation as you run them. Most code you write in Python is imperative, as is the following NumPy snippet. import numpy as np a = np . ones ( 10 ) b = np . ones ( 10 ) * 2 c = b * a d = c + 1 When the program executes c = b * a , it runs the actual numerical computation . Symbolic programs are a bit different. With symbolic-style programs, we first define a (potentially complex) function abstractly. When defining the function, no actual numerical computation takes place. We define the abstract function in terms of placeholder values. Then we can compile the function, and evaluate it given real inputs. In the following example, we rewrite the imperative program from above as a symbolic-style program: A = Variable ( 'A' ) B = Variable ( 'B' ) C = B * A D = C + Constant ( 1 ) # compiles the function f = compile ( D ) d = f ( A = np . ones ( 10 ), B = np . ones ( 10 ) * 2 ) As you can see, in the symbolic version, when C = B * A is executed, no computation occurs. Instead, this operation generates a computation graph (also called a symbolic graph ) that represents the computation . The following figure shows a computation graph to compute D . Most symbolic-style programs contain, either explicitly or implicitly, a compile step. This converts the computation graph into a function that we can later call. In the above example, numerical computation only occurs in the last line of code. The defining characteristic of symbolic programs is their clear separation between building the computation graph and executing it. For neural networks, we typically define the entire model as a single compute graph .","title":"Symbolic vs. Imperative Programs"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#deep#learning#libraries","text":"Among other popular deep learning libraries, Torch, Chainer, and Minerva embrace the imperative style . Examples of symbolic-style deep learning libraries include Theano, CGT, and TensorFlow. We might also view libraries like CXXNet and Caffe, which rely on configuration files, as symbolic-style libraries. In this interpretation, we\u2019d consider the content of the configuration file as defining the computation graph. Now that you understand the difference between these two programming models, let\u2019s compare the advantages of each.","title":"Deep learning libraries"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#imperative#programs#tend#to#be#more#flexible","text":"When you\u2019re using an imperative-style library from Python, you are writing in Python. Nearly anything that would be intuitive to write in Python, you could accelerate by calling down in the appropriate places to the imperative deep learning library. On the other hand, when you write a symbolic program , you may not have access to all the familiar Python constructs, like iteration. Consider the following imperative program , and think about how you can translate this into a symbolic program. a = 2 b = a + 1 d = np . zeros ( 10 ) for i in range ( d ): d += np . zeros ( 10 ) This wouldn\u2019t be so easy if the Python for-loop weren\u2019t supported by the symbolic API . When you write a symbolic program in Python, you\u2019re not writing in Python. Instead, you\u2019re writing in a domain-specific language (DSL) defined by the symbolic API . The symbolic APIs found in deep learning libraries are powerful DSLs that generate callable computation graphs for neural networks.","title":"Imperative Programs Tend to be More Flexible"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#symbolic#programs#tend#to#be#more#efficient","text":"As we\u2019ve seen, imperative programs tend to be flexible and fit nicely into the programming flow of a host language . So you might wonder, why do so many deep learning libraries embrace the symbolic paradigm ? The main reason is efficiency , both in terms of memory and speed . Let\u2019s revisit our toy example from before. NOTE: \u5173\u4e8ehost language\u548cDSL\u7684\u5185\u5bb9\uff0c\u53c2\u89c1 Theory\\Programming-language\\Host-language \u7ae0\u8282\u3002 import numpy as np a = np . ones ( 10 ) b = np . ones ( 10 ) * 2 c = b * a d = c + 1 Assume that each cell in the array occupies 8 bytes of memory. How much memory do you need to execute this program in the Python console? Assume that each cell in the array occupies 8 bytes of memory. How much memory do you need to execute this program in the Python console? As an imperative program we need to allocate memory at each line. That leaves us allocating 4 arrays of size 10. So we\u2019ll need 4 * 10 * 8 = 320 bytes. On the other hand, if we built a computation graph , and knew in advance that we only needed d , we could reuse the memory originally allocated for intermediate values . For example, by performing computations in-place, we might recycle the bits allocated for b to store c . And we might recycle the bits allocated for c to store d . In the end we could cut our memory requirement in half, requiring just 2 * 10 * 8 = 160 bytes. Symbolic programs are more restricted . When we call compile on D, we tell the system that only the value of d is needed. The intermediate values of the computation, in this case c , is then invisible to us. We benefit because the symbolic programs can then safely reuse the memory for in-place computation . But on the other hand, if we later decide that we need to access c , we\u2019re out of luck. So imperative programs are better prepared to encounter all possible demands. If we ran the imperative version of the code in a Python console, we could inspect any of the intermediate variables in the future. Symbolic programs can also perform another kind of optimization, called operation folding . Returning to our toy example, the multiplication and addition operations can be folded into one operation, as shown in the following graph. If the computation runs on a GPU processor, one GPU kernel will be executed, instead of two. In fact, this is one way we hand-craft operations in optimized libraries, such as CXXNet and Caffe. Operation folding improves computation efficiency. Note, you can\u2019t perform operation folding in imperative programs, because the intermediate values might be referenced in the future. Operation folding is possible in symbolic programs because you get the entire computation graph , and a clear specification of which values will be needed and which are not.","title":"Symbolic Programs Tend to be More Efficient"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#expression#template#and#statically#typed#language","text":"NOTE: \u5173\u4e8eExpression Template \uff0c\u53c2\u89c1\u5de5\u7a0bprogramming language\u7684 C-family-language\\C++\\Idiom\\TMP\\Expression-Template \u7ae0\u8282\u3002","title":"Expression Template and Statically Typed Language"},{"location":"Programming/Programming-paradigm/Symbolic-and-imperative/#tensorflow#what#are#symbolic#and#imperative#apis#in#tensorflow#20","text":"","title":"tensorflow What are Symbolic and Imperative APIs in TensorFlow 2.0?"},{"location":"Programming/TensorFlow/","text":"TensorFlow wikipedia TensorFlow Tensorflow is a symbolic math library based on dataflow and differentiable programming. NOTE: TensorFlow\u7684\u672c\u8d28\u6240\u5728\uff0c\u5173\u4e8esymbolic\uff0c\u53c2\u89c1\u5de5\u7a0bprogramming language\u7684 TensorFlow\u5b98\u7f51 https://tensorflow.google.cn/ \u4e2d\u56fd\u5b98\u7f51\uff0c\u7f51\u901f\u8f83\u5feb https://www.tensorflow.org/ \u5b98\u7f51\uff0c\u4e0d\u7ffb\u5899\uff0c\u65e0\u6cd5\u8bbf\u95ee github Tensorflow","title":"Introduction"},{"location":"Programming/TensorFlow/#tensorflow","text":"","title":"TensorFlow"},{"location":"Programming/TensorFlow/#wikipedia#tensorflow","text":"Tensorflow is a symbolic math library based on dataflow and differentiable programming. NOTE: TensorFlow\u7684\u672c\u8d28\u6240\u5728\uff0c\u5173\u4e8esymbolic\uff0c\u53c2\u89c1\u5de5\u7a0bprogramming language\u7684","title":"wikipedia TensorFlow"},{"location":"Programming/TensorFlow/#tensorflow_1","text":"https://tensorflow.google.cn/ \u4e2d\u56fd\u5b98\u7f51\uff0c\u7f51\u901f\u8f83\u5feb https://www.tensorflow.org/ \u5b98\u7f51\uff0c\u4e0d\u7ffb\u5899\uff0c\u65e0\u6cd5\u8bbf\u95ee","title":"TensorFlow\u5b98\u7f51"},{"location":"Programming/TensorFlow/#github#tensorflow","text":"","title":"github Tensorflow"},{"location":"Programming/TensorFlow/Doc/","text":"TensorFlow doc \u5b66\u4e60TensorFlow\u7684\u4e00\u4e2a\u5173\u952e\u662f\u9605\u8bfb\u5b83\u7684doc\uff0c\u672c\u6587\u603b\u7ed3TensorFlow doc\u8d44\u6e90\u3002 Tensorflow official site \u6709\u4e30\u5bcc\u7684\u5185\u5bb9\uff0c\u4f46\u662f\u5982\u679c\u4e0d\u7ffb\u5899\uff0c\u5219\u65e0\u6cd5\u8bbf\u95ee github tensorflow / docs haosdent.gitbooks TensorFlow for Googlers NOTE: \u8fd9\u662f\u6258\u7ba1\u5728gitbooks\u4e0a\u7684API\u6587\u6863\uff0c\u80fd\u591f\u5feb\u901f\u8bbf\u95ee\uff0c\u5e76\u4e14\u5185\u5bb9\u975e\u5e38\u597d This site has TensorFlow documentation for Google engineers. data-flair Tensorflow-tutorials https://data-flair.training/blogs/tensorflow-tutorials-home/ https://data-flair.training/blogs/tensorflow-tutorial/ stackoverflow https://stackoverflow.com/tags/tensorflow/ stackoverflow Official Tensorflow docs available in pdf form? (running Windows) A 1) http://devdocs.io/ \u65e0\u6cd5\u4f7f\u7528 2) TensorFlow documentation. 3) haosdent gitbook for TF 4)","title":"Doc"},{"location":"Programming/TensorFlow/Doc/#tensorflow#doc","text":"\u5b66\u4e60TensorFlow\u7684\u4e00\u4e2a\u5173\u952e\u662f\u9605\u8bfb\u5b83\u7684doc\uff0c\u672c\u6587\u603b\u7ed3TensorFlow doc\u8d44\u6e90\u3002","title":"TensorFlow doc"},{"location":"Programming/TensorFlow/Doc/#tensorflow#official#site","text":"\u6709\u4e30\u5bcc\u7684\u5185\u5bb9\uff0c\u4f46\u662f\u5982\u679c\u4e0d\u7ffb\u5899\uff0c\u5219\u65e0\u6cd5\u8bbf\u95ee","title":"Tensorflow official site"},{"location":"Programming/TensorFlow/Doc/#github#tensorflowdocs","text":"","title":"github tensorflow/docs"},{"location":"Programming/TensorFlow/Doc/#haosdentgitbooks#tensorflow#for#googlers","text":"NOTE: \u8fd9\u662f\u6258\u7ba1\u5728gitbooks\u4e0a\u7684API\u6587\u6863\uff0c\u80fd\u591f\u5feb\u901f\u8bbf\u95ee\uff0c\u5e76\u4e14\u5185\u5bb9\u975e\u5e38\u597d This site has TensorFlow documentation for Google engineers.","title":"haosdent.gitbooks TensorFlow for Googlers"},{"location":"Programming/TensorFlow/Doc/#data-flair#tensorflow-tutorials","text":"https://data-flair.training/blogs/tensorflow-tutorials-home/ https://data-flair.training/blogs/tensorflow-tutorial/","title":"data-flair Tensorflow-tutorials"},{"location":"Programming/TensorFlow/Doc/#stackoverflow","text":"https://stackoverflow.com/tags/tensorflow/","title":"stackoverflow"},{"location":"Programming/TensorFlow/Doc/#stackoverflow#official#tensorflow#docs#available#in#pdf#form#running#windows","text":"A 1) http://devdocs.io/ \u65e0\u6cd5\u4f7f\u7528 2) TensorFlow documentation. 3) haosdent gitbook for TF 4)","title":"stackoverflow Official Tensorflow docs available in pdf form? (running Windows)"},{"location":"Programming/TensorFlow/API/","text":"TensorFlow API API doc tensorflow TensorFlow API documentation \u8fd9\u662f\u5b98\u7f51\uff0c\u4f46\u662f\u5982\u679c\u4e0d\u7ffb\u5899\u5219\u8bbf\u95ee\u4e0d\u4e86 haosdent.gitbooks API Documentation TensorFlow for Googlers\uff0c\u8bbf\u95ee\u901f\u5ea6\u8f83\u5feb TensorFlow API \u4e0e \u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb \u5176\u5b9e\u8fd9\u79cd\u601d\u60f3\u6307\u5bfc\u4e86\u5982\u4f55\u4f7f\u7528TensorFlow\u6765\u642d\u5efa\u6a21\u578b\u3002 Module: tf.losses \u4e2d\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u635f\u5931\u51fd\u6570 Module: tf.train \u4e2d\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217optimizer","title":"Introduction"},{"location":"Programming/TensorFlow/API/#tensorflow#api","text":"","title":"TensorFlow API"},{"location":"Programming/TensorFlow/API/#api#doc","text":"","title":"API doc"},{"location":"Programming/TensorFlow/API/#tensorflow#tensorflow#api#documentation","text":"\u8fd9\u662f\u5b98\u7f51\uff0c\u4f46\u662f\u5982\u679c\u4e0d\u7ffb\u5899\u5219\u8bbf\u95ee\u4e0d\u4e86","title":"tensorflow TensorFlow API documentation"},{"location":"Programming/TensorFlow/API/#haosdentgitbooks#api#documentation","text":"TensorFlow for Googlers\uff0c\u8bbf\u95ee\u901f\u5ea6\u8f83\u5feb","title":"haosdent.gitbooks API Documentation"},{"location":"Programming/TensorFlow/API/#tensorflow#api_1","text":"\u5176\u5b9e\u8fd9\u79cd\u601d\u60f3\u6307\u5bfc\u4e86\u5982\u4f55\u4f7f\u7528TensorFlow\u6765\u642d\u5efa\u6a21\u578b\u3002 Module: tf.losses \u4e2d\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u635f\u5931\u51fd\u6570 Module: tf.train \u4e2d\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217optimizer","title":"TensorFlow API \u4e0e \u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb"},{"location":"Programming/TensorFlow/API/Python/","text":"TensorFlow Python reference documentation haosdent TensorFlow Python reference documentation Building Graphs Classes and functions for building TensorFlow graphs. Asserts and boolean checks assertion Constants, Sequences, and Random Values Constant: \u751f\u6210Constant Value Tensors\u7684API Sequences: \u751f\u6210sequence\u7684API Random Tensors: \u751f\u6210random tensors with different distributions\u7684API Variables Tensor Transformations \u5bf9Tensor\u8fdb\u884c\u64cd\u4f5c Math basic arithmetic operators Strings Histograms \u76f4\u65b9\u56fe Control Flow TensorFlow provides several operations and classes that you can use to control the execution of operations and add conditional dependencies to your graph. Higher Order Functions TensorFlow provides several higher order operators to simplify the common map-reduce programming patterns TensorArray Operations class tf.TensorArray Tensor Handle Operations TensorFlow provides several operators that allows the user to keep tensors \"in-place\" across run calls(\u5141\u8bb8\u7528\u6237\u5728\u8fd0\u884c\u8c03\u7528\u65f6\u5c06\u5f20\u91cf\u4fdd\u6301\u5728\u201c\u539f\u4f4d\u201d) Images \u56fe\u50cf\u8fdb\u884c\u64cd\u4f5c\u7684API Sparse Tensors Inputs and Readers Data IO (Python functions) feed data\u7684API Neural Network tf.nn - Activation Functions - Convolution - Pooling - Morphological filtering - Normalization - Losses - Classification - Embeddings - Recurrent Neural Networks - Connectionist Temporal Classification (CTC) - Evaluation - Candidate Sampling - Other Functions and Classes Neural Network RNN Cells Running Graphs This library contains classes for launching graphs and executing operations. The basic usage guide has examples of how a graph is launched in a tf.Session . Training This library provides a set of classes and functions that helps train models. Wraps python functions TensorFlow provides allows you to wrap python/numpy functions as TensorFlow operators. Summary Operations This module contains ops for generating summaries. Testing TensorFlow provides a convenience class inheriting from unittest.TestCase which adds methods relevant to TensorFlow tests. BayesFlow Entropy (contrib) BayesFlow Stochastic Tensors (contrib) BayesFlow Variational Inference (contrib) Variational(\u53d8\u5206\u6cd5) inference. CRF (contrib) Linear-chain CRF layer. Statistical distributions (contrib) Classes representing statistical distributions and ops for working with them. FFmpeg (contrib) Encoding and decoding audio using FFmpeg Framework (contrib) Graph Editor (contrib) The TensorFlow Graph Editor library allows for modification of an existing tf.Graph instance in-place. Layers (contrib) Ops for building neural network layers, regularizers, summaries, etc. Learn (contrib) High level API for learning with TensorFlow. Monitors (contrib) Monitors allow user instrumentation of the training process. Losses (contrib) Ops for building neural network losses. RNN (contrib) Additional RNN operations and cells. Metrics (contrib) Ops for evaluation metrics and summary statistics","title":"Introduction"},{"location":"Programming/TensorFlow/API/Python/#tensorflow#python#reference#documentation","text":"","title":"TensorFlow Python reference documentation"},{"location":"Programming/TensorFlow/API/Python/#haosdent#tensorflow#python#reference#documentation","text":"","title":"haosdent TensorFlow Python reference documentation"},{"location":"Programming/TensorFlow/API/Python/#building#graphs","text":"Classes and functions for building TensorFlow graphs.","title":"Building Graphs"},{"location":"Programming/TensorFlow/API/Python/#asserts#and#boolean#checks","text":"assertion","title":"Asserts and boolean checks"},{"location":"Programming/TensorFlow/API/Python/#constants#sequences#and#random#values","text":"Constant: \u751f\u6210Constant Value Tensors\u7684API Sequences: \u751f\u6210sequence\u7684API Random Tensors: \u751f\u6210random tensors with different distributions\u7684API","title":"Constants, Sequences, and Random Values"},{"location":"Programming/TensorFlow/API/Python/#variables","text":"","title":"Variables"},{"location":"Programming/TensorFlow/API/Python/#tensor#transformations","text":"\u5bf9Tensor\u8fdb\u884c\u64cd\u4f5c","title":"Tensor Transformations"},{"location":"Programming/TensorFlow/API/Python/#math","text":"basic arithmetic operators","title":"Math"},{"location":"Programming/TensorFlow/API/Python/#strings","text":"","title":"Strings"},{"location":"Programming/TensorFlow/API/Python/#histograms","text":"\u76f4\u65b9\u56fe","title":"Histograms"},{"location":"Programming/TensorFlow/API/Python/#control#flow","text":"TensorFlow provides several operations and classes that you can use to control the execution of operations and add conditional dependencies to your graph.","title":"Control Flow"},{"location":"Programming/TensorFlow/API/Python/#higher#order#functions","text":"TensorFlow provides several higher order operators to simplify the common map-reduce programming patterns","title":"Higher Order Functions"},{"location":"Programming/TensorFlow/API/Python/#tensorarray#operations","text":"class tf.TensorArray","title":"TensorArray Operations"},{"location":"Programming/TensorFlow/API/Python/#tensor#handle#operations","text":"TensorFlow provides several operators that allows the user to keep tensors \"in-place\" across run calls(\u5141\u8bb8\u7528\u6237\u5728\u8fd0\u884c\u8c03\u7528\u65f6\u5c06\u5f20\u91cf\u4fdd\u6301\u5728\u201c\u539f\u4f4d\u201d)","title":"Tensor Handle Operations"},{"location":"Programming/TensorFlow/API/Python/#images","text":"\u56fe\u50cf\u8fdb\u884c\u64cd\u4f5c\u7684API","title":"Images"},{"location":"Programming/TensorFlow/API/Python/#sparse#tensors","text":"","title":"Sparse Tensors"},{"location":"Programming/TensorFlow/API/Python/#inputs#and#readers","text":"","title":"Inputs and Readers"},{"location":"Programming/TensorFlow/API/Python/#data#io#python#functions","text":"feed data\u7684API","title":"Data IO (Python functions)"},{"location":"Programming/TensorFlow/API/Python/#neural#network","text":"tf.nn - Activation Functions - Convolution - Pooling - Morphological filtering - Normalization - Losses - Classification - Embeddings - Recurrent Neural Networks - Connectionist Temporal Classification (CTC) - Evaluation - Candidate Sampling - Other Functions and Classes","title":"Neural Network"},{"location":"Programming/TensorFlow/API/Python/#neural#network#rnn#cells","text":"","title":"Neural Network RNN Cells"},{"location":"Programming/TensorFlow/API/Python/#running#graphs","text":"This library contains classes for launching graphs and executing operations. The basic usage guide has examples of how a graph is launched in a tf.Session .","title":"Running Graphs"},{"location":"Programming/TensorFlow/API/Python/#training","text":"This library provides a set of classes and functions that helps train models.","title":"Training"},{"location":"Programming/TensorFlow/API/Python/#wraps#python#functions","text":"TensorFlow provides allows you to wrap python/numpy functions as TensorFlow operators.","title":"Wraps python functions"},{"location":"Programming/TensorFlow/API/Python/#summary#operations","text":"This module contains ops for generating summaries.","title":"Summary Operations"},{"location":"Programming/TensorFlow/API/Python/#testing","text":"TensorFlow provides a convenience class inheriting from unittest.TestCase which adds methods relevant to TensorFlow tests.","title":"Testing"},{"location":"Programming/TensorFlow/API/Python/#bayesflow#entropy#contrib","text":"","title":"BayesFlow Entropy (contrib)"},{"location":"Programming/TensorFlow/API/Python/#bayesflow#stochastic#tensors#contrib","text":"","title":"BayesFlow Stochastic Tensors (contrib)"},{"location":"Programming/TensorFlow/API/Python/#bayesflow#variational#inference#contrib","text":"Variational(\u53d8\u5206\u6cd5) inference.","title":"BayesFlow Variational Inference (contrib)"},{"location":"Programming/TensorFlow/API/Python/#crf#contrib","text":"Linear-chain CRF layer.","title":"CRF (contrib)"},{"location":"Programming/TensorFlow/API/Python/#statistical#distributions#contrib","text":"Classes representing statistical distributions and ops for working with them.","title":"Statistical distributions (contrib)"},{"location":"Programming/TensorFlow/API/Python/#ffmpeg#contrib","text":"Encoding and decoding audio using FFmpeg","title":"FFmpeg (contrib)"},{"location":"Programming/TensorFlow/API/Python/#framework#contrib","text":"","title":"Framework (contrib)"},{"location":"Programming/TensorFlow/API/Python/#graph#editor#contrib","text":"The TensorFlow Graph Editor library allows for modification of an existing tf.Graph instance in-place.","title":"Graph Editor (contrib)"},{"location":"Programming/TensorFlow/API/Python/#layers#contrib","text":"Ops for building neural network layers, regularizers, summaries, etc.","title":"Layers (contrib)"},{"location":"Programming/TensorFlow/API/Python/#learn#contrib","text":"High level API for learning with TensorFlow.","title":"Learn (contrib)"},{"location":"Programming/TensorFlow/API/Python/#monitors#contrib","text":"Monitors allow user instrumentation of the training process.","title":"Monitors (contrib)"},{"location":"Programming/TensorFlow/API/Python/#losses#contrib","text":"Ops for building neural network losses.","title":"Losses (contrib)"},{"location":"Programming/TensorFlow/API/Python/#rnn#contrib","text":"Additional RNN operations and cells.","title":"RNN (contrib)"},{"location":"Programming/TensorFlow/API/Python/#metrics#contrib","text":"Ops for evaluation metrics and summary statistics","title":"Metrics (contrib)"},{"location":"Programming/TensorFlow/API/Python/Core-graph-data-structures/","text":"Core graph data structures class tf.Graph A TensorFlow computation, represented as a dataflow graph. A Graph contains a set of Operation objects, which represent units of computation; and Tensor objects, which represent the units of data that flow between operations. class tf.Operation Represents a graph node that performs computation on tensors. class tf.Tensor","title":"Core-graph-data-structures"},{"location":"Programming/TensorFlow/API/Python/Core-graph-data-structures/#core#graph#data#structures","text":"","title":"Core graph data structures"},{"location":"Programming/TensorFlow/API/Python/Core-graph-data-structures/#class#tfgraph","text":"A TensorFlow computation, represented as a dataflow graph. A Graph contains a set of Operation objects, which represent units of computation; and Tensor objects, which represent the units of data that flow between operations.","title":"class tf.Graph"},{"location":"Programming/TensorFlow/API/Python/Core-graph-data-structures/#class#tfoperation","text":"Represents a graph node that performs computation on tensors.","title":"class tf.Operation"},{"location":"Programming/TensorFlow/API/Python/Core-graph-data-structures/#class#tftensor","text":"","title":"class tf.Tensor"},{"location":"Programming/TensorFlow/API/Python/Building-Graphs/","text":"Building graphs","title":"Introduction"},{"location":"Programming/TensorFlow/API/Python/Building-Graphs/#building#graphs","text":"","title":"Building graphs"},{"location":"Programming/TensorFlow/API/Python/Building-Graphs/tf.control_dependencies/","text":"tf.control_dependencies \u662f\u5728\u9605\u8bfb TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems \u65f6\uff0c\u5176\u4e2d\u6709\u5173\u4e8eControl dependency edge\u7684\u63cf\u8ff0\u3002 haosdent tf.control_dependencies(control_inputs) haosdent tf.Graph.control_dependencies(control_inputs) Use with the with keyword to specify that all operations constructed within the context should have control dependencies on control_inputs . For example: with g . control_dependencies ([ a , b , c ]): # `d` and `e` will only run after `a`, `b`, and `c` have executed. d = ... e = ... stackoverflow Understanding Tensorflow control dependencies A In most cases, control flow in TensorFlow is \"obvious\", in the sense that there is only one way to make a computation correctly. However, when stateful objects (i.e. variables) are involved, there are situations that may be ambiguous. Consider the following example: import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) upd1 = tf . assign ( v1 , v2 + 1 ) upd2 = tf . assign ( v2 , v1 + 1 ) init = tf . global_variables_initializer () NOTE: computation graph\u5982\u4e0b: v1 and v2 are both variables initialized to 0 and then updated. However, each use the value of the other variable in the update. In a regular Python program things would run sequentially, so upd1 would run first (so v1 would be 1 ) and upd2 after (so v2 would be 2 , because v1 was 1 ). But TensorFlow does not record the order in which operations are created, only their dependencies . So it may also happen that upd2 runs before upd1 (so v1 would be 2 and v2 would be 1 ) or that both update values ( v2 + 1 and v1 + 1 ) are computed before the assignments (so both v1 and v2 would be 1 in the end). NOTE: \u6709\u591a\u79cd\u53ef\u80fd\u7684\u8fd0\u884c\u60c5\u51b5\u3002 Indeed, if I run it several times: import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) upd1 = tf . assign ( v1 , v2 + 1 ) upd2 = tf . assign ( v2 , v1 + 1 ) init = tf . global_variables_initializer () for i in range ( 10 ): with tf . Session () as sess : sess . run ( init ) sess . run ([ upd1 , upd2 ]) print ( * sess . run ([ v1 , v2 ])) I do not always get the same result (personally I get 1 1 and 2 1 , although technically 1 2 would also be possible). If for example you wanted to compute the new value for v2 after v1 has been updated, you could just do the following: import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) upd1 = tf . assign ( v1 , v2 + 1 ) upd2 = tf . assign ( v2 , upd1 + 1 ) init = tf . global_variables_initializer () NOTE: \u548c\u524d\u9762\u7684\u76f8\u6bd4\uff0c\u5dee\u5f02\u5728\u4e8e upd2 = tf.assign(v2, upd1 + 1) \uff0c\u5165\u53c2\u662f upd1 \u3002 computation graph\u5982\u4e0b: \u4e0a\u8ff0\u8f93\u51fa\u4e3a 1, 2 Here the new value v2 is computed using upd1 , which is guaranteed to be the value of the variable after the update. So here upd2 would have an implicit dependency to the assignment, and so things would work as expected. But what if you wanted to always compute the new values for v1 and v2 using the non-updated variable values (that is, consistently end up with both v1 and v2 being 1 )? In that case you can use tf.control_dependencies : import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) new_v1 = v2 + 1 new_v2 = v1 + 1 with tf . control_dependencies ([ new_v1 , new_v2 ]): upd1 = tf . assign ( v1 , new_v1 ) upd2 = tf . assign ( v2 , new_v2 ) init = tf . global_variables_initializer () NOTE: computation graph\u5982\u4e0b: Here, the assignment operations cannot happen until the new values for v1 and v2 have been computed, so their final values will always be 1 in both cases.","title":"tf.control_dependencies"},{"location":"Programming/TensorFlow/API/Python/Building-Graphs/tf.control_dependencies/#tfcontrol_dependencies","text":"\u662f\u5728\u9605\u8bfb TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems \u65f6\uff0c\u5176\u4e2d\u6709\u5173\u4e8eControl dependency edge\u7684\u63cf\u8ff0\u3002","title":"tf.control_dependencies"},{"location":"Programming/TensorFlow/API/Python/Building-Graphs/tf.control_dependencies/#haosdent#tfcontrol_dependenciescontrol_inputs","text":"","title":"haosdent tf.control_dependencies(control_inputs)"},{"location":"Programming/TensorFlow/API/Python/Building-Graphs/tf.control_dependencies/#haosdent#tfgraphcontrol_dependenciescontrol_inputs","text":"Use with the with keyword to specify that all operations constructed within the context should have control dependencies on control_inputs . For example: with g . control_dependencies ([ a , b , c ]): # `d` and `e` will only run after `a`, `b`, and `c` have executed. d = ... e = ...","title":"haosdent tf.Graph.control_dependencies(control_inputs)"},{"location":"Programming/TensorFlow/API/Python/Building-Graphs/tf.control_dependencies/#stackoverflow#understanding#tensorflow#control#dependencies","text":"A In most cases, control flow in TensorFlow is \"obvious\", in the sense that there is only one way to make a computation correctly. However, when stateful objects (i.e. variables) are involved, there are situations that may be ambiguous. Consider the following example: import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) upd1 = tf . assign ( v1 , v2 + 1 ) upd2 = tf . assign ( v2 , v1 + 1 ) init = tf . global_variables_initializer () NOTE: computation graph\u5982\u4e0b: v1 and v2 are both variables initialized to 0 and then updated. However, each use the value of the other variable in the update. In a regular Python program things would run sequentially, so upd1 would run first (so v1 would be 1 ) and upd2 after (so v2 would be 2 , because v1 was 1 ). But TensorFlow does not record the order in which operations are created, only their dependencies . So it may also happen that upd2 runs before upd1 (so v1 would be 2 and v2 would be 1 ) or that both update values ( v2 + 1 and v1 + 1 ) are computed before the assignments (so both v1 and v2 would be 1 in the end). NOTE: \u6709\u591a\u79cd\u53ef\u80fd\u7684\u8fd0\u884c\u60c5\u51b5\u3002 Indeed, if I run it several times: import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) upd1 = tf . assign ( v1 , v2 + 1 ) upd2 = tf . assign ( v2 , v1 + 1 ) init = tf . global_variables_initializer () for i in range ( 10 ): with tf . Session () as sess : sess . run ( init ) sess . run ([ upd1 , upd2 ]) print ( * sess . run ([ v1 , v2 ])) I do not always get the same result (personally I get 1 1 and 2 1 , although technically 1 2 would also be possible). If for example you wanted to compute the new value for v2 after v1 has been updated, you could just do the following: import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) upd1 = tf . assign ( v1 , v2 + 1 ) upd2 = tf . assign ( v2 , upd1 + 1 ) init = tf . global_variables_initializer () NOTE: \u548c\u524d\u9762\u7684\u76f8\u6bd4\uff0c\u5dee\u5f02\u5728\u4e8e upd2 = tf.assign(v2, upd1 + 1) \uff0c\u5165\u53c2\u662f upd1 \u3002 computation graph\u5982\u4e0b: \u4e0a\u8ff0\u8f93\u51fa\u4e3a 1, 2 Here the new value v2 is computed using upd1 , which is guaranteed to be the value of the variable after the update. So here upd2 would have an implicit dependency to the assignment, and so things would work as expected. But what if you wanted to always compute the new values for v1 and v2 using the non-updated variable values (that is, consistently end up with both v1 and v2 being 1 )? In that case you can use tf.control_dependencies : import tensorflow as tf v1 = tf . Variable ( 0 ) v2 = tf . Variable ( 0 ) new_v1 = v2 + 1 new_v2 = v1 + 1 with tf . control_dependencies ([ new_v1 , new_v2 ]): upd1 = tf . assign ( v1 , new_v1 ) upd2 = tf . assign ( v2 , new_v2 ) init = tf . global_variables_initializer () NOTE: computation graph\u5982\u4e0b: Here, the assignment operations cannot happen until the new values for v1 and v2 have been computed, so their final values will always be 1 in both cases.","title":"stackoverflow Understanding Tensorflow control dependencies"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/","text":"tf.placeholder -VS- tf.Variable \u4ecesymbolic programming\u7684\u89d2\u5ea6\u6765\u770b\uff0c tf.placeholder \u5176\u5b9e\u5c31\u662fsymbol\u3002 stackoverflow What's the difference between tf.placeholder and tf.Variable? I'm a newbie to TensorFlow. I'm confused about the difference between tf.placeholder and tf.Variable . In my view, tf.placeholder is used for input data, and tf.Variable is used to store the state of data. This is all what I know. Could someone explain to me more in detail about their differences? In particular, when to use tf.Variable and when to use tf.placeholder ? COMMENTS : Intuitively, you'll want gradients with respect to Variable s, but not placeholder s (whose values must always be provided). \u2013 Yibo Yang Jun 6 '17 at 3:56 A In short, you use tf.Variable for trainable variables \uff08\u4e5f\u5c31\u662f\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\u7684\uff09 such as weights (W) and biases (B) for your model. weights = tf . Variable ( tf . truncated_normal ([ IMAGE_PIXELS , hidden1_units ], stddev = 1.0 / math . sqrt ( float ( IMAGE_PIXELS ))), name = 'weights' ) biases = tf . Variable ( tf . zeros ([ hidden1_units ]), name = 'biases' ) tf.placeholder is used to feed actual training examples. images_placeholder = tf . placeholder ( tf . float32 , shape = ( batch_size , IMAGE_PIXELS )) labels_placeholder = tf . placeholder ( tf . int32 , shape = ( batch_size )) This is how you feed the training examples during the training: for step in xrange ( FLAGS . max_steps ): feed_dict = { images_placeholder : images_feed , labels_placeholder : labels_feed , } _ , loss_value = sess . run ([ train_op , loss ], feed_dict = feed_dict ) Your tf.variables will be trained (modified) as the result of this training. See more at https://www.tensorflow.org/versions/r0.7/tutorials/mnist/tf/index.html . (Examples are taken from the web page.) A The difference is that with tf.Variable you have to provide an initial value when you declare it. With tf.placeholder you don't have to provide an initial value and you can specify it at run time with the feed_dict argument inside Session.run A Since Tensor computations compose of graphs then it's better to interpret the two in terms of graphs . Take for example the simple linear regression WX+B=Y(where W and B stand for the weights and bias and X for the observations' inputs and Y for the observations' outputs). Obviously X and Y are of the same nature( manifest variables ) which differ from that of W and B( latent variables ). X and Y are values of the samples(observations) and hence need a place to be filled , while W and B are the weights and bias, Variables (the previous value affects the later) in the graph which should be trained using different X and Y pairs. We place different samples to the Placeholders to train the Variables . We can and only need to save or restore the Variables (in checkpoints) to save or rebuild the graph with the code. Placeholders are mostly holders for the different datasets (for example training data or test data) but Variables are trained in the training process and remain the same(to predict the outcome of the input or map the inputs and outputs[labels] of the samples) later until you retrain or fine-tune the model(using different or the same samples to fill into the Placeholders often through the dict, for instance session.run(a_graph, dict={a_placeholder_name: sample_values}) , Placeholders are also passed as parameters to set models). If you change placeholders (add or delete or change the shape and etc) of a model in the middle of training, you still can reload the checkpoint without any other modifications. But if the variables of a saved model are changed you should adjust the checkpoint accordingly to reload it and continue the training(all variables defined in the graph should be available in the checkpoint). To sum up, if the values are from the samples(observations you already have) you safely make a placeholder to hold them, while if you need a parameter to be trained harness a Variable (simply put, set the Variables for the values you want to get using TF automatically). In some interesting models, like a style transfer model , the input pixes are going to be optimized and the normally-called model variables are fixed, then we should make the input(usually initialized randomly) as a variable as implemented in that link. \u5728\u4e00\u4e9b\u6709\u8da3\u7684\u6a21\u578b\u4e2d\uff0c\u6bd4\u5982\u4e00\u4e2a\u98ce\u683c\u8f6c\u6362\u6a21\u578b\uff0c\u8f93\u5165\u50cf\u7d20\u5c06\u88ab\u4f18\u5316\uff0c\u901a\u5e38\u88ab\u8c03\u7528\u7684\u6a21\u578b\u53d8\u91cf\u662f\u56fa\u5b9a\u7684\uff0c\u7136\u540e\u6211\u4eec\u5e94\u8be5\u628a\u8f93\u5165(\u901a\u5e38\u662f\u968f\u673a\u521d\u59cb\u5316\u7684)\u4f5c\u4e3a\u4e00\u4e2a\u53d8\u91cf\u5728\u94fe\u63a5\u4e2d\u5b9e\u73b0\u3002 For more information please infer to this simple and illustrating doc . A The most obvious difference between the tf.Variable and the tf.placeholder is that you use variables to hold and update parameters. Variables are in-memory buffers containing tensors. They must be explicitly initialized and can be saved to disk during and after training. You can later restore saved values to exercise or analyze the model. Initialization of the variables is done with sess.run(tf.global_variables_initializer()) . Also while creating a variable, you need to pass a Tensor as its initial value to the Variable() constructor and when you create a variable you always know its shape. On the other hand, you can't update the placeholder. They also should not be initialized, but because they are a promise to have a tensor, you need to feed the value into them sess.run(, {a: }) . And at last, in comparison to a variable, placeholder might not know the shape. You can either provide parts of the dimensions or provide nothing at all. There other differences: the values inside the variable can be updated during optimizations variables can be shared , and can be non-trainable the values inside the variable can be stored after training when the variable is created, 3 ops are added to a graph (variable op, initializer op, ops for the initial value) placeholder is a function, Variable is a class (hence an uppercase) when you use TF in a distributed environment, variables are stored in a special place ( parameter server ) and are shared between the workers. Interesting part is that not only placeholders can be fed. You can feed the value to a Variable and even to a constant.","title":"Introduction"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/#tfplaceholder-vs-tfvariable","text":"\u4ecesymbolic programming\u7684\u89d2\u5ea6\u6765\u770b\uff0c tf.placeholder \u5176\u5b9e\u5c31\u662fsymbol\u3002","title":"tf.placeholder-VS-tf.Variable"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/#stackoverflow#whats#the#difference#between#tfplaceholder#and#tfvariable","text":"I'm a newbie to TensorFlow. I'm confused about the difference between tf.placeholder and tf.Variable . In my view, tf.placeholder is used for input data, and tf.Variable is used to store the state of data. This is all what I know. Could someone explain to me more in detail about their differences? In particular, when to use tf.Variable and when to use tf.placeholder ? COMMENTS : Intuitively, you'll want gradients with respect to Variable s, but not placeholder s (whose values must always be provided). \u2013 Yibo Yang Jun 6 '17 at 3:56","title":"stackoverflow What's the difference between tf.placeholder and tf.Variable?"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/#a","text":"In short, you use tf.Variable for trainable variables \uff08\u4e5f\u5c31\u662f\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\u7684\uff09 such as weights (W) and biases (B) for your model. weights = tf . Variable ( tf . truncated_normal ([ IMAGE_PIXELS , hidden1_units ], stddev = 1.0 / math . sqrt ( float ( IMAGE_PIXELS ))), name = 'weights' ) biases = tf . Variable ( tf . zeros ([ hidden1_units ]), name = 'biases' ) tf.placeholder is used to feed actual training examples. images_placeholder = tf . placeholder ( tf . float32 , shape = ( batch_size , IMAGE_PIXELS )) labels_placeholder = tf . placeholder ( tf . int32 , shape = ( batch_size )) This is how you feed the training examples during the training: for step in xrange ( FLAGS . max_steps ): feed_dict = { images_placeholder : images_feed , labels_placeholder : labels_feed , } _ , loss_value = sess . run ([ train_op , loss ], feed_dict = feed_dict ) Your tf.variables will be trained (modified) as the result of this training. See more at https://www.tensorflow.org/versions/r0.7/tutorials/mnist/tf/index.html . (Examples are taken from the web page.)","title":"A"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/#a_1","text":"The difference is that with tf.Variable you have to provide an initial value when you declare it. With tf.placeholder you don't have to provide an initial value and you can specify it at run time with the feed_dict argument inside Session.run","title":"A"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/#a_2","text":"Since Tensor computations compose of graphs then it's better to interpret the two in terms of graphs . Take for example the simple linear regression WX+B=Y(where W and B stand for the weights and bias and X for the observations' inputs and Y for the observations' outputs). Obviously X and Y are of the same nature( manifest variables ) which differ from that of W and B( latent variables ). X and Y are values of the samples(observations) and hence need a place to be filled , while W and B are the weights and bias, Variables (the previous value affects the later) in the graph which should be trained using different X and Y pairs. We place different samples to the Placeholders to train the Variables . We can and only need to save or restore the Variables (in checkpoints) to save or rebuild the graph with the code. Placeholders are mostly holders for the different datasets (for example training data or test data) but Variables are trained in the training process and remain the same(to predict the outcome of the input or map the inputs and outputs[labels] of the samples) later until you retrain or fine-tune the model(using different or the same samples to fill into the Placeholders often through the dict, for instance session.run(a_graph, dict={a_placeholder_name: sample_values}) , Placeholders are also passed as parameters to set models). If you change placeholders (add or delete or change the shape and etc) of a model in the middle of training, you still can reload the checkpoint without any other modifications. But if the variables of a saved model are changed you should adjust the checkpoint accordingly to reload it and continue the training(all variables defined in the graph should be available in the checkpoint). To sum up, if the values are from the samples(observations you already have) you safely make a placeholder to hold them, while if you need a parameter to be trained harness a Variable (simply put, set the Variables for the values you want to get using TF automatically). In some interesting models, like a style transfer model , the input pixes are going to be optimized and the normally-called model variables are fixed, then we should make the input(usually initialized randomly) as a variable as implemented in that link. \u5728\u4e00\u4e9b\u6709\u8da3\u7684\u6a21\u578b\u4e2d\uff0c\u6bd4\u5982\u4e00\u4e2a\u98ce\u683c\u8f6c\u6362\u6a21\u578b\uff0c\u8f93\u5165\u50cf\u7d20\u5c06\u88ab\u4f18\u5316\uff0c\u901a\u5e38\u88ab\u8c03\u7528\u7684\u6a21\u578b\u53d8\u91cf\u662f\u56fa\u5b9a\u7684\uff0c\u7136\u540e\u6211\u4eec\u5e94\u8be5\u628a\u8f93\u5165(\u901a\u5e38\u662f\u968f\u673a\u521d\u59cb\u5316\u7684)\u4f5c\u4e3a\u4e00\u4e2a\u53d8\u91cf\u5728\u94fe\u63a5\u4e2d\u5b9e\u73b0\u3002 For more information please infer to this simple and illustrating doc .","title":"A"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/#a_3","text":"The most obvious difference between the tf.Variable and the tf.placeholder is that you use variables to hold and update parameters. Variables are in-memory buffers containing tensors. They must be explicitly initialized and can be saved to disk during and after training. You can later restore saved values to exercise or analyze the model. Initialization of the variables is done with sess.run(tf.global_variables_initializer()) . Also while creating a variable, you need to pass a Tensor as its initial value to the Variable() constructor and when you create a variable you always know its shape. On the other hand, you can't update the placeholder. They also should not be initialized, but because they are a promise to have a tensor, you need to feed the value into them sess.run(, {a: }) . And at last, in comparison to a variable, placeholder might not know the shape. You can either provide parts of the dimensions or provide nothing at all. There other differences: the values inside the variable can be updated during optimizations variables can be shared , and can be non-trainable the values inside the variable can be stored after training when the variable is created, 3 ops are added to a graph (variable op, initializer op, ops for the initial value) placeholder is a function, Variable is a class (hence an uppercase) when you use TF in a distributed environment, variables are stored in a special place ( parameter server ) and are shared between the workers. Interesting part is that not only placeholders can be fed. You can feed the value to a Variable and even to a constant.","title":"A"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/How-to-understand-tf.Variable/","text":"\u8d44\u6e90 TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems A TensorFlow computation is described by a directed graph , which is composed of a set of nodes . The graph represents a dataflow computation , with extensions for allowing some kinds of nodes to maintain and update persistent state and for branching and looping control structures within the graph in a manner similar to Naiad [36] . Clients typically construct a computational graph using one of the supported front end languages ( C++ or Python). An example fragment to construct and then execute a TensorFlow graph using the Python front end is shown in Figure 1, and the resulting computation graph in Figure 2. \u4e0a\u9762\u6bb5\u4e2d\u7684 with extensions for allowing some kinds of nodes to maintain and update persistent state \u6240\u6307\u7684\u5176\u5b9e\u5c31 tf.Variable \uff0c\u5176\u5b9e\u6240\u8c13\u7684**persistent state** \u5e94\u8be5\u5c31\u662f\u4e00\u4e2a\u8868\u793a**\u53c2\u6570**\u7684\u503c\uff0c**\u53c2\u6570**\u6240\u6307\u7684\u662f\u9700\u8981\u6a21\u578b\u8fdb\u884c\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u6bd4\u5982weight\u548cbias\uff1b\u6b63\u5982\u4e0a\u8ff0\u6240\u4ecb\u7ecd\u7684\uff0c tf.Variable \u5bf9\u5e94\u7684\u662fnode\uff0c\u5373\u5b83\u662f\u4e00\u4e2aoperation\uff0c\u6b63\u5982 tf.constant \u4e5f\u662f\u4e00\u4e2anode\uff0c\u8fd9\u4e2anode\u7684\u51fa\u8fb9\u662f\u5b83\u7684\u503c\uff0c\u6240\u4ee5 tf.Variable \u8fd9\u4e2anode\u7684\u51fa\u8fb9\u5c31\u662f\u5b83\u7684\u503c\uff1b \u5728\u8fd9\u7bc7\u8bba\u6587\u7684Figure 2: Corresponding computation graph for Figure 1\u4e2d\uff0c\u5c06 b \uff08 tf.Variable \uff09\u3001 W \uff08 tf.Variable \uff09\u3001 X \uff08 tf.placeholder \uff09\u90fd\u753b\u51fa\u4e86node\uff1b Graphs and Sessions Executing v = tf.Variable(0) adds to the graph a tf.Operation that will store a writeable tensor value that persists between tf.Session.run calls. The tf.Variable object wraps this operation, and can be used like a tensor , which will read the current value of the stored value. The tf.Variable object also has methods such as tf.Variable.assign and tf.Variable.assign_add that create tf.Operation objects that, when executed, update the stored value. (See Variables for more information about variables.) \u5176\u5b9e\u8fd9\u6bb5\u8bdd\u5bf9\u4e8e\u7406\u89e3\u4e3a\u4ec0\u4e48\u4f7f\u7528 tf.Variable \u6765\u4f5c\u4e3a\u53c2\u6570\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u89e3\u91ca\uff0c\u5b83\u6709\u7740\u5982\u4e0b\u7684\u7279\u6027\uff1a tf.Variable can be used like a tensor \uff0c\u5f53\u5b83\u4f5c\u4e3a\u4e00\u4e2atensor\u6765\u4f7f\u7528\u7684\u65f6\u5019\uff0c\u90a3\u4e48\u5b83\u5c31\u4f1a\u8bfb\u53d6the current value of the stored value\uff0c\u8fd9\u6837\u5b83\u5c31\u6709\u503c\u4e86\uff0c\u663e\u7136\u8fd9\u79cd\u60c5\u51b5\u5f80\u5f80\u662f\u51fa\u73b0\u5728\u524d\u9988\u7684\u65f6\u5019\uff1b\u5982\u679c\u4ecedataflow graph\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u8fd9\u79cd\u60c5\u51b5\u5c31\u76f8\u5f53\u4e8e\u4ecenode\u4e2d\u6d41\u51fatensor\u503c\uff1b The tf.Variable object also has methods such as tf.Variable.assign and tf.Variable.assign_add that create tf.Operation objects that, when executed, update the stored value.\u663e\u7136\u8fd9\u662f\u5728\u53cd\u9988\u7684\u65f6\u5019\u57fa\u4e8e\u68af\u5ea6\u6765\u5b66\u4e60\u53c2\u6570\u7684\u65f6\u5019\u8981\u4f7f\u7528\u7684\uff1b\u5982\u679c\u4ecedataflow graph\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u8fd9\u79cd\u60c5\u51b5\u5c31\u76f8\u5f53\u4e8etensor\u503c\u6d41\u5165\u5230node\u4e2d\uff1b Variables A TensorFlow variable is the best way to represent shared , persistent state manipulated by your program. Variables are manipulated via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Unlike tf.Tensor objects, a tf.Variable exists outside the context of a single session.run call. Internally, a tf.Variable stores a persistent tensor . Specific ops allow you to read and modify the values of this tensor. These modifications are visible across multiple tf.Session s, so multiple workers can see the same values for a tf.Variable . ***SUMMARY*** \uff1a \u663e\u7136 tf.Varialbe \u7684\u8fd9\u79cd\u7279\u6027\u662f\u975e\u5e38\u9002\u5408\u6765\u4f5c\u4e3a\u6a21\u578b\u7684\u53c2\u6570\uff0c\u6743\u91cd\u7684\uff1b\u56e0\u4e3a\u8bad\u7ec3\u7684\u8fc7\u7a0b\u5c31\u662f\u4e0d\u65ad\u5730\u8c03\u6574\u53c2\u6570\uff0c\u5e76\u4e14\u8bad\u7ec3\u7684\u8fc7\u7a0b\u5f80\u5f80\u4e0d\u662f\u5728\u4e00\u4e2a run \u4e2d\u5c31\u5b8c\u6210\u7684\uff0c\u800c\u662f\u9700\u8981\u7ecf\u8fc7\u591a\u6b21 run \uff0c\u56e0\u6b64 tf.Varaible \u7684persist\u7279\u6027\u5c31\u975e\u5e38\u91cd\u8981\u4e86\uff1b Tensors Some types of tensors are special, and these will be covered in other units of the TensorFlow guide. The main ones are: tf.Variable tf.constant tf.placeholder tf.SparseTensor With the exception of tf.Variable , the value of a tensor is immutable , which means that in the context of a single execution tensors only have a single value. However, evaluating the same tensor twice can return different values; for example that tensor can be the result of reading data from disk, or generating a random number. SUMMARY : \u4ececomputation graph\u7684\u89d2\u5ea6\u6765\u770b\u5f85\uff1a tf.Variable tf.constant tf.placeholder \u5b83\u4eec\u90fdnode\uff0c \u4f46\u662f\u5b83\u4eec\u90fd\u6709\u4e00\u4e2a\u51fa\u8fb9\uff0c\u8fd9\u4e2a\u51fa\u8fb9\u662f\u5b83\u6240\u7ef4\u62a4\u7684tensor\u7684\u503c\uff1b SUMMARY \u5176\u5b9e\u4ece\u4e0d\u540c\u7684\u89d2\u5ea6\u6765\u5bf9 tf.Variable \u8fdb\u884c\u5206\u6790\uff0c\u4f1a\u5f97\u51fa\u4e0d\u540c\u7684\u7ed3\u8bba\uff1b","title":"How-to-understand-tf.Variable"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/How-to-understand-tf.Variable/#_1","text":"","title":"\u8d44\u6e90"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/How-to-understand-tf.Variable/#tensorflow#large-scale#machine#learning#on#heterogeneous#distributed#systems","text":"A TensorFlow computation is described by a directed graph , which is composed of a set of nodes . The graph represents a dataflow computation , with extensions for allowing some kinds of nodes to maintain and update persistent state and for branching and looping control structures within the graph in a manner similar to Naiad [36] . Clients typically construct a computational graph using one of the supported front end languages ( C++ or Python). An example fragment to construct and then execute a TensorFlow graph using the Python front end is shown in Figure 1, and the resulting computation graph in Figure 2. \u4e0a\u9762\u6bb5\u4e2d\u7684 with extensions for allowing some kinds of nodes to maintain and update persistent state \u6240\u6307\u7684\u5176\u5b9e\u5c31 tf.Variable \uff0c\u5176\u5b9e\u6240\u8c13\u7684**persistent state** \u5e94\u8be5\u5c31\u662f\u4e00\u4e2a\u8868\u793a**\u53c2\u6570**\u7684\u503c\uff0c**\u53c2\u6570**\u6240\u6307\u7684\u662f\u9700\u8981\u6a21\u578b\u8fdb\u884c\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u6bd4\u5982weight\u548cbias\uff1b\u6b63\u5982\u4e0a\u8ff0\u6240\u4ecb\u7ecd\u7684\uff0c tf.Variable \u5bf9\u5e94\u7684\u662fnode\uff0c\u5373\u5b83\u662f\u4e00\u4e2aoperation\uff0c\u6b63\u5982 tf.constant \u4e5f\u662f\u4e00\u4e2anode\uff0c\u8fd9\u4e2anode\u7684\u51fa\u8fb9\u662f\u5b83\u7684\u503c\uff0c\u6240\u4ee5 tf.Variable \u8fd9\u4e2anode\u7684\u51fa\u8fb9\u5c31\u662f\u5b83\u7684\u503c\uff1b \u5728\u8fd9\u7bc7\u8bba\u6587\u7684Figure 2: Corresponding computation graph for Figure 1\u4e2d\uff0c\u5c06 b \uff08 tf.Variable \uff09\u3001 W \uff08 tf.Variable \uff09\u3001 X \uff08 tf.placeholder \uff09\u90fd\u753b\u51fa\u4e86node\uff1b","title":"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/How-to-understand-tf.Variable/#graphs#and#sessions","text":"Executing v = tf.Variable(0) adds to the graph a tf.Operation that will store a writeable tensor value that persists between tf.Session.run calls. The tf.Variable object wraps this operation, and can be used like a tensor , which will read the current value of the stored value. The tf.Variable object also has methods such as tf.Variable.assign and tf.Variable.assign_add that create tf.Operation objects that, when executed, update the stored value. (See Variables for more information about variables.) \u5176\u5b9e\u8fd9\u6bb5\u8bdd\u5bf9\u4e8e\u7406\u89e3\u4e3a\u4ec0\u4e48\u4f7f\u7528 tf.Variable \u6765\u4f5c\u4e3a\u53c2\u6570\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u89e3\u91ca\uff0c\u5b83\u6709\u7740\u5982\u4e0b\u7684\u7279\u6027\uff1a tf.Variable can be used like a tensor \uff0c\u5f53\u5b83\u4f5c\u4e3a\u4e00\u4e2atensor\u6765\u4f7f\u7528\u7684\u65f6\u5019\uff0c\u90a3\u4e48\u5b83\u5c31\u4f1a\u8bfb\u53d6the current value of the stored value\uff0c\u8fd9\u6837\u5b83\u5c31\u6709\u503c\u4e86\uff0c\u663e\u7136\u8fd9\u79cd\u60c5\u51b5\u5f80\u5f80\u662f\u51fa\u73b0\u5728\u524d\u9988\u7684\u65f6\u5019\uff1b\u5982\u679c\u4ecedataflow graph\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u8fd9\u79cd\u60c5\u51b5\u5c31\u76f8\u5f53\u4e8e\u4ecenode\u4e2d\u6d41\u51fatensor\u503c\uff1b The tf.Variable object also has methods such as tf.Variable.assign and tf.Variable.assign_add that create tf.Operation objects that, when executed, update the stored value.\u663e\u7136\u8fd9\u662f\u5728\u53cd\u9988\u7684\u65f6\u5019\u57fa\u4e8e\u68af\u5ea6\u6765\u5b66\u4e60\u53c2\u6570\u7684\u65f6\u5019\u8981\u4f7f\u7528\u7684\uff1b\u5982\u679c\u4ecedataflow graph\u7684\u89d2\u5ea6\u6765\u770b\u7684\u8bdd\uff0c\u8fd9\u79cd\u60c5\u51b5\u5c31\u76f8\u5f53\u4e8etensor\u503c\u6d41\u5165\u5230node\u4e2d\uff1b","title":"Graphs and Sessions"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/How-to-understand-tf.Variable/#variables","text":"A TensorFlow variable is the best way to represent shared , persistent state manipulated by your program. Variables are manipulated via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Unlike tf.Tensor objects, a tf.Variable exists outside the context of a single session.run call. Internally, a tf.Variable stores a persistent tensor . Specific ops allow you to read and modify the values of this tensor. These modifications are visible across multiple tf.Session s, so multiple workers can see the same values for a tf.Variable . ***SUMMARY*** \uff1a \u663e\u7136 tf.Varialbe \u7684\u8fd9\u79cd\u7279\u6027\u662f\u975e\u5e38\u9002\u5408\u6765\u4f5c\u4e3a\u6a21\u578b\u7684\u53c2\u6570\uff0c\u6743\u91cd\u7684\uff1b\u56e0\u4e3a\u8bad\u7ec3\u7684\u8fc7\u7a0b\u5c31\u662f\u4e0d\u65ad\u5730\u8c03\u6574\u53c2\u6570\uff0c\u5e76\u4e14\u8bad\u7ec3\u7684\u8fc7\u7a0b\u5f80\u5f80\u4e0d\u662f\u5728\u4e00\u4e2a run \u4e2d\u5c31\u5b8c\u6210\u7684\uff0c\u800c\u662f\u9700\u8981\u7ecf\u8fc7\u591a\u6b21 run \uff0c\u56e0\u6b64 tf.Varaible \u7684persist\u7279\u6027\u5c31\u975e\u5e38\u91cd\u8981\u4e86\uff1b","title":"Variables"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/How-to-understand-tf.Variable/#tensors","text":"Some types of tensors are special, and these will be covered in other units of the TensorFlow guide. The main ones are: tf.Variable tf.constant tf.placeholder tf.SparseTensor With the exception of tf.Variable , the value of a tensor is immutable , which means that in the context of a single execution tensors only have a single value. However, evaluating the same tensor twice can return different values; for example that tensor can be the result of reading data from disk, or generating a random number. SUMMARY : \u4ececomputation graph\u7684\u89d2\u5ea6\u6765\u770b\u5f85\uff1a tf.Variable tf.constant tf.placeholder \u5b83\u4eec\u90fdnode\uff0c \u4f46\u662f\u5b83\u4eec\u90fd\u6709\u4e00\u4e2a\u51fa\u8fb9\uff0c\u8fd9\u4e2a\u51fa\u8fb9\u662f\u5b83\u6240\u7ef4\u62a4\u7684tensor\u7684\u503c\uff1b","title":"Tensors"},{"location":"Programming/TensorFlow/API/Python/Low-level-API/tf.placeholder-VS-tf.Variable/How-to-understand-tf.Variable/#summary","text":"\u5176\u5b9e\u4ece\u4e0d\u540c\u7684\u89d2\u5ea6\u6765\u5bf9 tf.Variable \u8fdb\u884c\u5206\u6790\uff0c\u4f1a\u5f97\u51fa\u4e0d\u540c\u7684\u7ed3\u8bba\uff1b","title":"SUMMARY"},{"location":"Programming/TensorFlow/API/TODO-C%2B%2B/","text":"","title":"Introduction"},{"location":"Programming/TensorFlow/Guide/","text":"","title":"Index"},{"location":"Programming/TensorFlow/Guide/Adding-a-New-Op/","text":"Adding a New Op haosdent Adding a New Op TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems NOTE: \u5728\u5176\u4e2d\u4e5f\u6709\u5173\u4e8eadding a new op\u7684\u63cf\u8ff0 TODO 1) stackoverflow Understand Op Registration and Kernel Linking in TensorFlow","title":"Adding a New Op"},{"location":"Programming/TensorFlow/Guide/Adding-a-New-Op/#adding#a#new#op","text":"","title":"Adding a New Op"},{"location":"Programming/TensorFlow/Guide/Adding-a-New-Op/#haosdent#adding#a#new#op","text":"","title":"haosdent Adding a New Op"},{"location":"Programming/TensorFlow/Guide/Adding-a-New-Op/#tensorflow#large-scale#machine#learning#on#heterogeneous#distributed#systems","text":"NOTE: \u5728\u5176\u4e2d\u4e5f\u6709\u5173\u4e8eadding a new op\u7684\u63cf\u8ff0","title":"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"},{"location":"Programming/TensorFlow/Guide/Adding-a-New-Op/#todo","text":"1) stackoverflow Understand Op Registration and Kernel Linking in TensorFlow","title":"TODO"},{"location":"Programming/TensorFlow/Implementation/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u63a2\u8ba8tensorflow\u7684\u5b9e\u73b0\uff0c\u4e3b\u8981\u53c2\u8003\u7684\u6709\uff1a 1) whitepaper2015 2) \u56fe\u89e3tensorflow \u6e90\u7801 TensorFlow is a parallel numeric processing system \u672c\u8282\u6807\u9898\u7684\u542b\u4e49\u662f: TensorFlow\u662f\u4e00\u4e2aparallel numeric processing system\uff0c\u5173\u4e8eparallel numeric processing system\uff0c\u53c2\u89c1\u5de5\u7a0bparallel computing\u7684 Application\\Parallel-numeric-processing-system \u7ae0\u8282\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u5728haosdent TensorFlow for Googlers \u4e2d\u6709\u8fd9\u6837\u7684\u4ecb\u7ecd: TensorFlow\u2122 is an open source software library for numerical computation using data flow graphs. TensorFlow VS compiler \u4ece\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u6765\u8bf4\uff0cTensorFlow\u548ccompiler\u662f\u6709\u4e9b\u7c7b\u4f3c\u4e4b\u5904\u7684\uff0c\u53ef\u4ee5\u8fdb\u884c\u6bd4\u8f83: Front end/Interface \u8ba9programmer\u4f7f\u7528**symbol expression**\u6765\u63cf\u8ff0computation\uff08symbolic programming\uff09\uff0cTensorFlow\u7684front end\u4f7f\u7528computation graph\u7684\u6765\u8fdb\u884c**\u7ed3\u6784\u5316\u8868\u793a**\u3002\u5982\u679c\u4f7f\u7528compiler\u6765\u8fdb\u884c\u7c7b\u6bd4\u7684\u8bdd\uff0ccomputation graph\u5176\u5b9e\u548cAST\u975e\u5e38\u7c7b\u4f3c\uff0c\u5982\u679c\u4ece\u7ed3\u6784\u5316\u8868\u793a\u7684\u89d2\u5ea6\u6765\u770b: \u4e24\u8005\u672c\u8d28\u4e0a\u662f\u76f8\u540c\u7684\uff0c\u90fd\u662f\u5bf9symbol expression\u7684**\u7ed3\u6784\u5316\u8868\u793a**\u3002\u4f46\u662f\uff0c\u7531\u4e8e\u4e24\u8005\u662f\u4e0d\u540c\u9886\u57df\u7684\uff0c\u6240\u4ee5\u9700\u8981\u8003\u8651\u5404\u81ea\u9886\u57df\u4e2d\u7684\u7279\u5b9a \u95ee\u9898\uff0c\u5728\u4e0b\u9762\u7684\u7ae0\u8282\u4e2d\u4f1a\u8ba8\u8bbaTensorFlow computation graph\u9700\u8981\u8003\u8651\u7684\u95ee\u9898\u3002 Back end/Computation engine/Core Back end\u5b9e\u73b0computation graph\u8868\u793a\u7684computation\u3002\u4e0ecompiler\u4e2d\uff0c\u5c06AST\u8f6c\u6362\u4e3a\u4e09\u5730\u5740\u7801\u3001\u7136\u540e\u8f6c\u6362\u4e3ainstruction\u8fdb\u800c\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u4e0d\u540c\u7684\u662f\uff0cTensorFlow back end\u5e76\u4e0d\u4f1a\u5c06computation graph\u8f6c\u6362\u4e3ainstruction\u7684\u65b9\u5f0f\uff0cTensorFlow back end\u4f1a\u5c06computation graph\u5b8c\u6574\u5730\u4fdd\u5b58\uff0c\u7136\u540e\u57fa\u4e8ecomputation graph\u6765\u5b89\u6392\u8ba1\u7b97\uff0cTensorFlow back end: 1) dataflow programming paradigm 2) node\u5bf9\u5e94operator 3) distributed: TensorFlow\u5141\u8bb8\u7528\u6237\u5c06node\u6307\u5b9a\u5230\u4e0d\u540c\u7684computer\uff0c\u8fd9\u4e9bcomputer\u4e4b\u95f4\u901a\u8fc7network\u6765\u8fdb\u884ccommunicate\uff0c\u663e\u7136\u6574\u4f53\u6765\u770b\uff0c\u5b83\u4eec\u8fd8\u662f\u5bf9\u5e94\u7684\u7528\u6237\u5b9a\u4e49\u7684computation graph 4) abstraction: heterogeneous\u673a\u5668\u7684\u62bd\u8c61 5) \u501f\u9274\u4e86microsoft Naiad NOTE: \u5173\u4e8e\u4e0a\u8ff0\u8ba8\u8bba\uff0c\u5728infogalactic Dataflow programming#Properties of dataflow programming languages \u4e2d\u4e5f\u8fdb\u884c\u4e86\u8ba8\u8bba\u3002","title":"Introduction"},{"location":"Programming/TensorFlow/Implementation/#_1","text":"\u672c\u7ae0\u63a2\u8ba8tensorflow\u7684\u5b9e\u73b0\uff0c\u4e3b\u8981\u53c2\u8003\u7684\u6709\uff1a 1) whitepaper2015 2) \u56fe\u89e3tensorflow \u6e90\u7801","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Programming/TensorFlow/Implementation/#tensorflow#is#a#parallel#numeric#processing#system","text":"\u672c\u8282\u6807\u9898\u7684\u542b\u4e49\u662f: TensorFlow\u662f\u4e00\u4e2aparallel numeric processing system\uff0c\u5173\u4e8eparallel numeric processing system\uff0c\u53c2\u89c1\u5de5\u7a0bparallel computing\u7684 Application\\Parallel-numeric-processing-system \u7ae0\u8282\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u5728haosdent TensorFlow for Googlers \u4e2d\u6709\u8fd9\u6837\u7684\u4ecb\u7ecd: TensorFlow\u2122 is an open source software library for numerical computation using data flow graphs.","title":"TensorFlow is a parallel numeric processing system"},{"location":"Programming/TensorFlow/Implementation/#tensorflow#vs#compiler","text":"\u4ece\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u6765\u8bf4\uff0cTensorFlow\u548ccompiler\u662f\u6709\u4e9b\u7c7b\u4f3c\u4e4b\u5904\u7684\uff0c\u53ef\u4ee5\u8fdb\u884c\u6bd4\u8f83:","title":"TensorFlow VS compiler"},{"location":"Programming/TensorFlow/Implementation/#front#endinterface","text":"\u8ba9programmer\u4f7f\u7528**symbol expression**\u6765\u63cf\u8ff0computation\uff08symbolic programming\uff09\uff0cTensorFlow\u7684front end\u4f7f\u7528computation graph\u7684\u6765\u8fdb\u884c**\u7ed3\u6784\u5316\u8868\u793a**\u3002\u5982\u679c\u4f7f\u7528compiler\u6765\u8fdb\u884c\u7c7b\u6bd4\u7684\u8bdd\uff0ccomputation graph\u5176\u5b9e\u548cAST\u975e\u5e38\u7c7b\u4f3c\uff0c\u5982\u679c\u4ece\u7ed3\u6784\u5316\u8868\u793a\u7684\u89d2\u5ea6\u6765\u770b: \u4e24\u8005\u672c\u8d28\u4e0a\u662f\u76f8\u540c\u7684\uff0c\u90fd\u662f\u5bf9symbol expression\u7684**\u7ed3\u6784\u5316\u8868\u793a**\u3002\u4f46\u662f\uff0c\u7531\u4e8e\u4e24\u8005\u662f\u4e0d\u540c\u9886\u57df\u7684\uff0c\u6240\u4ee5\u9700\u8981\u8003\u8651\u5404\u81ea\u9886\u57df\u4e2d\u7684\u7279\u5b9a \u95ee\u9898\uff0c\u5728\u4e0b\u9762\u7684\u7ae0\u8282\u4e2d\u4f1a\u8ba8\u8bbaTensorFlow computation graph\u9700\u8981\u8003\u8651\u7684\u95ee\u9898\u3002","title":"Front end/Interface"},{"location":"Programming/TensorFlow/Implementation/#back#endcomputation#enginecore","text":"Back end\u5b9e\u73b0computation graph\u8868\u793a\u7684computation\u3002\u4e0ecompiler\u4e2d\uff0c\u5c06AST\u8f6c\u6362\u4e3a\u4e09\u5730\u5740\u7801\u3001\u7136\u540e\u8f6c\u6362\u4e3ainstruction\u8fdb\u800c\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u4e0d\u540c\u7684\u662f\uff0cTensorFlow back end\u5e76\u4e0d\u4f1a\u5c06computation graph\u8f6c\u6362\u4e3ainstruction\u7684\u65b9\u5f0f\uff0cTensorFlow back end\u4f1a\u5c06computation graph\u5b8c\u6574\u5730\u4fdd\u5b58\uff0c\u7136\u540e\u57fa\u4e8ecomputation graph\u6765\u5b89\u6392\u8ba1\u7b97\uff0cTensorFlow back end: 1) dataflow programming paradigm 2) node\u5bf9\u5e94operator 3) distributed: TensorFlow\u5141\u8bb8\u7528\u6237\u5c06node\u6307\u5b9a\u5230\u4e0d\u540c\u7684computer\uff0c\u8fd9\u4e9bcomputer\u4e4b\u95f4\u901a\u8fc7network\u6765\u8fdb\u884ccommunicate\uff0c\u663e\u7136\u6574\u4f53\u6765\u770b\uff0c\u5b83\u4eec\u8fd8\u662f\u5bf9\u5e94\u7684\u7528\u6237\u5b9a\u4e49\u7684computation graph 4) abstraction: heterogeneous\u673a\u5668\u7684\u62bd\u8c61 5) \u501f\u9274\u4e86microsoft Naiad NOTE: \u5173\u4e8e\u4e0a\u8ff0\u8ba8\u8bba\uff0c\u5728infogalactic Dataflow programming#Properties of dataflow programming languages \u4e2d\u4e5f\u8fdb\u884c\u4e86\u8ba8\u8bba\u3002","title":"Back end/Computation engine/Core"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/","text":"TensorFlow White Papers tensorflow TensorFlow White Papers 1) Large-Scale Machine Learning on Heterogeneous Distributed Systems 2) TensorFlow: A System for Large-Scale Machine Learning csdn Tensorflow White Paper\uff08\u4e00\uff09 Google\u5206\u522b\u5728 2015 \u548c 2016 \u53d1\u5e03\u4e86\u4e24\u4efdtensorflow\u767d\u76ae\u4e66\uff0c \u5185\u5bb9\u5404\u6709\u4fa7\u91cd\u3002\u5148\u8bfb15\u5e74\u7684\uff0c \u5b83\u504f\u5411\u4e8e\u6d45\u663e\u7684\u6846\u67b6\u6574\u4f53\u7279\u6027\u4ecb\u7ecd\u3002","title":"Introduction"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/#tensorflow#white#papers","text":"","title":"TensorFlow White Papers"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/#tensorflow#tensorflow#white#papers","text":"1) Large-Scale Machine Learning on Heterogeneous Distributed Systems 2) TensorFlow: A System for Large-Scale Machine Learning","title":"tensorflow TensorFlow White Papers"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/#csdn#tensorflow#white#paper","text":"Google\u5206\u522b\u5728 2015 \u548c 2016 \u53d1\u5e03\u4e86\u4e24\u4efdtensorflow\u767d\u76ae\u4e66\uff0c \u5185\u5bb9\u5404\u6709\u4fa7\u91cd\u3002\u5148\u8bfb15\u5e74\u7684\uff0c \u5b83\u504f\u5411\u4e8e\u6d45\u663e\u7684\u6846\u67b6\u6574\u4f53\u7279\u6027\u4ecb\u7ecd\u3002","title":"csdn Tensorflow White Paper\uff08\u4e00\uff09"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/","text":"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems Abstract TensorFlow [1] is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. NOTE: tensorflow\u65e2\u5b9e\u73b0\u4e86interface\uff08front end\uff09\u4e5f\u5b9e\u73b0\u4e86computation engine\uff08back end\uff09\uff0c\u800c Keras \u5219\u4ec5\u4ec5\u63d0\u4f9binterface\uff0c\u800c\u5c06tensorflow\u7b49\u4f5c\u4e3aback end\u3002 A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous\uff08\u5f02\u6784\u7684\uff09 systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. NOTE: \u663e\u7136\uff0ctensorflow\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u62bd\u8c61\u5c42\uff0c\u901a\u8fc7\u8fd9\u4e2a\u62bd\u8c61\u5c42\uff0c\u6211\u4eec\u7684algorithm\u53ef\u4ee5\u8fd0\u884c\u5728heterogeneous system\u4e0a\u3002 The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. NOTE: machine learning\u7684\u5e7f\u6cdb\u5e94\u7528\u3002 This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org . 1 Introduction Based on our experience with DistBelief and a more complete understanding of the desirable system properties and requirements for training and using neural networks, we have built TensorFlow, our second-generation system for the implementation and deployment of large-scale machine learning models. TensorFlow takes computations described using a dataflow-like model and maps them onto a wide variety of different hardware platforms, ranging from running inference on mobile device platforms such as Android and iOS to modest-sized training and inference systems using single machines containing one or many GPU cards to large-scale training systems running on hundreds of specialized machines with thousands of GPUs. NOTE: dataflow-like model\uff0c\u5176\u5b9e\u975e\u5e38\u7c7b\u4f3c\u4e8edataflow programming\u3002 Having a single system that can span such a broad range of platforms significantly simplifies the real-world use of machine learning system, as we have found that having separate systems for large-scale training and small-scale deployment leads to significant maintenance burdens and leaky abstractions(\u6cc4\u9732\u7684\u62bd\u8c61). NOTE: \u7edf\u4e00/abstraction\u7684\u4f18\u52bf TensorFlow computations are expressed as stateful dataflow graphs (described in more detail in Section 2), and we have focused on making the system both flexible enough for quickly experimenting with new models for research purposes and sufficiently high performance and robust for production training and deployment of machine learning models. For scaling neural network training to larger deployments, TensorFlow allows clients to easily express various kinds of parallelism through replication and parallel execution of a core model dataflow graph , with many different computational devices all collaborating to update a set of shared parameters or other state . Modest changes in the description of the computation allow a wide variety of different approaches to parallelism to be achieved and tried with low effort [14, 29, 42]. Some TensorFlow uses allow some flexibility in terms of the consistency of parameter updates, and we can easily express and take advantage of these relaxed synchronization requirements in some of our larger deployments. Compared to DistBelief, TensorFlow\u2019s programming model is more flexible, its performance is significantly better, and it supports training and using a broader range of models on a wider variety of heterogeneous hardware platforms NOTE: \u8fd9\u4e00\u6bb5\u4f5c\u8005\u6240\u8981\u8868\u8fbe\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u5982\u679c\u5c06tensorflow\u7684interface\u770b\u505a\u662f\u4e00\u95e8programming language\uff0c\u8fd9\u4e2aprogramming language\u662fflexible\u3001expressive\u7684\u3002\u4f7f\u7528\u5b83\uff0cclient\u80fd\u591f\u8f7b\u677e\u5730\u8868\u8ff0\u5404\u79cdparallelism\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0ctensorflow\u7684\u8bbe\u8ba1\u8005\u662f\u5c06\u5b83\u5b9a\u4f4d\u4e3a\u201cLarge-Scale Machine Learning on Heterogeneous Distributed Systems\u201d\uff0c\u6240\u4ee5\u5728\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\uff0c parallelism \u3001 consistency \u7b49**distributed computing**\u9886\u57df\u7684\u672f\u8bed\u662f\u4e0d\u8db3\u4e3a\u5947\u7684\u3002\u5173\u4e8e**distributed computing**\u6b64\uff0c\u53c2\u89c1\u5de5\u7a0bparallel computing\u3002 Although these applications have concentrated on machine learning and deep neural networks in particular, we expect that TensorFlow\u2019s abstractions will be useful in a variety of other domains, including other kinds of machine learning algorithms, and possibly other kinds of numerical computations . NOTE: tensorflow\u7684\u672c\u8d28\u662f\u4e00\u4e2anumerical computation framework\u3002 The rest of this paper describes TensorFlow in more detail. Section 2 describes the programming model and basic concepts of the TensorFlow interface. Section 3 describes both our single machine and distributed implementations . Section 4 describes several extensions to the basic programming model. Section 5 describes several optimizations to the basic implementations. Section 6 describes some of our experiences in using TensorFlow. Section 7 describes several programming idioms we have found helpful when using TensorFlow. Section 9 describes several auxiliary tools we have built around the core TensorFlow system. Sections 10 and 11 discuss future and related work, respectively. Section 12 offers concluding thoughts. 2 Programming Model and Basic Concepts A TensorFlow computation is described by a directed graph , which is composed of a set of nodes . The graph represents a dataflow computation , with extensions for allowing some kinds of nodes to maintain and update persistent state \uff08 tf.Variable \uff09 and for branching and looping control structures within the graph in a manner similar to Naiad [36] . Clients typically construct a computational graph using one of the supported front end languages ( C++ or Python). An example fragment to construct and then execute a TensorFlow graph using the Python front end is shown in Figure 1, and the resulting computation graph in Figure 2. NOTE: \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c TensorFlow\u7684computation model\u662f\u501f\u9274\u7684 Naiad \u3002 \u5728 import tensorflow as tf b = tf . Variable ( tf . zeros ([ 100 ])) # 100-d vector, init to zeroes W = tf . Variable ( tf . random_uniform ([ 784 , 100 ], - 1 , 1 )) # 784x100 matrix w/rnd vals x = tf . placeholder ( name = \"x\" ) # Placeholder for input relu = tf . nn . relu ( tf . matmul ( W , x ) + b ) # Relu(Wx+b) C = [ ... ] # Cost computed as a function # of Relu s = tf . Session () for step in xrange ( 0 , 10 ): input = ... construct 100 - D input array ... # Create 100-d vector for input result = s . run ( C , feed_dict = { x : input }) # Fetch cost, feeding x=input print step , result Figure 2: Corresponding computation graph for Figure 1 NOTE: \u6b63\u5982\u8fd9\u4e2a\u56fe\u7247\u4e2d\u6240\u5c55\u793a\u7684\uff0c b \u3001 W \u3001 X \u90fd\u662fnode\uff1b In a TensorFlow graph, each node has zero or more inputs and zero or more outputs, and represents the instantiation of an operation . Values that flow along normal edges in the graph (from outputs to inputs) are tensors , arbitrary dimensionality arrays where the underlying element type is specified or inferred at graph-construction time. Control dependencies edge Special edges , called control dependencies , can also exist in the graph: no data flows along such edges, but they indicate that the source node for the control dependence must finish executing before the destination node for the control dependence starts executing. Since our model includes mutable state , control dependencies can be used directly by clients to enforce happens before relationships . Our implementation also sometimes inserts control dependencies to enforce orderings between otherwise independent operations as a way of, for example, controlling the peak memory usage. NOTE: \u4e0a\u9762\u5f15\u5165\u4e86\u975e\u5e38\u91cd\u8981\u7684\u6982\u5ff5\uff1a graph tensorflow graph node operation edge tensor\u3001 control dependencies \u5173\u4e8econtrol dependency\uff0c\u53c2\u89c1 TensorFlow\\API\\Python\\Building-Graphs\\tf.control_dependencies \u3002 \u4e3a\u4ec0\u4e48\u53ebcontrol dependencies? \u56e0\u4e3acomputation graph\u5176\u5b9e\u53ef\u4ee5\u770b\u505a\u662fdependency graph\uff0c\u5b83\u672c\u8eab\u63cf\u8ff0\u4e86dependency\u5173\u7cfb\uff0ccontrol dependencies edge\u7ed9\u4e88\u4e86user\u5bf9dependency \u7684\u66f4\u591a\u63a7\u5236\u3002 Operations and Kernels NOTE: \u672c\u8282\u63cf\u8ff0\u4e86operation\u548ckernel\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5176\u5b9e\u5b83\u4eec\u7684\u5173\u7cfb\u975e\u5e38\u7c7b\u4f3c\u4e8einterface and implementation: operation\u662finterface\uff0ckernel\u662fimplementation\u3002\u4e00\u4e2aoperation\u662f\u53ef\u4ee5\u6709\u591a\u4e2akernel\u7684\uff0c\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u5728haosdent Adding a New Op \u4e2d\u6709\u8bf4\u660e: Implement the Op in C++. This implementation is called a \"kernel\", and there can be multiple kernels for different architectures (e.g. CPUs, GPUs) or input / output types. \u663e\u7136\uff0cTensorFlow\u7684\u5b9e\u73b0\u4e5f\u662f\u9075\u5faaprogram to interface\u539f\u5219\uff0c\u8fd9\u6837\u7684\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u652f\u6301heterogeneous\uff08\u5f02\u6784\u7684\uff09 systems\u7684\u7279\u6027\u3002 \u5173\u4e8e\u5982\u4f55add a new op\uff0c\u53c2\u89c1 TensorFlow\\Guide\\Adding-a-New-Op \u3002 TensorFlow\u7684operation\u548ckernel\u91c7\u7528\u7684\u662fregistration mechanism\uff0c\u8fd9\u589e\u52a0\u4e86\u5b83\u7684\u53ef\u6269\u5c55\u6027\u3002 An operation has a name and represents an abstract computation (e.g., \u201cmatrix multiply\u201d, or \u201cadd\u201d). An operation can have attributes , and all attributes must be provided or inferred at graph-construction time in order to instantiate a node to perform the operation. One common use of attributes is to make operations polymorphic over different tensor element types (e.g., add of two tensors of type float versus add of two tensors of type int32). A kernel is a particular implementation of an operation that can be run on a particular type of device (e.g., CPU or GPU). A TensorFlow binary defines the sets of operations and kernels available via a registration mechanism, and this set can be extended by linking in additional operation and/or kernel definitions/registrations. Table 1 shows some of the kinds of operations built into the core TensorFlow library. Category Examples Element-wise mathematical operations Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal, ... Array operations Concat, Slice, Split, Constant, Rank, Shape, Shuffle, ... Matrix operations MatMul, MatrixInverse, MatrixDeterminant, ... Stateful operations Variable, Assign, AssignAdd, ... Neural-net building blocks SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool, ... Checkpointing operations Save, Restore Queue and synchronization operations Enqueue, Dequeue, MutexAcquire, MutexRelease, ... Control flow operations Merge, Switch, Enter, Leave, NextIteration Table 1: Example TensorFlow operation types NOTE: tensorflow\u662f\u4e00\u4e2adistributed system\uff0c\u6240\u4ee5\u5b83\u63d0\u4f9b\u4e86\u201dQueue and synchronization operations\u201c NOTE: \u8bad\u7ec3\u6570\u636e\u9700\u8981\u6d41\u7ecf\u6574\u4e2a\u7f51\u7edc\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u8bad\u7ec3\u6570\u636e\u6267\u884c\u4e00\u5b9a\u7684\u8fd0\u7b97\uff1b\u8bad\u7ec3\u6570\u636e\u53ef\u80fd\u4f1a\u548cweight\uff0cbias\u7b49\u8fdb\u884c\u8fd0\u7b97\uff0c\u663e\u7136weight\u548cbias\u7b49\u662f\u548c\u8bad\u7ec3\u6570\u636e\u4e0d\u540c\u7684\uff0c\u5b83\u4eec\u662f\u9700\u8981\u7531\u6a21\u578b\u6765\u8fdb\u884c\u5b66\u4e60\u7684\uff0c\u5728\u5177\u4f53\u7f16\u7801\u7684\u65f6\u5019\uff0c\u8bad\u7ec3\u6570\u636e\u5f80\u5f80\u4f7f\u7528 tf.placeholder \u6765\u8868\u793a\uff0c\u800cweight\u548cbias\u7b49\u5219\u662f\u4f7f\u7528 tf.Variable \u6765\u8868\u793a\uff1b\u7406\u89e3\u4e24\u8005\u6700\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u5b9e\u73b0\u4e00\u4e2aMLP\uff1b Sessions Clients programs interact with the TensorFlow system by creating a Session . To create a computation graph , the Session interface supports an Extend method to augment\uff08\u6269\u5c55\uff09 the current graph managed by the session with additional nodes and edges (the initial graph when a session is created is empty). The other primary operation supported by the session interface is Run , which takes a set of output names that need to be computed, as well as an optional set of tensors to be fed into the graph in place of certain outputs of nodes. Using the arguments to Run , the TensorFlow implementation can compute the transitive closure of all nodes that must be executed in order to compute the outputs that were requested, and can then arrange to execute the appropriate nodes in an order that respects their dependencies (as described in more detail in 3.1). Most of our uses of TensorFlow set up a Session with a graph once, and then execute the full graph or a few distinct subgraphs thousands or millions of times via Run calls. NOTE: tensorflow\u7684computation graph\u5176\u5b9e\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2adependency graph\uff0c\u663e\u7136\u6700\u7ec8\u7684\u8f93\u51fa\u8282\u70b9\u662f\u4f9d\u8d56\u4e8e\u6240\u6709\u6d41\u5411\u5b83\u7684\u8f93\u5165tensor\u7684\uff0c\u800c\u8fd9\u4e9btensor\u53c8\u8fdb\u4e00\u6b65\u4f9d\u8d56\u4e8e\u6d41\u5165\u5b83\u7684tensor\u7684\uff0c\u663e\u7136\u8fd9\u79cddependency\u5173\u7cfb\u662ftransitive\u7684\uff0c\u4e5f\u5c31\u662f\u4e3a\u4e86\u8ba1\u7b97\u51faoutput\uff0c\u9700\u8981\u8ba1\u7b97\u51fa\u6240\u6709\u7684transitive closure\u3002\u8fd9\u5c31\u662f\u5728graph theory\u4e2d\u603b\u7ed3\u7684dependency model\u3002\u5173\u4e8eTensorFlow core\u662f\u5982\u4f55\u6267\u884ccomputation graph\u7684\uff0c\u5728\u540e\u9762\u7684: 3.1 Single-Device Execution 3.2 Multi-Device Execution 3.3 Distributed Execution \u7b2c\u4e00\u6b21\u9605\u8bfb\u8fd9\u4e00\u6bb5\u7684\u65f6\u5019\uff0c\u6211\u60f3\u5230\u4e86\u5728\u300a compile principle \u300b 4.6 Introduction to LR Parsing: Simple LR # 5.2 Evaluation Orders for SDD's # NOTE: \u5173\u4e8eSessions\uff0c\u53c2\u89c1haosdent Running Graphs \u3002 Variables In most computations a graph is executed multiple times. Most tensors do not survive past a single execution of the graph. However, a Variable is a special kind of operation that returns a handle to a persistent mutable tensor that survives across executions of a graph. Handles to these persistent mutable tensors can be passed to a handful of special operations, such as Assign and AssignAdd (equivalent to += ) that mutate the referenced tensor. For machine learning applications of TensorFlow, the parameters of the model are typically stored in tensors held in variables, and are updated as part of the Run of the training graph for the model. 3 Implementation Client\u3001master and worker process The main components in a TensorFlow system are the client , which uses the Session interface to communicate with the master , and one or more worker processes , with each worker process responsible for arbitrating\uff08\u4ef2\u88c1\uff09 access to one or more computational devices (such as CPU cores or GPU cards) and for executing graph nodes on those devices as instructed by the master. NOTE: client\u548cmaster\u8fdb\u884ccommunicate\uff0cmaster instruct(\u901a\u77e5\u3001\u6307\u6325) worker process\u5728computational device\u4e0a\u6267\u884cgraph nodes\u3002 \u5173\u4e8e\u5b83\u4eec\uff0c\u53c2\u89c1\u4e0b\u9762\u7684figure3\u3002 \u5173\u4e8eworker process\u548cdevice\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u53c2\u89c1\u4e0b\u9762\u7684device\u7ae0\u8282\u3002 We have both local and distributed implementations of the TensorFlow interface. Local implementation The local implementation is used when the client, the master, and the worker all run on a single machine in the context of a single operating system process (possibly with multiple devices, if for example, the machine has many GPU cards installed). Distributed implementation The distributed implementation shares most of the code with the local implementation, but extends it with support for an environment where the client, the master, and the workers can all be in different processes on different machines. In our distributed environment, these different tasks are containers in jobs managed by a cluster scheduling system [51]. These two different modes are illustrated in Figure 3. Most of the rest of this section discusses issues that are common to both implementations, while Section 3.3 discusses some issues that are particular to the distributed implementation. Devices Devices are the computational heart of TensorFlow. Each worker is responsible for one or more devices, and each device has a device type , and a name . Device names are composed of pieces that identify the device\u2019s type , the device\u2019s index within the worker, and, in our distributed setting, an identification of the job and task of the worker (or localhost for the case where the devices are local to the process). Example device names are\" /job:localhost/device:cpu:0 \"or \" /job:worker/task:17/device:gpu:3 \". We have implementations of our Device interface for CPUs and GPUs, and new device implementations for other device types can be provided via a registration mechanism. Each device object is responsible for managing allocation and deallocation of device memory, and for arranging for the execution of any kernels that are requested by higher levels in the TensorFlow implementation. Tensors A tensor in our implementation is a typed, multi-dimensional array. We support a variety of tensor element types, including signed and unsigned integers ranging in size from 8 bits to 64 bits, IEEE float and double types, a complex number type, and a string type (an arbitrary byte array). Backing store of the appropriate size is managed by an allocator that is specific to the device on which the tensor resides. Tensor backing store buffers are reference counted and are deallocated when no references remain. 3.1 Single-Device Execution Let\u2019s first consider the simplest execution scenario: a single worker process with a single device . The nodes of the graph are executed in an order that respects the dependencies between nodes. In particular, we keep track of a count per node of the number of dependencies of that node that have not yet been executed. Once this count drops to zero, the node is eligible(\u5408\u683c) for execution and is added to a ready queue . The ready queue is processed in some unspecified order, delegating execution of the kernel for a node to the device object. When a node has finished executing, the counts of all nodes that depend on the completed node are decremented. NOTE: \u4ece\u4e0a\u9762\u4e24\u6bb5\u63cf\u8ff0\u6765\uff0cTensorFlow\u7684execution\u7b97\u6cd5\u5982\u4e0b: 1) \u9996\u5148\u6839\u636edependency\u5173\u7cfb\u8fdb\u884c\u62d3\u6251\u6392\u5e8f\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u80fd\u591f\u5f97\u5230partial order\uff0c\u65e0\u6cd5\u5f97\u5230total order\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b58\u5728\u4e00\u4e9bnode\uff0c\u5b83\u4eec\u7684execution order\u662f\u65e0\u6cd5\u786e\u5b9a\u7684\u3002\u8fd9\u4e00\u6b65\u6240\u5f97\u5230\u7684\u53ea\u662f\u9759\u6001\u987a\u5e8f\uff0c\u771f\u5b9e\u7684\u6267\u884c\u987a\u5e8f\uff0c\u8fd8\u4f9d\u8d56\u4e8e\u5177\u4f53\u7684\u6267\u884c\u60c5\u51b5 2) \u6bcf\u4e2anode\u5b8c\u6210\u6267\u884c\u540e\uff0c\u5219\u5b83\u7684\u6240\u6709\u7684child nodes\u7684count\u90fd\u9700\u8981decrease 1\u3002\u4e00\u65e6\u4e00\u4e2anode\u7684dependency\u90fd\u6ee1\u8db3\u4e86\uff0c\u5219\u5b83\u5c31eligible for execution\u4e86\uff0c\u5c31\u5c06\u5b83\u653e\u5230ready queue\u4e2d\u3002 3.2 Multi-Device Execution Once a system has multiple devices, there are two main complications: 1) deciding which device to place the computation for each node in the graph 2) and then managing the required communication of data across device boundaries implied by these placement decisions. This subsection discusses these two issues. 3.2.1 Node Placement NOTE: TensorFlow\u4f7f\u7528place algorithm\u6765\u5b89\u6392node placement\uff0c\u8fd9\u4e2aalgorithm\u7684\u8f93\u5165\u6709: 1) cost model 2) nodes 3) feasible devices \u8f93\u51fa\u662f: \u5c06\u54ea\u4e9bnodes\u653e\u5230\u54ea\u4e2adevice\u4e0a\u8fdb\u884c\u6267\u884c\uff0c\u653e\u5230\u540c\u4e00\u4e2adevice\u7684nodes\u5f62\u6210\u4e86\u4e00\u4e2asubgraph\uff0c\u663e\u7136\u8fd9\u4e2a\u7ed3\u679c\u5c31\u662f\u5c06\u539fcomputation graph\u5206\u5272\u4e3a\u4e86\u4e00\u4e9b\u5217subgraph\u3002\u8fd9\u5c31\u5f15\u51fa\u4e86\u8fd9\u4e9bsubgraph\u4e4b\u95f4\u7684Cross-Device Communication\u95ee\u9898\uff0c\u8fd9\u5728\"3.2.2 Cross-Device Communication\"\u4e2d\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002 Given a computation graph, one of the main responsibilities of the TensorFlow implementation is to map the computation onto the set of available devices. A simplified version of this algorithm is presented here. See Section 4.3 for extensions supported by this algorithm. One input to the placement algorithm is a cost model , which contains estimates of the sizes (in bytes) of the input and output tensors for each graph node , along with estimates of the computation time required for each node when presented with its input tensors. This cost model is either statically estimated based on heuristics associated with different operation types , or is measured based on an actual set of placement decisions for earlier executions of the graph. NOTE: The placement algorithm first runs a simulated execution of the graph. The simulation is described below and ends up picking a device for each node in the graph using greedy heuristics . The node to device placement generated by this simulation is also used as the placement for the real execution. The placement algorithm starts with the sources of the computation graph , and simulates the activity on each device in the system as it progresses. For each node that is reached in this traversal, the set of feasible devices is considered (a device may not be feasible if the device does not provide a kernel that implements the particular operation). For nodes with multiple feasible devices, the placement algorithm uses a greedy heuristic that examines the effects on the completion time of the node of placing the node on each possible device. This heuristic takes into account the estimated or measured execution time of the operation on that kind of device from the cost model , and also includes the costs of any communication that would be introduced in order to transmit inputs to this node from other devices to the considered device. NOTE: \u601d\u8003\uff1asource of computation graph\u662fcomputation graph\u7684\u54ea\u4e00\u7aef\uff1f \u4e0a\u9762\u8fd9\u4e00\u6bb5\u6240\u63cf\u8ff0\u7684\u662f\u201cThe placement algorithm first runs a simulated execution of the graph\u201d\uff0c\u5373\u201csimulation \u201d The device where the node\u2019s operation would finish the soonest is selected as the device for that operation, and the placement process then continues onwards to make placement decisions for other nodes in the graph, including downstream nodes that are now ready for their own simulated execution. Section 4.3 describes some extensions that allow users to provide hints and partial constraints to guide the placement algorithm . The placement algorithm is an area of ongoing development within the system. 3.2.2 Cross-Device Communication Once the node placement has been computed, the graph is partitioned into a set of subgraphs, one per device. Any cross-device edge from x to y is removed and replaced by an edge from x to a new Send node in x\u2019s subgraph and an edge from a corresponding Receive node to y in y\u2019s subgraph. See Figure 4 for an example of this graph transformation. At runtime, the implementations of the Send and Receive nodes coordinate to transfer data across devices. This allows us to isolate all communication inside Send and Receive implementations, which simplifies the rest of the runtime. NOTE: \u7531send node\u548creceive node\u6765\u5b9e\u73b0cross-device communication\u3002\u5728\u540c\u4e00\u4e2asubgraph\u5185\u7684\u6240\u6709node\u4e4b\u95f4\u7684tensor flow\u662f\u4e0d\u7ecf\u8fc7send node\u548creceive node\u7684\u3002\u8fd9\u5c31\u662f\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u6700\u540e\u4e00\u53e5: \"This allows us to isolate all communication inside Send and Receive implementations\"\u7684\u542b\u4e49\u3002 When we insert Send and Receive nodes, we canonicalize\uff08\u89c4\u8303\u5316\u8f6c\u6362\uff09 all users of a particular tensor on a particular device to use a single Receive node , rather than one Receive node per downstream user on a particular device. This ensures that the data for the needed tensor is only transmitted once between a source (device \u2192 destination device pair), and that memory for the tensor on the destination device is only allocated once, rather than multiple times (e.g., see nodes b and c in Figure 4) NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u8fd9\u6837\u6765\u8fdb\u884c\u7b80\u5355\u7406\u89e3: \u6bcf\u4e2asubgraph\u53ea\u6709\u4e00\u4e2areceive node\uff0c\u8fd9\u6837\u505a\u7684\u597d\u5904\u6709: 1) \u4e0d\u540c\u7684subgraph\u4e4b\u95f4\u53ea\u9700\u8981\u4e00\u6b21cross-device transfer 2) \u4e0b\u9762\u8fd9\u4e00\u6bb5\u63cf\u8ff0\u4e86\u53e6\u5916\u4e00\u4e2a\u597d\u5904\uff0c\u5b83\u7684\u5927\u81f4\u610f\u601d\u662f: \u8fd9\u6837\u7684\u8bbe\u8ba1\u80fd\u591f\u8ba9TensorFlow\u5c06\" scheduling of individual nodes of the graph on different devices\"(\u6838\u5fc3\u8bcd\u8bed\u662f**scheduling**)\u5206\u6563\u5230\u5404\u4e2aworker\uff0c\u5373\u800c\u4e0d\u662f\u7531master\u8d1f\u8d23\u5168\u90e8\u7684node\u7684\u8c03\u5ea6\uff0c\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u539f\u6587\u4e2d\u4f7f\u7528\u7684\u662f\"decentralized\"\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u539f\u6587\u5bf9\u5b83\u7684\u5177\u4f53\u89e3\u91ca\u662f: the Send and Receive nodes impart(\u4f20\u6388) the necessary synchronization between different workers and devices, and the master only needs to issue a single Run request per graph execution to each worker that has any nodes for the graph \u8fd9\u6837\u505a\u7684\u4f18\u52bf\u662f: \u76f8\u6bd4\u4e8e\u7531master\u8d1f\u8d23\u5168\u90e8\u7684node\u7684\u8c03\u5ea6\uff0c\u8fd9\u79cd\u505a\u6cd5\u80fd\u591f\u4f7f\u7cfb\u7edf\u66f4\u52a0scalable\u3001allows much finer-granularity node executions \u3002 By handling communication in this manner, we also allow the scheduling of individual nodes of the graph on different devices to be decentralized into the workers: the Send and Receive nodes impart(\u4f20\u6388) the necessary synchronization between different workers and devices, and the master only needs to issue a single Run request per graph execution to each worker that has any nodes for the graph, rather than being involved in the scheduling of every node or every cross-device communication. This makes the system much more scalable and allows much finer-granularity node executions than if the scheduling were forced to be done by the master. 3.3 Distributed Execution Distributed execution of a graph is very similar to multidevice execution. After device placement, a subgraph is created per device. Send/Receive node pairs that communicate across worker processes use remote communication mechanisms such as TCP or RDMA to move data across machine boundaries. NOTE: \u8fd9\u4e9bworkerprocess\u4f4d\u4e8e\u4e0d\u540c\u7684machine\uff0c\u6240\u4ee5\u9700\u8981\u901a\u8fc7network\u8fdb\u884ccommunicate\u3002 Fault Tolerance Failures in a distributed execution can be detected in a variety of places. The main ones we rely on are (a) an error in a communication between a Send and Receive node pair, and (b) periodic health-checks from the master process to every worker process. When a failure is detected, the entire graph execution is aborted and restarted from scratch. Recall however that Variable nodes refer to tensors that persist across executions of the graph. We support consistent checkpointing and recovery of this state on a restart. In partcular, each Variable node is connected to a Save node . These Save nodes are executed periodically, say once every N iterations, or once every N seconds. When they execute, the contents of the variables are written to persistent storage, e.g., a distributed file system. Similarly each Variable is connected to a Restore node that is only enabled in the first iteration after a restart. See Section 4.2 for details on how some nodes can only be enabled on some executions of the graph. NOTE: \u539f\u6587\u672c\u6bb5\u4e3b\u8981\u8ba8\u8bbaTensorFlow\u7684fault Tolerance\uff1b\u5176\u4e2d\u975e\u5e38\u91cd\u8981\u7684\u4e00\u70b9\u662fTensorFlow variable\u7684\u5b9e\u73b0\u3002Variable node\u7684\u7279\u6027\u662f: \u5728\u56fe\u7684\u6267\u884c\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e0d\u53d8\uff0c\u5373\u5b83\u662fstate\uff0c\u5728\u524d\u9762\u7684\u8bba\u8ff0\u4e2d\u5df2\u7ecf\u4f7f\u7528\u4e86state\u8fd9\u4e2a\u8bcd\u8bed\u3002\u663e\u7136\u4e3a\u4e86\u652f\u6301variable\u7684\u7279\u6027\uff0cTensorFlow\u9700\u8981\u8fdb\u884c\u7279\u6b8a\u7684\u5b9e\u73b0: 1) consistent checkpoint 2) recover \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u540e\u534a\u6bb5\u63cf\u8ff0\u4e86TensorFlow\u5185\u90e8\u5bf9variable\u7684\u5b9e\u73b0: \u6bcf\u4e2a**Variable node**\u88ab\u8fde\u63a5\u5230\u4e00\u4e2a**Save node**\u3002\u8fd9\u4e9b**Save node**\u88ab\u5468\u671f\u6027\u5730\u6267\u884c\u3002\u5f53\u5b83\u4eec\u6267\u884c\u65f6\uff0cvariable\u7684\u5185\u5bb9\u88ab\u5199\u5165\u6301\u4e45\u5b58\u50a8\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf\u3002 \u6bcf\u4e2a**Variable node**\u90fd\u8fde\u63a5\u5230\u4e00\u4e2a**Restore node** \uff0c\u8be5\u8282\u70b9\u4ec5\u5728\u91cd\u542f\u540e\u7684\u7b2c\u4e00\u6b21\u8fed\u4ee3\u4e2d\u542f\u7528\u3002 4 Extensions In this section we describe several more advanced features of the basic programming model that was introduced in Section 2. 4.1 Gradient Computation NOTE: \u5176\u5b9e\u5c31\u662f\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u3002\u5728deep learning book\u7684\"6.5.5 Symbol-to-Symbol Derivatives\"\u4e2d\uff0c\u5df2\u7ecf\u4ecb\u7ecd\u4e86TensorFlow Gradient Computation\u7684\u601d\u8def\u4e86\uff0cdeep learning book\u4e2d\u5c06\u8fd9\u79cd\u601d\u8def\u79f0\u4e3aSymbol-to-Symbol Derivatives: Another approach is to take a computational graph and add additional nodes to the graph that provide a symbolic description of the desired derivatives. This is the approach taken by Theano (Bergstra et al., 2010; Bastien et al., 2012) and TensorFlow (Abadi et al., 2015). An example of how this approach works is illustrated in figure 6.10. The primary advantage of this approach is that the derivatives are described in the same language as the original expression. Because the derivatives are just another computational graph, it is possible to run back-propagation again, differentiating the derivatives in order to obtain higher derivatives. Computation of higher-order derivatives is described in section 6.5.10. Many optimization algorithms, including common machine learning training algorithms like stochastic gradient descent [45], compute the gradient of a cost function with respect to a set of inputs. Because this is such a common need, TensorFlow has built-in support for automatic gradient computation . If a tensor C in a TensorFlow graph depends, perhaps through a complex subgraph of operations, on some set of tensors {X k } , then there is a built-in function that will return the tensors {dC/dX k } \uff08\u8fd9\u5c31\u662fgradient\uff09. Gradient tensors are computed, like other tensors, by extending the TensorFlow graph , using the following procedure. When TensorFlow needs to compute the gradient of a tensor C with respect to some tensor I on which C depends, it first finds the path in the computation graph from I to C . Then it backtracks from C to I , and for each operation on the backward path it adds a node to the TensorFlow graph, composing the partial gradients along the backwards path using the chain rule . The newly added node computes the \u201c gradient function \u201d for the corresponding operation in the forward path . NOTE: \u6bcf\u4e2aoperation\u5bf9\u5e94\u7684\u662f\u4e00\u4e2anode\u3001\u4e00\u4e2afunction\uff0c\u5b83\u7684\u6c42\u5bfc\u51fd\u6570\u662f\u5df2\u77e5\u7684\u3002TensorFlow\u65b0\u589e\u7684\u4e3a\u4e86\u8ba1\u7b97gradient\u7684node\u5b9e\u73b0\u4e86gradient function\u7684\u529f\u80fd\u3002 A gradient function may be registered by any operation. This function takes as input not only the partial gradients computed already along the backward path, but also, optionally, the inputs and outputs of the forward operation . Figure 5 shows gradients for a cost computed from the example of Figure 2. Grey arrows show potential inputs to gradient functions that are not used for the particular operations shown. The addition needed to Figure 1 to compute these gradients is: [ db , dW , dx ] = tf . gradients ( C , [ b , W , x ]) In general an operation may have multiple outputs, and C may only depend on some of them. If, for example, operation O has two outputs y1 and y2 , and C only depends on y2 , then the first input to O \u2019s gradient function is set to 0 since dC=dy1 = 0 . Automatic gradient computation complicates optimization, particularly of memory usage. When executing \u201cforward\u201d computation subgraphs, i.e., those that are explicitly constructed by the user, a sensible heuristic breaks ties when deciding which node to execute next by observing the order in which the graph was constructed. \u7ffb\u8bd1: \u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\u4f7f\u4f18\u5316\u590d\u6742\u5316\uff0c\u7279\u522b\u662f\u5185\u5b58\u7684\u4f7f\u7528\u3002\u5f53\u6267\u884c\u201c\u6b63\u5411\u201d\u8ba1\u7b97\u5b50\u56fe\u65f6\uff0c\u4e5f\u5c31\u662f\u90a3\u4e9b\u7531\u7528\u6237\u663e\u5f0f\u6784\u9020\u7684\u5b50\u56fe\u65f6\uff0c\u4e00\u4e2a\u5408\u7406\u7684\u542f\u53d1\u5f0f\u901a\u8fc7\u89c2\u5bdf\u56fe\u7684\u6784\u9020\u987a\u5e8f\u6765\u51b3\u5b9a\u63a5\u4e0b\u6765\u6267\u884c\u54ea\u4e2a\u8282\u70b9\u3002 \u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u91cd\u70b9\u662f\u7406\u89e3\"breaks ties\"\uff0c\u8bb0\u5f97\u4e4b\u524d\u9047\u5230\u8fc7\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u5b83\u7684\u610f\u601d\u662f: \u6253\u7834\u50f5\u5c40 NOTE: forward computation subgraph\u662f\u7531user\u663e\u5f0f\u6784\u9020\u7684\uff1bbackward computation subgraph\u662fTensorFlow\u9690\u5f0f\u6784\u9020\u7684\uff1b This generally means that temporary outputs are consumed soon after being constructed, so their memory can be reused quickly. When the heuristic is ineffective, the user can change the order of graph construction, or add control dependencies as described in Section 5. When gradient nodes are automatically added to the graph, the user has less control, and the heuristics may break down(\u53d1\u751f\u6545\u969c\u3001\u5931\u6548). In particular, because gradients reverse the forward computation order , tensors that are used early in a graph\u2019s execution are frequently needed again near the end of a gradient computation. Such tensors can hold on to a lot of scarce GPU memory and unnecessarily limit the size of computations. We are actively working on improvements to memory management to deal better with such cases. Options include using more sophisticated heuristics to determine the order of graph execution, recomputing tensors instead of retaining them in memory, and swapping out long-lived tensors from GPU memory to more plentiful host CPU memory. NOTE: \u8fd9\u6bb5\u8bdd\u4f5c\u8005\u6240\u63cf\u8ff0\u7684\u662f\u5728\u5b9e\u73b0\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u65f6\u6240\u9047\u5230\u7684\u96be\u9898\uff0c\u4f5c\u8005\u6240\u63cf\u8ff0\u7684\u96be\u9898\u4e3b\u8981\u662fGPU memory\uff0c\u4f5c\u8005\u7ed9\u51fa\u7684\u89e3\u51b3\u65b9\u6cd5\u662f: 1) using more sophisticated heuristics to determine the order of graph execution NOTE: algorithm\u4e2d\u7684heuristic\u7684\u8bbe\u8ba1\uff0c\u8c8c\u4f3c\u662f\u4e00\u4e2a\u6bd4\u8f83\u9ad8\u6df1\u7684\u5185\u5bb9 2) ecomputing tensors instead of retaining them in memory NOTE: \u56e0\u4e3aGPU memory\u662f\u4e3b\u8981\u77db\u76fe\uff0c\u800cGPU computation\u662f\u975e\u5e38\u5bb9\u6613\u7684\uff0c\u6240\u4ee5\u65e0\u9700cache\u3002\u8fd9\u548c\u6211\u4eec\u7684\u5bfb\u5e38\u8ba4\u77e5\u662f\u76f8\u53cd\u7684 3) swapping out long-lived tensors from GPU memory to more plentiful host CPU memory 4.2 Partial Execution Often a client wants to execute just a subgraph of the entire execution graph. To support this, once the client has set up a computation graph in a Session, our Run method allows them to execute an arbitrary subgraph of the whole graph, and to inject arbitrary data along any edge in the graph, and to retrieve data flowing along any edge in the graph. Output of a node Each node in the graph has a name, and each output of a node is identified by the source node name and the output port from the node, numbered from 0 (e.g., \u201c bar:0 \u201d refers to the 1 st output of the \u201c bar \u201d node, while \u201c bar:1 \u201d refers to the 2 nd output). NOTE: output port\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u4f7f\u7528\u7c7b\u6bd4\u7684\u601d\u60f3\u6765\u7406\u89e3port\u7684\u542b\u4e49\uff0c\u5728network\u4e2d\uff0cport\u6807\u8bc6\u4e00\u4e2aservice\uff0c\u5728TensorFlow\u4e2d\uff0c\u4e00\u4e2anode\u662f\u53ef\u4ee5\u6709\u591a\u4e2aoutput\u7684\uff0c\u6240\u4ee5\u9700\u8981\u6807\u8bc6\u6bcf\u4e2aoutput\uff0c\u8fd9\u5c31\u662fport\u7684\u7528\u9014\u3002 Run call Two arguments to the Run call help define the exact subgraph of the computation graph that will be executed. First, the Run call accepts inputs , an optional mapping of name:port names to \u201cfed\u201d tensors values. NOTE: \u4e3a\u4ec0\u4e48input\u4e2d\u9700\u8981\u6307\u5b9aport\uff1f Second, the Run call accepts output_names , a list of output name[:port] specifications indicating which nodes should be executed, and, if the port portion is present in a name, that that particular output tensor value for the node should be returned to the client if the Run call completes successfully. NOTE: \u663e\u7136\u5bf9\u4e8e Run \u800c\u8a00\uff0c\u6700\u6700\u91cd\u8981\u7684\u5c31\u662f\u6307\u5b9ainput\u548coutput Graph transformation The graph is transformed based on the values of inputs and outputs . Each node:port specified in inputs is replaced with a feed node , which will pick up the provided input tensor from specially-initialized entries in a Rendezvous object used for the Run call. Similarly, each output name with a port is connected to a special fetch node that arranges to save the output tensor and return it to the client when the Run call is complete. Finally, once the graph has been rewritten with the insertion of these special feed and fetch nodes, the set of nodes to execute can be determined by starting at each of the nodes named by any output and working backwards in the graph using the graph dependencies to determine the full set of nodes that must be executed in the rewritten graph in order to compute the outputs. Figure 6 shows an original graph on the left, and the transformed graph that results when Run is invoked with inputs==fbg and outputs==ff:0g . Since we only need to compute the output of node f , we will not execute nodes d and e , since they have no contribution to the output of f . 4.3 Device Constraints TensorFlow clients can control the placement of nodes on devices by providing partial constraints for a node about which devices it can execute on. For example, \u201conly place this node on a device of type GPU\u201d, or \u201cthis node can be placed on any device in /job:worker/task:17 \u201d, or \u201cColocate(\u5171\u7f6e\uff0c\u5373\u653e\u5230\u4e00\u8d77) this node with the node named variable13 \u201d. Within the confines of these constraints, the placement algorithm is responsible for choosing an assignment of nodes to devices that provides fast execution of the computation and also satisfies various constraints imposed by the devices themselves, such as limiting the total amount of memory needed on a device in order to execute its subset of graph nodes. Supporting such constraints requires changes to the placement algorithm described in Section 3.2.1. We first compute the feasible set of devices for each node, and then use union-find on the graph of colocation constraints to compute the graph components that must be placed together. For each such component, we compute the intersection of the feasible device sets. The computed feasible device set per node fits easily into the placement algorithm\u2019s simulator. NOTE: \u4e0a\u8ff0\u63cf\u8ff0\u7684\u7b97\u6cd5\u7684\u5185\u90e8\u5b9e\u73b0\u903b\u8f91\uff0c\u6bd4\u8f83\u590d\u6742 4.4 Control Flow NOTE: TensorFlow\u7684control flow operator\u5176\u5b9e\u548c\u5404\u79cd\u9ad8\u7ea7\u8bed\u8a00\u8bed\u8a00\u4e2d\u7684control statement\u672c\u8d28\u4e0a\u662f\u76f8\u540c\u7684\u3002TensorFlow\u652f\u6301\u5982\u4e0b\u7c7b\u578b\u7684control flow: 1) conditionals 2) loops Although dataflow graphs without any explicit control flow are quite expressive, we have observed a number of cases where supporting conditionals and loops can lead to more concise and efficient representations of machine learning algorithms. Much as in the dataflow-machine approach described by Arvind [3], we introduce a small set of primitive control flow operators into TensorFlow and generalize TensorFlow to handle cyclic dataflow graphs. The Switch and Merge operators allow us to skip the execution of an entire subgraph based on the value of a boolean tensor. The Enter , Leave , and NextIteration operators allow us to express iteration. High-level programming constructs such as if-conditionals and while-loops can be easily compiled into dataflow graphs with these control flow operators. Tags and frames The TensorFlow runtime implements a notion of tags and frames conceptually similar to the MIT Tagged- Token machine [4]. Each iteration of a loop is uniquely identified by a tag , and its execution state is represented by a frame . An input can enter an iteration whenever it becomes available; thus, multiple iterations can be executed concurrently. Distributed coordination mechanism TensorFlow uses a distributed coordination mechanism to execute graphs with control flow . In general, a loop can contain nodes that are assigned to many different devices. Therefore, managing the state of a loop becomes a problem of distributed termination detection . TensorFlow\u2019s solution is based on graph rewriting . During the graph partitioning, we automatically add control nodes to each partition . These nodes implement a small state machine that orchestrates(\u628a\u2026\u534f\u8c03\u5730\u7ed3\u5408\u8d77\u6765) the start and termination of each iteration, and decides the termination of the loop. For each iteration, the device that owns the loop termination predicate sends a tiny control message to every participating device. Control flow and backprog As explained above, we often train machine learning models by gradient descent , and represent gradient computations as part of dataflow graphs. When a model includes control-flow operations, we must account for them in the corresponding gradient computation. For example, the gradient computation for a model with an if-conditional will need to know which branch of the conditional was taken, then apply the gradient logic to this branch. Similarly, the gradient computation for a model with a while-loop will need to know how many iterations were taken, and will also rely on the intermediate values computed during those iterations. The basic technique is to rewrite the graph so to memorize the values needed for the gradient computation. We omit the somewhat intricate(\u590d\u6742\u7684) details of this encoding. 4.5 Input Operations Although input data can be provided to a computation via feed nodes, another common mechanism used for training large-scale machine learning models is to have special input operation nodes in the graph, which are typically configured with a set of filenames and which yield a tensor containing one or more examples from the data stored in that set of files each time they are executed. This allows data to be read directly from the underlying storage system into the memory of the machine that will perform subsequent processing on the data. In configurations where the client process is separate from the worker process, if the data were fed, it typically would require an extra network hop (from the storage system to the client and then from the client to the worker vs. directly from the storage system to ther worker when using an input node). NOTE: \u4e3b\u8981\u8ba8\u8bba\u7684\u662fbig data\u7684feed\u95ee\u9898\u3002 4.6 Queues Queues are a useful feature that we have added to TensorFlow. They allow different portions of the graph to execute asynchronously, possibly at different candences, and to hand off data through Enqueue and Dequeue operations. Enqueue operations can block until space becomes available in the queue, and Dequeue operations can block until a desired minimum number of elements are available in the queue. One use of queues is to allow input data to be prefetched from disk files while a previous batch of data is still being processed by the computational portion of a machine learning model. They can also be used for other kinds of grouping, including accumulating many gradients in order to compute some more complex combination of gradients over a larger batch, or to group different input sentences for recurrent language models into bins of sentences that are approximately the same length, which can then be processed more efficiently. In addition to normal FIFO queues, we have also implemented a shuffling queue, which randomly shuffles its elements within a large in-memory buffer. This shuffling functionality is useful for machine learning algorithms that want to randomize the order in which they process examples, for example. 4.7 Containers A Container is the mechanism within TensorFlow for managing longer-lived mutable state. The backing store for a Variable lives in a container . The default container is one that persists until the process terminates, but we also allow other named containers. A container can be reset by clearing it of its contents entirely. Using containers, it is possible to share state even across completely disjoint computation graphs associated with different Sessions. 5 Optimizations NOTE: \u8fd9\u4e00\u8282\u6240\u63cf\u8ff0\u7684TensorFlow\u5b9e\u73b0\u5c42\u9762\u7684\u4f18\u5316\uff0c\u4e0d\u662fmachine learning\u4e2d\u7684optimization\u3002 In this section, we describe some of the optimizations in the TensorFlow implementation that improve performance or resource usage of the system. 5.1 Common Subexpression Elimination NOTE: \u8fd9\u662fcompiler principle\u4e2d\u6700\u6700\u5e38\u7528\u7684\u4e00\u79cd\u624b\u6bb5 Since the construction of computation graphs is often done by many different layers of abstractions in the client code, computation graphs can easily end up with redundant copies of the same computation. To handle this, we have implemented a common subexpression pass similar to the algorithm described by Click [ 12 ] that runs over the computation graph and canonicalizes multiple copies of operations with identical inputs and operation types to just a single one of these nodes, and redirects graph edges appropriately to reflect this canonicalization\uff08\u6807\u51c6\u5316\uff09. 5.2 Controlling Data Communication and Memory Usage NOTE: \u672c\u6bb5\u6807\u9898\u5df2\u7ecf\u603b\u7ed3\u5f97\u975e\u5e38\u597d\u4e86: \u901a\u8fc7\u63a7\u5236data communication\u548cmemory usage\u6765\u5b9e\u73b0optimization\u3002 5.3 Asynchronous Kernels In addition to normal synchronous kernels that complete their execution at the end of the Compute method, our framework also supports non-blocking kernels . Such non-blocking kernels use a slightly different interface whereby the Compute method is passed a continuation that should be invoked when the kernel\u2019s execution is complete. This is an optimization for environments where having many active threads is relatively expensive in terms of memory usage or other resources, and allows us to avoid tying up an execution thread for unbounded periods of time while waiting for I/O or other events to occur. NOTE: \u6700\u540e\u4e00\u6bb5\u63cf\u8ff0\u4e86\u4f7f\u7528asynchronous kernel\u7684\u539f\u56e0\uff0c\u53ef\u4ee5\u8fd9\u6837\u7406\u89e3: \u4f7f\u7528non-blocking kernel\uff0c\u6211\u4eec\u53ef\u4ee5\u53ea\u4f7f\u7528\u4e00\u4e2athread\u6765\u5904\u7406\u5f88\u591a\u7684\u4e8b\u60c5\uff0c\u56e0\u4e3a\u5f53I/O\u672a\u5b8c\u6210\u7684\u65f6\u5019\u3001\u671f\u5f85\u7684event\u672a\u53d1\u751f\u7684\u65f6\u5019\uff0cthread\u662f\u53ef\u4ee5\u4e0d\u963b\u585e\u7684\uff0c\u53ef\u4ee5\u53bb\u505a\u5176\u4ed6\u7684\u4e8b\u60c5\uff1b\u8fd9\u79cd\u505a\u6cd5\u975e\u5e38\u7c7b\u4f3c\u4e8e epoll \u7b49IO multiplex\u3002 Examples of asynchronous kernels include the Receive kernel, and the Enqueue and Dequeue kernels (which might need to block if queue space is not available or if no data is available to be read, respectively). 5.4 Optimized Libraries for Kernel Implementations We often make use of pre-existing highly-optimized numerical libraries to implement kernels for some operations. For example, there are a number of optimized libraries for performing matrix multiplies on different devices including BLAS [15] and cuBLAS [39], or GPU libraries for convolutional kernels for deep neural nets such as cuda-convnet [28] and cuDNN [9]. Many of our kernel implementations are relatively thin wrappers around such optimized libraries. We make fairly extensive use of the open-source Eigen linear algebra library [25] for many of the kernel implementations in the system. As one part of the development of TensorFlow, our team (primarily Benoit Steiner) has extended the open source Eigen library with support for arbitrary dimensionality tensor operations. 5.5 Lossy Compression NOTE: \u542b\u4e49\u662f: \u6709\u635f\u538b\u7f29 Some machine learning algorithms, including those typically used for training neural networks, are tolerant of noise and reduced precision arithmetic. In a manner similar to the DistBelief system [14], we often use lossy compression of higher precision internal representations when sending data between devices (sometimes within the same machine but especially across machine boundaries). For example, we often insert special conversion nodes that convert 32-bit floating point representations into a 16-bit floating point representation (not the proposed IEEE 16-bit floating point standard, but rather just a 32-bit IEEE 794 float format, but with 16 bits less precision in the mantissa), and then convert back to a 32-bit representation on the other side of the communication channel (by just filling in zeroes for the lost portion of the mantissa, since that\u2019s less computationally expensive than doing the mathematically correct probabilistic rounding when doing this 32 -16 - 32-bit conversion). 6 Status and Experience The TensorFlow interface and a reference implementation have been open sourced under an Apache 2.0 license, and the system is available for download at www.tensorflow.org . The system includes detailed documentation, a number of tutorials, and a number of examples demonstrating how to use the system for a variety of different machine learning tasks. The examples include models for classifying hand-written digits from the MNIST dataset (the \u201chello world\u201d of machine learning algorithms) [32], classifying images from the CIFAR-10 dataset [30], doing language modeling using a recurrent LSTM [22] network, training word embedding vectors [35] and more. The system includes front-ends for specifying TensorFlow computations in Python and C++, and we expect other front-ends to be added over time in response to the desires of both internal Google users and the broader open-source community. 7 Common Programming Idioms TensorFlow\u2019s basic dataflow graph model can be used in a variety of ways for machine learning applications. One domain we care about is speeding up training of computationally intensive neural network models on large datasets. This section describes several techniques that we and others have developed in order to accomplish this, and illustrates how to use TensorFlow to realize these various approaches. The approaches in this subsection assume that the model is being trained using stochastic gradient descent (SGD) with relatively modest-sized mini-batches of 100 to 1000 examples. Data Parallel Training One simple technique for speeding up SGD is to parallelize the computation of the gradient for a mini-batch across mini-batch elements. For example, if we are using a mini-batch size of 1000 elements, we can use 10 replicas of the model to each compute the gradient for 100 elements, and then combine the gradients and apply updates to the parameters synchronously, in order to behave exactly as if we were running the sequential SGD algorithm with a batch size of 1000 elements. In this case, the TensorFlow graph simply has many replicas of the portion of the graph that does the bulk of the model computation, and a single client thread drives the entire training loop for this large graph. This is illustrated in the top portion of Figure 7. This approach can also be made asynchronous, where the TensorFlow graph has many replicas of the portion of the graph that does the bulk of the model computation, and each one of these replicas also applies the parameter updates to the model parameters asynchronously. In this configuration, there is one client thread for each of the graph replicas. This is illustrated in the bottom portion of Figure 7. This asynchronous approach was also described in [14]. Model Parallel Training Model parallel training, where different portions of the model computation are done on different computational devices simultaneously for the same batch of examples, is also easy to express in TensorFlow. Figure 8 shows an example of a recurrent, deep LSTM model used for sequence to sequence learning (see [47]), parallelized across three different devices. Concurrent Steps for Model Computation Pipelining Another common way to get better utilization for training deep neural networks is to pipeline the computation of the model within the same devices, by running a small number of concurrent steps within the same set of devices. This is shown in Figure 9. It is somewhat similar to asynchronous data parallelism, except that the parallelism occurs within the same device(s), rather than replicating the computation graph on different devices. This allows \u201cfilling in the gaps\u201d where computation of a single batch of examples might not be able to fully utilize the full parallelism on all devices at all times during a single step. 8 Performance 9 Tools This section describes some tools we have developed that sit alongside the core TensorFlow graph execution engine. 9.1 TensorBoard: Visualization of graph structures and summary statistics In order to help users understand the structure of their computation graphs and also to understand the overall behavior of machine learning models, we have built TensorBoard, a companion visualization tool for TensorFlow that is included in the open source release. Visualization of Computation Graphs Visualization of Summary Data 9.2 Performance Tracing 10 Future Work We have several different directions for future work. One extension to the basic programming model that we are considering is a function mechanism , whereby a user can specify an entire subgraph of a TensorFlow computation to be a reusable component. In the implementation we have designed, these functions can become reusable components even across different front-end languages for TensorFlow, so that a user could define a function using the Python front end, but then use that function as a basic building block from within the C++ frontend. We are hopeful that this cross-language reusability will bootstrap a vibrant community of machine learning researchers publishing not just whole examples of their research, but also small reusable components from their work that can be reused in other contexts. We also have a number of concrete directions to improve the performance of TensorFlow. One such direction is our initial work on a just-in-time compiler that can take a subgraph of a TensorFlow execution, perhaps with some runtime profiling information about the typical sizes and shapes of tensors, and can generate an optimized routine for this subgraph. This compiler will understand the semantics of perform a number of optimizations such as loop fusion, blocking and tiling for locality, specialization for particular shapes and sizes, etc. We also imagine that a significant area for future work will be in improving the placement and node scheduling algorithms used to decide where different nodes will execute, and when they should start executing. We have currently implemented a number of heuristics in these subsystems, and we\u2019d like to have the system instead learn to make good placement decisions (perhaps using a deep neural network, combined with a reinforcement learning objective function). 11 Related Work There are many other systems that are comparable in various ways with TensorFlow. Theano [7], Torch [13], Caffe [26], Chainer [49] and the Computational Network Toolkit [54] are a few systems designed primarily for the training of neural networks. Each of these systems maps the computation onto a single machine , unlike the distributed TensorFlow implementation . Like Theano and Chainer, TensorFlow supports symbolic differentiation , thus making it easier to define and work with gradient based optimization algorithms. Like Caffe, TensorFlow has a core written in C++, simplifying the deployment of trained models in a wide variety of production settings, including memory- and computation-constrained environments such as mobile devices. The TensorFlow system shares some design characteristics with its predecessor system, DistBelief [14], and with later systems with similar designs like Project Adam [10] and the Parameter Server project [33]. Like DistBelief and Project Adam, TensorFlow allows computations to be spread out across many computational devices across many machines, and allows users to specify machine learning models using relatively high-level descriptions. Unlike DistBelief and Project Adam, though, the general-purpose dataflow graph model in TensorFlow is more flexible and more amenable to expressing a wider variety of machine learning models and optimization algorithms. It also permits a significant simplification by allowing the expression of stateful parameter nodes as variables , and variable update operations that are just additional nodes in the graph; in contrast, DistBelief, Project Adam and the Parameter Server systems all have whole separate parameter server subsystems devoted to communicating and updating parameter values. 12 Conclusions We have described TensorFlow, a flexible data flowbased programming model, as well as single machine and distributed implementations of this programming model.","title":"whitepaper2015"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#tensorflow#large-scale#machine#learning#on#heterogeneous#distributed#systems","text":"","title":"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#abstract","text":"TensorFlow [1] is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. NOTE: tensorflow\u65e2\u5b9e\u73b0\u4e86interface\uff08front end\uff09\u4e5f\u5b9e\u73b0\u4e86computation engine\uff08back end\uff09\uff0c\u800c Keras \u5219\u4ec5\u4ec5\u63d0\u4f9binterface\uff0c\u800c\u5c06tensorflow\u7b49\u4f5c\u4e3aback end\u3002 A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous\uff08\u5f02\u6784\u7684\uff09 systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. NOTE: \u663e\u7136\uff0ctensorflow\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u62bd\u8c61\u5c42\uff0c\u901a\u8fc7\u8fd9\u4e2a\u62bd\u8c61\u5c42\uff0c\u6211\u4eec\u7684algorithm\u53ef\u4ee5\u8fd0\u884c\u5728heterogeneous system\u4e0a\u3002 The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. NOTE: machine learning\u7684\u5e7f\u6cdb\u5e94\u7528\u3002 This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org .","title":"Abstract"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#1#introduction","text":"Based on our experience with DistBelief and a more complete understanding of the desirable system properties and requirements for training and using neural networks, we have built TensorFlow, our second-generation system for the implementation and deployment of large-scale machine learning models. TensorFlow takes computations described using a dataflow-like model and maps them onto a wide variety of different hardware platforms, ranging from running inference on mobile device platforms such as Android and iOS to modest-sized training and inference systems using single machines containing one or many GPU cards to large-scale training systems running on hundreds of specialized machines with thousands of GPUs. NOTE: dataflow-like model\uff0c\u5176\u5b9e\u975e\u5e38\u7c7b\u4f3c\u4e8edataflow programming\u3002 Having a single system that can span such a broad range of platforms significantly simplifies the real-world use of machine learning system, as we have found that having separate systems for large-scale training and small-scale deployment leads to significant maintenance burdens and leaky abstractions(\u6cc4\u9732\u7684\u62bd\u8c61). NOTE: \u7edf\u4e00/abstraction\u7684\u4f18\u52bf TensorFlow computations are expressed as stateful dataflow graphs (described in more detail in Section 2), and we have focused on making the system both flexible enough for quickly experimenting with new models for research purposes and sufficiently high performance and robust for production training and deployment of machine learning models. For scaling neural network training to larger deployments, TensorFlow allows clients to easily express various kinds of parallelism through replication and parallel execution of a core model dataflow graph , with many different computational devices all collaborating to update a set of shared parameters or other state . Modest changes in the description of the computation allow a wide variety of different approaches to parallelism to be achieved and tried with low effort [14, 29, 42]. Some TensorFlow uses allow some flexibility in terms of the consistency of parameter updates, and we can easily express and take advantage of these relaxed synchronization requirements in some of our larger deployments. Compared to DistBelief, TensorFlow\u2019s programming model is more flexible, its performance is significantly better, and it supports training and using a broader range of models on a wider variety of heterogeneous hardware platforms NOTE: \u8fd9\u4e00\u6bb5\u4f5c\u8005\u6240\u8981\u8868\u8fbe\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u5982\u679c\u5c06tensorflow\u7684interface\u770b\u505a\u662f\u4e00\u95e8programming language\uff0c\u8fd9\u4e2aprogramming language\u662fflexible\u3001expressive\u7684\u3002\u4f7f\u7528\u5b83\uff0cclient\u80fd\u591f\u8f7b\u677e\u5730\u8868\u8ff0\u5404\u79cdparallelism\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0ctensorflow\u7684\u8bbe\u8ba1\u8005\u662f\u5c06\u5b83\u5b9a\u4f4d\u4e3a\u201cLarge-Scale Machine Learning on Heterogeneous Distributed Systems\u201d\uff0c\u6240\u4ee5\u5728\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\uff0c parallelism \u3001 consistency \u7b49**distributed computing**\u9886\u57df\u7684\u672f\u8bed\u662f\u4e0d\u8db3\u4e3a\u5947\u7684\u3002\u5173\u4e8e**distributed computing**\u6b64\uff0c\u53c2\u89c1\u5de5\u7a0bparallel computing\u3002 Although these applications have concentrated on machine learning and deep neural networks in particular, we expect that TensorFlow\u2019s abstractions will be useful in a variety of other domains, including other kinds of machine learning algorithms, and possibly other kinds of numerical computations . NOTE: tensorflow\u7684\u672c\u8d28\u662f\u4e00\u4e2anumerical computation framework\u3002 The rest of this paper describes TensorFlow in more detail. Section 2 describes the programming model and basic concepts of the TensorFlow interface. Section 3 describes both our single machine and distributed implementations . Section 4 describes several extensions to the basic programming model. Section 5 describes several optimizations to the basic implementations. Section 6 describes some of our experiences in using TensorFlow. Section 7 describes several programming idioms we have found helpful when using TensorFlow. Section 9 describes several auxiliary tools we have built around the core TensorFlow system. Sections 10 and 11 discuss future and related work, respectively. Section 12 offers concluding thoughts.","title":"1 Introduction"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#2#programming#model#and#basic#concepts","text":"A TensorFlow computation is described by a directed graph , which is composed of a set of nodes . The graph represents a dataflow computation , with extensions for allowing some kinds of nodes to maintain and update persistent state \uff08 tf.Variable \uff09 and for branching and looping control structures within the graph in a manner similar to Naiad [36] . Clients typically construct a computational graph using one of the supported front end languages ( C++ or Python). An example fragment to construct and then execute a TensorFlow graph using the Python front end is shown in Figure 1, and the resulting computation graph in Figure 2. NOTE: \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c TensorFlow\u7684computation model\u662f\u501f\u9274\u7684 Naiad \u3002 \u5728 import tensorflow as tf b = tf . Variable ( tf . zeros ([ 100 ])) # 100-d vector, init to zeroes W = tf . Variable ( tf . random_uniform ([ 784 , 100 ], - 1 , 1 )) # 784x100 matrix w/rnd vals x = tf . placeholder ( name = \"x\" ) # Placeholder for input relu = tf . nn . relu ( tf . matmul ( W , x ) + b ) # Relu(Wx+b) C = [ ... ] # Cost computed as a function # of Relu s = tf . Session () for step in xrange ( 0 , 10 ): input = ... construct 100 - D input array ... # Create 100-d vector for input result = s . run ( C , feed_dict = { x : input }) # Fetch cost, feeding x=input print step , result Figure 2: Corresponding computation graph for Figure 1 NOTE: \u6b63\u5982\u8fd9\u4e2a\u56fe\u7247\u4e2d\u6240\u5c55\u793a\u7684\uff0c b \u3001 W \u3001 X \u90fd\u662fnode\uff1b In a TensorFlow graph, each node has zero or more inputs and zero or more outputs, and represents the instantiation of an operation . Values that flow along normal edges in the graph (from outputs to inputs) are tensors , arbitrary dimensionality arrays where the underlying element type is specified or inferred at graph-construction time.","title":"2 Programming Model and Basic Concepts"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#control#dependencies#edge","text":"Special edges , called control dependencies , can also exist in the graph: no data flows along such edges, but they indicate that the source node for the control dependence must finish executing before the destination node for the control dependence starts executing. Since our model includes mutable state , control dependencies can be used directly by clients to enforce happens before relationships . Our implementation also sometimes inserts control dependencies to enforce orderings between otherwise independent operations as a way of, for example, controlling the peak memory usage. NOTE: \u4e0a\u9762\u5f15\u5165\u4e86\u975e\u5e38\u91cd\u8981\u7684\u6982\u5ff5\uff1a graph tensorflow graph node operation edge tensor\u3001 control dependencies \u5173\u4e8econtrol dependency\uff0c\u53c2\u89c1 TensorFlow\\API\\Python\\Building-Graphs\\tf.control_dependencies \u3002 \u4e3a\u4ec0\u4e48\u53ebcontrol dependencies? \u56e0\u4e3acomputation graph\u5176\u5b9e\u53ef\u4ee5\u770b\u505a\u662fdependency graph\uff0c\u5b83\u672c\u8eab\u63cf\u8ff0\u4e86dependency\u5173\u7cfb\uff0ccontrol dependencies edge\u7ed9\u4e88\u4e86user\u5bf9dependency \u7684\u66f4\u591a\u63a7\u5236\u3002","title":"Control dependencies edge"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#operations#and#kernels","text":"NOTE: \u672c\u8282\u63cf\u8ff0\u4e86operation\u548ckernel\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5176\u5b9e\u5b83\u4eec\u7684\u5173\u7cfb\u975e\u5e38\u7c7b\u4f3c\u4e8einterface and implementation: operation\u662finterface\uff0ckernel\u662fimplementation\u3002\u4e00\u4e2aoperation\u662f\u53ef\u4ee5\u6709\u591a\u4e2akernel\u7684\uff0c\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u5728haosdent Adding a New Op \u4e2d\u6709\u8bf4\u660e: Implement the Op in C++. This implementation is called a \"kernel\", and there can be multiple kernels for different architectures (e.g. CPUs, GPUs) or input / output types. \u663e\u7136\uff0cTensorFlow\u7684\u5b9e\u73b0\u4e5f\u662f\u9075\u5faaprogram to interface\u539f\u5219\uff0c\u8fd9\u6837\u7684\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u652f\u6301heterogeneous\uff08\u5f02\u6784\u7684\uff09 systems\u7684\u7279\u6027\u3002 \u5173\u4e8e\u5982\u4f55add a new op\uff0c\u53c2\u89c1 TensorFlow\\Guide\\Adding-a-New-Op \u3002 TensorFlow\u7684operation\u548ckernel\u91c7\u7528\u7684\u662fregistration mechanism\uff0c\u8fd9\u589e\u52a0\u4e86\u5b83\u7684\u53ef\u6269\u5c55\u6027\u3002 An operation has a name and represents an abstract computation (e.g., \u201cmatrix multiply\u201d, or \u201cadd\u201d). An operation can have attributes , and all attributes must be provided or inferred at graph-construction time in order to instantiate a node to perform the operation. One common use of attributes is to make operations polymorphic over different tensor element types (e.g., add of two tensors of type float versus add of two tensors of type int32). A kernel is a particular implementation of an operation that can be run on a particular type of device (e.g., CPU or GPU). A TensorFlow binary defines the sets of operations and kernels available via a registration mechanism, and this set can be extended by linking in additional operation and/or kernel definitions/registrations. Table 1 shows some of the kinds of operations built into the core TensorFlow library. Category Examples Element-wise mathematical operations Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal, ... Array operations Concat, Slice, Split, Constant, Rank, Shape, Shuffle, ... Matrix operations MatMul, MatrixInverse, MatrixDeterminant, ... Stateful operations Variable, Assign, AssignAdd, ... Neural-net building blocks SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool, ... Checkpointing operations Save, Restore Queue and synchronization operations Enqueue, Dequeue, MutexAcquire, MutexRelease, ... Control flow operations Merge, Switch, Enter, Leave, NextIteration Table 1: Example TensorFlow operation types NOTE: tensorflow\u662f\u4e00\u4e2adistributed system\uff0c\u6240\u4ee5\u5b83\u63d0\u4f9b\u4e86\u201dQueue and synchronization operations\u201c NOTE: \u8bad\u7ec3\u6570\u636e\u9700\u8981\u6d41\u7ecf\u6574\u4e2a\u7f51\u7edc\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u8bad\u7ec3\u6570\u636e\u6267\u884c\u4e00\u5b9a\u7684\u8fd0\u7b97\uff1b\u8bad\u7ec3\u6570\u636e\u53ef\u80fd\u4f1a\u548cweight\uff0cbias\u7b49\u8fdb\u884c\u8fd0\u7b97\uff0c\u663e\u7136weight\u548cbias\u7b49\u662f\u548c\u8bad\u7ec3\u6570\u636e\u4e0d\u540c\u7684\uff0c\u5b83\u4eec\u662f\u9700\u8981\u7531\u6a21\u578b\u6765\u8fdb\u884c\u5b66\u4e60\u7684\uff0c\u5728\u5177\u4f53\u7f16\u7801\u7684\u65f6\u5019\uff0c\u8bad\u7ec3\u6570\u636e\u5f80\u5f80\u4f7f\u7528 tf.placeholder \u6765\u8868\u793a\uff0c\u800cweight\u548cbias\u7b49\u5219\u662f\u4f7f\u7528 tf.Variable \u6765\u8868\u793a\uff1b\u7406\u89e3\u4e24\u8005\u6700\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u5b9e\u73b0\u4e00\u4e2aMLP\uff1b","title":"Operations and Kernels"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#sessions","text":"Clients programs interact with the TensorFlow system by creating a Session . To create a computation graph , the Session interface supports an Extend method to augment\uff08\u6269\u5c55\uff09 the current graph managed by the session with additional nodes and edges (the initial graph when a session is created is empty). The other primary operation supported by the session interface is Run , which takes a set of output names that need to be computed, as well as an optional set of tensors to be fed into the graph in place of certain outputs of nodes. Using the arguments to Run , the TensorFlow implementation can compute the transitive closure of all nodes that must be executed in order to compute the outputs that were requested, and can then arrange to execute the appropriate nodes in an order that respects their dependencies (as described in more detail in 3.1). Most of our uses of TensorFlow set up a Session with a graph once, and then execute the full graph or a few distinct subgraphs thousands or millions of times via Run calls. NOTE: tensorflow\u7684computation graph\u5176\u5b9e\u4e5f\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2adependency graph\uff0c\u663e\u7136\u6700\u7ec8\u7684\u8f93\u51fa\u8282\u70b9\u662f\u4f9d\u8d56\u4e8e\u6240\u6709\u6d41\u5411\u5b83\u7684\u8f93\u5165tensor\u7684\uff0c\u800c\u8fd9\u4e9btensor\u53c8\u8fdb\u4e00\u6b65\u4f9d\u8d56\u4e8e\u6d41\u5165\u5b83\u7684tensor\u7684\uff0c\u663e\u7136\u8fd9\u79cddependency\u5173\u7cfb\u662ftransitive\u7684\uff0c\u4e5f\u5c31\u662f\u4e3a\u4e86\u8ba1\u7b97\u51faoutput\uff0c\u9700\u8981\u8ba1\u7b97\u51fa\u6240\u6709\u7684transitive closure\u3002\u8fd9\u5c31\u662f\u5728graph theory\u4e2d\u603b\u7ed3\u7684dependency model\u3002\u5173\u4e8eTensorFlow core\u662f\u5982\u4f55\u6267\u884ccomputation graph\u7684\uff0c\u5728\u540e\u9762\u7684: 3.1 Single-Device Execution 3.2 Multi-Device Execution 3.3 Distributed Execution \u7b2c\u4e00\u6b21\u9605\u8bfb\u8fd9\u4e00\u6bb5\u7684\u65f6\u5019\uff0c\u6211\u60f3\u5230\u4e86\u5728\u300a compile principle \u300b 4.6 Introduction to LR Parsing: Simple LR # 5.2 Evaluation Orders for SDD's # NOTE: \u5173\u4e8eSessions\uff0c\u53c2\u89c1haosdent Running Graphs \u3002","title":"Sessions"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#variables","text":"In most computations a graph is executed multiple times. Most tensors do not survive past a single execution of the graph. However, a Variable is a special kind of operation that returns a handle to a persistent mutable tensor that survives across executions of a graph. Handles to these persistent mutable tensors can be passed to a handful of special operations, such as Assign and AssignAdd (equivalent to += ) that mutate the referenced tensor. For machine learning applications of TensorFlow, the parameters of the model are typically stored in tensors held in variables, and are updated as part of the Run of the training graph for the model.","title":"Variables"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#3#implementation","text":"","title":"3 Implementation"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#clientmaster#and#worker#process","text":"The main components in a TensorFlow system are the client , which uses the Session interface to communicate with the master , and one or more worker processes , with each worker process responsible for arbitrating\uff08\u4ef2\u88c1\uff09 access to one or more computational devices (such as CPU cores or GPU cards) and for executing graph nodes on those devices as instructed by the master. NOTE: client\u548cmaster\u8fdb\u884ccommunicate\uff0cmaster instruct(\u901a\u77e5\u3001\u6307\u6325) worker process\u5728computational device\u4e0a\u6267\u884cgraph nodes\u3002 \u5173\u4e8e\u5b83\u4eec\uff0c\u53c2\u89c1\u4e0b\u9762\u7684figure3\u3002 \u5173\u4e8eworker process\u548cdevice\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u53c2\u89c1\u4e0b\u9762\u7684device\u7ae0\u8282\u3002 We have both local and distributed implementations of the TensorFlow interface.","title":"Client\u3001master and worker process"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#local#implementation","text":"The local implementation is used when the client, the master, and the worker all run on a single machine in the context of a single operating system process (possibly with multiple devices, if for example, the machine has many GPU cards installed).","title":"Local implementation"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#distributed#implementation","text":"The distributed implementation shares most of the code with the local implementation, but extends it with support for an environment where the client, the master, and the workers can all be in different processes on different machines. In our distributed environment, these different tasks are containers in jobs managed by a cluster scheduling system [51]. These two different modes are illustrated in Figure 3. Most of the rest of this section discusses issues that are common to both implementations, while Section 3.3 discusses some issues that are particular to the distributed implementation.","title":"Distributed implementation"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#devices","text":"Devices are the computational heart of TensorFlow. Each worker is responsible for one or more devices, and each device has a device type , and a name . Device names are composed of pieces that identify the device\u2019s type , the device\u2019s index within the worker, and, in our distributed setting, an identification of the job and task of the worker (or localhost for the case where the devices are local to the process). Example device names are\" /job:localhost/device:cpu:0 \"or \" /job:worker/task:17/device:gpu:3 \". We have implementations of our Device interface for CPUs and GPUs, and new device implementations for other device types can be provided via a registration mechanism. Each device object is responsible for managing allocation and deallocation of device memory, and for arranging for the execution of any kernels that are requested by higher levels in the TensorFlow implementation.","title":"Devices"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#tensors","text":"A tensor in our implementation is a typed, multi-dimensional array. We support a variety of tensor element types, including signed and unsigned integers ranging in size from 8 bits to 64 bits, IEEE float and double types, a complex number type, and a string type (an arbitrary byte array). Backing store of the appropriate size is managed by an allocator that is specific to the device on which the tensor resides. Tensor backing store buffers are reference counted and are deallocated when no references remain.","title":"Tensors"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#31#single-device#execution","text":"Let\u2019s first consider the simplest execution scenario: a single worker process with a single device . The nodes of the graph are executed in an order that respects the dependencies between nodes. In particular, we keep track of a count per node of the number of dependencies of that node that have not yet been executed. Once this count drops to zero, the node is eligible(\u5408\u683c) for execution and is added to a ready queue . The ready queue is processed in some unspecified order, delegating execution of the kernel for a node to the device object. When a node has finished executing, the counts of all nodes that depend on the completed node are decremented. NOTE: \u4ece\u4e0a\u9762\u4e24\u6bb5\u63cf\u8ff0\u6765\uff0cTensorFlow\u7684execution\u7b97\u6cd5\u5982\u4e0b: 1) \u9996\u5148\u6839\u636edependency\u5173\u7cfb\u8fdb\u884c\u62d3\u6251\u6392\u5e8f\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u80fd\u591f\u5f97\u5230partial order\uff0c\u65e0\u6cd5\u5f97\u5230total order\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b58\u5728\u4e00\u4e9bnode\uff0c\u5b83\u4eec\u7684execution order\u662f\u65e0\u6cd5\u786e\u5b9a\u7684\u3002\u8fd9\u4e00\u6b65\u6240\u5f97\u5230\u7684\u53ea\u662f\u9759\u6001\u987a\u5e8f\uff0c\u771f\u5b9e\u7684\u6267\u884c\u987a\u5e8f\uff0c\u8fd8\u4f9d\u8d56\u4e8e\u5177\u4f53\u7684\u6267\u884c\u60c5\u51b5 2) \u6bcf\u4e2anode\u5b8c\u6210\u6267\u884c\u540e\uff0c\u5219\u5b83\u7684\u6240\u6709\u7684child nodes\u7684count\u90fd\u9700\u8981decrease 1\u3002\u4e00\u65e6\u4e00\u4e2anode\u7684dependency\u90fd\u6ee1\u8db3\u4e86\uff0c\u5219\u5b83\u5c31eligible for execution\u4e86\uff0c\u5c31\u5c06\u5b83\u653e\u5230ready queue\u4e2d\u3002","title":"3.1 Single-Device Execution"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#32#multi-device#execution","text":"Once a system has multiple devices, there are two main complications: 1) deciding which device to place the computation for each node in the graph 2) and then managing the required communication of data across device boundaries implied by these placement decisions. This subsection discusses these two issues.","title":"3.2 Multi-Device Execution"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#321#node#placement","text":"NOTE: TensorFlow\u4f7f\u7528place algorithm\u6765\u5b89\u6392node placement\uff0c\u8fd9\u4e2aalgorithm\u7684\u8f93\u5165\u6709: 1) cost model 2) nodes 3) feasible devices \u8f93\u51fa\u662f: \u5c06\u54ea\u4e9bnodes\u653e\u5230\u54ea\u4e2adevice\u4e0a\u8fdb\u884c\u6267\u884c\uff0c\u653e\u5230\u540c\u4e00\u4e2adevice\u7684nodes\u5f62\u6210\u4e86\u4e00\u4e2asubgraph\uff0c\u663e\u7136\u8fd9\u4e2a\u7ed3\u679c\u5c31\u662f\u5c06\u539fcomputation graph\u5206\u5272\u4e3a\u4e86\u4e00\u4e9b\u5217subgraph\u3002\u8fd9\u5c31\u5f15\u51fa\u4e86\u8fd9\u4e9bsubgraph\u4e4b\u95f4\u7684Cross-Device Communication\u95ee\u9898\uff0c\u8fd9\u5728\"3.2.2 Cross-Device Communication\"\u4e2d\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002 Given a computation graph, one of the main responsibilities of the TensorFlow implementation is to map the computation onto the set of available devices. A simplified version of this algorithm is presented here. See Section 4.3 for extensions supported by this algorithm. One input to the placement algorithm is a cost model , which contains estimates of the sizes (in bytes) of the input and output tensors for each graph node , along with estimates of the computation time required for each node when presented with its input tensors. This cost model is either statically estimated based on heuristics associated with different operation types , or is measured based on an actual set of placement decisions for earlier executions of the graph. NOTE: The placement algorithm first runs a simulated execution of the graph. The simulation is described below and ends up picking a device for each node in the graph using greedy heuristics . The node to device placement generated by this simulation is also used as the placement for the real execution. The placement algorithm starts with the sources of the computation graph , and simulates the activity on each device in the system as it progresses. For each node that is reached in this traversal, the set of feasible devices is considered (a device may not be feasible if the device does not provide a kernel that implements the particular operation). For nodes with multiple feasible devices, the placement algorithm uses a greedy heuristic that examines the effects on the completion time of the node of placing the node on each possible device. This heuristic takes into account the estimated or measured execution time of the operation on that kind of device from the cost model , and also includes the costs of any communication that would be introduced in order to transmit inputs to this node from other devices to the considered device. NOTE: \u601d\u8003\uff1asource of computation graph\u662fcomputation graph\u7684\u54ea\u4e00\u7aef\uff1f \u4e0a\u9762\u8fd9\u4e00\u6bb5\u6240\u63cf\u8ff0\u7684\u662f\u201cThe placement algorithm first runs a simulated execution of the graph\u201d\uff0c\u5373\u201csimulation \u201d The device where the node\u2019s operation would finish the soonest is selected as the device for that operation, and the placement process then continues onwards to make placement decisions for other nodes in the graph, including downstream nodes that are now ready for their own simulated execution. Section 4.3 describes some extensions that allow users to provide hints and partial constraints to guide the placement algorithm . The placement algorithm is an area of ongoing development within the system.","title":"3.2.1 Node Placement"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#322#cross-device#communication","text":"Once the node placement has been computed, the graph is partitioned into a set of subgraphs, one per device. Any cross-device edge from x to y is removed and replaced by an edge from x to a new Send node in x\u2019s subgraph and an edge from a corresponding Receive node to y in y\u2019s subgraph. See Figure 4 for an example of this graph transformation. At runtime, the implementations of the Send and Receive nodes coordinate to transfer data across devices. This allows us to isolate all communication inside Send and Receive implementations, which simplifies the rest of the runtime. NOTE: \u7531send node\u548creceive node\u6765\u5b9e\u73b0cross-device communication\u3002\u5728\u540c\u4e00\u4e2asubgraph\u5185\u7684\u6240\u6709node\u4e4b\u95f4\u7684tensor flow\u662f\u4e0d\u7ecf\u8fc7send node\u548creceive node\u7684\u3002\u8fd9\u5c31\u662f\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u6700\u540e\u4e00\u53e5: \"This allows us to isolate all communication inside Send and Receive implementations\"\u7684\u542b\u4e49\u3002 When we insert Send and Receive nodes, we canonicalize\uff08\u89c4\u8303\u5316\u8f6c\u6362\uff09 all users of a particular tensor on a particular device to use a single Receive node , rather than one Receive node per downstream user on a particular device. This ensures that the data for the needed tensor is only transmitted once between a source (device \u2192 destination device pair), and that memory for the tensor on the destination device is only allocated once, rather than multiple times (e.g., see nodes b and c in Figure 4) NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u8fd9\u6837\u6765\u8fdb\u884c\u7b80\u5355\u7406\u89e3: \u6bcf\u4e2asubgraph\u53ea\u6709\u4e00\u4e2areceive node\uff0c\u8fd9\u6837\u505a\u7684\u597d\u5904\u6709: 1) \u4e0d\u540c\u7684subgraph\u4e4b\u95f4\u53ea\u9700\u8981\u4e00\u6b21cross-device transfer 2) \u4e0b\u9762\u8fd9\u4e00\u6bb5\u63cf\u8ff0\u4e86\u53e6\u5916\u4e00\u4e2a\u597d\u5904\uff0c\u5b83\u7684\u5927\u81f4\u610f\u601d\u662f: \u8fd9\u6837\u7684\u8bbe\u8ba1\u80fd\u591f\u8ba9TensorFlow\u5c06\" scheduling of individual nodes of the graph on different devices\"(\u6838\u5fc3\u8bcd\u8bed\u662f**scheduling**)\u5206\u6563\u5230\u5404\u4e2aworker\uff0c\u5373\u800c\u4e0d\u662f\u7531master\u8d1f\u8d23\u5168\u90e8\u7684node\u7684\u8c03\u5ea6\uff0c\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u539f\u6587\u4e2d\u4f7f\u7528\u7684\u662f\"decentralized\"\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u539f\u6587\u5bf9\u5b83\u7684\u5177\u4f53\u89e3\u91ca\u662f: the Send and Receive nodes impart(\u4f20\u6388) the necessary synchronization between different workers and devices, and the master only needs to issue a single Run request per graph execution to each worker that has any nodes for the graph \u8fd9\u6837\u505a\u7684\u4f18\u52bf\u662f: \u76f8\u6bd4\u4e8e\u7531master\u8d1f\u8d23\u5168\u90e8\u7684node\u7684\u8c03\u5ea6\uff0c\u8fd9\u79cd\u505a\u6cd5\u80fd\u591f\u4f7f\u7cfb\u7edf\u66f4\u52a0scalable\u3001allows much finer-granularity node executions \u3002 By handling communication in this manner, we also allow the scheduling of individual nodes of the graph on different devices to be decentralized into the workers: the Send and Receive nodes impart(\u4f20\u6388) the necessary synchronization between different workers and devices, and the master only needs to issue a single Run request per graph execution to each worker that has any nodes for the graph, rather than being involved in the scheduling of every node or every cross-device communication. This makes the system much more scalable and allows much finer-granularity node executions than if the scheduling were forced to be done by the master.","title":"3.2.2 Cross-Device Communication"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#33#distributed#execution","text":"Distributed execution of a graph is very similar to multidevice execution. After device placement, a subgraph is created per device. Send/Receive node pairs that communicate across worker processes use remote communication mechanisms such as TCP or RDMA to move data across machine boundaries. NOTE: \u8fd9\u4e9bworkerprocess\u4f4d\u4e8e\u4e0d\u540c\u7684machine\uff0c\u6240\u4ee5\u9700\u8981\u901a\u8fc7network\u8fdb\u884ccommunicate\u3002","title":"3.3 Distributed Execution"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#fault#tolerance","text":"Failures in a distributed execution can be detected in a variety of places. The main ones we rely on are (a) an error in a communication between a Send and Receive node pair, and (b) periodic health-checks from the master process to every worker process. When a failure is detected, the entire graph execution is aborted and restarted from scratch. Recall however that Variable nodes refer to tensors that persist across executions of the graph. We support consistent checkpointing and recovery of this state on a restart. In partcular, each Variable node is connected to a Save node . These Save nodes are executed periodically, say once every N iterations, or once every N seconds. When they execute, the contents of the variables are written to persistent storage, e.g., a distributed file system. Similarly each Variable is connected to a Restore node that is only enabled in the first iteration after a restart. See Section 4.2 for details on how some nodes can only be enabled on some executions of the graph. NOTE: \u539f\u6587\u672c\u6bb5\u4e3b\u8981\u8ba8\u8bbaTensorFlow\u7684fault Tolerance\uff1b\u5176\u4e2d\u975e\u5e38\u91cd\u8981\u7684\u4e00\u70b9\u662fTensorFlow variable\u7684\u5b9e\u73b0\u3002Variable node\u7684\u7279\u6027\u662f: \u5728\u56fe\u7684\u6267\u884c\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e0d\u53d8\uff0c\u5373\u5b83\u662fstate\uff0c\u5728\u524d\u9762\u7684\u8bba\u8ff0\u4e2d\u5df2\u7ecf\u4f7f\u7528\u4e86state\u8fd9\u4e2a\u8bcd\u8bed\u3002\u663e\u7136\u4e3a\u4e86\u652f\u6301variable\u7684\u7279\u6027\uff0cTensorFlow\u9700\u8981\u8fdb\u884c\u7279\u6b8a\u7684\u5b9e\u73b0: 1) consistent checkpoint 2) recover \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u540e\u534a\u6bb5\u63cf\u8ff0\u4e86TensorFlow\u5185\u90e8\u5bf9variable\u7684\u5b9e\u73b0: \u6bcf\u4e2a**Variable node**\u88ab\u8fde\u63a5\u5230\u4e00\u4e2a**Save node**\u3002\u8fd9\u4e9b**Save node**\u88ab\u5468\u671f\u6027\u5730\u6267\u884c\u3002\u5f53\u5b83\u4eec\u6267\u884c\u65f6\uff0cvariable\u7684\u5185\u5bb9\u88ab\u5199\u5165\u6301\u4e45\u5b58\u50a8\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf\u3002 \u6bcf\u4e2a**Variable node**\u90fd\u8fde\u63a5\u5230\u4e00\u4e2a**Restore node** \uff0c\u8be5\u8282\u70b9\u4ec5\u5728\u91cd\u542f\u540e\u7684\u7b2c\u4e00\u6b21\u8fed\u4ee3\u4e2d\u542f\u7528\u3002","title":"Fault Tolerance"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#4#extensions","text":"In this section we describe several more advanced features of the basic programming model that was introduced in Section 2.","title":"4 Extensions"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#41#gradient#computation","text":"NOTE: \u5176\u5b9e\u5c31\u662f\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u3002\u5728deep learning book\u7684\"6.5.5 Symbol-to-Symbol Derivatives\"\u4e2d\uff0c\u5df2\u7ecf\u4ecb\u7ecd\u4e86TensorFlow Gradient Computation\u7684\u601d\u8def\u4e86\uff0cdeep learning book\u4e2d\u5c06\u8fd9\u79cd\u601d\u8def\u79f0\u4e3aSymbol-to-Symbol Derivatives: Another approach is to take a computational graph and add additional nodes to the graph that provide a symbolic description of the desired derivatives. This is the approach taken by Theano (Bergstra et al., 2010; Bastien et al., 2012) and TensorFlow (Abadi et al., 2015). An example of how this approach works is illustrated in figure 6.10. The primary advantage of this approach is that the derivatives are described in the same language as the original expression. Because the derivatives are just another computational graph, it is possible to run back-propagation again, differentiating the derivatives in order to obtain higher derivatives. Computation of higher-order derivatives is described in section 6.5.10. Many optimization algorithms, including common machine learning training algorithms like stochastic gradient descent [45], compute the gradient of a cost function with respect to a set of inputs. Because this is such a common need, TensorFlow has built-in support for automatic gradient computation . If a tensor C in a TensorFlow graph depends, perhaps through a complex subgraph of operations, on some set of tensors {X k } , then there is a built-in function that will return the tensors {dC/dX k } \uff08\u8fd9\u5c31\u662fgradient\uff09. Gradient tensors are computed, like other tensors, by extending the TensorFlow graph , using the following procedure. When TensorFlow needs to compute the gradient of a tensor C with respect to some tensor I on which C depends, it first finds the path in the computation graph from I to C . Then it backtracks from C to I , and for each operation on the backward path it adds a node to the TensorFlow graph, composing the partial gradients along the backwards path using the chain rule . The newly added node computes the \u201c gradient function \u201d for the corresponding operation in the forward path . NOTE: \u6bcf\u4e2aoperation\u5bf9\u5e94\u7684\u662f\u4e00\u4e2anode\u3001\u4e00\u4e2afunction\uff0c\u5b83\u7684\u6c42\u5bfc\u51fd\u6570\u662f\u5df2\u77e5\u7684\u3002TensorFlow\u65b0\u589e\u7684\u4e3a\u4e86\u8ba1\u7b97gradient\u7684node\u5b9e\u73b0\u4e86gradient function\u7684\u529f\u80fd\u3002 A gradient function may be registered by any operation. This function takes as input not only the partial gradients computed already along the backward path, but also, optionally, the inputs and outputs of the forward operation . Figure 5 shows gradients for a cost computed from the example of Figure 2. Grey arrows show potential inputs to gradient functions that are not used for the particular operations shown. The addition needed to Figure 1 to compute these gradients is: [ db , dW , dx ] = tf . gradients ( C , [ b , W , x ]) In general an operation may have multiple outputs, and C may only depend on some of them. If, for example, operation O has two outputs y1 and y2 , and C only depends on y2 , then the first input to O \u2019s gradient function is set to 0 since dC=dy1 = 0 . Automatic gradient computation complicates optimization, particularly of memory usage. When executing \u201cforward\u201d computation subgraphs, i.e., those that are explicitly constructed by the user, a sensible heuristic breaks ties when deciding which node to execute next by observing the order in which the graph was constructed. \u7ffb\u8bd1: \u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\u4f7f\u4f18\u5316\u590d\u6742\u5316\uff0c\u7279\u522b\u662f\u5185\u5b58\u7684\u4f7f\u7528\u3002\u5f53\u6267\u884c\u201c\u6b63\u5411\u201d\u8ba1\u7b97\u5b50\u56fe\u65f6\uff0c\u4e5f\u5c31\u662f\u90a3\u4e9b\u7531\u7528\u6237\u663e\u5f0f\u6784\u9020\u7684\u5b50\u56fe\u65f6\uff0c\u4e00\u4e2a\u5408\u7406\u7684\u542f\u53d1\u5f0f\u901a\u8fc7\u89c2\u5bdf\u56fe\u7684\u6784\u9020\u987a\u5e8f\u6765\u51b3\u5b9a\u63a5\u4e0b\u6765\u6267\u884c\u54ea\u4e2a\u8282\u70b9\u3002 \u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u91cd\u70b9\u662f\u7406\u89e3\"breaks ties\"\uff0c\u8bb0\u5f97\u4e4b\u524d\u9047\u5230\u8fc7\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u5b83\u7684\u610f\u601d\u662f: \u6253\u7834\u50f5\u5c40 NOTE: forward computation subgraph\u662f\u7531user\u663e\u5f0f\u6784\u9020\u7684\uff1bbackward computation subgraph\u662fTensorFlow\u9690\u5f0f\u6784\u9020\u7684\uff1b This generally means that temporary outputs are consumed soon after being constructed, so their memory can be reused quickly. When the heuristic is ineffective, the user can change the order of graph construction, or add control dependencies as described in Section 5. When gradient nodes are automatically added to the graph, the user has less control, and the heuristics may break down(\u53d1\u751f\u6545\u969c\u3001\u5931\u6548). In particular, because gradients reverse the forward computation order , tensors that are used early in a graph\u2019s execution are frequently needed again near the end of a gradient computation. Such tensors can hold on to a lot of scarce GPU memory and unnecessarily limit the size of computations. We are actively working on improvements to memory management to deal better with such cases. Options include using more sophisticated heuristics to determine the order of graph execution, recomputing tensors instead of retaining them in memory, and swapping out long-lived tensors from GPU memory to more plentiful host CPU memory. NOTE: \u8fd9\u6bb5\u8bdd\u4f5c\u8005\u6240\u63cf\u8ff0\u7684\u662f\u5728\u5b9e\u73b0\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u65f6\u6240\u9047\u5230\u7684\u96be\u9898\uff0c\u4f5c\u8005\u6240\u63cf\u8ff0\u7684\u96be\u9898\u4e3b\u8981\u662fGPU memory\uff0c\u4f5c\u8005\u7ed9\u51fa\u7684\u89e3\u51b3\u65b9\u6cd5\u662f: 1) using more sophisticated heuristics to determine the order of graph execution NOTE: algorithm\u4e2d\u7684heuristic\u7684\u8bbe\u8ba1\uff0c\u8c8c\u4f3c\u662f\u4e00\u4e2a\u6bd4\u8f83\u9ad8\u6df1\u7684\u5185\u5bb9 2) ecomputing tensors instead of retaining them in memory NOTE: \u56e0\u4e3aGPU memory\u662f\u4e3b\u8981\u77db\u76fe\uff0c\u800cGPU computation\u662f\u975e\u5e38\u5bb9\u6613\u7684\uff0c\u6240\u4ee5\u65e0\u9700cache\u3002\u8fd9\u548c\u6211\u4eec\u7684\u5bfb\u5e38\u8ba4\u77e5\u662f\u76f8\u53cd\u7684 3) swapping out long-lived tensors from GPU memory to more plentiful host CPU memory","title":"4.1 Gradient Computation"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#42#partial#execution","text":"Often a client wants to execute just a subgraph of the entire execution graph. To support this, once the client has set up a computation graph in a Session, our Run method allows them to execute an arbitrary subgraph of the whole graph, and to inject arbitrary data along any edge in the graph, and to retrieve data flowing along any edge in the graph.","title":"4.2 Partial Execution"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#output#of#a#node","text":"Each node in the graph has a name, and each output of a node is identified by the source node name and the output port from the node, numbered from 0 (e.g., \u201c bar:0 \u201d refers to the 1 st output of the \u201c bar \u201d node, while \u201c bar:1 \u201d refers to the 2 nd output). NOTE: output port\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u4f7f\u7528\u7c7b\u6bd4\u7684\u601d\u60f3\u6765\u7406\u89e3port\u7684\u542b\u4e49\uff0c\u5728network\u4e2d\uff0cport\u6807\u8bc6\u4e00\u4e2aservice\uff0c\u5728TensorFlow\u4e2d\uff0c\u4e00\u4e2anode\u662f\u53ef\u4ee5\u6709\u591a\u4e2aoutput\u7684\uff0c\u6240\u4ee5\u9700\u8981\u6807\u8bc6\u6bcf\u4e2aoutput\uff0c\u8fd9\u5c31\u662fport\u7684\u7528\u9014\u3002","title":"Output of a node"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#run#call","text":"Two arguments to the Run call help define the exact subgraph of the computation graph that will be executed. First, the Run call accepts inputs , an optional mapping of name:port names to \u201cfed\u201d tensors values. NOTE: \u4e3a\u4ec0\u4e48input\u4e2d\u9700\u8981\u6307\u5b9aport\uff1f Second, the Run call accepts output_names , a list of output name[:port] specifications indicating which nodes should be executed, and, if the port portion is present in a name, that that particular output tensor value for the node should be returned to the client if the Run call completes successfully. NOTE: \u663e\u7136\u5bf9\u4e8e Run \u800c\u8a00\uff0c\u6700\u6700\u91cd\u8981\u7684\u5c31\u662f\u6307\u5b9ainput\u548coutput","title":"Run call"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#graph#transformation","text":"The graph is transformed based on the values of inputs and outputs . Each node:port specified in inputs is replaced with a feed node , which will pick up the provided input tensor from specially-initialized entries in a Rendezvous object used for the Run call. Similarly, each output name with a port is connected to a special fetch node that arranges to save the output tensor and return it to the client when the Run call is complete. Finally, once the graph has been rewritten with the insertion of these special feed and fetch nodes, the set of nodes to execute can be determined by starting at each of the nodes named by any output and working backwards in the graph using the graph dependencies to determine the full set of nodes that must be executed in the rewritten graph in order to compute the outputs. Figure 6 shows an original graph on the left, and the transformed graph that results when Run is invoked with inputs==fbg and outputs==ff:0g . Since we only need to compute the output of node f , we will not execute nodes d and e , since they have no contribution to the output of f .","title":"Graph transformation"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#43#device#constraints","text":"TensorFlow clients can control the placement of nodes on devices by providing partial constraints for a node about which devices it can execute on. For example, \u201conly place this node on a device of type GPU\u201d, or \u201cthis node can be placed on any device in /job:worker/task:17 \u201d, or \u201cColocate(\u5171\u7f6e\uff0c\u5373\u653e\u5230\u4e00\u8d77) this node with the node named variable13 \u201d. Within the confines of these constraints, the placement algorithm is responsible for choosing an assignment of nodes to devices that provides fast execution of the computation and also satisfies various constraints imposed by the devices themselves, such as limiting the total amount of memory needed on a device in order to execute its subset of graph nodes. Supporting such constraints requires changes to the placement algorithm described in Section 3.2.1. We first compute the feasible set of devices for each node, and then use union-find on the graph of colocation constraints to compute the graph components that must be placed together. For each such component, we compute the intersection of the feasible device sets. The computed feasible device set per node fits easily into the placement algorithm\u2019s simulator. NOTE: \u4e0a\u8ff0\u63cf\u8ff0\u7684\u7b97\u6cd5\u7684\u5185\u90e8\u5b9e\u73b0\u903b\u8f91\uff0c\u6bd4\u8f83\u590d\u6742","title":"4.3 Device Constraints"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#44#control#flow","text":"NOTE: TensorFlow\u7684control flow operator\u5176\u5b9e\u548c\u5404\u79cd\u9ad8\u7ea7\u8bed\u8a00\u8bed\u8a00\u4e2d\u7684control statement\u672c\u8d28\u4e0a\u662f\u76f8\u540c\u7684\u3002TensorFlow\u652f\u6301\u5982\u4e0b\u7c7b\u578b\u7684control flow: 1) conditionals 2) loops Although dataflow graphs without any explicit control flow are quite expressive, we have observed a number of cases where supporting conditionals and loops can lead to more concise and efficient representations of machine learning algorithms. Much as in the dataflow-machine approach described by Arvind [3], we introduce a small set of primitive control flow operators into TensorFlow and generalize TensorFlow to handle cyclic dataflow graphs. The Switch and Merge operators allow us to skip the execution of an entire subgraph based on the value of a boolean tensor. The Enter , Leave , and NextIteration operators allow us to express iteration. High-level programming constructs such as if-conditionals and while-loops can be easily compiled into dataflow graphs with these control flow operators.","title":"4.4 Control Flow"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#tags#and#frames","text":"The TensorFlow runtime implements a notion of tags and frames conceptually similar to the MIT Tagged- Token machine [4]. Each iteration of a loop is uniquely identified by a tag , and its execution state is represented by a frame . An input can enter an iteration whenever it becomes available; thus, multiple iterations can be executed concurrently.","title":"Tags and frames"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#distributed#coordination#mechanism","text":"TensorFlow uses a distributed coordination mechanism to execute graphs with control flow . In general, a loop can contain nodes that are assigned to many different devices. Therefore, managing the state of a loop becomes a problem of distributed termination detection . TensorFlow\u2019s solution is based on graph rewriting . During the graph partitioning, we automatically add control nodes to each partition . These nodes implement a small state machine that orchestrates(\u628a\u2026\u534f\u8c03\u5730\u7ed3\u5408\u8d77\u6765) the start and termination of each iteration, and decides the termination of the loop. For each iteration, the device that owns the loop termination predicate sends a tiny control message to every participating device.","title":"Distributed coordination mechanism"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#control#flow#and#backprog","text":"As explained above, we often train machine learning models by gradient descent , and represent gradient computations as part of dataflow graphs. When a model includes control-flow operations, we must account for them in the corresponding gradient computation. For example, the gradient computation for a model with an if-conditional will need to know which branch of the conditional was taken, then apply the gradient logic to this branch. Similarly, the gradient computation for a model with a while-loop will need to know how many iterations were taken, and will also rely on the intermediate values computed during those iterations. The basic technique is to rewrite the graph so to memorize the values needed for the gradient computation. We omit the somewhat intricate(\u590d\u6742\u7684) details of this encoding.","title":"Control flow and backprog"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#45#input#operations","text":"Although input data can be provided to a computation via feed nodes, another common mechanism used for training large-scale machine learning models is to have special input operation nodes in the graph, which are typically configured with a set of filenames and which yield a tensor containing one or more examples from the data stored in that set of files each time they are executed. This allows data to be read directly from the underlying storage system into the memory of the machine that will perform subsequent processing on the data. In configurations where the client process is separate from the worker process, if the data were fed, it typically would require an extra network hop (from the storage system to the client and then from the client to the worker vs. directly from the storage system to ther worker when using an input node). NOTE: \u4e3b\u8981\u8ba8\u8bba\u7684\u662fbig data\u7684feed\u95ee\u9898\u3002","title":"4.5 Input Operations"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#46#queues","text":"Queues are a useful feature that we have added to TensorFlow. They allow different portions of the graph to execute asynchronously, possibly at different candences, and to hand off data through Enqueue and Dequeue operations. Enqueue operations can block until space becomes available in the queue, and Dequeue operations can block until a desired minimum number of elements are available in the queue. One use of queues is to allow input data to be prefetched from disk files while a previous batch of data is still being processed by the computational portion of a machine learning model. They can also be used for other kinds of grouping, including accumulating many gradients in order to compute some more complex combination of gradients over a larger batch, or to group different input sentences for recurrent language models into bins of sentences that are approximately the same length, which can then be processed more efficiently. In addition to normal FIFO queues, we have also implemented a shuffling queue, which randomly shuffles its elements within a large in-memory buffer. This shuffling functionality is useful for machine learning algorithms that want to randomize the order in which they process examples, for example.","title":"4.6 Queues"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#47#containers","text":"A Container is the mechanism within TensorFlow for managing longer-lived mutable state. The backing store for a Variable lives in a container . The default container is one that persists until the process terminates, but we also allow other named containers. A container can be reset by clearing it of its contents entirely. Using containers, it is possible to share state even across completely disjoint computation graphs associated with different Sessions.","title":"4.7 Containers"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#5#optimizations","text":"NOTE: \u8fd9\u4e00\u8282\u6240\u63cf\u8ff0\u7684TensorFlow\u5b9e\u73b0\u5c42\u9762\u7684\u4f18\u5316\uff0c\u4e0d\u662fmachine learning\u4e2d\u7684optimization\u3002 In this section, we describe some of the optimizations in the TensorFlow implementation that improve performance or resource usage of the system.","title":"5 Optimizations"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#51#common#subexpression#elimination","text":"NOTE: \u8fd9\u662fcompiler principle\u4e2d\u6700\u6700\u5e38\u7528\u7684\u4e00\u79cd\u624b\u6bb5 Since the construction of computation graphs is often done by many different layers of abstractions in the client code, computation graphs can easily end up with redundant copies of the same computation. To handle this, we have implemented a common subexpression pass similar to the algorithm described by Click [ 12 ] that runs over the computation graph and canonicalizes multiple copies of operations with identical inputs and operation types to just a single one of these nodes, and redirects graph edges appropriately to reflect this canonicalization\uff08\u6807\u51c6\u5316\uff09.","title":"5.1 Common Subexpression Elimination"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#52#controlling#data#communication#and#memory#usage","text":"NOTE: \u672c\u6bb5\u6807\u9898\u5df2\u7ecf\u603b\u7ed3\u5f97\u975e\u5e38\u597d\u4e86: \u901a\u8fc7\u63a7\u5236data communication\u548cmemory usage\u6765\u5b9e\u73b0optimization\u3002","title":"5.2 Controlling Data Communication and Memory Usage"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#53#asynchronous#kernels","text":"In addition to normal synchronous kernels that complete their execution at the end of the Compute method, our framework also supports non-blocking kernels . Such non-blocking kernels use a slightly different interface whereby the Compute method is passed a continuation that should be invoked when the kernel\u2019s execution is complete. This is an optimization for environments where having many active threads is relatively expensive in terms of memory usage or other resources, and allows us to avoid tying up an execution thread for unbounded periods of time while waiting for I/O or other events to occur. NOTE: \u6700\u540e\u4e00\u6bb5\u63cf\u8ff0\u4e86\u4f7f\u7528asynchronous kernel\u7684\u539f\u56e0\uff0c\u53ef\u4ee5\u8fd9\u6837\u7406\u89e3: \u4f7f\u7528non-blocking kernel\uff0c\u6211\u4eec\u53ef\u4ee5\u53ea\u4f7f\u7528\u4e00\u4e2athread\u6765\u5904\u7406\u5f88\u591a\u7684\u4e8b\u60c5\uff0c\u56e0\u4e3a\u5f53I/O\u672a\u5b8c\u6210\u7684\u65f6\u5019\u3001\u671f\u5f85\u7684event\u672a\u53d1\u751f\u7684\u65f6\u5019\uff0cthread\u662f\u53ef\u4ee5\u4e0d\u963b\u585e\u7684\uff0c\u53ef\u4ee5\u53bb\u505a\u5176\u4ed6\u7684\u4e8b\u60c5\uff1b\u8fd9\u79cd\u505a\u6cd5\u975e\u5e38\u7c7b\u4f3c\u4e8e epoll \u7b49IO multiplex\u3002 Examples of asynchronous kernels include the Receive kernel, and the Enqueue and Dequeue kernels (which might need to block if queue space is not available or if no data is available to be read, respectively).","title":"5.3 Asynchronous Kernels"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#54#optimized#libraries#for#kernel#implementations","text":"We often make use of pre-existing highly-optimized numerical libraries to implement kernels for some operations. For example, there are a number of optimized libraries for performing matrix multiplies on different devices including BLAS [15] and cuBLAS [39], or GPU libraries for convolutional kernels for deep neural nets such as cuda-convnet [28] and cuDNN [9]. Many of our kernel implementations are relatively thin wrappers around such optimized libraries. We make fairly extensive use of the open-source Eigen linear algebra library [25] for many of the kernel implementations in the system. As one part of the development of TensorFlow, our team (primarily Benoit Steiner) has extended the open source Eigen library with support for arbitrary dimensionality tensor operations.","title":"5.4 Optimized Libraries for Kernel Implementations"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#55#lossy#compression","text":"NOTE: \u542b\u4e49\u662f: \u6709\u635f\u538b\u7f29 Some machine learning algorithms, including those typically used for training neural networks, are tolerant of noise and reduced precision arithmetic. In a manner similar to the DistBelief system [14], we often use lossy compression of higher precision internal representations when sending data between devices (sometimes within the same machine but especially across machine boundaries). For example, we often insert special conversion nodes that convert 32-bit floating point representations into a 16-bit floating point representation (not the proposed IEEE 16-bit floating point standard, but rather just a 32-bit IEEE 794 float format, but with 16 bits less precision in the mantissa), and then convert back to a 32-bit representation on the other side of the communication channel (by just filling in zeroes for the lost portion of the mantissa, since that\u2019s less computationally expensive than doing the mathematically correct probabilistic rounding when doing this 32 -16 - 32-bit conversion).","title":"5.5 Lossy Compression"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#6#status#and#experience","text":"The TensorFlow interface and a reference implementation have been open sourced under an Apache 2.0 license, and the system is available for download at www.tensorflow.org . The system includes detailed documentation, a number of tutorials, and a number of examples demonstrating how to use the system for a variety of different machine learning tasks. The examples include models for classifying hand-written digits from the MNIST dataset (the \u201chello world\u201d of machine learning algorithms) [32], classifying images from the CIFAR-10 dataset [30], doing language modeling using a recurrent LSTM [22] network, training word embedding vectors [35] and more. The system includes front-ends for specifying TensorFlow computations in Python and C++, and we expect other front-ends to be added over time in response to the desires of both internal Google users and the broader open-source community.","title":"6 Status and Experience"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#7#common#programming#idioms","text":"TensorFlow\u2019s basic dataflow graph model can be used in a variety of ways for machine learning applications. One domain we care about is speeding up training of computationally intensive neural network models on large datasets. This section describes several techniques that we and others have developed in order to accomplish this, and illustrates how to use TensorFlow to realize these various approaches. The approaches in this subsection assume that the model is being trained using stochastic gradient descent (SGD) with relatively modest-sized mini-batches of 100 to 1000 examples.","title":"7 Common Programming Idioms"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#data#parallel#training","text":"One simple technique for speeding up SGD is to parallelize the computation of the gradient for a mini-batch across mini-batch elements. For example, if we are using a mini-batch size of 1000 elements, we can use 10 replicas of the model to each compute the gradient for 100 elements, and then combine the gradients and apply updates to the parameters synchronously, in order to behave exactly as if we were running the sequential SGD algorithm with a batch size of 1000 elements. In this case, the TensorFlow graph simply has many replicas of the portion of the graph that does the bulk of the model computation, and a single client thread drives the entire training loop for this large graph. This is illustrated in the top portion of Figure 7. This approach can also be made asynchronous, where the TensorFlow graph has many replicas of the portion of the graph that does the bulk of the model computation, and each one of these replicas also applies the parameter updates to the model parameters asynchronously. In this configuration, there is one client thread for each of the graph replicas. This is illustrated in the bottom portion of Figure 7. This asynchronous approach was also described in [14].","title":"Data Parallel Training"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#model#parallel#training","text":"Model parallel training, where different portions of the model computation are done on different computational devices simultaneously for the same batch of examples, is also easy to express in TensorFlow. Figure 8 shows an example of a recurrent, deep LSTM model used for sequence to sequence learning (see [47]), parallelized across three different devices.","title":"Model Parallel Training"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#concurrent#steps#for#model#computation#pipelining","text":"Another common way to get better utilization for training deep neural networks is to pipeline the computation of the model within the same devices, by running a small number of concurrent steps within the same set of devices. This is shown in Figure 9. It is somewhat similar to asynchronous data parallelism, except that the parallelism occurs within the same device(s), rather than replicating the computation graph on different devices. This allows \u201cfilling in the gaps\u201d where computation of a single batch of examples might not be able to fully utilize the full parallelism on all devices at all times during a single step.","title":"Concurrent Steps for Model Computation Pipelining"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#8#performance","text":"","title":"8 Performance"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#9#tools","text":"This section describes some tools we have developed that sit alongside the core TensorFlow graph execution engine.","title":"9 Tools"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#91#tensorboard#visualization#of#graph#structures#and#summary#statistics","text":"In order to help users understand the structure of their computation graphs and also to understand the overall behavior of machine learning models, we have built TensorBoard, a companion visualization tool for TensorFlow that is included in the open source release.","title":"9.1 TensorBoard: Visualization of graph structures and summary statistics"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#visualization#of#computation#graphs","text":"","title":"Visualization of Computation Graphs"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#visualization#of#summary#data","text":"","title":"Visualization of Summary Data"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#92#performance#tracing","text":"","title":"9.2 Performance Tracing"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#10#future#work","text":"We have several different directions for future work. One extension to the basic programming model that we are considering is a function mechanism , whereby a user can specify an entire subgraph of a TensorFlow computation to be a reusable component. In the implementation we have designed, these functions can become reusable components even across different front-end languages for TensorFlow, so that a user could define a function using the Python front end, but then use that function as a basic building block from within the C++ frontend. We are hopeful that this cross-language reusability will bootstrap a vibrant community of machine learning researchers publishing not just whole examples of their research, but also small reusable components from their work that can be reused in other contexts. We also have a number of concrete directions to improve the performance of TensorFlow. One such direction is our initial work on a just-in-time compiler that can take a subgraph of a TensorFlow execution, perhaps with some runtime profiling information about the typical sizes and shapes of tensors, and can generate an optimized routine for this subgraph. This compiler will understand the semantics of perform a number of optimizations such as loop fusion, blocking and tiling for locality, specialization for particular shapes and sizes, etc. We also imagine that a significant area for future work will be in improving the placement and node scheduling algorithms used to decide where different nodes will execute, and when they should start executing. We have currently implemented a number of heuristics in these subsystems, and we\u2019d like to have the system instead learn to make good placement decisions (perhaps using a deep neural network, combined with a reinforcement learning objective function).","title":"10 Future Work"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#11#related#work","text":"There are many other systems that are comparable in various ways with TensorFlow. Theano [7], Torch [13], Caffe [26], Chainer [49] and the Computational Network Toolkit [54] are a few systems designed primarily for the training of neural networks. Each of these systems maps the computation onto a single machine , unlike the distributed TensorFlow implementation . Like Theano and Chainer, TensorFlow supports symbolic differentiation , thus making it easier to define and work with gradient based optimization algorithms. Like Caffe, TensorFlow has a core written in C++, simplifying the deployment of trained models in a wide variety of production settings, including memory- and computation-constrained environments such as mobile devices. The TensorFlow system shares some design characteristics with its predecessor system, DistBelief [14], and with later systems with similar designs like Project Adam [10] and the Parameter Server project [33]. Like DistBelief and Project Adam, TensorFlow allows computations to be spread out across many computational devices across many machines, and allows users to specify machine learning models using relatively high-level descriptions. Unlike DistBelief and Project Adam, though, the general-purpose dataflow graph model in TensorFlow is more flexible and more amenable to expressing a wider variety of machine learning models and optimization algorithms. It also permits a significant simplification by allowing the expression of stateful parameter nodes as variables , and variable update operations that are just additional nodes in the graph; in contrast, DistBelief, Project Adam and the Parameter Server systems all have whole separate parameter server subsystems devoted to communicating and updating parameter values.","title":"11 Related Work"},{"location":"Programming/TensorFlow/Implementation/TensorFlow-white-paper/whitepaper2015/#12#conclusions","text":"We have described TensorFlow, a flexible data flowbased programming model, as well as single machine and distributed implementations of this programming model.","title":"12 Conclusions"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u57fa\u4e8e github \u56fe\u89e3tensorflow \u6e90\u7801 \u6765\u63a2\u7d22TensorFlow source code\u3002 \u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u4e5f\u5305\u542b\u8fd9\u4e2a\u4e3b\u9898: https://www.leiphone.com/news/201702/n0uj58iHaNpW9RJG.html?viewType=weixin","title":"Introduction"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/#_1","text":"\u672c\u7ae0\u57fa\u4e8e github \u56fe\u89e3tensorflow \u6e90\u7801 \u6765\u63a2\u7d22TensorFlow source code\u3002 \u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u4e5f\u5305\u542b\u8fd9\u4e2a\u4e3b\u9898: https://www.leiphone.com/news/201702/n0uj58iHaNpW9RJG.html?viewType=weixin","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","text":"\u4ece\u7cfb\u7edf\u548c\u4ee3\u7801\u5b9e\u73b0\u89d2\u5ea6\u89e3\u6790TensorFlow\u7684\u5185\u90e8\u5b9e\u73b0\u539f\u7406 1. TF\u7cfb\u7edf\u67b6\u6784 1.1 TF\u4f9d\u8d56\u89c6\u56fe TF\u7684\u4f9d\u8d56\u89c6\u56fe\u5982\u56fe1\u6240\u793a[4]\uff0c\u63cf\u8ff0\u4e86TF\u7684\u4e0a\u4e0b\u6e38\u5173\u7cfb\u94fe\u3002 \u56fe 1 TensorFlow\u4f9d\u8d56\u89c6\u56fe TF\u6258\u7ba1\u5728github\u5e73\u53f0\uff0c\u6709google groups\u548ccontributors\u5171\u540c\u7ef4\u62a4\u3002 TF\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684API\uff0c\u652f\u6301Python\u548cC/C++\u63a5\u53e3\u3002 TF\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177Tensorboard\uff0c\u65b9\u4fbf\u5206\u6790\u548c\u8c03\u6574\u6a21\u578b\u3002 TF\u652f\u6301Linux\u5e73\u53f0\uff0cWindows\u5e73\u53f0\uff0cMac\u5e73\u53f0\uff0c\u751a\u81f3\u624b\u673a\u79fb\u52a8\u8bbe\u5907\u7b49\u5404\u79cd\u5e73\u53f0\u3002 1.2 TF\u7cfb\u7edf\u67b6\u6784 \u56fe2\u662fTF\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u4ece\u5e95\u5411\u4e0a\u5206\u4e3a\u8bbe\u5907\u7ba1\u7406\u548c\u901a\u4fe1\u5c42\u3001\u6570\u636e\u64cd\u4f5c\u5c42\u3001\u56fe\u8ba1\u7b97\u5c42\u3001API\u63a5\u53e3\u5c42\u3001\u5e94\u7528\u5c42\u3002\u5176\u4e2d\u8bbe\u5907\u7ba1\u7406\u548c\u901a\u4fe1\u5c42\u3001\u6570\u636e\u64cd\u4f5c\u5c42\u3001\u56fe\u8ba1\u7b97\u5c42\u662fTF\u7684\u6838\u5fc3\u5c42\u3002 \u56fe2 TF\u7cfb\u7edf\u67b6\u6784 \u5e95\u5c42\u8bbe\u5907\u901a\u4fe1\u5c42**\u8d1f\u8d23**\u7f51\u7edc\u901a\u4fe1**\u548c**\u8bbe\u5907\u7ba1\u7406 \u3002\u8bbe\u5907\u7ba1\u7406\u53ef\u4ee5\u5b9e\u73b0TF\u8bbe\u5907\u5f02\u6784\u7684\u7279\u6027\uff0c\u652f\u6301CPU\u3001GPU\u3001Mobile\u7b49\u4e0d\u540c\u8bbe\u5907\u3002**\u7f51\u7edc\u901a\u4fe1**\u4f9d\u8d56**gRPC\u901a\u4fe1\u534f\u8bae**\u5b9e\u73b0\u4e0d\u540c\u8bbe\u5907\u95f4\u7684\u6570\u636e\u4f20\u8f93\u548c\u66f4\u65b0\u3002 \u7b2c\u4e8c\u5c42\u662fTensor\u7684**OpKernels**\u5b9e\u73b0\u3002\u8fd9\u4e9b**OpKernels**\u4ee5**Tensor**\u4e3a\u5904\u7406\u5bf9\u8c61\uff0c\u4f9d\u8d56**\u7f51\u7edc\u901a\u4fe1**\u548c**\u8bbe\u5907\u5185\u5b58\u5206\u914d**\uff0c\u5b9e\u73b0\u4e86\u5404\u79cd**Tensor**\u64cd\u4f5c\u6216\u8ba1\u7b97\u3002Opkernels\u4e0d\u4ec5\u5305\u542bMatMul\u7b49**\u8ba1\u7b97\u64cd\u4f5c**\uff0c\u8fd8\u5305\u542bQueue\u7b49**\u975e\u8ba1\u7b97\u64cd\u4f5c**\uff0c\u8fd9\u4e9b\u5c06\u5728\u7b2c5\u7ae0Kernels\u6a21\u5757\u8be6\u7ec6\u4ecb\u7ecd\u3002 \u7b2c\u4e09\u5c42\u662f**\u56fe\u8ba1\u7b97\u5c42\uff08Graph\uff09 \uff0c\u5305\u542b**\u672c\u5730\u8ba1\u7b97\u6d41\u56fe**\u548c**\u5206\u5e03\u5f0f\u8ba1\u7b97\u6d41\u56fe**\u7684\u5b9e\u73b0\u3002Graph\u6a21\u5757\u5305\u542bGraph\u7684**\u521b\u5efa \u3001 \u7f16\u8bd1 \u3001**\u4f18\u5316**\u548c**\u6267\u884c**\u7b49\u90e8\u5206\uff0cGraph\u4e2d\u6bcf\u4e2a**\u8282\u70b9**\u90fd\u662f**OpKernels\u7c7b\u578b**\u8868\u793a\u3002\u5173\u4e8e\u56fe\u8ba1\u7b97\u5c06\u5728\u7b2c6\u7ae0Graph\u6a21\u5757\u8be6\u7ec6\u4ecb\u7ecd\u3002 \u770b\u5230\u8fd9\u91cc\uff0c\u9700\u8981\u8bb0\u4f4f\u4e0b\u9762\u8fd9\u53e5\u8bdd\uff1aTensorFlow is a computational dataflow graph library.\u5e76\u4e14\uff0c\u6211\u9700\u8981\u597d\u597d\u7684\u9886\u609f\u4e00\u4e0b\u4ed6\u7684\u5b9e\u73b0\u601d\u8def\u3002 \u7b2c\u56db\u5c42\u662fAPI\u63a5\u53e3\u5c42\u3002Tensor C API\u662f\u5bf9TF\u529f\u80fd\u6a21\u5757\u7684\u63a5\u53e3\u5c01\u88c5\uff0c\u4fbf\u4e8e\u5176\u4ed6\u8bed\u8a00\u5e73\u53f0\u8c03\u7528\u3002 \u7b2c\u56db\u5c42\u4ee5\u4e0a\u662f\u5e94\u7528\u5c42\u3002\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5728\u5e94\u7528\u5c42\u901a\u8fc7API\u63a5\u53e3\u5c42\u8c03\u7528TF\u6838\u5fc3\u529f\u80fd\u5b9e\u73b0\u76f8\u5173\u5b9e\u9a8c\u548c\u5e94\u7528\u3002 1.3 TF\u4ee3\u7801\u76ee\u5f55\u7ec4\u7ec7 \u56fe3\u662fTF\u7684\u4ee3\u7801\u7ed3\u6784\u89c6\u56fe\uff0c\u4e0b\u9762\u5c06\u7b80\u5355\u4ecb\u7ecdTF\u7684\u76ee\u5f55\u7ec4\u7ec7\u7ed3\u6784\u3002 \u73b0\u5728\u518d\u6765\u770b\u65b0\u7248\u672c\u7684\u4ee3\u7801\u7ed3\u6784\uff0c\u53d1\u73b0\u5df2\u7ecf\u548c\u8fd9\u4e2a\u7ed3\u6784\u4e0d\u76f8\u540c\u4e86\u3002\u663e\u7136\uff0c\u76ee\u5f55\u7ed3\u6784\u662f\u5728\u4e0d\u65ad\u53d8\u66f4\u7684\u3002 \u56fe3 TF\u4ee3\u7801\u76ee\u5f55\u7ec4\u7ec7\u7ed3\u6784 Tensorflow/core\u76ee\u5f55\u5305\u542b\u4e86TF\u6838\u5fc3\u6a21\u5757\u4ee3\u7801\u3002 public: API\u63a5\u53e3\u5934\u6587\u4ef6\u76ee\u5f55\uff0c\u7528\u4e8e\u5916\u90e8\u63a5\u53e3\u8c03\u7528\u7684API\u5b9a\u4e49\uff0c\u4e3b\u8981\u662fsession.h \u548ctensor_c_api.h\u3002 client: API\u63a5\u53e3\u5b9e\u73b0\u6587\u4ef6\u76ee\u5f55\u3002 platform: OS\u7cfb\u7edf\u76f8\u5173\u63a5\u53e3\u6587\u4ef6\uff0c\u5982file system, env\u7b49\u3002 protobuf: \u5747\u4e3a.proto\u6587\u4ef6\uff0c\u7528\u4e8e\u6570\u636e\u4f20\u8f93\u65f6\u7684\u7ed3\u6784\u5e8f\u5217\u5316. common_runtime: \u516c\u5171\u8fd0\u884c\u5e93\uff0c\u5305\u542bsession, executor, threadpool, rendezvous, memory\u7ba1\u7406, \u8bbe\u5907\u5206\u914d\u7b97\u6cd5\u7b49\u3002 distributed_runtime: \u5206\u5e03\u5f0f\u6267\u884c\u6a21\u5757\uff0c\u5982rpc session, rpc master, rpc worker, graph manager\u3002 framework: \u5305\u542b\u57fa\u7840\u529f\u80fd\u6a21\u5757\uff0c\u5982log, memory, tensor graph: \u8ba1\u7b97\u6d41\u56fe\u76f8\u5173\u64cd\u4f5c\uff0c\u5982construct, partition, optimize, execute\u7b49 kernels : \u6838\u5fc3Op\uff0c\u5982matmul, conv2d, argmax, batch_norm\u7b49 lib: \u516c\u5171\u57fa\u7840\u5e93\uff0c\u5982gif\u3001gtl(google\u6a21\u677f\u5e93)\u3001hash\u3001histogram\u7b49\u3002 ops : \u57fa\u672cops\u8fd0\u7b97\uff0cops\u68af\u5ea6\u8fd0\u7b97\uff0cio\u76f8\u5173\u7684ops\uff0c\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\u64cd\u4f5c Tensorflow/stream_executor\u76ee\u5f55\u662f**\u5e76\u884c\u8ba1\u7b97\u6846\u67b6**\uff0c\u7531google stream executor\u56e2\u961f\u5f00\u53d1\u3002 Tensorflow/contrib\u76ee\u5f55\u662fcontributor\u5f00\u53d1\u76ee\u5f55\u3002 Tensroflow/python\u76ee\u5f55\u662fpython API\u5ba2\u6237\u7aef\u811a\u672c\u3002 Tensorflow/tensorboard\u76ee\u5f55\u662f\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u4e0d\u4ec5\u53ef\u4ee5\u6a21\u578b\u53ef\u89c6\u5316\uff0c\u8fd8\u53ef\u4ee5\u76d1\u63a7\u6a21\u578b\u53c2\u6570\u53d8\u5316\u3002 third_party\u76ee\u5f55\u662fTF\u7b2c\u4e09\u65b9\u4f9d\u8d56\u5e93\u3002 eigen3: eigen\u77e9\u9635\u8fd0\u7b97\u5e93\uff0cTF\u57fa\u7840ops\u8c03\u7528 gpus: \u5c01\u88c5\u4e86cuda/cudnn\u7f16\u7a0b\u5e93 2. TF\u6838\u5fc3\u6982\u5ff5 TF\u7684\u6838\u5fc3\u662f\u56f4\u7ed5**Graph**\u5c55\u5f00\u7684\uff0c\u7b80\u800c\u8a00\u4e4b\uff0c\u5c31\u662fTensor\u6cbf\u7740Graph\u4f20\u9012\u95ed\u5305\u5b8c\u6210Flow\u7684\u8fc7\u7a0b\u3002\u6240\u4ee5\u5728\u4ecb\u7ecdGraph\u4e4b\u524d\u9700\u8981\u8bb2\u8ff0\u4e00\u4e0b\u7b26\u53f7\u7f16\u7a0b\u3001\u8ba1\u7b97\u6d41\u56fe\u3001\u68af\u5ea6\u8ba1\u7b97\u3001\u63a7\u5236\u6d41\u7684\u6982\u5ff5\u3002 \u9700\u8981\u5b8c\u6574\u5730\u5c06\u56fe\u7684\u521b\u5efa\uff0c\u4fdd\u5b58\uff0c\u8bfb\u53d6\u90fd\u8dd1\u4e00\u904d 2.1 Tensor \u5728\u6570\u5b66\u4e0a\uff0cMatrix\u8868\u793a\u4e8c\u7ef4\u7ebf\u6027\u6620\u5c04\uff0cTensor\u8868\u793a\u591a\u7ef4\u7ebf\u6027\u6620\u5c04\uff0cTensor\u662f\u5bf9Matrix\u7684\u6cdb\u5316\uff0c\u53ef\u4ee5\u8868\u793a1-dim\u30012-dim\u3001N-dim\u7684\u9ad8\u7ef4\u7a7a\u95f4\u3002\u56fe4\u5bf9\u6bd4\u4e86\u77e9\u9635\u4e58\u6cd5\uff08Matrix Product\uff09\u548c\u5f20\u91cf\u79ef\uff08Tensor Contract\uff09\uff0c\u53ef\u4ee5\u770b\u51faTensor\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5176\u4e2d\u5f20\u91cf\u79ef\u8fd0\u7b97\u5728TF\u7684MatMul\u548cConv2D\u8fd0\u7b97\u4e2d\u90fd\u6709\u7528\u5230\u3002 \u56fe4 Tensor contract **Tensor**\u5728**\u9ad8\u7ef4\u7a7a\u95f4\u6570\u5b66\u8fd0\u7b97**\u6bd4Matrix\u8ba1\u7b97\u590d\u6742\uff0c\u8ba1\u7b97\u91cf\u4e5f\u975e\u5e38\u5927\uff0c\u52a0\u901f\u5f20\u91cf\u5e76\u884c\u8fd0\u7b97\u662fTF\u4f18\u5148\u8003\u8651\u7684\u95ee\u9898\uff0c\u5982add, contract, slice, reshape, reduce, shuffle\u7b49\u8fd0\u7b97\u3002 TF\u4e2dTensor\u7684\u7ef4\u6570\u63cf\u8ff0\u4e3a\u9636\uff0c\u6570\u503c\u662f0\u9636\uff0c\u5411\u91cf\u662f1\u9636\uff0c\u77e9\u9635\u662f2\u9636\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u53ef\u4ee5\u8868\u793an\u9636\u9ad8\u7ef4\u6570\u636e\u3002 TF\u4e2dTensor\u652f\u6301\u7684**\u6570\u636e\u7c7b\u578b**\u6709\u5f88\u591a\uff0c\u5982tf.float16, tf.float32, tf.float64, tf.uint8, tf.int8, tf.int16, tf.int32, tf.int64, tf.string, tf.bool, tf.complex64\u7b49\uff0c\u6240\u6709Tensor\u8fd0\u7b97\u90fd\u4f7f\u7528\u6cdb\u5316\u7684\u6570\u636e\u7c7b\u578b\u8868\u793a\u3002 TF\u7684 Tensor \u5b9a\u4e49\u548c\u8fd0\u7b97\u4e3b\u8981\u662f\u8c03\u7528Eigen\u77e9\u9635\u8ba1\u7b97\u5e93\u5b8c\u6210\u7684\u3002TF\u4e2d**Tensor**\u7684UML\u5b9a\u4e49\u5982\u56fe4\u3002\u5176\u4e2d**TensorBuffer**\u6307\u9488\u6307\u5411 Eigen::Tensor \u7c7b\u578b\u3002\u5176\u4e2d\uff0c Eigen::Tensor[5][6] \u4e0d\u5c5e\u4e8eEigen\u5b98\u65b9\u7ef4\u62a4\u7684\u7a0b\u5e8f\uff0c\u7531**\u8d21\u732e\u8005**\u63d0\u4f9b\u6587\u6863\u548c\u7ef4\u62a4\uff0c\u6240\u4ee5Tensor\u5b9a\u4e49\u5728Eigen unsupported\u6a21\u5757\u4e2d\u3002 \u56fe5 Tensor\u6570\u636e\u7ed3\u6784\u5b9a\u4e49 \u56fe5\u4e2d\uff0cTensor\u4e3b\u8981\u5305\u542b\u4e24\u4e2a\u53d8\u91cf m_data \u548c m_dimension \uff0c m_data \u4fdd\u5b58\u4e86**Tensor**\u7684**\u6570\u636e\u5757**\uff0cT\u662f\u6cdb\u5316\u7684\u6570\u636e\u7c7b\u578b\uff0c\u00b7m_dimensions\u00b7\u4fdd\u5b58\u4e86**Tensor**\u7684**\u7ef4\u5ea6\u4fe1\u606f**\u3002 Eigen:Tensor \u7684\u6210\u5458\u53d8\u91cf\u5f88\u7b80\u5355\uff0c\u5374\u652f\u6301\u975e\u5e38\u591a\u7684\u57fa\u672c\u8fd0\u7b97\uff0c\u518d\u501f\u52a9**Eigen**\u7684\u52a0\u901f\u673a\u5236\u5b9e\u73b0\u5feb\u901f\u8ba1\u7b97\uff0c\u53c2\u8003\u7ae0\u82823.2\u3002 Eigen::Tensor \u4e3b\u8981\u5305\u542b\u4e86 \u4e00\u5143\u8fd0\u7b97\uff08Unary\uff09\uff0c\u5982sqrt\u3001square\u3001exp\u3001abs\u7b49\u3002 \u4e8c\u5143\u8fd0\u7b97\uff08Binary\uff09\uff0c\u5982add\uff0csub\uff0cmul\uff0cdiv\u7b49 \u9009\u62e9\u8fd0\u7b97\uff08Selection\uff09\uff0c\u5373if / else\u6761\u4ef6\u8fd0\u7b97 \u5f52\u7eb3\u8fd0\u7b97\uff08Reduce\uff09\uff0c\u5982reduce_sum\uff0c reduce_mean\u7b49 \u51e0\u4f55\u8fd0\u7b97\uff08Geometry\uff09\uff0c\u5982reshape\uff0cslice\uff0cshuffle\uff0cchip\uff0creverse\uff0cpad\uff0cconcatenate\uff0cextract_patches\uff0cextract_image_patches\u7b49 \u5f20\u91cf\u79ef \uff08Contract\uff09\u548c**\u5377\u79ef\u8fd0\u7b97**\uff08Convolve\uff09\u662f\u91cd\u70b9\u8fd0\u7b97\uff0c\u540e\u7eed\u4f1a\u8be6\u7ec6\u8bb2\u89e3\u3002 2.2 \u7b26\u53f7\u7f16\u7a0b \u7f16\u7a0b\u6a21\u5f0f**\u901a\u5e38\u5206\u4e3a**\u547d\u4ee4\u5f0f\u7f16\u7a0b \uff08imperative style programs\uff09\u548c**\u7b26\u53f7\u5f0f\u7f16\u7a0b**\uff08symbolic style programs\uff09\u3002 \u5173\u4e8e\u4e24\u8005\u7684\u533a\u5206\uff0c\u5728\u4e0b\u9762\u6709\u6bd4\u8f83\u8be6\u7ec6\u7684\u4ecb\u7ecd\uff1b\u5343\u4e07\u4e0d\u8981\u4ec5\u4ec5\u6839\u636e\u540d\u5b57\u800c\u8fdb\u884c\u63e3\u6d4b **\u547d\u4ee4\u5f0f\u7f16\u7a0b**\u5bb9\u6613\u7406\u89e3\u548c\u8c03\u8bd5\uff0c\u547d\u4ee4\u8bed\u53e5\u57fa\u672c\u6ca1\u6709\u4f18\u5316\uff0c\u6309\u539f\u6709\u903b\u8f91\u6267\u884c\u3002**\u7b26\u53f7\u5f0f\u7f16\u7a0b**\u6d89\u53ca\u8f83\u591a\u7684\u5d4c\u5165\u548c\u4f18\u5316\uff0c\u4e0d\u5bb9\u6613\u7406\u89e3\u548c\u8c03\u8bd5\uff0c\u4f46\u8fd0\u884c\u901f\u5ea6\u6709\u540c\u6bd4\u63d0\u5347\u3002 \u8fd9\u4e24\u79cd**\u7f16\u7a0b\u6a21\u5f0f**\u5728\u5b9e\u9645\u4e2d\u90fd\u6709\u5e94\u7528\uff0cTorch\u662f\u5178\u578b\u7684\u547d\u4ee4\u5f0f\u98ce\u683c\uff0ccaffe\u3001theano\u3001mxnet\u548cTensorflow\u90fd\u4f7f\u7528\u4e86\u7b26\u53f7\u5f0f\u7f16\u7a0b\u3002\u5176\u4e2dcaffe\u3001mxnet\u91c7\u7528\u4e86\u4e24\u79cd\u7f16\u7a0b\u6a21\u5f0f\u6df7\u5408\u7684\u65b9\u6cd5\uff0c\u800c**Tensorflow**\u662f\u5b8c\u5168\u91c7\u7528\u4e86**\u7b26\u53f7\u5f0f\u7f16\u7a0b**\uff0cTheano\u548c**Tensorflow**\u7684\u7f16\u7a0b\u6a21\u5f0f\u66f4\u76f8\u8fd1\u3002 \u547d\u4ee4\u5f0f\u7f16\u7a0b\u662f\u5e38\u89c1\u7684\u7f16\u7a0b\u6a21\u5f0f\uff0c\u7f16\u7a0b\u8bed\u8a00\u5982python/C++\u90fd\u91c7\u7528**\u547d\u4ee4\u5f0f\u7f16\u7a0b**\u3002\u547d\u4ee4\u5f0f\u7f16\u7a0b\u660e\u786e\u8f93\u5165\u53d8\u91cf\uff0c\u5e76\u6839\u636e\u7a0b\u5e8f\u903b\u8f91\u9010\u6b65\u8fd0\u7b97\uff0c\u8fd9\u79cd\u6a21\u5f0f\u975e\u5e38\u5728\u8c03\u8bd5\u7a0b\u5e8f\u65f6\u8fdb\u884c\u5355\u6b65\u8ddf\u8e2a\uff0c\u5206\u6790\u4e2d\u95f4\u53d8\u91cf\u3002\u4e3e\u4f8b\u6765\u8bf4\uff0c\u8bbeA=10, B=10\uff0c\u8ba1\u7b97\u903b\u8f91\uff1a \u7b2c\u4e00\u6b65\u8ba1\u7b97\u5f97\u51faC=100\uff0c\u7b2c\u4e8c\u6b65\u8ba1\u7b97\u5f97\u51faD=101\uff0c\u8f93\u51fa\u7ed3\u679cD=101\u3002 \u7b26\u53f7\u5f0f\u7f16\u7a0b**\u5c06\u8ba1\u7b97\u8fc7\u7a0b\u62bd\u8c61\u4e3a**\u8ba1\u7b97\u56fe \uff0c \u8ba1\u7b97\u6d41\u56fe**\u53ef\u4ee5\u65b9\u4fbf\u7684\u63cf\u8ff0**\u8ba1\u7b97\u8fc7\u7a0b \uff0c\u6240\u6709**\u8f93\u5165\u8282\u70b9**\u3001 \u8fd0\u7b97\u8282\u70b9 \u3001 \u8f93\u51fa\u8282\u70b9**\u5747**\u7b26\u53f7\u5316**\u5904\u7406\u3002**\u8ba1\u7b97\u56fe**\u901a\u8fc7\u5efa\u7acb\u8f93\u5165\u8282\u70b9\u5230\u8f93\u51fa\u8282\u70b9\u7684**\u4f20\u9012\u95ed\u5305 \uff0c\u4ece\u8f93\u5165\u8282\u70b9\u51fa\u53d1\uff0c\u6cbf\u7740**\u4f20\u9012\u95ed\u5305**\u5b8c\u6210**\u6570\u503c\u8ba1\u7b97**\u548c**\u6570\u636e\u6d41\u52a8**\uff0c\u76f4\u5230\u8fbe\u5230**\u8f93\u51fa\u8282\u70b9**\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u7ecf\u8fc7\u8ba1\u7b97\u56fe\u4f18\u5316\uff0c\u4ee5\u6570\u636e\uff08\u8ba1\u7b97\uff09\u6d41\u65b9\u5f0f\u5b8c\u6210\uff0c\u8282\u7701\u5185\u5b58\u7a7a\u95f4\u4f7f\u7528\uff0c\u8ba1\u7b97\u901f\u5ea6\u5feb\uff0c\u4f46\u4e0d\u9002\u5408\u7a0b\u5e8f\u8c03\u8bd5\uff0c\u901a\u5e38\u4e0d\u7528\u4e8e**\u7f16\u7a0b\u8bed\u8a00**\u4e2d\u3002\u4e3e\u4e0a\u9762\u7684\u4f8b\u5b50\uff0c\u5148\u6839\u636e\u8ba1\u7b97\u903b\u8f91\u7f16\u5199\u7b26\u53f7\u5f0f\u7a0b\u5e8f\u5e76\u751f\u6210\u8ba1\u7b97\u56fe \u5176\u4e2dA\u548cB\u662f\u8f93\u5165\u7b26\u53f7\u53d8\u91cf\uff0cC\u548cD\u662f\u8fd0\u7b97\u7b26\u53f7\u53d8\u91cf\uff0ccompile\u51fd\u6570\u751f\u6210\u8ba1\u7b97\u56feF\uff0c\u5982\u56fe6\u6240\u793a\u3002 \u56fe6 \u7b26\u53f7\u7f16\u7a0b\u7684\u6b63\u5411\u8ba1\u7b97\u56fe \u6700\u540e\u5f97\u5230A=10, B=10\u65f6\u53d8\u91cfD\u7684\u503c\uff0c\u8fd9\u91ccD\u53ef\u4ee5\u590d\u7528C\u7684\u5185\u5b58\u7a7a\u95f4\uff0c\u7701\u53bb\u4e86\u4e2d\u95f4\u53d8\u91cf\u7684\u7a7a\u95f4\u5b58\u50a8\u3002 \u56fe 6\u662fTF\u4e2d\u7684\u8ba1\u7b97\u6d41\u56fe\uff0cC=F(Relu(Add(MatMul(W, x), b)))\uff0c\u5176\u4e2d\u6bcf\u4e2a\u8282\u70b9\u90fd\u662f\u7b26\u53f7\u5316\u8868\u793a\u7684\u3002\u901a\u8fc7session\u521b\u5efagraph\uff0c\u5728\u8c03\u7528session.run\u6267\u884c\u8ba1\u7b97\u3002 \u56fe7 TF\u7b26\u53f7\u8ba1\u7b97\u56fe \u548c\u76ee\u524d\u7684**\u7b26\u53f7\u8bed\u8a00**\u6bd4\u8d77\u6765\uff0cTF\u6700\u5927\u7684\u7279\u70b9\u662f\u5f3a\u5316\u4e86**\u6570\u636e\u6d41\u56fe**\uff0c\u5f15\u5165\u4e86mutation\u7684\u6982\u5ff5\u3002\u8fd9\u4e00\u70b9\u662fTF\u548c\u5305\u62ecTheano\u5728\u5185\u7684\u7b26\u53f7\u7f16\u7a0b\u6846\u67b6\u6700\u5927\u7684\u4e0d\u540c\u3002\u6240\u8c13**mutation**\uff0c\u5c31\u662f\u53ef\u4ee5\u5728\u8ba1\u7b97\u7684\u8fc7\u7a0b\u66f4\u6539\u4e00\u4e2a\u53d8\u91cf\u7684\u503c\uff0c\u800c\u8fd9\u4e2a\u53d8\u91cf\u5728\u8ba1\u7b97\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u88ab\u5e26\u5165\u5230\u4e0b\u4e00\u8f6e\u8fed\u4ee3\u91cc\u9762\u53bb\u3002 Mutation\u662f\u673a\u5668\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u51e0\u4e4e\u5fc5\u987b\u8981\u5f15\u5165\u7684\u4e1c\u897f\uff08\u867d\u7136\u4e5f\u53ef\u4ee5\u901a\u8fc7immutable replacement\u6765\u4ee3\u66ff\uff0c\u4f46\u662f\u4f1a\u6709\u6548\u7387\u7684\u95ee\u9898\uff09\u3002 Theano\u7684\u505a\u6cd5\u662f\u5f15\u5165\u4e86update statement\u6765\u5904\u7406mutation\u3002TF\u9009\u62e9\u4e86\u7eaf\u7b26\u53f7\u8ba1\u7b97\u7684\u8def\u7ebf\uff0c\u5e76\u4e14\u76f4\u63a5\u628a\u66f4\u65b0\u5f15\u5165\u4e86\u6570\u636e\u6d41\u56fe\u4e2d\u53bb\u3002\u4ece\u76ee\u524d\u7684\u767d\u76ae\u4e66\u770b\u8fd8\u4f1a\u652f\u6301\u6761\u4ef6\u548c\u5faa\u73af\u3002\u8fd9\u6837\u5c31\u51e0\u4e4e\u8ba9TF\u672c\u8eab\u6210\u4e3a\u4e00\u95e8\u72ec\u7acb\u7684\u8bed\u8a00\u3002\u4e0d\u8fc7\u8fd9\u4e00\u70b9\u4f1a\u5bfc\u81f4\u6700\u540e\u7684API\u8bbe\u8ba1\u548c\u4f7f\u7528\u9700\u8981\u7279\u522b\u5c0f\u5fc3\uff0c\u628amutation \u5f15\u5165\u5230\u6570\u636e\u6d41\u56fe\u4e2d\u4f1a\u5e26\u6765\u4e00\u4e9b\u65b0\u7684\u95ee\u9898\uff0c\u6bd4\u5982\u5982\u4f55\u5904\u7406\u5199\u4e0e\u5199\u4e4b\u95f4\u7684\u4f9d\u8d56\u3002[7] 2.3 \u68af\u5ea6\u8ba1\u7b97 \u68af\u5ea6\u8ba1\u7b97**\u4e3b\u8981\u5e94\u7528\u5728**\u8bef\u5dee\u53cd\u5411\u4f20\u64ad**\u548c**\u6570\u636e\u66f4\u65b0 \uff0c\u662f\u6df1\u5ea6\u5b66\u4e60\u5e73\u53f0\u8981\u89e3\u51b3\u7684\u6838\u5fc3\u95ee\u9898\u3002\u68af\u5ea6\u8ba1\u7b97\u6d89\u53ca\u6bcf\u4e2a\u8ba1\u7b97\u8282\u70b9\uff0c\u6bcf\u4e2a\u81ea\u5b9a\u4e49\u7684**\u524d\u5411\u8ba1\u7b97\u56fe**\u90fd\u5305\u542b\u4e00\u4e2a\u9690\u5f0f\u7684**\u53cd\u5411\u8ba1\u7b97\u56fe**\u3002\u4ece\u6570\u636e\u6d41\u5411\u4e0a\u770b\uff0c**\u6b63\u5411\u8ba1\u7b97\u56fe**\u662f\u6570\u636e\u4ece**\u8f93\u5165\u8282\u70b9**\u5230**\u8f93\u51fa\u8282\u70b9**\u7684\u6d41\u5411\u8fc7\u7a0b\uff0c**\u53cd\u5411\u8ba1\u7b97\u56fe**\u662f\u6570\u636e\u4ece**\u8f93\u51fa\u8282\u70b9**\u5230**\u8f93\u5165\u8282\u70b9**\u7684\u6d41\u5411\u8fc7\u7a0b\u3002 \u56fe8\u662f2.2\u8282\u4e2d\u56fe6\u5bf9\u5e94\u7684\u53cd\u5411\u8ba1\u7b97\u56fe\u3002\u56fe\u4e2d\uff0c\u7531\u4e8eC=A*B\uff0c\u5219dA=B*dC, dB=A*dC\u3002\u5728\u53cd\u5411\u8ba1\u7b97\u56fe\u4e2d\uff0c\u8f93\u5165\u8282\u70b9dD\uff0c\u8f93\u51fa\u8282\u70b9dA\u548cdB\uff0c\u8ba1\u7b97\u8868\u8fbe\u5f0f\u4e3adA=B*dC=B*dD, dB=A*dC=A*dD\u3002\u6bcf\u4e00\u4e2a\u6b63\u5411\u8ba1\u7b97\u8282\u70b9\u5bf9\u5e94\u4e00\u4e2a\u9690\u5f0f\u68af\u5ea6\u8ba1\u7b97\u8282\u70b9\u3002 \u56fe8 \u7b26\u53f7\u7f16\u7a0b\u7684\u53cd\u5411\u8ba1\u7b97\u56fe \u53cd\u5411\u8ba1\u7b97\u9650\u5236\u4e86\u7b26\u53f7\u7f16\u7a0b\u4e2d\u5185\u5b58\u7a7a\u95f4\u590d\u7528\u7684\u4f18\u52bf\uff0c\u56e0\u4e3a\u5728\u6b63\u5411\u8ba1\u7b97\u4e2d\u7684\u8ba1\u7b97\u6570\u636e\u5728\u53cd\u5411\u8ba1\u7b97\u4e2d\u4e5f\u53ef\u80fd\u8981\u7528\u5230\u3002\u4ece\u8fd9\u4e00\u70b9\u4e0a\u8bb2\uff0c\u7c97\u7c92\u5ea6\u7684\u8ba1\u7b97\u8282\u70b9\u6bd4\u7ec6\u7c92\u5ea6\u7684\u8ba1\u7b97\u8282\u70b9\u66f4\u6709\u4f18\u52bf\uff0c\u800cTF\u5927\u90e8\u5206\u4e3a\u7ec6\u7c92\u5ea6\u64cd\u4f5c\uff0c\u867d\u7136\u7075\u6d3b\u6027\u5f88\u5f3a\uff0c\u4f46\u7ec6\u7c92\u5ea6\u64cd\u4f5c\u6d89\u53ca\u5230\u66f4\u591a\u7684\u4f18\u5316\u65b9\u6848\uff0c\u5728\u5de5\u7a0b\u5b9e\u73b0\u4e0a\u5f00\u9500\u8f83\u5927\uff0c\u4e0d\u53ca\u7c97\u7c92\u5ea6\u7b80\u5355\u76f4\u63a5\u3002\u5728\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\uff0cTF\u5c06\u9010\u6b65\u4fa7\u91cd\u7c97\u7c92\u5ea6\u8fd0\u7b97\u3002 2.4 \u63a7\u5236\u6d41 TF\u7684\u8ba1\u7b97\u56fe\u5982\u540c\u6570\u636e\u6d41\u4e00\u6837\uff0c\u6570\u636e\u6d41\u5411\u8868\u793a\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u5982\u56fe9\u3002\u6570\u636e\u6d41\u56fe\u53ef\u4ee5\u5f88\u597d\u7684\u8868\u8fbe\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u4e3a\u4e86\u6269\u5c55TF\u7684\u8868\u8fbe\u80fd\u529b\uff0cTF\u4e2d\u5f15\u5165**\u63a7\u5236\u6d41**\u3002 \u56fe9 Graph\u7684\u6570\u636e\u6d41 \u5728\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0cif\u2026else\u2026\u662f\u6700\u5e38\u89c1\u7684\u903b\u8f91\u63a7\u5236\uff0c\u5728TF\u7684\u6570\u636e\u6d41\u4e2d\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u63a7\u5236\u6570\u636e\u6d41\u5411\u3002\u63a5\u53e3\u51fd\u6570\u5982\u4e0b\uff0cpred\u4e3a\u5224\u522b\u8868\u8fbe\u5f0f\uff0cfn1\u548cfn2\u4e3a\u8fd0\u7b97\u8868\u8fbe\u5f0f\u3002\u5f53pred\u4e3atrue\u662f\uff0c\u6267\u884cfn1\u64cd\u4f5c\uff1b\u5f53pred\u4e3afalse\u65f6\uff0c\u6267\u884cfn2\u64cd\u4f5c\u3002 TF\u8fd8\u53ef\u4ee5\u534f\u8c03\u591a\u4e2a**\u6570\u636e\u6d41**\uff0c\u5728\u5b58\u5728\u4f9d\u8d56\u8282\u70b9\u7684\u573a\u666f\u4e0b\u975e\u5e38\u6709\u7528\uff0c\u4f8b\u5982\u8282\u70b9B\u8981\u8bfb\u53d6\u6a21\u578b\u53c2\u6570\u03b8\u66f4\u65b0\u540e\u7684\u503c\uff0c\u800c\u8282\u70b9A\u8d1f\u8d23\u66f4\u65b0\u53c2\u6570\u03b8\uff0c\u5219\u8282\u70b9B\u5fc5\u987b\u7b49\u8282\u70b9A\u5b8c\u6210\u540e\u624d\u80fd\u6267\u884c\uff0c\u5426\u5219\u8bfb\u53d6\u7684\u53c2\u6570\u03b8\u4e3a\u66f4\u65b0\u524d\u7684\u6570\u503c\uff0c\u8fd9\u65f6\u9700\u8981\u4e00\u4e2a\u8fd0\u7b97\u63a7\u5236\u5668\u3002\u63a5\u53e3\u51fd\u6570\u5982\u4e0b\uff0ctf.control_dependencies\u51fd\u6570\u53ef\u4ee5\u63a7\u5236\u591a\u4e2a\u6570\u636e\u6d41\u6267\u884c\u5b8c\u6210\u540e\u624d\u80fd\u6267\u884c\u63a5\u4e0b\u6765\u7684\u64cd\u4f5c\uff0c\u901a\u5e38\u4e0etf.group\u51fd\u6570\u7ed3\u5408\u4f7f\u7528\u3002 TF\u652f\u6301\u7684\u63a7\u5236\u7b97\u5b50\u6709Switch\u3001Merge\u3001Enter\u3001Leave\u548cNextIteration\u7b49\u3002 TF\u4e0d\u4ec5\u652f\u6301\u903b\u8f91\u63a7\u5236\uff0c\u8fd8\u652f\u6301\u5faa\u73af\u63a7\u5236\u3002TF\u4f7f\u7528\u548cMIT Token-Tagged machine\u76f8\u4f3c\u7684\u8868\u793a\u7cfb\u7edf\uff0c\u5c06\u5faa\u73af\u7684\u6bcf\u6b21\u8fed\u4ee3\u6807\u8bb0\u4e3a\u4e00\u4e2atag\uff0c\u8fed\u4ee3\u7684\u6267\u884c\u72b6\u6001\u6807\u8bb0\u4e3a\u4e00\u4e2aframe\uff0c\u4f46\u8fed\u4ee3\u6240\u9700\u7684\u6570\u636e\u51c6\u5907\u597d\u7684\u65f6\u5019\uff0c\u5c31\u53ef\u4ee5\u5f00\u59cb\u8ba1\u7b97\uff0c\u4ece\u800c\u591a\u4e2a\u8fed\u4ee3\u53ef\u4ee5\u540c\u65f6\u6267\u884c\u3002","title":"[\u4ece\u7cfb\u7edf\u548c\u4ee3\u7801\u5b9e\u73b0\u89d2\u5ea6\u89e3\u6790TensorFlow\u7684\u5185\u90e8\u5b9e\u73b0\u539f\u7406](https://www.leiphone.com/news/201702/n0uj58iHaNpW9RJG.html?viewType=weixin)"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#tensorflow","text":"","title":"\u4ece\u7cfb\u7edf\u548c\u4ee3\u7801\u5b9e\u73b0\u89d2\u5ea6\u89e3\u6790TensorFlow\u7684\u5185\u90e8\u5b9e\u73b0\u539f\u7406"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#1#tf","text":"","title":"1. TF\u7cfb\u7edf\u67b6\u6784"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#11#tf","text":"TF\u7684\u4f9d\u8d56\u89c6\u56fe\u5982\u56fe1\u6240\u793a[4]\uff0c\u63cf\u8ff0\u4e86TF\u7684\u4e0a\u4e0b\u6e38\u5173\u7cfb\u94fe\u3002 \u56fe 1 TensorFlow\u4f9d\u8d56\u89c6\u56fe TF\u6258\u7ba1\u5728github\u5e73\u53f0\uff0c\u6709google groups\u548ccontributors\u5171\u540c\u7ef4\u62a4\u3002 TF\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684API\uff0c\u652f\u6301Python\u548cC/C++\u63a5\u53e3\u3002 TF\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177Tensorboard\uff0c\u65b9\u4fbf\u5206\u6790\u548c\u8c03\u6574\u6a21\u578b\u3002 TF\u652f\u6301Linux\u5e73\u53f0\uff0cWindows\u5e73\u53f0\uff0cMac\u5e73\u53f0\uff0c\u751a\u81f3\u624b\u673a\u79fb\u52a8\u8bbe\u5907\u7b49\u5404\u79cd\u5e73\u53f0\u3002","title":"1.1 TF\u4f9d\u8d56\u89c6\u56fe"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#12#tf","text":"\u56fe2\u662fTF\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u4ece\u5e95\u5411\u4e0a\u5206\u4e3a\u8bbe\u5907\u7ba1\u7406\u548c\u901a\u4fe1\u5c42\u3001\u6570\u636e\u64cd\u4f5c\u5c42\u3001\u56fe\u8ba1\u7b97\u5c42\u3001API\u63a5\u53e3\u5c42\u3001\u5e94\u7528\u5c42\u3002\u5176\u4e2d\u8bbe\u5907\u7ba1\u7406\u548c\u901a\u4fe1\u5c42\u3001\u6570\u636e\u64cd\u4f5c\u5c42\u3001\u56fe\u8ba1\u7b97\u5c42\u662fTF\u7684\u6838\u5fc3\u5c42\u3002 \u56fe2 TF\u7cfb\u7edf\u67b6\u6784 \u5e95\u5c42\u8bbe\u5907\u901a\u4fe1\u5c42**\u8d1f\u8d23**\u7f51\u7edc\u901a\u4fe1**\u548c**\u8bbe\u5907\u7ba1\u7406 \u3002\u8bbe\u5907\u7ba1\u7406\u53ef\u4ee5\u5b9e\u73b0TF\u8bbe\u5907\u5f02\u6784\u7684\u7279\u6027\uff0c\u652f\u6301CPU\u3001GPU\u3001Mobile\u7b49\u4e0d\u540c\u8bbe\u5907\u3002**\u7f51\u7edc\u901a\u4fe1**\u4f9d\u8d56**gRPC\u901a\u4fe1\u534f\u8bae**\u5b9e\u73b0\u4e0d\u540c\u8bbe\u5907\u95f4\u7684\u6570\u636e\u4f20\u8f93\u548c\u66f4\u65b0\u3002 \u7b2c\u4e8c\u5c42\u662fTensor\u7684**OpKernels**\u5b9e\u73b0\u3002\u8fd9\u4e9b**OpKernels**\u4ee5**Tensor**\u4e3a\u5904\u7406\u5bf9\u8c61\uff0c\u4f9d\u8d56**\u7f51\u7edc\u901a\u4fe1**\u548c**\u8bbe\u5907\u5185\u5b58\u5206\u914d**\uff0c\u5b9e\u73b0\u4e86\u5404\u79cd**Tensor**\u64cd\u4f5c\u6216\u8ba1\u7b97\u3002Opkernels\u4e0d\u4ec5\u5305\u542bMatMul\u7b49**\u8ba1\u7b97\u64cd\u4f5c**\uff0c\u8fd8\u5305\u542bQueue\u7b49**\u975e\u8ba1\u7b97\u64cd\u4f5c**\uff0c\u8fd9\u4e9b\u5c06\u5728\u7b2c5\u7ae0Kernels\u6a21\u5757\u8be6\u7ec6\u4ecb\u7ecd\u3002 \u7b2c\u4e09\u5c42\u662f**\u56fe\u8ba1\u7b97\u5c42\uff08Graph\uff09 \uff0c\u5305\u542b**\u672c\u5730\u8ba1\u7b97\u6d41\u56fe**\u548c**\u5206\u5e03\u5f0f\u8ba1\u7b97\u6d41\u56fe**\u7684\u5b9e\u73b0\u3002Graph\u6a21\u5757\u5305\u542bGraph\u7684**\u521b\u5efa \u3001 \u7f16\u8bd1 \u3001**\u4f18\u5316**\u548c**\u6267\u884c**\u7b49\u90e8\u5206\uff0cGraph\u4e2d\u6bcf\u4e2a**\u8282\u70b9**\u90fd\u662f**OpKernels\u7c7b\u578b**\u8868\u793a\u3002\u5173\u4e8e\u56fe\u8ba1\u7b97\u5c06\u5728\u7b2c6\u7ae0Graph\u6a21\u5757\u8be6\u7ec6\u4ecb\u7ecd\u3002 \u770b\u5230\u8fd9\u91cc\uff0c\u9700\u8981\u8bb0\u4f4f\u4e0b\u9762\u8fd9\u53e5\u8bdd\uff1aTensorFlow is a computational dataflow graph library.\u5e76\u4e14\uff0c\u6211\u9700\u8981\u597d\u597d\u7684\u9886\u609f\u4e00\u4e0b\u4ed6\u7684\u5b9e\u73b0\u601d\u8def\u3002 \u7b2c\u56db\u5c42\u662fAPI\u63a5\u53e3\u5c42\u3002Tensor C API\u662f\u5bf9TF\u529f\u80fd\u6a21\u5757\u7684\u63a5\u53e3\u5c01\u88c5\uff0c\u4fbf\u4e8e\u5176\u4ed6\u8bed\u8a00\u5e73\u53f0\u8c03\u7528\u3002 \u7b2c\u56db\u5c42\u4ee5\u4e0a\u662f\u5e94\u7528\u5c42\u3002\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5728\u5e94\u7528\u5c42\u901a\u8fc7API\u63a5\u53e3\u5c42\u8c03\u7528TF\u6838\u5fc3\u529f\u80fd\u5b9e\u73b0\u76f8\u5173\u5b9e\u9a8c\u548c\u5e94\u7528\u3002","title":"1.2 TF\u7cfb\u7edf\u67b6\u6784"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#13#tf","text":"\u56fe3\u662fTF\u7684\u4ee3\u7801\u7ed3\u6784\u89c6\u56fe\uff0c\u4e0b\u9762\u5c06\u7b80\u5355\u4ecb\u7ecdTF\u7684\u76ee\u5f55\u7ec4\u7ec7\u7ed3\u6784\u3002 \u73b0\u5728\u518d\u6765\u770b\u65b0\u7248\u672c\u7684\u4ee3\u7801\u7ed3\u6784\uff0c\u53d1\u73b0\u5df2\u7ecf\u548c\u8fd9\u4e2a\u7ed3\u6784\u4e0d\u76f8\u540c\u4e86\u3002\u663e\u7136\uff0c\u76ee\u5f55\u7ed3\u6784\u662f\u5728\u4e0d\u65ad\u53d8\u66f4\u7684\u3002 \u56fe3 TF\u4ee3\u7801\u76ee\u5f55\u7ec4\u7ec7\u7ed3\u6784 Tensorflow/core\u76ee\u5f55\u5305\u542b\u4e86TF\u6838\u5fc3\u6a21\u5757\u4ee3\u7801\u3002 public: API\u63a5\u53e3\u5934\u6587\u4ef6\u76ee\u5f55\uff0c\u7528\u4e8e\u5916\u90e8\u63a5\u53e3\u8c03\u7528\u7684API\u5b9a\u4e49\uff0c\u4e3b\u8981\u662fsession.h \u548ctensor_c_api.h\u3002 client: API\u63a5\u53e3\u5b9e\u73b0\u6587\u4ef6\u76ee\u5f55\u3002 platform: OS\u7cfb\u7edf\u76f8\u5173\u63a5\u53e3\u6587\u4ef6\uff0c\u5982file system, env\u7b49\u3002 protobuf: \u5747\u4e3a.proto\u6587\u4ef6\uff0c\u7528\u4e8e\u6570\u636e\u4f20\u8f93\u65f6\u7684\u7ed3\u6784\u5e8f\u5217\u5316. common_runtime: \u516c\u5171\u8fd0\u884c\u5e93\uff0c\u5305\u542bsession, executor, threadpool, rendezvous, memory\u7ba1\u7406, \u8bbe\u5907\u5206\u914d\u7b97\u6cd5\u7b49\u3002 distributed_runtime: \u5206\u5e03\u5f0f\u6267\u884c\u6a21\u5757\uff0c\u5982rpc session, rpc master, rpc worker, graph manager\u3002 framework: \u5305\u542b\u57fa\u7840\u529f\u80fd\u6a21\u5757\uff0c\u5982log, memory, tensor graph: \u8ba1\u7b97\u6d41\u56fe\u76f8\u5173\u64cd\u4f5c\uff0c\u5982construct, partition, optimize, execute\u7b49 kernels : \u6838\u5fc3Op\uff0c\u5982matmul, conv2d, argmax, batch_norm\u7b49 lib: \u516c\u5171\u57fa\u7840\u5e93\uff0c\u5982gif\u3001gtl(google\u6a21\u677f\u5e93)\u3001hash\u3001histogram\u7b49\u3002 ops : \u57fa\u672cops\u8fd0\u7b97\uff0cops\u68af\u5ea6\u8fd0\u7b97\uff0cio\u76f8\u5173\u7684ops\uff0c\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\u64cd\u4f5c Tensorflow/stream_executor\u76ee\u5f55\u662f**\u5e76\u884c\u8ba1\u7b97\u6846\u67b6**\uff0c\u7531google stream executor\u56e2\u961f\u5f00\u53d1\u3002 Tensorflow/contrib\u76ee\u5f55\u662fcontributor\u5f00\u53d1\u76ee\u5f55\u3002 Tensroflow/python\u76ee\u5f55\u662fpython API\u5ba2\u6237\u7aef\u811a\u672c\u3002 Tensorflow/tensorboard\u76ee\u5f55\u662f\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u4e0d\u4ec5\u53ef\u4ee5\u6a21\u578b\u53ef\u89c6\u5316\uff0c\u8fd8\u53ef\u4ee5\u76d1\u63a7\u6a21\u578b\u53c2\u6570\u53d8\u5316\u3002 third_party\u76ee\u5f55\u662fTF\u7b2c\u4e09\u65b9\u4f9d\u8d56\u5e93\u3002 eigen3: eigen\u77e9\u9635\u8fd0\u7b97\u5e93\uff0cTF\u57fa\u7840ops\u8c03\u7528 gpus: \u5c01\u88c5\u4e86cuda/cudnn\u7f16\u7a0b\u5e93","title":"1.3 TF\u4ee3\u7801\u76ee\u5f55\u7ec4\u7ec7"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#2#tf","text":"TF\u7684\u6838\u5fc3\u662f\u56f4\u7ed5**Graph**\u5c55\u5f00\u7684\uff0c\u7b80\u800c\u8a00\u4e4b\uff0c\u5c31\u662fTensor\u6cbf\u7740Graph\u4f20\u9012\u95ed\u5305\u5b8c\u6210Flow\u7684\u8fc7\u7a0b\u3002\u6240\u4ee5\u5728\u4ecb\u7ecdGraph\u4e4b\u524d\u9700\u8981\u8bb2\u8ff0\u4e00\u4e0b\u7b26\u53f7\u7f16\u7a0b\u3001\u8ba1\u7b97\u6d41\u56fe\u3001\u68af\u5ea6\u8ba1\u7b97\u3001\u63a7\u5236\u6d41\u7684\u6982\u5ff5\u3002 \u9700\u8981\u5b8c\u6574\u5730\u5c06\u56fe\u7684\u521b\u5efa\uff0c\u4fdd\u5b58\uff0c\u8bfb\u53d6\u90fd\u8dd1\u4e00\u904d","title":"2. TF\u6838\u5fc3\u6982\u5ff5"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#21#tensor","text":"\u5728\u6570\u5b66\u4e0a\uff0cMatrix\u8868\u793a\u4e8c\u7ef4\u7ebf\u6027\u6620\u5c04\uff0cTensor\u8868\u793a\u591a\u7ef4\u7ebf\u6027\u6620\u5c04\uff0cTensor\u662f\u5bf9Matrix\u7684\u6cdb\u5316\uff0c\u53ef\u4ee5\u8868\u793a1-dim\u30012-dim\u3001N-dim\u7684\u9ad8\u7ef4\u7a7a\u95f4\u3002\u56fe4\u5bf9\u6bd4\u4e86\u77e9\u9635\u4e58\u6cd5\uff08Matrix Product\uff09\u548c\u5f20\u91cf\u79ef\uff08Tensor Contract\uff09\uff0c\u53ef\u4ee5\u770b\u51faTensor\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5176\u4e2d\u5f20\u91cf\u79ef\u8fd0\u7b97\u5728TF\u7684MatMul\u548cConv2D\u8fd0\u7b97\u4e2d\u90fd\u6709\u7528\u5230\u3002 \u56fe4 Tensor contract **Tensor**\u5728**\u9ad8\u7ef4\u7a7a\u95f4\u6570\u5b66\u8fd0\u7b97**\u6bd4Matrix\u8ba1\u7b97\u590d\u6742\uff0c\u8ba1\u7b97\u91cf\u4e5f\u975e\u5e38\u5927\uff0c\u52a0\u901f\u5f20\u91cf\u5e76\u884c\u8fd0\u7b97\u662fTF\u4f18\u5148\u8003\u8651\u7684\u95ee\u9898\uff0c\u5982add, contract, slice, reshape, reduce, shuffle\u7b49\u8fd0\u7b97\u3002 TF\u4e2dTensor\u7684\u7ef4\u6570\u63cf\u8ff0\u4e3a\u9636\uff0c\u6570\u503c\u662f0\u9636\uff0c\u5411\u91cf\u662f1\u9636\uff0c\u77e9\u9635\u662f2\u9636\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u53ef\u4ee5\u8868\u793an\u9636\u9ad8\u7ef4\u6570\u636e\u3002 TF\u4e2dTensor\u652f\u6301\u7684**\u6570\u636e\u7c7b\u578b**\u6709\u5f88\u591a\uff0c\u5982tf.float16, tf.float32, tf.float64, tf.uint8, tf.int8, tf.int16, tf.int32, tf.int64, tf.string, tf.bool, tf.complex64\u7b49\uff0c\u6240\u6709Tensor\u8fd0\u7b97\u90fd\u4f7f\u7528\u6cdb\u5316\u7684\u6570\u636e\u7c7b\u578b\u8868\u793a\u3002 TF\u7684 Tensor \u5b9a\u4e49\u548c\u8fd0\u7b97\u4e3b\u8981\u662f\u8c03\u7528Eigen\u77e9\u9635\u8ba1\u7b97\u5e93\u5b8c\u6210\u7684\u3002TF\u4e2d**Tensor**\u7684UML\u5b9a\u4e49\u5982\u56fe4\u3002\u5176\u4e2d**TensorBuffer**\u6307\u9488\u6307\u5411 Eigen::Tensor \u7c7b\u578b\u3002\u5176\u4e2d\uff0c Eigen::Tensor[5][6] \u4e0d\u5c5e\u4e8eEigen\u5b98\u65b9\u7ef4\u62a4\u7684\u7a0b\u5e8f\uff0c\u7531**\u8d21\u732e\u8005**\u63d0\u4f9b\u6587\u6863\u548c\u7ef4\u62a4\uff0c\u6240\u4ee5Tensor\u5b9a\u4e49\u5728Eigen unsupported\u6a21\u5757\u4e2d\u3002 \u56fe5 Tensor\u6570\u636e\u7ed3\u6784\u5b9a\u4e49 \u56fe5\u4e2d\uff0cTensor\u4e3b\u8981\u5305\u542b\u4e24\u4e2a\u53d8\u91cf m_data \u548c m_dimension \uff0c m_data \u4fdd\u5b58\u4e86**Tensor**\u7684**\u6570\u636e\u5757**\uff0cT\u662f\u6cdb\u5316\u7684\u6570\u636e\u7c7b\u578b\uff0c\u00b7m_dimensions\u00b7\u4fdd\u5b58\u4e86**Tensor**\u7684**\u7ef4\u5ea6\u4fe1\u606f**\u3002 Eigen:Tensor \u7684\u6210\u5458\u53d8\u91cf\u5f88\u7b80\u5355\uff0c\u5374\u652f\u6301\u975e\u5e38\u591a\u7684\u57fa\u672c\u8fd0\u7b97\uff0c\u518d\u501f\u52a9**Eigen**\u7684\u52a0\u901f\u673a\u5236\u5b9e\u73b0\u5feb\u901f\u8ba1\u7b97\uff0c\u53c2\u8003\u7ae0\u82823.2\u3002 Eigen::Tensor \u4e3b\u8981\u5305\u542b\u4e86 \u4e00\u5143\u8fd0\u7b97\uff08Unary\uff09\uff0c\u5982sqrt\u3001square\u3001exp\u3001abs\u7b49\u3002 \u4e8c\u5143\u8fd0\u7b97\uff08Binary\uff09\uff0c\u5982add\uff0csub\uff0cmul\uff0cdiv\u7b49 \u9009\u62e9\u8fd0\u7b97\uff08Selection\uff09\uff0c\u5373if / else\u6761\u4ef6\u8fd0\u7b97 \u5f52\u7eb3\u8fd0\u7b97\uff08Reduce\uff09\uff0c\u5982reduce_sum\uff0c reduce_mean\u7b49 \u51e0\u4f55\u8fd0\u7b97\uff08Geometry\uff09\uff0c\u5982reshape\uff0cslice\uff0cshuffle\uff0cchip\uff0creverse\uff0cpad\uff0cconcatenate\uff0cextract_patches\uff0cextract_image_patches\u7b49 \u5f20\u91cf\u79ef \uff08Contract\uff09\u548c**\u5377\u79ef\u8fd0\u7b97**\uff08Convolve\uff09\u662f\u91cd\u70b9\u8fd0\u7b97\uff0c\u540e\u7eed\u4f1a\u8be6\u7ec6\u8bb2\u89e3\u3002","title":"2.1 Tensor"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#22","text":"\u7f16\u7a0b\u6a21\u5f0f**\u901a\u5e38\u5206\u4e3a**\u547d\u4ee4\u5f0f\u7f16\u7a0b \uff08imperative style programs\uff09\u548c**\u7b26\u53f7\u5f0f\u7f16\u7a0b**\uff08symbolic style programs\uff09\u3002 \u5173\u4e8e\u4e24\u8005\u7684\u533a\u5206\uff0c\u5728\u4e0b\u9762\u6709\u6bd4\u8f83\u8be6\u7ec6\u7684\u4ecb\u7ecd\uff1b\u5343\u4e07\u4e0d\u8981\u4ec5\u4ec5\u6839\u636e\u540d\u5b57\u800c\u8fdb\u884c\u63e3\u6d4b **\u547d\u4ee4\u5f0f\u7f16\u7a0b**\u5bb9\u6613\u7406\u89e3\u548c\u8c03\u8bd5\uff0c\u547d\u4ee4\u8bed\u53e5\u57fa\u672c\u6ca1\u6709\u4f18\u5316\uff0c\u6309\u539f\u6709\u903b\u8f91\u6267\u884c\u3002**\u7b26\u53f7\u5f0f\u7f16\u7a0b**\u6d89\u53ca\u8f83\u591a\u7684\u5d4c\u5165\u548c\u4f18\u5316\uff0c\u4e0d\u5bb9\u6613\u7406\u89e3\u548c\u8c03\u8bd5\uff0c\u4f46\u8fd0\u884c\u901f\u5ea6\u6709\u540c\u6bd4\u63d0\u5347\u3002 \u8fd9\u4e24\u79cd**\u7f16\u7a0b\u6a21\u5f0f**\u5728\u5b9e\u9645\u4e2d\u90fd\u6709\u5e94\u7528\uff0cTorch\u662f\u5178\u578b\u7684\u547d\u4ee4\u5f0f\u98ce\u683c\uff0ccaffe\u3001theano\u3001mxnet\u548cTensorflow\u90fd\u4f7f\u7528\u4e86\u7b26\u53f7\u5f0f\u7f16\u7a0b\u3002\u5176\u4e2dcaffe\u3001mxnet\u91c7\u7528\u4e86\u4e24\u79cd\u7f16\u7a0b\u6a21\u5f0f\u6df7\u5408\u7684\u65b9\u6cd5\uff0c\u800c**Tensorflow**\u662f\u5b8c\u5168\u91c7\u7528\u4e86**\u7b26\u53f7\u5f0f\u7f16\u7a0b**\uff0cTheano\u548c**Tensorflow**\u7684\u7f16\u7a0b\u6a21\u5f0f\u66f4\u76f8\u8fd1\u3002 \u547d\u4ee4\u5f0f\u7f16\u7a0b\u662f\u5e38\u89c1\u7684\u7f16\u7a0b\u6a21\u5f0f\uff0c\u7f16\u7a0b\u8bed\u8a00\u5982python/C++\u90fd\u91c7\u7528**\u547d\u4ee4\u5f0f\u7f16\u7a0b**\u3002\u547d\u4ee4\u5f0f\u7f16\u7a0b\u660e\u786e\u8f93\u5165\u53d8\u91cf\uff0c\u5e76\u6839\u636e\u7a0b\u5e8f\u903b\u8f91\u9010\u6b65\u8fd0\u7b97\uff0c\u8fd9\u79cd\u6a21\u5f0f\u975e\u5e38\u5728\u8c03\u8bd5\u7a0b\u5e8f\u65f6\u8fdb\u884c\u5355\u6b65\u8ddf\u8e2a\uff0c\u5206\u6790\u4e2d\u95f4\u53d8\u91cf\u3002\u4e3e\u4f8b\u6765\u8bf4\uff0c\u8bbeA=10, B=10\uff0c\u8ba1\u7b97\u903b\u8f91\uff1a \u7b2c\u4e00\u6b65\u8ba1\u7b97\u5f97\u51faC=100\uff0c\u7b2c\u4e8c\u6b65\u8ba1\u7b97\u5f97\u51faD=101\uff0c\u8f93\u51fa\u7ed3\u679cD=101\u3002 \u7b26\u53f7\u5f0f\u7f16\u7a0b**\u5c06\u8ba1\u7b97\u8fc7\u7a0b\u62bd\u8c61\u4e3a**\u8ba1\u7b97\u56fe \uff0c \u8ba1\u7b97\u6d41\u56fe**\u53ef\u4ee5\u65b9\u4fbf\u7684\u63cf\u8ff0**\u8ba1\u7b97\u8fc7\u7a0b \uff0c\u6240\u6709**\u8f93\u5165\u8282\u70b9**\u3001 \u8fd0\u7b97\u8282\u70b9 \u3001 \u8f93\u51fa\u8282\u70b9**\u5747**\u7b26\u53f7\u5316**\u5904\u7406\u3002**\u8ba1\u7b97\u56fe**\u901a\u8fc7\u5efa\u7acb\u8f93\u5165\u8282\u70b9\u5230\u8f93\u51fa\u8282\u70b9\u7684**\u4f20\u9012\u95ed\u5305 \uff0c\u4ece\u8f93\u5165\u8282\u70b9\u51fa\u53d1\uff0c\u6cbf\u7740**\u4f20\u9012\u95ed\u5305**\u5b8c\u6210**\u6570\u503c\u8ba1\u7b97**\u548c**\u6570\u636e\u6d41\u52a8**\uff0c\u76f4\u5230\u8fbe\u5230**\u8f93\u51fa\u8282\u70b9**\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u7ecf\u8fc7\u8ba1\u7b97\u56fe\u4f18\u5316\uff0c\u4ee5\u6570\u636e\uff08\u8ba1\u7b97\uff09\u6d41\u65b9\u5f0f\u5b8c\u6210\uff0c\u8282\u7701\u5185\u5b58\u7a7a\u95f4\u4f7f\u7528\uff0c\u8ba1\u7b97\u901f\u5ea6\u5feb\uff0c\u4f46\u4e0d\u9002\u5408\u7a0b\u5e8f\u8c03\u8bd5\uff0c\u901a\u5e38\u4e0d\u7528\u4e8e**\u7f16\u7a0b\u8bed\u8a00**\u4e2d\u3002\u4e3e\u4e0a\u9762\u7684\u4f8b\u5b50\uff0c\u5148\u6839\u636e\u8ba1\u7b97\u903b\u8f91\u7f16\u5199\u7b26\u53f7\u5f0f\u7a0b\u5e8f\u5e76\u751f\u6210\u8ba1\u7b97\u56fe \u5176\u4e2dA\u548cB\u662f\u8f93\u5165\u7b26\u53f7\u53d8\u91cf\uff0cC\u548cD\u662f\u8fd0\u7b97\u7b26\u53f7\u53d8\u91cf\uff0ccompile\u51fd\u6570\u751f\u6210\u8ba1\u7b97\u56feF\uff0c\u5982\u56fe6\u6240\u793a\u3002 \u56fe6 \u7b26\u53f7\u7f16\u7a0b\u7684\u6b63\u5411\u8ba1\u7b97\u56fe \u6700\u540e\u5f97\u5230A=10, B=10\u65f6\u53d8\u91cfD\u7684\u503c\uff0c\u8fd9\u91ccD\u53ef\u4ee5\u590d\u7528C\u7684\u5185\u5b58\u7a7a\u95f4\uff0c\u7701\u53bb\u4e86\u4e2d\u95f4\u53d8\u91cf\u7684\u7a7a\u95f4\u5b58\u50a8\u3002 \u56fe 6\u662fTF\u4e2d\u7684\u8ba1\u7b97\u6d41\u56fe\uff0cC=F(Relu(Add(MatMul(W, x), b)))\uff0c\u5176\u4e2d\u6bcf\u4e2a\u8282\u70b9\u90fd\u662f\u7b26\u53f7\u5316\u8868\u793a\u7684\u3002\u901a\u8fc7session\u521b\u5efagraph\uff0c\u5728\u8c03\u7528session.run\u6267\u884c\u8ba1\u7b97\u3002 \u56fe7 TF\u7b26\u53f7\u8ba1\u7b97\u56fe \u548c\u76ee\u524d\u7684**\u7b26\u53f7\u8bed\u8a00**\u6bd4\u8d77\u6765\uff0cTF\u6700\u5927\u7684\u7279\u70b9\u662f\u5f3a\u5316\u4e86**\u6570\u636e\u6d41\u56fe**\uff0c\u5f15\u5165\u4e86mutation\u7684\u6982\u5ff5\u3002\u8fd9\u4e00\u70b9\u662fTF\u548c\u5305\u62ecTheano\u5728\u5185\u7684\u7b26\u53f7\u7f16\u7a0b\u6846\u67b6\u6700\u5927\u7684\u4e0d\u540c\u3002\u6240\u8c13**mutation**\uff0c\u5c31\u662f\u53ef\u4ee5\u5728\u8ba1\u7b97\u7684\u8fc7\u7a0b\u66f4\u6539\u4e00\u4e2a\u53d8\u91cf\u7684\u503c\uff0c\u800c\u8fd9\u4e2a\u53d8\u91cf\u5728\u8ba1\u7b97\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u88ab\u5e26\u5165\u5230\u4e0b\u4e00\u8f6e\u8fed\u4ee3\u91cc\u9762\u53bb\u3002 Mutation\u662f\u673a\u5668\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u51e0\u4e4e\u5fc5\u987b\u8981\u5f15\u5165\u7684\u4e1c\u897f\uff08\u867d\u7136\u4e5f\u53ef\u4ee5\u901a\u8fc7immutable replacement\u6765\u4ee3\u66ff\uff0c\u4f46\u662f\u4f1a\u6709\u6548\u7387\u7684\u95ee\u9898\uff09\u3002 Theano\u7684\u505a\u6cd5\u662f\u5f15\u5165\u4e86update statement\u6765\u5904\u7406mutation\u3002TF\u9009\u62e9\u4e86\u7eaf\u7b26\u53f7\u8ba1\u7b97\u7684\u8def\u7ebf\uff0c\u5e76\u4e14\u76f4\u63a5\u628a\u66f4\u65b0\u5f15\u5165\u4e86\u6570\u636e\u6d41\u56fe\u4e2d\u53bb\u3002\u4ece\u76ee\u524d\u7684\u767d\u76ae\u4e66\u770b\u8fd8\u4f1a\u652f\u6301\u6761\u4ef6\u548c\u5faa\u73af\u3002\u8fd9\u6837\u5c31\u51e0\u4e4e\u8ba9TF\u672c\u8eab\u6210\u4e3a\u4e00\u95e8\u72ec\u7acb\u7684\u8bed\u8a00\u3002\u4e0d\u8fc7\u8fd9\u4e00\u70b9\u4f1a\u5bfc\u81f4\u6700\u540e\u7684API\u8bbe\u8ba1\u548c\u4f7f\u7528\u9700\u8981\u7279\u522b\u5c0f\u5fc3\uff0c\u628amutation \u5f15\u5165\u5230\u6570\u636e\u6d41\u56fe\u4e2d\u4f1a\u5e26\u6765\u4e00\u4e9b\u65b0\u7684\u95ee\u9898\uff0c\u6bd4\u5982\u5982\u4f55\u5904\u7406\u5199\u4e0e\u5199\u4e4b\u95f4\u7684\u4f9d\u8d56\u3002[7]","title":"2.2 \u7b26\u53f7\u7f16\u7a0b"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#23","text":"\u68af\u5ea6\u8ba1\u7b97**\u4e3b\u8981\u5e94\u7528\u5728**\u8bef\u5dee\u53cd\u5411\u4f20\u64ad**\u548c**\u6570\u636e\u66f4\u65b0 \uff0c\u662f\u6df1\u5ea6\u5b66\u4e60\u5e73\u53f0\u8981\u89e3\u51b3\u7684\u6838\u5fc3\u95ee\u9898\u3002\u68af\u5ea6\u8ba1\u7b97\u6d89\u53ca\u6bcf\u4e2a\u8ba1\u7b97\u8282\u70b9\uff0c\u6bcf\u4e2a\u81ea\u5b9a\u4e49\u7684**\u524d\u5411\u8ba1\u7b97\u56fe**\u90fd\u5305\u542b\u4e00\u4e2a\u9690\u5f0f\u7684**\u53cd\u5411\u8ba1\u7b97\u56fe**\u3002\u4ece\u6570\u636e\u6d41\u5411\u4e0a\u770b\uff0c**\u6b63\u5411\u8ba1\u7b97\u56fe**\u662f\u6570\u636e\u4ece**\u8f93\u5165\u8282\u70b9**\u5230**\u8f93\u51fa\u8282\u70b9**\u7684\u6d41\u5411\u8fc7\u7a0b\uff0c**\u53cd\u5411\u8ba1\u7b97\u56fe**\u662f\u6570\u636e\u4ece**\u8f93\u51fa\u8282\u70b9**\u5230**\u8f93\u5165\u8282\u70b9**\u7684\u6d41\u5411\u8fc7\u7a0b\u3002 \u56fe8\u662f2.2\u8282\u4e2d\u56fe6\u5bf9\u5e94\u7684\u53cd\u5411\u8ba1\u7b97\u56fe\u3002\u56fe\u4e2d\uff0c\u7531\u4e8eC=A*B\uff0c\u5219dA=B*dC, dB=A*dC\u3002\u5728\u53cd\u5411\u8ba1\u7b97\u56fe\u4e2d\uff0c\u8f93\u5165\u8282\u70b9dD\uff0c\u8f93\u51fa\u8282\u70b9dA\u548cdB\uff0c\u8ba1\u7b97\u8868\u8fbe\u5f0f\u4e3adA=B*dC=B*dD, dB=A*dC=A*dD\u3002\u6bcf\u4e00\u4e2a\u6b63\u5411\u8ba1\u7b97\u8282\u70b9\u5bf9\u5e94\u4e00\u4e2a\u9690\u5f0f\u68af\u5ea6\u8ba1\u7b97\u8282\u70b9\u3002 \u56fe8 \u7b26\u53f7\u7f16\u7a0b\u7684\u53cd\u5411\u8ba1\u7b97\u56fe \u53cd\u5411\u8ba1\u7b97\u9650\u5236\u4e86\u7b26\u53f7\u7f16\u7a0b\u4e2d\u5185\u5b58\u7a7a\u95f4\u590d\u7528\u7684\u4f18\u52bf\uff0c\u56e0\u4e3a\u5728\u6b63\u5411\u8ba1\u7b97\u4e2d\u7684\u8ba1\u7b97\u6570\u636e\u5728\u53cd\u5411\u8ba1\u7b97\u4e2d\u4e5f\u53ef\u80fd\u8981\u7528\u5230\u3002\u4ece\u8fd9\u4e00\u70b9\u4e0a\u8bb2\uff0c\u7c97\u7c92\u5ea6\u7684\u8ba1\u7b97\u8282\u70b9\u6bd4\u7ec6\u7c92\u5ea6\u7684\u8ba1\u7b97\u8282\u70b9\u66f4\u6709\u4f18\u52bf\uff0c\u800cTF\u5927\u90e8\u5206\u4e3a\u7ec6\u7c92\u5ea6\u64cd\u4f5c\uff0c\u867d\u7136\u7075\u6d3b\u6027\u5f88\u5f3a\uff0c\u4f46\u7ec6\u7c92\u5ea6\u64cd\u4f5c\u6d89\u53ca\u5230\u66f4\u591a\u7684\u4f18\u5316\u65b9\u6848\uff0c\u5728\u5de5\u7a0b\u5b9e\u73b0\u4e0a\u5f00\u9500\u8f83\u5927\uff0c\u4e0d\u53ca\u7c97\u7c92\u5ea6\u7b80\u5355\u76f4\u63a5\u3002\u5728\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\uff0cTF\u5c06\u9010\u6b65\u4fa7\u91cd\u7c97\u7c92\u5ea6\u8fd0\u7b97\u3002","title":"2.3 \u68af\u5ea6\u8ba1\u7b97"},{"location":"Programming/TensorFlow/Implementation/Tensorflow-src-explanation/%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E8%A7%92%E5%BA%A6%E8%A7%A3%E6%9E%90TensorFlow%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/#24","text":"TF\u7684\u8ba1\u7b97\u56fe\u5982\u540c\u6570\u636e\u6d41\u4e00\u6837\uff0c\u6570\u636e\u6d41\u5411\u8868\u793a\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u5982\u56fe9\u3002\u6570\u636e\u6d41\u56fe\u53ef\u4ee5\u5f88\u597d\u7684\u8868\u8fbe\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u4e3a\u4e86\u6269\u5c55TF\u7684\u8868\u8fbe\u80fd\u529b\uff0cTF\u4e2d\u5f15\u5165**\u63a7\u5236\u6d41**\u3002 \u56fe9 Graph\u7684\u6570\u636e\u6d41 \u5728\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0cif\u2026else\u2026\u662f\u6700\u5e38\u89c1\u7684\u903b\u8f91\u63a7\u5236\uff0c\u5728TF\u7684\u6570\u636e\u6d41\u4e2d\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u63a7\u5236\u6570\u636e\u6d41\u5411\u3002\u63a5\u53e3\u51fd\u6570\u5982\u4e0b\uff0cpred\u4e3a\u5224\u522b\u8868\u8fbe\u5f0f\uff0cfn1\u548cfn2\u4e3a\u8fd0\u7b97\u8868\u8fbe\u5f0f\u3002\u5f53pred\u4e3atrue\u662f\uff0c\u6267\u884cfn1\u64cd\u4f5c\uff1b\u5f53pred\u4e3afalse\u65f6\uff0c\u6267\u884cfn2\u64cd\u4f5c\u3002 TF\u8fd8\u53ef\u4ee5\u534f\u8c03\u591a\u4e2a**\u6570\u636e\u6d41**\uff0c\u5728\u5b58\u5728\u4f9d\u8d56\u8282\u70b9\u7684\u573a\u666f\u4e0b\u975e\u5e38\u6709\u7528\uff0c\u4f8b\u5982\u8282\u70b9B\u8981\u8bfb\u53d6\u6a21\u578b\u53c2\u6570\u03b8\u66f4\u65b0\u540e\u7684\u503c\uff0c\u800c\u8282\u70b9A\u8d1f\u8d23\u66f4\u65b0\u53c2\u6570\u03b8\uff0c\u5219\u8282\u70b9B\u5fc5\u987b\u7b49\u8282\u70b9A\u5b8c\u6210\u540e\u624d\u80fd\u6267\u884c\uff0c\u5426\u5219\u8bfb\u53d6\u7684\u53c2\u6570\u03b8\u4e3a\u66f4\u65b0\u524d\u7684\u6570\u503c\uff0c\u8fd9\u65f6\u9700\u8981\u4e00\u4e2a\u8fd0\u7b97\u63a7\u5236\u5668\u3002\u63a5\u53e3\u51fd\u6570\u5982\u4e0b\uff0ctf.control_dependencies\u51fd\u6570\u53ef\u4ee5\u63a7\u5236\u591a\u4e2a\u6570\u636e\u6d41\u6267\u884c\u5b8c\u6210\u540e\u624d\u80fd\u6267\u884c\u63a5\u4e0b\u6765\u7684\u64cd\u4f5c\uff0c\u901a\u5e38\u4e0etf.group\u51fd\u6570\u7ed3\u5408\u4f7f\u7528\u3002 TF\u652f\u6301\u7684\u63a7\u5236\u7b97\u5b50\u6709Switch\u3001Merge\u3001Enter\u3001Leave\u548cNextIteration\u7b49\u3002 TF\u4e0d\u4ec5\u652f\u6301\u903b\u8f91\u63a7\u5236\uff0c\u8fd8\u652f\u6301\u5faa\u73af\u63a7\u5236\u3002TF\u4f7f\u7528\u548cMIT Token-Tagged machine\u76f8\u4f3c\u7684\u8868\u793a\u7cfb\u7edf\uff0c\u5c06\u5faa\u73af\u7684\u6bcf\u6b21\u8fed\u4ee3\u6807\u8bb0\u4e3a\u4e00\u4e2atag\uff0c\u8fed\u4ee3\u7684\u6267\u884c\u72b6\u6001\u6807\u8bb0\u4e3a\u4e00\u4e2aframe\uff0c\u4f46\u8fed\u4ee3\u6240\u9700\u7684\u6570\u636e\u51c6\u5907\u597d\u7684\u65f6\u5019\uff0c\u5c31\u53ef\u4ee5\u5f00\u59cb\u8ba1\u7b97\uff0c\u4ece\u800c\u591a\u4e2a\u8fed\u4ee3\u53ef\u4ee5\u540c\u65f6\u6267\u884c\u3002","title":"2.4 \u63a7\u5236\u6d41"},{"location":"Programming/TensorFlow/Implementation/XLA/","text":"XLA: Optimizing Compiler for Machine Learning https://www.tensorflow.org/xla https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/g3doc/index.md","title":"Introduction"},{"location":"Programming/TensorFlow/Implementation/XLA/#xla#optimizing#compiler#for#machine#learning","text":"https://www.tensorflow.org/xla https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/g3doc/index.md","title":"XLA: Optimizing Compiler for Machine Learning"},{"location":"Programming/pytorch/paper-Automatic-differentiation-in-PyTorch/","text":"","title":"paper-Automatic-differentiation-in-PyTorch"},{"location":"Research-Institution%26Researcher/Research-institution/","text":"\u7814\u7a76\u673a\u6784 \u4e2d\u56fd\u79d1\u5b66\u9662\u81ea\u52a8\u5316\u7814\u7a76\u6240","title":"Research-institution"},{"location":"Research-Institution%26Researcher/Research-institution/#_1","text":"","title":"\u7814\u7a76\u673a\u6784"},{"location":"Research-Institution%26Researcher/Research-institution/#_2","text":"","title":"\u4e2d\u56fd\u79d1\u5b66\u9662\u81ea\u52a8\u5316\u7814\u7a76\u6240"},{"location":"Research-Institution%26Researcher/Researcher/","text":"\u7814\u7a76\u5458 \u8d75\u519b http://people.ucas.edu.cn/~zhaojun Michael Nielsen Neural Networks and Deep Learning LiHang Recent Progress in Deep Learning for Natural Language Processing","title":"Researcher"},{"location":"Research-Institution%26Researcher/Researcher/#_1","text":"","title":"\u7814\u7a76\u5458"},{"location":"Research-Institution%26Researcher/Researcher/#_2","text":"http://people.ucas.edu.cn/~zhaojun","title":"\u8d75\u519b"},{"location":"Research-Institution%26Researcher/Researcher/#michael#nielsen","text":"Neural Networks and Deep Learning","title":"Michael Nielsen"},{"location":"Research-Institution%26Researcher/Researcher/#lihang","text":"Recent Progress in Deep Learning for Natural Language Processing","title":"LiHang"},{"location":"Theory/","text":"\u524d\u8a00 \u672c\u7ae0\u4ecb\u7ecd\u673a\u5668\u5b66\u4e60\u7684\u76f8\u5173\u7684\u7406\u8bba\u77e5\u8bc6\u3002 \u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1\uff1a\u5728Probability-theory-and-Statistics\u7ae0\u8282 \u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\uff1a\u5728Deep-learning\u7ae0\u8282","title":"Introduction"},{"location":"Theory/#_1","text":"\u672c\u7ae0\u4ecb\u7ecd\u673a\u5668\u5b66\u4e60\u7684\u76f8\u5173\u7684\u7406\u8bba\u77e5\u8bc6\u3002 \u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1\uff1a\u5728Probability-theory-and-Statistics\u7ae0\u8282 \u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\uff1a\u5728Deep-learning\u7ae0\u8282","title":"\u524d\u8a00"},{"location":"Theory/Data-generating-process/","text":"Data-generating process \u5728\u591a\u4e2a\u5730\u65b9\u9047\u5230\u4e86\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u4f46\u662f\u76ee\u524d\u8fd8\u662f\u6ca1\u6709\u5145\u5206\u7406\u89e3\u5b83\u7684\u542b\u4e49\u3002 \u4e0b\u9762\u679a\u4e3e\u4e86\u78b0\u5230\u8be5\u8bcd\u7684\u5730\u65b9\uff1a Statistical model Deep learning book\u76845.2 Capacity, Overfitting and Underfitting","title":"Data-generating-process"},{"location":"Theory/Data-generating-process/#data-generating#process","text":"\u5728\u591a\u4e2a\u5730\u65b9\u9047\u5230\u4e86\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u4f46\u662f\u76ee\u524d\u8fd8\u662f\u6ca1\u6709\u5145\u5206\u7406\u89e3\u5b83\u7684\u542b\u4e49\u3002 \u4e0b\u9762\u679a\u4e3e\u4e86\u78b0\u5230\u8be5\u8bcd\u7684\u5730\u65b9\uff1a Statistical model Deep learning book\u76845.2 Capacity, Overfitting and Underfitting","title":"Data-generating process"},{"location":"Theory/VS-statistical-model-VS-machine-learning-model/","text":"VS: statistical model VS machine learning model Machine learning\u672c\u8d28\u4e0a\u662f\u4e00\u79cdstatistical inference\uff0c\u673a\u5668\u5b66\u4e60\u7684\u8f93\u51fa\u662f\u4e00\u4e2astatistical model\u3002 Statistical model \u4e2d\u5173\u4e8estatistical model\u7684\u96be\u70b9\uff1a Choosing an appropriate statistical model to represent a given data-generating process is sometimes extremely difficult, and may require knowledge of both the process and relevant statistical analyses. Relatedly, the statistician Sir David Cox has said, \"How [the] translation from subject-matter problem to statistical model is done is often the most critical part of an analysis\". Statistical model\u7684\u96be\u70b9\u662fmachine learning model\u9700\u8981\u53bb\u89e3\u51b3\u7684\u3002 Statistical model VS machine learning Deep learning book\u7684Chapter 5 Machine Learning Basics\u4e2d\u7528regression\uff08\u4e00\u79cdstatistical model\uff09\u5bfc\u5f15\u4ecb\u7ecd\u4e86machine learning\u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u5728\u540e\u9762\u5b66\u4e60\u5b8c\u4e86deep learning\u7684\u7406\u8bba\u540e\uff0c\u5bf9\u6bd4\u6765\u770bChapter 5 Machine Learning Basics\u4e2d\u5173\u4e8eregression\u7684\u4ecb\u7ecd\uff0c\u6709\u5982\u4e0b\u53d1\u73b0\uff1a deep learning\u548cregression\u4e4b\u95f4\u6709\u7740\u672c\u8d28\u7684\u5dee\u522b\uff1a regression\u6b63\u5982\u5728chapter 5.2 Capacity, Overfitting and Underfitting\u4e2d\u6240\u63cf\u8ff0\u7684\uff1a\u5b83\u4f1a\u9650\u5236model\u7684**hypothesis space** One way to control the capacity of a learning algorithm is by choosing its hypothesis space, the set of functions that the learning algorithm is allowed to select as being the solution. For example, the linear regression algorithm has the set of all linear functions of its input as its hypothesis space. We can generalize linear regression to include polynomials, rather than just linear functions, in its hypothesis space. Doing so increases the model\u2019s capacity. A polynomial of degree one gives us the linear regression model with which we are already familiar, with prediction $ y=b+wx.$ \u663e\u7136\u5728linear regression\u4e2d\uff0c\u9700\u8981\u5b66\u4e60\u7684\u53c2\u6570\u662f b \u548c w \u4f46\u662fdeep learning\u5219\u4e0d\u540c\uff0c\u5b83\u5e76\u4e0d\u4f1a\u9650\u5236model\u7684**hypothesis space**\uff0c\u800c\u662f\u53bbapproximate\uff0c\u4e5f\u5c31\u662f**universal approximation theorem**\u4e2d\u6240\u63cf\u8ff0\u7684\u90a3\u6837\uff1b deep learning\u548cregression\u4e4b\u95f4\u7684\u5171\u540c\u70b9\uff1a \u672c\u8d28\u4e0a\u6765\u8bf4deep learning\u548cregression\u9700\u8981\u5b66\u4e60\u7684\u90fd\u662fparameter\uff1b\u4e0d\u7ba1\u662f\u591a\u4e48\u590d\u6742\u7684model\uff08MLP\uff0cCNN\uff0cRNN\uff0cLSTM\u7b49\u7b49\uff09\uff0c\u5b83\u6700\u7ec8\u90fd\u662f\u7531\u4e00\u7cfb\u5217\u7684parameter\u6765\u51b3\u5b9a\uff1b","title":"VS-statistical-model-VS-machine-learning-model"},{"location":"Theory/VS-statistical-model-VS-machine-learning-model/#vs#statistical#model#vs#machine#learning#model","text":"Machine learning\u672c\u8d28\u4e0a\u662f\u4e00\u79cdstatistical inference\uff0c\u673a\u5668\u5b66\u4e60\u7684\u8f93\u51fa\u662f\u4e00\u4e2astatistical model\u3002 Statistical model \u4e2d\u5173\u4e8estatistical model\u7684\u96be\u70b9\uff1a Choosing an appropriate statistical model to represent a given data-generating process is sometimes extremely difficult, and may require knowledge of both the process and relevant statistical analyses. Relatedly, the statistician Sir David Cox has said, \"How [the] translation from subject-matter problem to statistical model is done is often the most critical part of an analysis\". Statistical model\u7684\u96be\u70b9\u662fmachine learning model\u9700\u8981\u53bb\u89e3\u51b3\u7684\u3002","title":"VS: statistical model VS machine learning model"},{"location":"Theory/VS-statistical-model-VS-machine-learning-model/#statistical#model#vs#machine#learning","text":"Deep learning book\u7684Chapter 5 Machine Learning Basics\u4e2d\u7528regression\uff08\u4e00\u79cdstatistical model\uff09\u5bfc\u5f15\u4ecb\u7ecd\u4e86machine learning\u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u5728\u540e\u9762\u5b66\u4e60\u5b8c\u4e86deep learning\u7684\u7406\u8bba\u540e\uff0c\u5bf9\u6bd4\u6765\u770bChapter 5 Machine Learning Basics\u4e2d\u5173\u4e8eregression\u7684\u4ecb\u7ecd\uff0c\u6709\u5982\u4e0b\u53d1\u73b0\uff1a deep learning\u548cregression\u4e4b\u95f4\u6709\u7740\u672c\u8d28\u7684\u5dee\u522b\uff1a regression\u6b63\u5982\u5728chapter 5.2 Capacity, Overfitting and Underfitting\u4e2d\u6240\u63cf\u8ff0\u7684\uff1a\u5b83\u4f1a\u9650\u5236model\u7684**hypothesis space** One way to control the capacity of a learning algorithm is by choosing its hypothesis space, the set of functions that the learning algorithm is allowed to select as being the solution. For example, the linear regression algorithm has the set of all linear functions of its input as its hypothesis space. We can generalize linear regression to include polynomials, rather than just linear functions, in its hypothesis space. Doing so increases the model\u2019s capacity. A polynomial of degree one gives us the linear regression model with which we are already familiar, with prediction $ y=b+wx.$ \u663e\u7136\u5728linear regression\u4e2d\uff0c\u9700\u8981\u5b66\u4e60\u7684\u53c2\u6570\u662f b \u548c w \u4f46\u662fdeep learning\u5219\u4e0d\u540c\uff0c\u5b83\u5e76\u4e0d\u4f1a\u9650\u5236model\u7684**hypothesis space**\uff0c\u800c\u662f\u53bbapproximate\uff0c\u4e5f\u5c31\u662f**universal approximation theorem**\u4e2d\u6240\u63cf\u8ff0\u7684\u90a3\u6837\uff1b deep learning\u548cregression\u4e4b\u95f4\u7684\u5171\u540c\u70b9\uff1a \u672c\u8d28\u4e0a\u6765\u8bf4deep learning\u548cregression\u9700\u8981\u5b66\u4e60\u7684\u90fd\u662fparameter\uff1b\u4e0d\u7ba1\u662f\u591a\u4e48\u590d\u6742\u7684model\uff08MLP\uff0cCNN\uff0cRNN\uff0cLSTM\u7b49\u7b49\uff09\uff0c\u5b83\u6700\u7ec8\u90fd\u662f\u7531\u4e00\u7cfb\u5217\u7684parameter\u6765\u51b3\u5b9a\uff1b","title":"Statistical model VS machine learning"},{"location":"Theory/VS-statistical-model-VS-stochastic-process/","text":"Statistical model VS stochastic process \u6b63\u5982\u7ef4\u57fa\u767e\u79d1 Statistical model \u4e2d\u6240\u8ff0\uff1a A statistical model is usually specified as a mathematical relationship between one or more random variables and other non-random variables. \u5373statistical model\u662frandom variable\u4e4b\u95f4\u7684relationship\uff0c\u6700\u6700\u5178\u578b\u7684statistical model\u662f linear regression model\uff08\u663e\u7136\uff0c\u81ea\u53d8\u91cf\u548c\u56e0\u53d8\u91cf\u4e4b\u95f4\u662f\u7ebf\u6027\u5173\u7cfb\uff09\u3002machine learning model\u662fmachine\u5b66\u4e60\u7684\u7ed3\u679c\uff0c\u6211\u89c9\u5f97\u5b83\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u4e2astatistical model\u3002 stochastic process\u5373\u968f\u673a\u8fc7\u7a0b\uff0c\u5b83\u6240\u63cf\u8ff0\u7684\u662f\u4e00\u65cfrandom variable\u7684\u53d8\u5316\u8fc7\u7a0b\u3002 \u53ef\u4ee5\u53c2\u770b\uff1a \u767e\u5ea6\u767e\u79d1 \u968f\u673a\u8fc7\u7a0b \u5728 Theory\\Probability-theory-and-Statistics\\Probability-theory\\\\Stochastic-process \u4e2d\u5bf9\u5b83\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002","title":"VS-statistics-model-VS-stochastic-process"},{"location":"Theory/VS-statistical-model-VS-stochastic-process/#statistical#model#vs#stochastic#process","text":"\u6b63\u5982\u7ef4\u57fa\u767e\u79d1 Statistical model \u4e2d\u6240\u8ff0\uff1a A statistical model is usually specified as a mathematical relationship between one or more random variables and other non-random variables. \u5373statistical model\u662frandom variable\u4e4b\u95f4\u7684relationship\uff0c\u6700\u6700\u5178\u578b\u7684statistical model\u662f linear regression model\uff08\u663e\u7136\uff0c\u81ea\u53d8\u91cf\u548c\u56e0\u53d8\u91cf\u4e4b\u95f4\u662f\u7ebf\u6027\u5173\u7cfb\uff09\u3002machine learning model\u662fmachine\u5b66\u4e60\u7684\u7ed3\u679c\uff0c\u6211\u89c9\u5f97\u5b83\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u4e2astatistical model\u3002 stochastic process\u5373\u968f\u673a\u8fc7\u7a0b\uff0c\u5b83\u6240\u63cf\u8ff0\u7684\u662f\u4e00\u65cfrandom variable\u7684\u53d8\u5316\u8fc7\u7a0b\u3002 \u53ef\u4ee5\u53c2\u770b\uff1a \u767e\u5ea6\u767e\u79d1 \u968f\u673a\u8fc7\u7a0b \u5728 Theory\\Probability-theory-and-Statistics\\Probability-theory\\\\Stochastic-process \u4e2d\u5bf9\u5b83\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002","title":"Statistical model VS stochastic process"},{"location":"Theory/Deep-learning/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u4e3b\u8981\u63cf\u8ff0\u7684\u662fdeep learning\u76f8\u5173\u7406\u8bba\uff1a deep learning\u57fa\u7840\u7406\u8bba\uff1a\u4ee5deep learning book\u4e3a\u53c2\u8003\uff0c\u5728Book-deep-learning\u7ae0\u8282\u8bb0\u5f55\u4e86\u9605\u8bfb\u7b14\u8bb0\uff1b Attention\uff1a\u5728Attention\u7ae0\u8282\u63cf\u8ff0\uff1b end-to-end\uff1a\u5728End-to-end\u7ae0\u8282\u63cf\u8ff0\uff1b \u6982\u62ec model\u662f\u5bf9\u5173\u7cfb\u7684\u5047\u8bbe\uff0c\u662f\u5bf9\u65e0\u6cd5\u5f62\u5f0f\u5316\u63cf\u8ff0\u7684\u5173\u7cfb\u7684\u8868\u8fbe\uff1bmodel\u6709\u7740parameter\uff0c\u5982\u4f55\u5b66\u4e60\u5230\u4e00\u4e2amodel\uff1f\u663e\u7136\u5c31\u662f\u5b66\u4e60\u8fd9\u4e2amodel\u7684parameter\uff1b \u663e\u7136\u8fd9\u4e9bparameter\u662f\u6211\u4eec\u9700\u8981\u5b66\u4e60\u7684\uff1b\u90a3\u5982\u4f55\u5b66\u4e60\u5462\uff1f \u901a\u8fc7minimize loss\u6765\u8fdb\u884c\u5b66\u4e60\uff1b\u5982\u4f55\u6765\u5b9a\u4e49loss\uff1f\u771f\u5b9e\u4e0emodel\u8f93\u51fa\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b minimize loss function\u5373\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570 \u4f18\u5316\u7406\u8bba\uff0c\u5bfb\u627e\u6700\u4f18\u89e3\u7684\u8fc7\u7a0b\u4e86\u3002\u5c31\u597d\u6bd4\u9ad8\u4e2d\u8bfe\u7a0b\u4e2d\u6240\u5b66\u4e60\u7684\u51fd\u6570\u5728\u4f55\u5904\u53d6\u5f97\u6781\u503c\u3002 \u6b63\u5411\u4f20\u64ad\u4e0e\u53cd\u5411\u4f20\u64ad\u3002","title":"Introduction"},{"location":"Theory/Deep-learning/#_1","text":"\u672c\u7ae0\u4e3b\u8981\u63cf\u8ff0\u7684\u662fdeep learning\u76f8\u5173\u7406\u8bba\uff1a deep learning\u57fa\u7840\u7406\u8bba\uff1a\u4ee5deep learning book\u4e3a\u53c2\u8003\uff0c\u5728Book-deep-learning\u7ae0\u8282\u8bb0\u5f55\u4e86\u9605\u8bfb\u7b14\u8bb0\uff1b Attention\uff1a\u5728Attention\u7ae0\u8282\u63cf\u8ff0\uff1b end-to-end\uff1a\u5728End-to-end\u7ae0\u8282\u63cf\u8ff0\uff1b","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Deep-learning/#_2","text":"model\u662f\u5bf9\u5173\u7cfb\u7684\u5047\u8bbe\uff0c\u662f\u5bf9\u65e0\u6cd5\u5f62\u5f0f\u5316\u63cf\u8ff0\u7684\u5173\u7cfb\u7684\u8868\u8fbe\uff1bmodel\u6709\u7740parameter\uff0c\u5982\u4f55\u5b66\u4e60\u5230\u4e00\u4e2amodel\uff1f\u663e\u7136\u5c31\u662f\u5b66\u4e60\u8fd9\u4e2amodel\u7684parameter\uff1b \u663e\u7136\u8fd9\u4e9bparameter\u662f\u6211\u4eec\u9700\u8981\u5b66\u4e60\u7684\uff1b\u90a3\u5982\u4f55\u5b66\u4e60\u5462\uff1f \u901a\u8fc7minimize loss\u6765\u8fdb\u884c\u5b66\u4e60\uff1b\u5982\u4f55\u6765\u5b9a\u4e49loss\uff1f\u771f\u5b9e\u4e0emodel\u8f93\u51fa\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b minimize loss function\u5373\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570 \u4f18\u5316\u7406\u8bba\uff0c\u5bfb\u627e\u6700\u4f18\u89e3\u7684\u8fc7\u7a0b\u4e86\u3002\u5c31\u597d\u6bd4\u9ad8\u4e2d\u8bfe\u7a0b\u4e2d\u6240\u5b66\u4e60\u7684\u51fd\u6570\u5728\u4f55\u5904\u53d6\u5f97\u6781\u503c\u3002 \u6b63\u5411\u4f20\u64ad\u4e0e\u53cd\u5411\u4f20\u64ad\u3002","title":"\u6982\u62ec"},{"location":"Theory/Deep-learning/Book-Neural-Networks-and-Deep-Learning/","text":"Neural Networks and Deep Learning","title":"Introduction"},{"location":"Theory/Deep-learning/Book-Neural-Networks-and-Deep-Learning/#neural#networks#and#deep#learning","text":"","title":"Neural Networks and Deep Learning"},{"location":"Theory/Deep-learning/Book-deep-learning/Deep-learning-book/","text":"\u5173\u4e8e\u672c\u7ae0 \u672c\u7ae0\u662f\u6211\u9605\u8bfb Deep Learning Book \u7684\u9605\u8bfb\u7b14\u8bb0\u3002 https://github.com/janishar/mit-deep-learning-book-pdf","title":"Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Deep-learning-book/#_1","text":"\u672c\u7ae0\u662f\u6211\u9605\u8bfb Deep Learning Book \u7684\u9605\u8bfb\u7b14\u8bb0\u3002 https://github.com/janishar/mit-deep-learning-book-pdf","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/1-Introduction/","text":"Chapter 1 Introduction In the early days of artificial intelligence, the field rapidly tackled and solved problems that are intellectually difficult for human beings but relatively straightforward for computers\u2014 problems that can be described by a list of formal, mathematical rules . The true challenge to artificial intelligence proved to be solving the tasks that are easy for people to perform but hard for people to describe formally \u2014problems that we solve intuitively, that feel automatic, like recognizing spoken words or faces in images. \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u672c\u7ae0\u4e2d\uff0c\u4f5c\u8005\u9891\u7e41\u7684\u4f7f\u7528\u4e86**formal**\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u6240\u4ee5\u7406\u89e3\u8fd9\u4e2a\u8bcd\u8bed\u5bf9\u4e8e\u7406\u89e3\u672c\u6587\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u8bfb\u8005\u53ef\u4ee5\u5c06\u5b83\u7b80\u5355\u7684\u7406\u89e3\u4e3a\u53ef\u4ee5\u89c4\u5219\u5316\u7684\uff0c\u53ef\u4ee5\u4f7f\u7528\u6570\u5b66\u516c\u5f0f\u8fdb\u884c\u63cf\u8ff0\u7684\u3002\u6709\u7ecf\u9a8c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u4e00\u5b9a\u80fd\u591f\u60f3\u5230\uff0c**problems that can be described by a list of formal, mathematical rules**\u662f\u6bd4\u8f83\u5bb9\u6613\u7528\u7a0b\u5e8f\u6765\u8fdb\u884c\u5b9e\u73b0\u7684\u3002 \u8ba1\u7b97\u673a\u548c\u4eba\u7c7b\u6240\u64c5\u957f\u7684\u662f\u4e0d\u540c\u7684\uff1a\u8ba1\u7b97\u673a\u6240\u64c5\u957f\u7684\u662f\u89e3\u51b3\u5982\u4e0b\u7c7b\u578b\u7684\u95ee\u9898\uff1a problems that can be described by a list of formal, mathematical rules \u5bf9\u4e8e\u8fd9\u7c7b\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7b97\u6cd5\u57fa\u672c\u80fd\u591f\u5b9e\u73b0\u3002 \u4eba\u7c7b\u6240\u64c5\u957f\u7684\u662f\u89e3\u51b3\u7684\u662f: problems that are intuitive and hard for people to describe formally \u5bf9\u4e8e\u8fd9\u7c7b\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7b97\u6cd5\u662f\u975e\u5e38\u96be\u4ee5\u5b9e\u73b0\u7684\u3002\u8fd9\u7c7b\u95ee\u9898\u6b63\u662f\u672c\u4e66\u6240\u63cf\u8ff0\u7684deep learning\u6280\u672f\u5fd7\u4e8e\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u89e3\u51b3\u601d\u60f3\u5982\u4e0b\uff1a This book is about a solution to these more intuitive problems . This solution is to allow computers to learn from experience and understand the world in terms of a hierarchy of concepts, with each concept defined in terms of its relation to simpler concepts . By gathering knowledge from experience, this approach avoids the need for human operators to formally specify all of the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason, we call this approach to AI deep learning . \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86\u5f53\u524d**machine learning**\u7684\u6838\u5fc3\u601d\u60f3\uff0c\u8fd9\u4e2a\u601d\u60f3\u7684\u5bf9\u4e8e\u7406\u89e3\u540e\u9762\u7ae0\u8282\u7684\u5185\u5bb9\u662f\u975e\u5e38\u91cd\u8981\u7684\uff0c\u6216\u8005\u8bf4\uff0c\u540e\u9762\u7ae0\u8282\u5c31\u662f\u5728\u544a\u8bc9\u8bfb\u8005\u5982\u4f55\u6765\u5b9e\u73b0machine learning\u3002 \u539f\u4e66\u7684\u8fd9\u4e00\u8282\u7684\u540e\u7eed\u5185\u5bb9\u57fa\u672c\u4e0a\u5c31\u662f\u56f4\u7ed5\u7740\u6211\u4e0a\u9762\u6240\u603b\u7ed3\u7684\u5185\u5bb9\u5c55\u5f00\u7684\u3002 \u6848\u4f8b\uff1aFormal language and natural language \u5173\u4e8e\u8ba1\u7b97\u673a\u548c\u4eba\u7c7b\u6240\u64c5\u957f\u89e3\u51b3\u7684\u95ee\u9898\u7684\u4e00\u4e2a\u5178\u578b\u6848\u4f8b\u5c31\u662f\uff1aformal language\u548cnatural language\u3002\u8ba1\u7b97\u673a\u80fd\u591f\u8f7b\u677e\u7406\u89e3formal language\uff08\u56e0\u4e3aformal language\u7684grammar\u548csemantic\u90fd\u80fd\u591f\u5f62\u5f0f\u5316\u5730\u8fdb\u884c\u63cf\u8ff0\uff09\uff0c\u4f46\u662f\u5bf9\u4e8enatural language\u7684\u7406\u89e3\u5219\u662f\u975e\u5e38\u53ef\u80fd\u7684\uff08natural language\u7684grammar\u548csemantic\u662f\u975e\u5e38\u590d\u6742\u7684\uff0c\u65e0\u6cd5\u8fdb\u884c\u5f62\u5f0f\u5316\u7684\u63cf\u8ff0\uff09\u3002\u800c\u4eba\u7c7b\u57fa\u672c\u76f8\u53cd\u3002 \u6848\u4f8b\uff1a Pattern matching and Pattern recognition \u8fd9\u662f\u53e6\u5916\u4e00\u4e2a\u6848\u4f8b\u3002 \u5173\u4e8emachine learning\u80fd\u591f\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u53c2\u89c1chapter 5.1 Learning Algorithms\u3002","title":"1-Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/1-Introduction/#chapter#1#introduction","text":"In the early days of artificial intelligence, the field rapidly tackled and solved problems that are intellectually difficult for human beings but relatively straightforward for computers\u2014 problems that can be described by a list of formal, mathematical rules . The true challenge to artificial intelligence proved to be solving the tasks that are easy for people to perform but hard for people to describe formally \u2014problems that we solve intuitively, that feel automatic, like recognizing spoken words or faces in images. \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u672c\u7ae0\u4e2d\uff0c\u4f5c\u8005\u9891\u7e41\u7684\u4f7f\u7528\u4e86**formal**\u8fd9\u4e2a\u8bcd\u8bed\uff0c\u6240\u4ee5\u7406\u89e3\u8fd9\u4e2a\u8bcd\u8bed\u5bf9\u4e8e\u7406\u89e3\u672c\u6587\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u8bfb\u8005\u53ef\u4ee5\u5c06\u5b83\u7b80\u5355\u7684\u7406\u89e3\u4e3a\u53ef\u4ee5\u89c4\u5219\u5316\u7684\uff0c\u53ef\u4ee5\u4f7f\u7528\u6570\u5b66\u516c\u5f0f\u8fdb\u884c\u63cf\u8ff0\u7684\u3002\u6709\u7ecf\u9a8c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u4e00\u5b9a\u80fd\u591f\u60f3\u5230\uff0c**problems that can be described by a list of formal, mathematical rules**\u662f\u6bd4\u8f83\u5bb9\u6613\u7528\u7a0b\u5e8f\u6765\u8fdb\u884c\u5b9e\u73b0\u7684\u3002 \u8ba1\u7b97\u673a\u548c\u4eba\u7c7b\u6240\u64c5\u957f\u7684\u662f\u4e0d\u540c\u7684\uff1a\u8ba1\u7b97\u673a\u6240\u64c5\u957f\u7684\u662f\u89e3\u51b3\u5982\u4e0b\u7c7b\u578b\u7684\u95ee\u9898\uff1a problems that can be described by a list of formal, mathematical rules \u5bf9\u4e8e\u8fd9\u7c7b\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7b97\u6cd5\u57fa\u672c\u80fd\u591f\u5b9e\u73b0\u3002 \u4eba\u7c7b\u6240\u64c5\u957f\u7684\u662f\u89e3\u51b3\u7684\u662f: problems that are intuitive and hard for people to describe formally \u5bf9\u4e8e\u8fd9\u7c7b\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u7b97\u6cd5\u662f\u975e\u5e38\u96be\u4ee5\u5b9e\u73b0\u7684\u3002\u8fd9\u7c7b\u95ee\u9898\u6b63\u662f\u672c\u4e66\u6240\u63cf\u8ff0\u7684deep learning\u6280\u672f\u5fd7\u4e8e\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u89e3\u51b3\u601d\u60f3\u5982\u4e0b\uff1a This book is about a solution to these more intuitive problems . This solution is to allow computers to learn from experience and understand the world in terms of a hierarchy of concepts, with each concept defined in terms of its relation to simpler concepts . By gathering knowledge from experience, this approach avoids the need for human operators to formally specify all of the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason, we call this approach to AI deep learning . \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u63cf\u8ff0\u4e86\u5f53\u524d**machine learning**\u7684\u6838\u5fc3\u601d\u60f3\uff0c\u8fd9\u4e2a\u601d\u60f3\u7684\u5bf9\u4e8e\u7406\u89e3\u540e\u9762\u7ae0\u8282\u7684\u5185\u5bb9\u662f\u975e\u5e38\u91cd\u8981\u7684\uff0c\u6216\u8005\u8bf4\uff0c\u540e\u9762\u7ae0\u8282\u5c31\u662f\u5728\u544a\u8bc9\u8bfb\u8005\u5982\u4f55\u6765\u5b9e\u73b0machine learning\u3002 \u539f\u4e66\u7684\u8fd9\u4e00\u8282\u7684\u540e\u7eed\u5185\u5bb9\u57fa\u672c\u4e0a\u5c31\u662f\u56f4\u7ed5\u7740\u6211\u4e0a\u9762\u6240\u603b\u7ed3\u7684\u5185\u5bb9\u5c55\u5f00\u7684\u3002","title":"Chapter 1 Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/1-Introduction/#formal#language#and#natural#language","text":"\u5173\u4e8e\u8ba1\u7b97\u673a\u548c\u4eba\u7c7b\u6240\u64c5\u957f\u89e3\u51b3\u7684\u95ee\u9898\u7684\u4e00\u4e2a\u5178\u578b\u6848\u4f8b\u5c31\u662f\uff1aformal language\u548cnatural language\u3002\u8ba1\u7b97\u673a\u80fd\u591f\u8f7b\u677e\u7406\u89e3formal language\uff08\u56e0\u4e3aformal language\u7684grammar\u548csemantic\u90fd\u80fd\u591f\u5f62\u5f0f\u5316\u5730\u8fdb\u884c\u63cf\u8ff0\uff09\uff0c\u4f46\u662f\u5bf9\u4e8enatural language\u7684\u7406\u89e3\u5219\u662f\u975e\u5e38\u53ef\u80fd\u7684\uff08natural language\u7684grammar\u548csemantic\u662f\u975e\u5e38\u590d\u6742\u7684\uff0c\u65e0\u6cd5\u8fdb\u884c\u5f62\u5f0f\u5316\u7684\u63cf\u8ff0\uff09\u3002\u800c\u4eba\u7c7b\u57fa\u672c\u76f8\u53cd\u3002","title":"\u6848\u4f8b\uff1aFormal language and natural language"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/1-Introduction/#pattern#matching#and#pattern#recognition","text":"\u8fd9\u662f\u53e6\u5916\u4e00\u4e2a\u6848\u4f8b\u3002 \u5173\u4e8emachine learning\u80fd\u591f\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u53c2\u89c1chapter 5.1 Learning Algorithms\u3002","title":"\u6848\u4f8b\uff1aPattern matching and Pattern recognition"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5-Machine-Learning-Basics/","text":"Chapter 5 Machine Learning Basics \u6bcf\u7ae0\u7684\u5f00\u5934\u4f5c\u8005\u90fd\u4f1a\u629b\u51fa\u4e00\u7cfb\u5217\u7684\u95ee\u9898\uff0c\u672c\u7ae0\u4f5c\u8005\u6240\u629b\u51fa\u7684\u95ee\u9898\u53ef\u4ee5\u8bf4\u662fmachine learning\u4e2d\u6700\u6700\u672c\u8d28\u7684\u95ee\u9898\uff1a What a learning algorithm is How the challenge of fitting the training data differs from the challenge of finding patterns that generalize to new data How to set hyperparameters Machine learning is essentially a form of applied statistics with increased emphasis on the use of computers to statistically estimate complicated functions and a decreased emphasis on proving confidence intervals around these functions; we therefore present the two central approaches to statistics: frequentist estimators and Bayesian inference. \u8fd9\u6bb5\u8bdd\u5982\u4f55\u7406\u89e3\uff1f \u672c\u8d28\u4e0a\u6765\u8bf4\uff0c\u201cmachine learning\u201d\u5c5e\u201capplied statistics\u201d\u3002\u6240\u4ee5\u8981\u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u9700\u8981\u5bf9 Statistics \u7684\u7814\u7a76\u5206\u652f\u6709\u4e00\u4e9b\u4e86\u89e3\u4e86\u3002\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684\u201cfrequentist estimators\u201d\u548c\u201cBayesian inference\u201d\u90fd\u5c5e\u4e8e Statistical inference \u8303\u8f74\uff0c\u6309\u7167 Statistical inference \u7684\u8bf4\u6cd5\uff0c\u201cfrequentist estimators \u201d\u5bf9\u5e94\u7684\u662f Frequentist inference \uff0c\u201cBayesian inference\u201d\u5bf9\u5e94\u7684\u662f Bayesian inference \uff0c\u5b83\u4eec\u662f Frequentist inference \u7684\u4e24\u4e2a\u5b66\u6d3e\uff08\u6216paradigm\uff09\uff0c\u5173\u4e8e Frequentist inference \u7684\u5b66\u6d3e\uff0c\u53c2\u89c1 Paradigms for inference \u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a These schools\u2014or \"paradigms\"\u2014are not mutually exclusive, and methods that work well under one paradigm often have attractive interpretations under other paradigms. \u201cconfidence intervals\u201d\u7684\u4e2d\u6587\u610f\u601d\u662f\uff1a\u7f6e\u4fe1\u533a\u95f4\uff0c\u53c2\u89c1 Confidence Interval \u3002 \u5173\u4e8e\u7edf\u8ba1\u5b66\uff08statistics\uff09\u7684\u5185\u5bb9\uff0c\u53c2\u89c1 Probability-theory-and-Statistics \u7ae0\u8282\u3002 We describe how to combine various algorithm components such as an optimization algorithm , a cost function , a model , and a dataset to build a machine learning algorithm . \u6211\u89c9\u5f97\u8fd9\u6bb5\u8bdd\u6240\u4f20\u8fbe\u7684\u601d\u60f3\u662f\u6bd4\u8f83\u597d\u7684\uff1a\u5982\u679c\u5c06machine learning algorithm\u770b\u505a\u662f\u4e00\u4e2a\u673a\u5668\u7684\uff0c\u90a3\u4e48\u5b83\u6709\u5982\u4e0b\u96f6\u4ef6\uff08component\uff09\u7ec4\u6210\uff1a optimization algorithm model dataset \u90a3\u8bfb\u8005\u770b\u5230\u4f1a\u63d0\u51fa\u8fd9\u6837\u7684\u95ee\u9898\uff1a \u8fd9\u4e9bcomponent\u5206\u522b\u8868\u793a\u7684\u662f\u4ec0\u4e48\uff1f \u5b83\u4eec\u4e4b\u95f4\u662f\u5982\u4f55\u7ec4\u88c5\u3001\u534f\u52a9\u6765\u6784\u6210\u4e00\u4e2a\u5b8c\u6574\u7684machine learning algorithm\uff1f \u6bcf\u4e2acomponent\u6709\u54ea\u4e9b\u53ef\u4f9b\u9009\u62e9\u7684option\uff1f \u8fd9\u4e9b\u95ee\u9898\u5728\u672c\u4e66\u7684\u540e\u7eed\u7ae0\u8282\u4f1a\u4e13\u95e8\u8fdb\u884c\u4ecb\u7ecd\u3002 Finally, in section , we describe some of the 5.11 factors that have limited the ability of traditional machine learning to generalize. These challenges have motivated the development of deep learning algorithms that overcome these obstacles. \u4e0a\u8ff0ability\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1fdeep learning algorithm\u8f83traditional machine learning algorithm\u7684\u4f18\u52bf\u4f55\u5728\uff1f","title":"5-Machine-Learning-Basics"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5-Machine-Learning-Basics/#chapter#5#machine#learning#basics","text":"\u6bcf\u7ae0\u7684\u5f00\u5934\u4f5c\u8005\u90fd\u4f1a\u629b\u51fa\u4e00\u7cfb\u5217\u7684\u95ee\u9898\uff0c\u672c\u7ae0\u4f5c\u8005\u6240\u629b\u51fa\u7684\u95ee\u9898\u53ef\u4ee5\u8bf4\u662fmachine learning\u4e2d\u6700\u6700\u672c\u8d28\u7684\u95ee\u9898\uff1a What a learning algorithm is How the challenge of fitting the training data differs from the challenge of finding patterns that generalize to new data How to set hyperparameters Machine learning is essentially a form of applied statistics with increased emphasis on the use of computers to statistically estimate complicated functions and a decreased emphasis on proving confidence intervals around these functions; we therefore present the two central approaches to statistics: frequentist estimators and Bayesian inference. \u8fd9\u6bb5\u8bdd\u5982\u4f55\u7406\u89e3\uff1f \u672c\u8d28\u4e0a\u6765\u8bf4\uff0c\u201cmachine learning\u201d\u5c5e\u201capplied statistics\u201d\u3002\u6240\u4ee5\u8981\u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u9700\u8981\u5bf9 Statistics \u7684\u7814\u7a76\u5206\u652f\u6709\u4e00\u4e9b\u4e86\u89e3\u4e86\u3002\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684\u201cfrequentist estimators\u201d\u548c\u201cBayesian inference\u201d\u90fd\u5c5e\u4e8e Statistical inference \u8303\u8f74\uff0c\u6309\u7167 Statistical inference \u7684\u8bf4\u6cd5\uff0c\u201cfrequentist estimators \u201d\u5bf9\u5e94\u7684\u662f Frequentist inference \uff0c\u201cBayesian inference\u201d\u5bf9\u5e94\u7684\u662f Bayesian inference \uff0c\u5b83\u4eec\u662f Frequentist inference \u7684\u4e24\u4e2a\u5b66\u6d3e\uff08\u6216paradigm\uff09\uff0c\u5173\u4e8e Frequentist inference \u7684\u5b66\u6d3e\uff0c\u53c2\u89c1 Paradigms for inference \u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a These schools\u2014or \"paradigms\"\u2014are not mutually exclusive, and methods that work well under one paradigm often have attractive interpretations under other paradigms. \u201cconfidence intervals\u201d\u7684\u4e2d\u6587\u610f\u601d\u662f\uff1a\u7f6e\u4fe1\u533a\u95f4\uff0c\u53c2\u89c1 Confidence Interval \u3002 \u5173\u4e8e\u7edf\u8ba1\u5b66\uff08statistics\uff09\u7684\u5185\u5bb9\uff0c\u53c2\u89c1 Probability-theory-and-Statistics \u7ae0\u8282\u3002 We describe how to combine various algorithm components such as an optimization algorithm , a cost function , a model , and a dataset to build a machine learning algorithm . \u6211\u89c9\u5f97\u8fd9\u6bb5\u8bdd\u6240\u4f20\u8fbe\u7684\u601d\u60f3\u662f\u6bd4\u8f83\u597d\u7684\uff1a\u5982\u679c\u5c06machine learning algorithm\u770b\u505a\u662f\u4e00\u4e2a\u673a\u5668\u7684\uff0c\u90a3\u4e48\u5b83\u6709\u5982\u4e0b\u96f6\u4ef6\uff08component\uff09\u7ec4\u6210\uff1a optimization algorithm model dataset \u90a3\u8bfb\u8005\u770b\u5230\u4f1a\u63d0\u51fa\u8fd9\u6837\u7684\u95ee\u9898\uff1a \u8fd9\u4e9bcomponent\u5206\u522b\u8868\u793a\u7684\u662f\u4ec0\u4e48\uff1f \u5b83\u4eec\u4e4b\u95f4\u662f\u5982\u4f55\u7ec4\u88c5\u3001\u534f\u52a9\u6765\u6784\u6210\u4e00\u4e2a\u5b8c\u6574\u7684machine learning algorithm\uff1f \u6bcf\u4e2acomponent\u6709\u54ea\u4e9b\u53ef\u4f9b\u9009\u62e9\u7684option\uff1f \u8fd9\u4e9b\u95ee\u9898\u5728\u672c\u4e66\u7684\u540e\u7eed\u7ae0\u8282\u4f1a\u4e13\u95e8\u8fdb\u884c\u4ecb\u7ecd\u3002 Finally, in section , we describe some of the 5.11 factors that have limited the ability of traditional machine learning to generalize. These challenges have motivated the development of deep learning algorithms that overcome these obstacles. \u4e0a\u8ff0ability\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1fdeep learning algorithm\u8f83traditional machine learning algorithm\u7684\u4f18\u52bf\u4f55\u5728\uff1f","title":"Chapter 5 Machine Learning Basics"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.1-Learning-Algorithms/","text":"5.1 Learning Algorithms \u672c\u6bb5\u4e2d\u5173\u4e8e\u201clearning\u201d\u7684\u5b9a\u4e49\u662f\u5f15\u7528\u7684\u5982\u4e0b\u4e66\u7c4d\uff1a Machine Learning , Tom Mitchell , McGraw Hill, 1997. 5.1.1 The Task, T \u672c\u8282\u4f5c\u8005\u6240\u8981\u8868\u8fbe\u7684\u4e3b\u8981\u601d\u60f3\u7b80\u5355\u63cf\u8ff0\u5982\u4e0b\uff1a \u4eba\u7c7b\u5f00\u53d1computer program\u6765\u89e3\u51b3\u5f62\u5f62\u8272\u8272\u7684problem\uff0c\u8fd9\u4e9bproblem\u5c31\u662fprogram\u6240\u8981\u6267\u884c\u7684task\uff0c\u4f46\u662f\u6211\u4eec\u77e5\u9053\uff0cprogram\u5e76\u975e\u4e07\u80fd\u7684\uff0c\u8fd8\u662f\u6709\u975e\u5e38\u975e\u5e38\u591a\u7684problem\u662f\u65e0\u6cd5\u4f7f\u7528program\u6765\u89e3\u51b3\u7684\u3002\u968f\u7740\u79d1\u6280\u7684\u53d1\u5c55\uff0cprogram\u80fd\u591f\u89e3\u51b3\u7684problem\u4e5f\u8d8a\u6765\u8d8a\u591a\u4e86\uff0c\u4e5f\u5c31\u662fprogram\u7684\u80fd\u529b\u8d8a\u6765\u8d8a\u5f3a\u4e86\u3002machine learning algorithm\u5c31\u662f\u4e00\u79cd\u5728\u4e00\u7c7btask\u4e2d \u601d\u8003\uff1amachine learning algorithm VS \u666e\u901aalgorithm\uff1f machine learning algorithm\u662f\u4e00\u79cd\u5168\u65b0\u7684\u7b97\u6cd5\u8303\u5f0f\uff0c\u5b83\u4f7fprogram\u80fd\u591f\u201clearning\u201d\uff08\u201clearning\u201d\u57285.1 Learning Algorithms\u4e2d\u7ed9\u51fa\u5b9a\u4e49\uff09 Learning is our means of attaining the ability to perform the task. Pattern recognition\u662f\u4e00\u7c7b\u975e\u5e38\u666e\u904d\u7684task\uff0c\u5728\u4e0b\u8282\u4e2d\u4f1a\u8fdb\u884c\u8ba8\u8bba\u3002","title":"5.1-Learning-Algorithms"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.1-Learning-Algorithms/#51#learning#algorithms","text":"\u672c\u6bb5\u4e2d\u5173\u4e8e\u201clearning\u201d\u7684\u5b9a\u4e49\u662f\u5f15\u7528\u7684\u5982\u4e0b\u4e66\u7c4d\uff1a Machine Learning , Tom Mitchell , McGraw Hill, 1997.","title":"5.1 Learning Algorithms"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.1-Learning-Algorithms/#511#the#task#t","text":"\u672c\u8282\u4f5c\u8005\u6240\u8981\u8868\u8fbe\u7684\u4e3b\u8981\u601d\u60f3\u7b80\u5355\u63cf\u8ff0\u5982\u4e0b\uff1a \u4eba\u7c7b\u5f00\u53d1computer program\u6765\u89e3\u51b3\u5f62\u5f62\u8272\u8272\u7684problem\uff0c\u8fd9\u4e9bproblem\u5c31\u662fprogram\u6240\u8981\u6267\u884c\u7684task\uff0c\u4f46\u662f\u6211\u4eec\u77e5\u9053\uff0cprogram\u5e76\u975e\u4e07\u80fd\u7684\uff0c\u8fd8\u662f\u6709\u975e\u5e38\u975e\u5e38\u591a\u7684problem\u662f\u65e0\u6cd5\u4f7f\u7528program\u6765\u89e3\u51b3\u7684\u3002\u968f\u7740\u79d1\u6280\u7684\u53d1\u5c55\uff0cprogram\u80fd\u591f\u89e3\u51b3\u7684problem\u4e5f\u8d8a\u6765\u8d8a\u591a\u4e86\uff0c\u4e5f\u5c31\u662fprogram\u7684\u80fd\u529b\u8d8a\u6765\u8d8a\u5f3a\u4e86\u3002machine learning algorithm\u5c31\u662f\u4e00\u79cd\u5728\u4e00\u7c7btask\u4e2d \u601d\u8003\uff1amachine learning algorithm VS \u666e\u901aalgorithm\uff1f machine learning algorithm\u662f\u4e00\u79cd\u5168\u65b0\u7684\u7b97\u6cd5\u8303\u5f0f\uff0c\u5b83\u4f7fprogram\u80fd\u591f\u201clearning\u201d\uff08\u201clearning\u201d\u57285.1 Learning Algorithms\u4e2d\u7ed9\u51fa\u5b9a\u4e49\uff09 Learning is our means of attaining the ability to perform the task. Pattern recognition\u662f\u4e00\u7c7b\u975e\u5e38\u666e\u904d\u7684task\uff0c\u5728\u4e0b\u8282\u4e2d\u4f1a\u8fdb\u884c\u8ba8\u8bba\u3002","title":"5.1.1 The Task, T"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.2-Capacity-Overfitting-and-Underfitting/","text":"5.2 Capacity, Overfitting and Underfitting The train and test data are generated by a probability distribution over datasets called the data generating process . We typically make a set of assumptions known collectively as the i.i.d. assumptions . These assumptions are that the examples in each dataset are independent from each other, and that the train set and test set are identically distributed , drawn from the same probability distribution as each other. This assumption allows us to describe the data generating process with a probability distribution over a single example. The same distribution is then used to generate every train example and every test example. We call that shared underlying distribution the data generating distribution , denoted p_{data} p_{data} . This probabilistic framework and the i.i.d. assumptions allow us to mathematically study the relationship between training error and test error. \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u539f\u6587\u4e2d\u6bd4\u8f83\u4e0d\u5bb9\u6613\u7406\u89e3\u7684\u4e00\u6bb5\uff0c\u5b83\u7684\u4e2d\u6587\u7ffb\u8bd1\u5982\u4e0b\uff1a \u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u662f\u901a\u8fc7\u6570\u636e\u96c6\u4e0a\u88ab\u79f0\u4e3a\u201c\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u201d\uff08data generating process\uff09\u7684\u6982\u7387\u5206\u5e03\u751f\u6210\u3002\u6211\u4eec\u901a\u5e38\u4f1a\u505a\u4e00\u7cfb\u5217\u88ab\u79f0\u4e3a\u201c\u72ec\u7acb\u540c\u5206\u5e03\u5047\u8bbe\u201d\uff08i.i.d assumptions\uff09\u7684\u5047\u8bbe\u3002\u8be5\u5047\u8bbe\u7684\u542b\u4e49\u662f\uff1a\u6bcf\u4e2a\u6570\u636e\u96c6\u4e2d\u7684\u6837\u672c\u90fd\u662f\u5f7c\u6b64\u201c\u76f8\u4e92\u72ec\u7acb\u7684\u201d\uff08independent\uff09\uff0c\u5e76\u4e14\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u662f\u201c\u540c\u5206\u5e03\u7684\u201d\uff08identically distributed\uff09\uff0c\u91c7\u6837\u81ea\u7cfb\u7edf\u7684\u6982\u7387\u5206\u5e03\u3002\u8fd9\u4e2a\u5047\u8bbe\u5141\u8bb8\u6211\u4eec\u80fd\u591f\u5728\u5355\u4e2a\u6837\u672c\u7684\u6982\u7387\u5206\u5e03\u63cf\u8ff0**\u6570\u636e\u751f\u6210\u8fc7\u7a0b**\u3002\u7136\u540e\u76f8\u540c\u7684\u5206\u5e03\u53ef\u4ee5\u7528\u6765\u751f\u6210\u6bcf\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\u548c\u6bcf\u4e2a\u6d4b\u8bd5\u6837\u672c\u3002\u6211\u4eec\u5c31\u5c06\u8fd9\u4e2a\u5171\u4eab\u7684\u6f5c\u5728\u5206\u5e03\u79f0\u4e3a\u201c\u6570\u636e\u751f\u6210\u5206\u5e03\u201d\uff08data generating distribution\uff09\u3002\u8fd9\u4e2a\u6982\u7387\u6846\u67b6\u548c\u72ec\u7acb\u540c\u5206\u5e03\u5047\u8bbe\u5141\u8bb8\u6211\u4eec\u4ece\u6570\u5b66\u4e0a\u7814\u7a76\u8bad\u7ec3\u8bef\u5dee\u548c\u6d4b\u8bd5\u8bef\u5dee\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u201cdata generation distribution\u201d\u662f\u771f\u5b9e\u7684\u5206\u5e03\uff0c\u800c\u201cdata generating process\u201d\u5219\u662f\u6211\u4eec\u6839\u636etrain set\u5b66\u4e60\u5230\u7684\u53d1\u5e03\u3002\u5728\u7edf\u8ba1\u5b66\u4e2d\uff0c\u4f7f\u7528 Statistical model \u6765\u63cf\u8ff0\u201cdata generating process\u201d\u3002\u5173\u4e8e\u6b64\uff0c\u53c2\u89c1 \u5173\u4e8e**i.i.d. assumptions** \uff0c\u53c2\u89c1 Independent and identically distributed random variables \u3002 \u201cprobability distribution\u201d\u662f Probability theory \u4e2d\u7684\u6982\u5ff5\uff0c\u53c2\u89c1 probability distributions \u3002\u6240\u8c13\u201c identically distributed \u201d\uff0c\u662f\u6307\u4e24\u79cd\u7684 probability distributions \u76f8\u540c\u3002 \u540e\u8bb0 \u5bf9\u4e8ecapacity\u3001overfitting\u3001underfitting\u7684\u8ba8\u8bba\u662fmachine learning\u4e2d\u7684\u91cd\u8981\u95ee\u9898\u4e4b\u4e00\uff0c\u5728\u540e\u7eed\u7684\u7ae0\u8282\u4e2d\u8fd8\u5c06\u7ee7\u7eed\u5bf9\u5b83\u7684\u8ba8\u8bba\u3002","title":"5.2-Capacity-Overfitting-and-Underfitting"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.2-Capacity-Overfitting-and-Underfitting/#52#capacity#overfitting#and#underfitting","text":"The train and test data are generated by a probability distribution over datasets called the data generating process . We typically make a set of assumptions known collectively as the i.i.d. assumptions . These assumptions are that the examples in each dataset are independent from each other, and that the train set and test set are identically distributed , drawn from the same probability distribution as each other. This assumption allows us to describe the data generating process with a probability distribution over a single example. The same distribution is then used to generate every train example and every test example. We call that shared underlying distribution the data generating distribution , denoted p_{data} p_{data} . This probabilistic framework and the i.i.d. assumptions allow us to mathematically study the relationship between training error and test error. \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u539f\u6587\u4e2d\u6bd4\u8f83\u4e0d\u5bb9\u6613\u7406\u89e3\u7684\u4e00\u6bb5\uff0c\u5b83\u7684\u4e2d\u6587\u7ffb\u8bd1\u5982\u4e0b\uff1a \u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u662f\u901a\u8fc7\u6570\u636e\u96c6\u4e0a\u88ab\u79f0\u4e3a\u201c\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u201d\uff08data generating process\uff09\u7684\u6982\u7387\u5206\u5e03\u751f\u6210\u3002\u6211\u4eec\u901a\u5e38\u4f1a\u505a\u4e00\u7cfb\u5217\u88ab\u79f0\u4e3a\u201c\u72ec\u7acb\u540c\u5206\u5e03\u5047\u8bbe\u201d\uff08i.i.d assumptions\uff09\u7684\u5047\u8bbe\u3002\u8be5\u5047\u8bbe\u7684\u542b\u4e49\u662f\uff1a\u6bcf\u4e2a\u6570\u636e\u96c6\u4e2d\u7684\u6837\u672c\u90fd\u662f\u5f7c\u6b64\u201c\u76f8\u4e92\u72ec\u7acb\u7684\u201d\uff08independent\uff09\uff0c\u5e76\u4e14\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u662f\u201c\u540c\u5206\u5e03\u7684\u201d\uff08identically distributed\uff09\uff0c\u91c7\u6837\u81ea\u7cfb\u7edf\u7684\u6982\u7387\u5206\u5e03\u3002\u8fd9\u4e2a\u5047\u8bbe\u5141\u8bb8\u6211\u4eec\u80fd\u591f\u5728\u5355\u4e2a\u6837\u672c\u7684\u6982\u7387\u5206\u5e03\u63cf\u8ff0**\u6570\u636e\u751f\u6210\u8fc7\u7a0b**\u3002\u7136\u540e\u76f8\u540c\u7684\u5206\u5e03\u53ef\u4ee5\u7528\u6765\u751f\u6210\u6bcf\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\u548c\u6bcf\u4e2a\u6d4b\u8bd5\u6837\u672c\u3002\u6211\u4eec\u5c31\u5c06\u8fd9\u4e2a\u5171\u4eab\u7684\u6f5c\u5728\u5206\u5e03\u79f0\u4e3a\u201c\u6570\u636e\u751f\u6210\u5206\u5e03\u201d\uff08data generating distribution\uff09\u3002\u8fd9\u4e2a\u6982\u7387\u6846\u67b6\u548c\u72ec\u7acb\u540c\u5206\u5e03\u5047\u8bbe\u5141\u8bb8\u6211\u4eec\u4ece\u6570\u5b66\u4e0a\u7814\u7a76\u8bad\u7ec3\u8bef\u5dee\u548c\u6d4b\u8bd5\u8bef\u5dee\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u201cdata generation distribution\u201d\u662f\u771f\u5b9e\u7684\u5206\u5e03\uff0c\u800c\u201cdata generating process\u201d\u5219\u662f\u6211\u4eec\u6839\u636etrain set\u5b66\u4e60\u5230\u7684\u53d1\u5e03\u3002\u5728\u7edf\u8ba1\u5b66\u4e2d\uff0c\u4f7f\u7528 Statistical model \u6765\u63cf\u8ff0\u201cdata generating process\u201d\u3002\u5173\u4e8e\u6b64\uff0c\u53c2\u89c1 \u5173\u4e8e**i.i.d. assumptions** \uff0c\u53c2\u89c1 Independent and identically distributed random variables \u3002 \u201cprobability distribution\u201d\u662f Probability theory \u4e2d\u7684\u6982\u5ff5\uff0c\u53c2\u89c1 probability distributions \u3002\u6240\u8c13\u201c identically distributed \u201d\uff0c\u662f\u6307\u4e24\u79cd\u7684 probability distributions \u76f8\u540c\u3002","title":"5.2 Capacity, Overfitting and Underfitting"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.2-Capacity-Overfitting-and-Underfitting/#_1","text":"\u5bf9\u4e8ecapacity\u3001overfitting\u3001underfitting\u7684\u8ba8\u8bba\u662fmachine learning\u4e2d\u7684\u91cd\u8981\u95ee\u9898\u4e4b\u4e00\uff0c\u5728\u540e\u7eed\u7684\u7ae0\u8282\u4e2d\u8fd8\u5c06\u7ee7\u7eed\u5bf9\u5b83\u7684\u8ba8\u8bba\u3002","title":"\u540e\u8bb0"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.3-Hyperparameters-and-Validation-Sets/Cross-validation%28statistics%29/","text":"Cross-validation (statistics) stanford K Fold Cross Validation http://statweb.stanford.edu/~tibs/sta306bfiles/cvwrong.pdf","title":"Cross-validation(statistics)"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.3-Hyperparameters-and-Validation-Sets/Cross-validation%28statistics%29/#cross-validation#statistics","text":"","title":"Cross-validation (statistics)"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.3-Hyperparameters-and-Validation-Sets/Cross-validation%28statistics%29/#stanford#k#fold#cross#validation","text":"http://statweb.stanford.edu/~tibs/sta306bfiles/cvwrong.pdf","title":"stanford K Fold Cross Validation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.3-Hyperparameters-and-Validation-Sets/Hyperparameter%28machine-learning%29/","text":"Hyperparameter (machine learning) In machine learning , a hyperparameter is a parameter whose value is set before the learning process begins. By contrast, the values of other parameters are derived via training. Different model training algorithms require different hyperparameters, some simple algorithms (such as ordinary least squares regression) require none. Given these hyperparameters, the training algorithm learns the parameters from the data. For instance, LASSO is an algorithm that adds a regularization hyperparameter to ordinary least squares regression, which has to be set before estimating the parameters through the training algorithm.","title":"Hyperparameter(machine-learning)"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.3-Hyperparameters-and-Validation-Sets/Hyperparameter%28machine-learning%29/#hyperparameter#machine#learning","text":"In machine learning , a hyperparameter is a parameter whose value is set before the learning process begins. By contrast, the values of other parameters are derived via training. Different model training algorithms require different hyperparameters, some simple algorithms (such as ordinary least squares regression) require none. Given these hyperparameters, the training algorithm learns the parameters from the data. For instance, LASSO is an algorithm that adds a regularization hyperparameter to ordinary least squares regression, which has to be set before estimating the parameters through the training algorithm.","title":"Hyperparameter (machine learning)"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/","text":"5.4 Estimators, Bias and Variance The field of statistics gives us many tools that can be used to achieve the machine learning goal of solving a task not only on the training set but also to generalize. Foundational concepts such as parameter estimation, bias and variance are useful to formally characterize notions of generalization, underfitting and overfitting. SUMMARY : \u672c\u8282\u6240\u63cf\u8ff0\u7684\u5185\u5bb9\u5c31\u662f\u4f7f\u7528\u7edf\u8ba1\u5b66\u7684\u7406\u8bba\u6765\u63cf\u8ff0deep learning\u4e2d\u7684generalization, underfitting and overfitting\u3002 \u8865\u5145 \u7ef4\u57fa\u767e\u79d1 Bias of an estimator \u673a\u5668\u5b66\u4e60\u4e2d\u7684Bias(\u504f\u5dee)\uff0cError(\u8bef\u5dee)\uff0c\u548cVariance(\u65b9\u5dee)\u6709\u4ec0\u4e48\u533a\u522b\u548c\u8054\u7cfb\uff1f \u504f\u5dee(Bias)\u548c\u65b9\u5dee(Variance)\u2014\u2014\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6a21\u578b\u9009\u62e9 \u6a21\u578b\u6027\u80fd\u7684\u5ea6\u91cf \u5728\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u5df2\u77e5\u6837\u672c \uff0c\u8981\u6c42\u62df\u5408\u51fa\u4e00\u4e2a\u6a21\u578b\uff08\u51fd\u6570\uff09 \uff0c\u5176\u9884\u6d4b\u503c \u4e0e\u6837\u672c\u5b9e\u9645\u503c \u7684**\u8bef\u5dee**\u6700\u5c0f\u3002 \u8003\u8651\u5230**\u6837\u672c\u6570\u636e**\u5176\u5b9e\u662f**\u91c7\u6837**\uff0c \u5e76\u4e0d\u662f\u771f\u5b9e\u503c\u672c\u8eab\uff0c\u5047\u8bbe\u771f\u5b9e\u6a21\u578b\uff08\u51fd\u6570\uff09\u662f \uff0c\u5219\u91c7\u6837\u503c \uff0c\u5176\u4e2d \u4ee3\u8868\u566a\u97f3\uff0c\u5176\u5747\u503c\u4e3a0\uff0c\u65b9\u5dee\u4e3a \u3002 \u62df\u5408\u51fd\u6570 \u7684\u4e3b\u8981\u76ee\u7684\u662f\u5e0c\u671b\u5b83\u80fd\u5bf9\u65b0\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b\uff0c\u6240\u4ee5\uff0c\u62df\u5408\u51fa\u51fd\u6570 \u540e\uff0c\u9700\u8981\u5728\u6d4b\u8bd5\u96c6\uff08\u8bad\u7ec3\u65f6\u672a\u89c1\u8fc7\u7684\u6570\u636e\uff09\u4e0a\u68c0\u6d4b\u5176\u9884\u6d4b\u503c\u4e0e\u5b9e\u9645\u503c \u4e4b\u95f4\u7684**\u8bef\u5dee**\u3002\u53ef\u4ee5\u91c7\u7528\u5e73\u65b9\u8bef\u5dee\u51fd\u6570\uff08mean squared error\uff09\u6765\u5ea6\u91cf\u5176\u62df\u5408\u7684\u597d\u574f\u7a0b\u5ea6\uff0c\u5373 (y-\\hat{f}(x))^2 (y-\\hat{f}(x))^2 \u8bef\u5dee\u671f\u671b\u503c\u7684\u5206\u89e3 \u7ecf\u8fc7\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u67d0\u79cd\u7279\u5b9a\u7684\u6a21\u578b\uff08\u4e0b\u9762\u8fd8\u4f1a\u8fdb\u4e00\u6b65\u8bf4\u660e\u201c\u7279\u5b9a\u6a21\u578b\u201d\u7684\u542b\u4e49\uff09\uff0c\u5176**\u8bef\u5dee\u7684\u671f\u671b\u503c**\u53ef\u4ee5\u5206\u89e3\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a\u6837\u672c**\u566a\u97f3**\u3001\u6a21\u578b\u9884\u6d4b\u503c\u7684**\u65b9\u5dee**\u3001\u9884\u6d4b\u503c\u76f8\u5bf9\u771f\u5b9e\u503c\u7684**\u504f\u5dee** \u516c\u5f0f\u4e3a\uff1a $$ E((y-\\hat{f}(x))^2) = \\sigma^2 + Var[\\hat{f}(x))] + (Bias[\\hat{f}(x)])^2 $$ \u5176\u4e2d \u5373\uff1a \u8bef\u5dee\u7684\u671f\u671b\u503c = \u566a\u97f3\u7684\u65b9\u5dee + \u6a21\u578b\u9884\u6d4b\u503c\u7684\u65b9\u5dee + \u9884\u6d4b\u503c\u76f8\u5bf9\u771f\u5b9e\u503c\u7684\u504f\u5dee\u7684\u5e73\u65b9 \u5148\u770b\u4e00\u4e2a\u56fe\u6bd4\u8f83\u76f4\u89c2\u3002 \u56fe1 \u8bef\u5dee\u671f\u671b\u503c\u7684\u5206\u89e3 \u4f7f\u7528\u7279\u5b9a\u6a21\u578b\u5bf9\u4e00\u4e2a\u6d4b\u8bd5\u6837\u672c\u8fdb\u884c**\u9884\u6d4b**\uff0c\u5c31\u50cf\u6253\u9776\u4e00\u6837\u3002 \u9776\u5fc3\uff08\u7ea2\u70b9\uff09\u662f\u6d4b\u8bd5\u6837\u672c\u7684\u771f\u5b9e\u503c\uff0c\u6d4b\u8bd5\u6837\u672c\u7684y\uff08\u6a59\u8272\u70b9\uff09\u662f**\u771f\u5b9e\u503c**\u52a0\u4e0a**\u566a\u97f3**\uff0c\u7279\u5b9a\u6a21\u578b\u91cd\u590d\u591a\u6b21\u8bad\u7ec3\u4f1a\u5f97\u5230\u591a\u4e2a\u5177\u4f53\u7684\u6a21\u578b\uff0c\u6bcf\u4e00\u4e2a\u5177\u4f53\u6a21\u578b\u5bf9\u6d4b\u8bd5\u6837\u672c\u8fdb\u884c\u4e00\u6b21\u9884\u6d4b\uff0c\u5c31\u5728\u9776\u4e0a\u6253\u51fa\u4e00\u4e2a\u9884\u6d4b\u503c\uff08\u56fe\u4e0a\u84dd\u8272\u7684\u70b9\uff09\u3002\u6240\u6709\u9884\u6d4b\u503c\u7684**\u5e73\u5747**\u5c31\u662f**\u9884\u6d4b\u503c\u7684\u671f\u671b**\uff08\u8f83\u5927\u7684\u6d45\u84dd\u8272\u70b9\uff09\uff0c\u6d45\u84dd\u8272\u7684\u5706\u5708\u8868\u793a\u9884\u6d4b\u503c\u7684\u79bb\u6563\u7a0b\u5ea6\uff0c\u5373**\u9884\u6d4b\u503c\u7684\u65b9\u5dee**\u3002 \u6240\u4ee5\uff0c\u7279\u5b9a\u6a21\u578b\u7684\u9884\u6d4b\u503c \u4e0e \u771f\u5b9e\u503c \u7684\u8bef\u5dee\u7684 \u671f\u671b\u503c\uff0c\u5206\u89e3\u4e3a\u4e0a\u9762\u516c\u5f0f\u4e2d\u7684\u4e09\u4e2a\u90e8\u5206\uff0c\u5bf9\u5e94\u5230\u56fe\u4e0a\u7684\u4e09\u6761\u6a59\u8272\u7ebf\u6bb5\uff1a\u9884\u6d4b\u503c\u7684\u504f\u5dee\u3001\u9884\u6d4b\u503c\u7684\u65b9\u5dee\u3001\u6837\u672c\u566a\u97f3\u3002 \u7406\u89e3\u8bef\u5dee\u671f\u671b\u503c \u56de\u987e\u4e00\u4e0b\uff0c \u671f\u671b\u503c**\u7684\u542b\u4e49\u662f\u6307\u5728**\u540c\u6837\u7684\u6761\u4ef6**\u4e0b**\u91cd\u590d\u591a\u6b21**\u968f\u673a\u8bd5\u9a8c\uff0c\u5f97\u5230\u7684\u6240\u6709\u53ef\u80fd\u72b6\u6001\u7684**\u5e73\u5747\u7ed3\u679c \uff08\u66f4\u8be6\u7ec6\u7684\u5b9a\u4e49\u53c2\u8003 \u7ef4\u57fa\u767e\u79d1-\u671f\u671b\u503c \uff09\u3002\u5bf9\u4e8e\u673a\u5668\u5b66\u4e60\u6765\u8bf4\uff0c\u8fd9\u79cd\u5b9e\u9a8c\u5c31\u662f\u6211\u4eec\u9009\u62e9\u4e00\u79cd\u7b97\u6cd5\uff08\u5e76\u9009\u5b9a\u8d85\u53c2\u6570\uff09\uff0c\u4ee5\u53ca\u8bbe\u7f6e\u4e00\u4e2a\u56fa\u5b9a\u7684\u8bad\u7ec3\u96c6\u5927\u5c0f\uff0c\u8fd9\u5c31\u662f\u540c\u6837\u7684\u6761\u4ef6\uff0c\u4e5f\u5c31\u662f\u4e0a\u6587\u6240\u8bf4\u7684**\u7279\u5b9a\u7684\u6a21\u578b**\u3002\u7136\u540e\u6bcf\u6b21\u8bad\u7ec3\u65f6\u4ece\u6837\u672c\u7a7a\u95f4\u4e2d\u9009\u62e9\u4e00\u6279\u6837\u672c\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c\u4f46\u6bcf\u6b21\u90fd\u968f\u673a\u62bd\u53d6\u4e0d\u540c\u7684\u6837\u672c\uff0c\u8fd9\u6837\u91cd\u590d\u8fdb\u884c\u591a\u6b21\u8bad\u7ec3\u3002\u6bcf\u6b21\u8bad\u7ec3\u4f1a\u5f97\u5230\u4e00\u4e2a\u5177\u4f53\u7684\u6a21\u578b\uff0c\u6bcf\u4e2a\u5177\u4f53\u6a21\u578b\u5bf9\u540c\u4e00\u4e2a\u672a\u89c1\u8fc7\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b\u53ef\u4ee5\u5f97\u5230**\u9884\u6d4b\u503c**\u3002\u4e0d\u65ad\u91cd\u590d\u8bad\u7ec3\u548c\u9884\u6d4b\uff0c\u5c31\u80fd\u5f97\u5230\u4e00\u7cfb\u5217\u9884\u6d4b\u503c\uff0c\u6839\u636e\u6837\u672c\u548c\u8fd9\u4e9b\u9884\u6d4b\u503c\u8ba1\u7b97\u51fa\u65b9\u5dee\u548c\u504f\u5dee\uff0c\u5c31\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u8003\u5bdf\u8be5\u7279\u5b9a\u6a21\u578b\u7684**\u9884\u6d4b\u8bef\u5dee\u7684\u671f\u671b\u503c**\uff0c\u4e5f\u5c31\u80fd\u8861\u91cf\u8be5\u7279\u5b9a\u6a21\u578b\u7684\u6027\u80fd\u3002\u5bf9\u6bd4\u591a\u4e2a\u7279\u5b9a\u6a21\u578b\u7684**\u8bef\u5dee\u7684\u671f\u671b\u503c**\uff0c\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002 \u8fdb\u4e00\u6b65\u7406\u89e3\u8bef\u5dee\u671f\u671b\u503c \u518d\u770b\u4e00\u4e2a\u66f4\u63a5\u8fd1\u5b9e\u9645\u7684\u4f8b\u5b50\uff0c\u6765\u81ea Bias-Variance in Machine Learning \u6211\u4eec\u8bbe\u7f6e\u771f\u5b9e\u6a21\u578b \uff0c\u51fd\u6570\u56fe\u50cf\u5982\u4e0b\u56fe\u66f2\u7ebf\u6240\u793a\u3002 \u6837\u672c\u503c y \u5c31\u5728**\u771f\u5b9e\u503c**\u7684\u57fa\u7840\u4e0a\u53e0\u52a0\u4e00\u4e2a\u968f\u673a\u566a\u97f3 N(0, 0.2)\u3002 \u56fe2 \u6a21\u578b\u53ca\u6837\u672c \u73b0\u5728\u6211\u4eec\u7528\u7ebf\u6027\u51fd\u6570\u6765\u6784\u5efa\u6a21\u578b\uff0c\u8bad\u7ec3\u6837\u672c\u6765\u81ea\u968f\u673a\u91c7\u96c6\u7684\u4e00\u7ec4 y\uff0c\u7ecf\u8fc7\u591a\u6b21\u91cd\u590d\uff0c\u53ef\u4ee5\u5f97\u5230\u4e00\u7cfb\u5217\u5177\u4f53\u7684\u7ebf\u6027\u6a21\u578b\uff0c\u5982\u4e0b\u56fe\u4e2d\u90a3\u4e00\u7ec4\u805a\u96c6\u5728\u4e00\u8d77\u7684\u9ed1\u8272\u76f4\u7ebf\u6240\u793a\uff0c\u5176\u4e2d\u95f4\u6709\u4e00\u6761\u7ea2\u8272\u7ebf\u662f\u8fd9\u4e00\u7ec4\u7ebf\u6027\u51fd\u6570\u7684\u5e73\u5747\uff08\u671f\u671b\u503c\uff09\u3002\u8fd9\u5c31\u662f\u7279\u5b9a\u6a21\u578b\uff08\u7ebf\u6027\u51fd\u6570\uff09\u5728\u540c\u6837\u6761\u4ef6\u4e0b\uff08\u6bcf\u6b21\u53d620\u4e2a\u6837\u672c\u70b9\uff09\u91cd\u590d\u591a\u6b21\uff08\u5f97\u523050\u4e2a\u7ebf\u6027\u51fd\u6570\uff09\u3002 \u6839\u636e\u751f\u6210\u768450\u4e2a\u5177\u4f53\u7684\u7ebf\u6027\u51fd\u6570\u6765\u8003\u5bdf\u8be5\u7ebf\u6027\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u9009\u53d6\u4e00\u4e2a\u6837\u672c\u70b9\uff0c\u6bd4\u5982\u9009\u62e9 x=5 \u65f6\uff08\u4e0b\u56fe\u4e2d\u7ea2\u8272\u7ad6\u7ebf\u4f4d\u7f6e\uff09\uff0c\u771f\u5b9e\u503c f(x) = 6.876\uff0c\u6837\u672c \uff0cy \u4e0e f(x) \u7684\u504f\u5dee\u4f53\u73b0\u5728\u56fe\u7247\u53f3\u4e0b\u65b9\u7684**\u566a\u97f3\uff08noise\uff09** \u90e8\u5206\u3002\u7ea2\u8272\u7ebf\u6027\u51fd\u6570\u5728 x=5 \u4f4d\u7f6e\u7684\u503c\u662f\u8fd950\u4e2a\u7ebf\u6027\u51fd\u6570\u5728\u8be5\u4f4d\u7f6e\u7684\u671f\u671b\u503c\uff0c\u9ed1\u8272\u76f4\u7ebf\u5728 x=5 \u4f4d\u7f6e\u7684\u4e00\u7cfb\u5217\u503c\u7684\u5206\u5e03\u5219\u53cd\u6620\u4e86\u5b83\u4eec\u7684**\u65b9\u5dee\uff08Variance\uff09 \u300250\u4e2a\u9884\u6d4b\u7684\u671f\u671b\u503c\u4e0e\u771f\u5b9e\u503c f(x) \u4e4b\u95f4\u7684\u8ddd\u79bb\u4f53\u73b0\u4e86**\u504f\u5dee\uff08Bias\uff09 \u3002\uff08\u53c2\u8003\u4e0b\u56fe\u53f3\u4e0b\u90e8\u5206\u7684 variance \u548c bias\uff09\u3002 \u56fe3 \u504f\u5dee\u3001\u65b9\u5dee\u8ba1\u7b97 \u603b\u4e4b\uff0c\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u8003\u5bdf \u504f\u5dee \u548c \u65b9\u5dee\uff0c\u6700\u91cd\u8981\u7684\u662f\u8981\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u51fa\u4e00\u7ec4\u7279\u5b9a\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e00\u4e2a\u6d4b\u8bd5\u6837\u672c\u8fdb\u884c\u9884\u6d4b\uff0c\u8003\u5bdf\u8fd9\u4e00\u7ec4\u9884\u6d4b\u503c\u7684\u65b9\u5dee\u548c\u504f\u5dee\u3002 \u8bef\u5dee\u7684\u671f\u671b\u503c\u516c\u5f0f\u63a8\u5bfc \u8bef\u5dee\u7684\u671f\u671b\u503c\u516c\u5f0f\u4e3a\u4ec0\u4e48\u53ef\u4ee5\u5206\u89e3\u4e3a \u566a\u97f3\u3001\u504f\u5dee\u548c\u65b9\u5dee\uff0c\u53ef\u4ee5\u4ece\u6570\u5b66\u4e0a\u63a8\u5bfc\u5f97\u6765\u3002\u5148\u51c6\u5907\u51e0\u4e2a\u63a8\u5bfc\u4e2d\u9700\u8981\u7528\u5230\u7684\u516c\u5f0f\uff0c\u4e3a\u4e86\u65b9\u4fbf\uff0c\u6211\u4eec\u7b80\u5316\u7b26\u53f7\uff0c\u8bb0\u4f5c \u65b9\u5dee\u7684\u5b9a\u4e49\u548c\u8ba1\u7b97\u516c\u5f0f \u5373 \u968f\u673a\u53d8\u91cfX\u7684\u65b9\u5dee = X\u5e73\u65b9\u7684\u671f\u671b - X\u671f\u671b\u7684\u5e73\u65b9\uff08\u53c2\u8003 \u7ef4\u57fa\u767e\u79d1-\u65b9\u5dee \uff09\uff0c\u79fb\u9879\u540e\u5f97\u5230 \u6d4b\u8bd5\u6837\u672cy\u7684\u671f\u671b\u503c \u56e0\u4e3a\u771f\u5b9e\u503c \u662f\u4e00\u4e2a\u786e\u5b9a\u7684\u503c\uff0c\u6240\u4ee5 \u53e6\u5916\u6839\u636e\u4e0a\u6587\u6d4b\u8bd5\u6837\u672c\u503c\u548c\u566a\u97f3\u7684\u5b9a\u4e49 \u6240\u4ee5 \uff0c\u5373 \u6d4b\u8bd5\u6837\u672cy\u7684\u65b9\u5dee $$ Var[y] = E[(y - E[y])^2] = E[(y-f)^2] \\ = E[(f+\\varepsilon-f)^2] = E[\\varepsilon^2] \\ = Var[\\varepsilon] + (E[\\varepsilon])^2 = \\sigma^2 $$ \u5373 \u6837\u672c\u566a\u97f3\u4e0e\u9884\u6d4b\u503c\u65e0\u5173 \u56e0\u4e3a \u4e0e \u4e0d\u76f8\u5173\uff0c\u6240\u4ee5 \uff08\u53c2\u8003 \u7ef4\u57fa\u767e\u79d1-\u671f\u671b\u503c ) \u8bef\u5dee\u7684\u671f\u671b \u516c\u5f0f\u63a8\u5bfc\u5982\u4e0b $$ E[(y-\\hat{f})^2] = E[y^2 + \\hat{f}^2 - 2y\\hat{f}] \\ = E[y^2] + E[\\hat{f}^2] - E[2y\\hat{f}] \\ = \\Big(Var[y] + (E[y]))^2 \\Big) + \\Big(Var[\\hat{f}] + (E[\\hat{f}])^2 \\Big) - E[2(f+\\varepsilon) \\hat{f}] \\ = Var[y] + Var[\\hat{f}] + (E[y])^2 + (E[\\hat{f}])^2 - E[2f\\hat{f} +2\\varepsilon \\hat{f}] \\ = Var[y] + Var[\\hat{f}] + f^2 + (E[\\hat{f}])^2 - E[2f\\hat{f}] -E[2\\varepsilon \\hat{f}] \\ = Var[y] + Var[\\hat{f}] + f^2 + (E[\\hat{f}])^2 - 2fE[\\hat{f}] -2E[\\varepsilon]E[\\hat{f}] \\ = Var[y] + Var[\\hat{f}] + \\Big(f^2 + (E[\\hat{f}])^2 - 2fE[\\hat{f}] \\Big) \\ = Var[y] + Var[\\hat{f}] + (f - E[\\hat{f}])^2 \\ = \\sigma^2 + Var[\\hat{f}] + (Bias[\\hat{f}])^2 $$ \u6700\u540e\u5f97\u5230\u7684\u4e09\u4e2a\u9879\u5206\u522b\u662f\uff1a\u566a\u97f3\u7684\u65b9\u5dee\u3001\u6a21\u578b\u9884\u6d4b\u503c\u7684\u65b9\u5dee\u3001\u9884\u6d4b\u503c\u76f8\u5bf9\u771f\u5b9e\u503c\u7684\u504f\u5dee\u7684\u5e73\u65b9\u3002 \u504f\u5dee - \u65b9\u5dee\u7684\u9009\u62e9 \u7406\u60f3\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u5f97\u5230\u4e00\u4e2a\u504f\u5dee\u548c\u65b9\u5dee\u90fd\u5f88\u5c0f\u7684\u6a21\u578b\uff08\u4e0b\u56fe\u5de6\u4e0a\uff09\uff0c\u4f46\u5b9e\u9645\u4e0a\u5f80\u5f80\u5f88\u56f0\u96be\u3002 image \u9009\u62e9\u76f8\u5bf9\u8f83\u597d\u7684\u6a21\u578b\u7684\u987a\u5e8f\uff1a\uff08\u65b9\u5dee\u5c0f\uff0c\u504f\u5dee\u5c0f\uff09 > \uff08\u65b9\u5dee\u5c0f\uff0c\u504f\u5dee\u5927\uff09 > \uff08\u65b9\u5dee\u5927\uff0c\u504f\u5dee\u5c0f\uff09 > \uff08\u65b9\u5dee\u5927\uff0c\u504f\u5dee\u5927\uff09\u3002 \u65b9\u5dee\u5c0f\uff0c\u504f\u5dee\u5927 \u4e4b\u6240\u4ee5\u5728\u5b9e\u9645\u4e2d\u6392\u4f4d\u76f8\u5bf9\u9760\u524d\uff0c\u662f\u56e0\u4e3a\u5b83\u6bd4\u8f83**\u7a33\u5b9a**\u3002\u5f88\u591a\u65f6\u5019\u5b9e\u9645\u4e2d\u65e0\u6cd5\u83b7\u5f97\u975e\u5e38\u5168\u9762\u7684**\u6570\u636e\u96c6**\uff0c\u90a3\u4e48\uff0c\u5982\u679c\u4e00\u4e2a\u6a21\u578b\u5728\u53ef\u83b7\u5f97\u7684\u6837\u672c\u4e0a\u6709\u8f83\u5c0f\u7684\u65b9\u5dee\uff0c\u8bf4\u660e\u5b83\u5bf9\u4e0d\u540c\u6570\u636e\u96c6\u7684\u654f\u611f\u5ea6\u4e0d\u9ad8\uff0c\u53ef\u4ee5\u671f\u671b\u5b83\u5bf9\u65b0\u6570\u636e\u96c6\u7684\u9884\u6d4b\u6548\u679c\u6bd4\u8f83\u7a33\u5b9a\u3002 \u9009\u62e9\u5047\u8bbe\u96c6\u5408 \u5f88\u591a\u65f6\u5019\uff0c\u673a\u5668\u5b66\u4e60\u6240\u9762\u4e34\u7684\u95ee\u9898\uff0c\u6211\u4eec\u4e8b\u5148\u5e76\u4e0d\u786e\u5207\u7684\u77e5\u9053\u8981\u62df\u5408\u7684\u662f\u4e00\u4e2a\u600e\u6837\u5f62\u5f0f\u7684\u51fd\u6570\uff0c\u662f\u51e0\u6b21\u591a\u9879\u5f0f\uff0c\u662f\u51e0\u5c42\u795e\u7ecf\u7f51\u7edc\uff0c\u9009\u62e9\u6837\u672c\u7684\u54ea\u4e9b\u7279\u5f81\uff0c\u7b49\u7b49\uff0c\u90fd\u7f3a\u4e4f\u5148\u9a8c\u7684\u77e5\u8bc6\u6765\u5e2e\u52a9\u6211\u4eec\u9009\u62e9\u3002\u6211\u4eec\u5728\u4e00\u4e2a\u57fa\u672c\u4e0a\u65e0\u7a77\u5927\u7684**\u5047\u8bbe\uff08\u6a21\u578b\uff09\u96c6\u5408**\u4e2d\uff0c\u51ed\u501f\u6709\u9650\u7684\u7ecf\u9a8c\u8fdb\u884c\u5c1d\u8bd5\u548c\u9009\u62e9\u3002 \u673a\u5668\u5b66\u4e60\u6709\u591a\u79cd\u7b97\u6cd5\uff0c\u4ee5\u53ca\u6bcf\u79cd\u7b97\u6cd5\u4e2d\u7ecf\u5e38\u53c8\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u7684\u7ed3\u6784\u548c\u8d85\u53c2\u6570\u3002\u5b83\u4eec\u6240\u8986\u76d6\u7684\u5047\u8bbe\u96c6\u5408\u6709\u4e0d\u540c\u7684\u5927\u5c0f\u3002\u6240\u4ee5\uff0c\u9009\u62e9\u4e00\u79cd\u7b97\u6cd5\uff08\u5305\u62ec\u5176\u7ed3\u6784\u548c\u8d85\u53c2\u6570\uff09\uff0c\u5c31\u662f\u9009\u62e9\uff08\u9650\u5b9a\uff09\u4e86\u4e00\u4e2a**\u5047\u8bbe\u96c6\u5408**\u3002\u6211\u4eec\u671f\u671b\u771f\u5b9e\u6a21\u578b\u5b58\u5728\u4e8e\u6211\u4eec\u6240\u9009\u5b9a\u7684**\u5047\u8bbe\u96c6\u5408**\u8303\u56f4\u5185\uff0c\u5e76\u4e14\u8be5**\u5047\u8bbe\u96c6\u5408**\u8d8a\u5c0f\u8d8a\u597d\u3002 \u4e0b\u9762\u4e24\u5e45\u56fe\u7c97\u7565\u8868\u73b0\u4e86\u4e0d\u540c**\u5047\u8bbe\u96c6\u5408**\u7684\u5173\u7cfb \u4e0d\u540c\u7684**\u5047\u8bbe\u96c6\u5408** **\u6b63\u5219\u5316\u9879**\u5bf9\u5047\u8bbe\u96c6\u5408\u7684\u5f71\u54cd \u6211\u4eec\u601d\u8003\u4e00\u4e0b\u76d1\u7763\u5b66\u4e60\u7684\u6574\u4e2a\u6d41\u7a0b\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u4e0d\u65ad\u7f29\u5c0f**\u5047\u8bbe\u96c6\u5408**\u7684\u8fc7\u7a0b\u3002\u4ece\u5927\u7684\u65b9\u9762\u770b\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4\u3002 \u9009\u62e9\u4e00\u4e2a**\u5047\u8bbe\u96c6\u5408**\uff0c\u5305\u62ec\u6a21\u578b\u53ca\u76f8\u5173\u7ed3\u6784\u3001\u8d85\u53c2\u6570\u7b49\u3002 \u4f7f\u7528\u6837\u672c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f7f\u8be5\u6a21\u578b\u5c3d\u91cf\u62df\u5408\u6837\u672c\uff0c\u5c31\u662f\u4ece\u4e0a\u9762\u9009\u5b9a\u7684\u5047\u8bbe\u96c6\u5408\u4e2d\u627e\u5230\u4e00\u4e2a\u7279\u5b9a\u7684\u5047\u8bbe\uff08\u6a21\u578b\uff09\u3002 \u4e0a\u9762\u7b2c\u4e00\u4e2a\u6b65\u9aa4\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u4e00\u4e9b\u4e0d\u540c\u7684\u5047\u8bbe\u96c6\u5408\uff0c\u7136\u540e\u901a\u8fc7\u8003\u5bdf\u5b83\u4eec\u7684**\u504f\u5dee\u65b9\u5dee**\uff0c\u5bf9\u5404**\u5047\u8bbe\u96c6\u5408**\u7684**\u6027\u80fd**\u8fdb\u884c\u8bc4\u4f30\u3002\u6bd4\u5982\u591a\u9879\u5f0f\u7684\u6b21\u6570\uff0c\u4e0a\u56fe\u5047\u8bbe\u771f\u5b9e\u6a21\u578b\u662f\u4e00\u4e2a\u4e8c\u6b21\u591a\u9879\u5f0f\uff0c\u90a3\u4e48\u7ebf\u6027\u51fd\u6570\u96c6\u5408\u4e2d\u7684\u6a21\u578b\u4f1a**\u6b20\u62df\u5408**\uff08 \u65b9\u5dee\u4f4e \uff0c \u504f\u5dee\u592a\u9ad8 \uff09\uff0c\u9ad8\u6b21\u591a\u9879\u5f0f\u96c6\u5408\u4e2d\u7684\u6a21\u578b\u5bb9\u6613**\u8fc7\u62df\u5408**\uff08\u65b9\u5dee\u592a\u9ad8\uff0c\u504f\u5dee\u4f4e\uff09\uff0c\u4e8c\u9879\u5f0f\u96c6\u5408\u4e2d\u7684\u6a21\u578b\u80fd\u591f\u6709\u8f83\u597d\u7684\u6298\u4e2d\uff08\u65b9\u5dee\u548c\u504f\u5dee\u90fd\u76f8\u5bf9\u8f83\u4f4e\uff09\uff0c\u603b\u4f53**\u8bef\u5dee**\u6700\u5c0f\u3002 \u504f\u5dee - \u65b9\u5dee\u6743\u8861 \u591a\u9879\u5f0f\u56de\u5f52 \u591a\u9879\u5f0f\u56de\u5f52\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u7684\u591a\u9879\u5f0f\u7684\u6b21\u6570\uff0c\u5bf9\u6a21\u578b\u7684\u5f71\u54cd\u5982\u4e0b\u3002 \u591a\u9879\u5f0f\u6b21\u6570\u5bf9\u6a21\u578b\u504f\u5dee\u65b9\u5dee\u7684\u5f71\u54cd \u591a\u9879\u5f0f\u6b21\u6570 \u6a21\u578b\u590d\u6742\u5ea6 \u65b9\u5dee \u504f\u5dee \u8fc7/\u6b20\u62df\u5408 \u4f4e \u4f4e \u4f4e \u9ad8 \u6b20\u62df\u5408 \u4e2d \u4e2d \u4e2d \u4e2d \u9002\u5ea6 \u9ad8 \u9ad8 \u9ad8 \u4f4e \u8fc7\u62df\u5408 \u591a\u9879\u5f0f\u6b21\u6570\u5bf9\u8bad\u7ec3\u8bef\u5dee/\u6d4b\u8bd5\u8bef\u5dee\u7684\u5f71\u54cd \u591a\u9879\u5f0f\u6b21\u6570 \u6a21\u578b\u590d\u6742\u5ea6 \u8bad\u7ec3\u8bef\u5dee \u6d4b\u8bd5\u8bef\u5dee \u4f4e \u4f4e \u9ad8 \u9ad8 \u4e2d \u4e2d \u4e2d \u4f4e \u9ad8 \u9ad8 \u4f4e \u9ad8 \u6b63\u5219\u5316\u9879 \u6dfb\u52a0\u6b63\u5219\u5316\u9879\uff08Regularization\uff09\u76f8\u5f53\u4e8e\u5bf9\u6a21\u578b\u53c2\u6570\u65bd\u52a0\u60e9\u7f5a\uff0c\u538b\u7f29\u4e86\u53c2\u6570\u7684\u8303\u56f4\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u590d\u6742\u5ea6\uff0c\u4ece\u800c\u6709\u52a9\u4e8e\u7f13\u89e3\u6a21\u578b\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u9009\u62e9\u4e0d\u540c\u7684 \u6b63\u5219\u5316\u9879\u6743\u91cd\u03bb \u5bf9\u6a21\u578b\u7684\u5f71\u54cd\u5982\u4e0b\u3002 \u6b63\u5219\u5316\u9879\u5bf9\u6a21\u578b\u504f\u5dee\u65b9\u5dee\u7684\u5f71\u54cd \u6b63\u5219\u5316\u9879\u6743\u91cd\u03bb \u6a21\u578b\u590d\u6742\u5ea6 \u65b9\u5dee \u504f\u5dee \u8fc7/\u6b20\u62df\u5408 \u5927 \u4f4e \u4f4e \u9ad8 \u6b20\u62df\u5408 \u4e2d \u4e2d \u4e2d \u4e2d \u9002\u5ea6 \u5c0f \u9ad8 \u9ad8 \u4f4e \u8fc7\u62df\u5408 \u6b63\u5219\u5316\u9879\u5bf9\u8bad\u7ec3\u8bef\u5dee/\u6d4b\u8bd5\u8bef\u5dee\u7684\u5f71\u54cd \u6b63\u5219\u5316\u9879\u6743\u91cd\u03bb \u6a21\u578b\u590d\u6742\u5ea6 \u8bad\u7ec3\u8bef\u5dee \u6d4b\u8bd5\u8bef\u5dee \u5927 \u4f4e \u9ad8 \u9ad8 \u4e2d \u4e2d \u4e2d \u4f4e \u5c0f \u9ad8 \u4f4e \u9ad8 \u6837\u672c\u6570\u91cf \u4e00\u822c\u6765\u8bf4\uff0c\u6211\u4eec\u5e0c\u671b**\u6837\u672c\u6570\u91cf**\u8d8a\u591a\u8d8a\u597d\u3002\u968f\u7740**\u6837\u672c\u6570\u91cf**\u589e\u52a0\uff0c\u8bad\u7ec3\u8bef\u5dee\u4f1a\u9010\u6e10\u589e\u957f\uff0c\u6d4b\u8bd5\u8bef\u5dee\u4f1a\u9010\u6e10\u964d\u4f4e\u3002 \u6837\u672c\u6570\u91cf\u5bf9\u8bad\u7ec3\u8bef\u5dee/\u6d4b\u8bd5\u8bef\u5dee\u7684\u5f71\u54cd \u795e\u7ecf\u7f51\u7edc \u795e\u7ecf\u7f51\u7edc\u7ed3\u6784 \u795e\u7ecf\u7f51\u7edc\u7ed3\u6784 \u6a21\u578b\u590d\u6742\u5ea6 \u65b9\u5dee \u504f\u5dee \u8fc7/\u6b20\u62df\u5408 \u5c0f \u4f4e \u4f4e \u9ad8 \u6b20\u62df\u5408 \u4e2d \u4e2d \u4e2d \u4e2d \u9002\u5ea6 \u5927 \u9ad8 \u9ad8 \u4f4e \u8fc7\u62df\u5408 K-Fold \u4ea4\u53c9\u9a8c\u8bc1 \u8ba1\u7b97\u504f\u5dee\u3001\u65b9\u5dee\u53ef\u4ee5\u5e2e\u52a9\u8bc4\u4f30\u4e0d\u540c\u7684\u5047\u8bbe\u96c6\u5408\uff0c\u4e0d\u8fc7\u5b83\u9700\u8981\u8f83\u591a\u7684\u6837\u672c\uff0c\u4ee5\u53ca\u91cd\u590d\u591a\u6b21\u62df\u5408\u6a21\u578b\uff0c\u9700\u8981\u6bd4\u8f83\u591a\u7684\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff08\u53c2\u8003\u4e0a\u9762\u56fe3\uff09\u3002 \u5b9e\u9645\u4e2d\uff0c\u6bd4\u8f83\u5e38\u7528\u7684\u65b9\u6cd5\u662fK-Fold\u4ea4\u53c9\u9a8c\u8bc1\u3002\u5b83\u4e0e\u6807\u51c6\u7684\u504f\u5dee\u3001\u65b9\u5dee\u8ba1\u7b97\u8fc7\u7a0b\u4e0d\u592a\u4e00\u6837\u3002\u7b80\u5355\u7684\u8bf4\uff0c\u5c31\u662f\u5c06\u8bad\u7ec3\u6837\u672c\u5206\u6210k\u4efd\uff0c\u6bcf\u6b21\u53d6\u5176\u4e2d\u4e00\u4efd\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u53e6\u5916 k-1 \u4efd\u4f5c\u8bad\u7ec3\u96c6\u3002\u8fd9\u6837\u8fdb\u884c k \u6b21\u8bad\u7ec3\u5f97\u5230 k \u4e2a\u6a21\u578b\u3002\u8fd9 k \u4e2a\u6a21\u578b\u5bf9\u5404\u81ea\u7684\u9a8c\u8bc1\u96c6\u8fdb\u884c\u9884\u6d4b\uff0c\u5f97\u5230 k \u4e2a\u8bc4\u4f30\u503c\uff08\u53ef\u4ee5\u662f\u8bef\u5dee\u3001\u51c6\u786e\u7387\uff0c\u6216\u6309\u67d0\u79cd\u89c4\u5219\u8ba1\u7b97\u7684\u5f97\u5206\u7b49\u7b49\uff09\u3002\u6ce8\u610f\u5230\u6bcf\u4e2a\u6837\u672c\u53c2\u4e0e\u4e86 k-1 \u4e2a\u6a21\u578b\u7684\u8bad\u7ec3\uff08\u5bfc\u81f4\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u5173\u8054\uff09\uff0c\u6bcf\u4e2a\u6837\u672c\u6709\u4e00\u6b21\u88ab\u7528\u4f5c\u6d4b\u8bd5\uff08\u6ca1\u6709\u7528\u53e6\u5916\u7684\u4ece\u672a\u89c1\u8fc7\u7684\u6d4b\u8bd5\u96c6\u6570\u636e\uff09\uff0c\u6240\u4ee5\u8fd9\u4e0e\u6807\u51c6\u7684\u8ba1\u7b97\u8fc7\u7a0b\u662f\u4e0d\u4e00\u6837\u7684\u3002 \u4e0d\u8fc7\uff0cK-Fold\u4f9d\u7136\u662f\u5f88\u6709\u4ef7\u503c\u7684\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\u3002\u53ef\u4ee5\u76f4\u63a5\u9488\u5bf9\u8fd9 k \u4e2a\u6a21\u578b\u7684\u8bc4\u4f30\u503c\uff08\u8bef\u5dee\u3001\u51c6\u786e\u7387\uff0c\u6216\u6309\u67d0\u79cd\u89c4\u5219\u8ba1\u7b97\u7684\u5f97\u5206\u7b49\u7b49\uff09\u8fdb\u884c\u5206\u6790\uff0c\u53d6\u5176\u5e73\u5747\u53ef\u4ee5\u4f53\u73b0\u8be5\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u5bf9\u8fd9 k \u4e2a\u503c\uff0c\u6bd4\u5982k\u4e2a\u8bef\u5dee\u503c\uff0c\u8ba1\u7b97**\u65b9\u5dee**\uff0c\u53ef\u4ee5\u53cd\u5e94\u8be5\u6a21\u578b\u7684\u9884\u6d4b\u8bef\u5dee\u7684\u79bb\u6563\u7a0b\u5ea6\uff0c\u5373\u540e\u7eed\u7528\u4e8e\u672a\u89c1\u8fc7\u7684\u6837\u672c\u6570\u636e\u65f6\uff0c\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u662f\u5426**\u7a33\u5b9a**\u3002 \u53c2\u8003 \u7ef4\u57fa\u767e\u79d1 - Bias\u2013variance tradeoff Bias-Variance in Machine Learning \u7ef4\u57fa\u767e\u79d1 - \u65b9\u5dee \u7ef4\u57fa\u767e\u79d1 - \u671f\u671b\u503c \u300aPattern Recognition and Machine Learning\u300b\u4e4b 3.2. The Bias-Variance Decomposition","title":"5.4-Estimators-Bias-and-Variance"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#54#estimators#bias#and#variance","text":"The field of statistics gives us many tools that can be used to achieve the machine learning goal of solving a task not only on the training set but also to generalize. Foundational concepts such as parameter estimation, bias and variance are useful to formally characterize notions of generalization, underfitting and overfitting. SUMMARY : \u672c\u8282\u6240\u63cf\u8ff0\u7684\u5185\u5bb9\u5c31\u662f\u4f7f\u7528\u7edf\u8ba1\u5b66\u7684\u7406\u8bba\u6765\u63cf\u8ff0deep learning\u4e2d\u7684generalization, underfitting and overfitting\u3002","title":"5.4 Estimators, Bias and Variance"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_1","text":"","title":"\u8865\u5145"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#bias#of#an#estimator","text":"","title":"\u7ef4\u57fa\u767e\u79d1Bias of an estimator"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#biaserrorvariance","text":"","title":"\u673a\u5668\u5b66\u4e60\u4e2d\u7684Bias(\u504f\u5dee)\uff0cError(\u8bef\u5dee)\uff0c\u548cVariance(\u65b9\u5dee)\u6709\u4ec0\u4e48\u533a\u522b\u548c\u8054\u7cfb\uff1f"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#biasvariance","text":"","title":"\u504f\u5dee(Bias)\u548c\u65b9\u5dee(Variance)\u2014\u2014\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6a21\u578b\u9009\u62e9"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_2","text":"\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u5df2\u77e5\u6837\u672c \uff0c\u8981\u6c42\u62df\u5408\u51fa\u4e00\u4e2a\u6a21\u578b\uff08\u51fd\u6570\uff09 \uff0c\u5176\u9884\u6d4b\u503c \u4e0e\u6837\u672c\u5b9e\u9645\u503c \u7684**\u8bef\u5dee**\u6700\u5c0f\u3002 \u8003\u8651\u5230**\u6837\u672c\u6570\u636e**\u5176\u5b9e\u662f**\u91c7\u6837**\uff0c \u5e76\u4e0d\u662f\u771f\u5b9e\u503c\u672c\u8eab\uff0c\u5047\u8bbe\u771f\u5b9e\u6a21\u578b\uff08\u51fd\u6570\uff09\u662f \uff0c\u5219\u91c7\u6837\u503c \uff0c\u5176\u4e2d \u4ee3\u8868\u566a\u97f3\uff0c\u5176\u5747\u503c\u4e3a0\uff0c\u65b9\u5dee\u4e3a \u3002 \u62df\u5408\u51fd\u6570 \u7684\u4e3b\u8981\u76ee\u7684\u662f\u5e0c\u671b\u5b83\u80fd\u5bf9\u65b0\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b\uff0c\u6240\u4ee5\uff0c\u62df\u5408\u51fa\u51fd\u6570 \u540e\uff0c\u9700\u8981\u5728\u6d4b\u8bd5\u96c6\uff08\u8bad\u7ec3\u65f6\u672a\u89c1\u8fc7\u7684\u6570\u636e\uff09\u4e0a\u68c0\u6d4b\u5176\u9884\u6d4b\u503c\u4e0e\u5b9e\u9645\u503c \u4e4b\u95f4\u7684**\u8bef\u5dee**\u3002\u53ef\u4ee5\u91c7\u7528\u5e73\u65b9\u8bef\u5dee\u51fd\u6570\uff08mean squared error\uff09\u6765\u5ea6\u91cf\u5176\u62df\u5408\u7684\u597d\u574f\u7a0b\u5ea6\uff0c\u5373 (y-\\hat{f}(x))^2 (y-\\hat{f}(x))^2","title":"\u6a21\u578b\u6027\u80fd\u7684\u5ea6\u91cf"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_3","text":"\u7ecf\u8fc7\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u67d0\u79cd\u7279\u5b9a\u7684\u6a21\u578b\uff08\u4e0b\u9762\u8fd8\u4f1a\u8fdb\u4e00\u6b65\u8bf4\u660e\u201c\u7279\u5b9a\u6a21\u578b\u201d\u7684\u542b\u4e49\uff09\uff0c\u5176**\u8bef\u5dee\u7684\u671f\u671b\u503c**\u53ef\u4ee5\u5206\u89e3\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a\u6837\u672c**\u566a\u97f3**\u3001\u6a21\u578b\u9884\u6d4b\u503c\u7684**\u65b9\u5dee**\u3001\u9884\u6d4b\u503c\u76f8\u5bf9\u771f\u5b9e\u503c\u7684**\u504f\u5dee** \u516c\u5f0f\u4e3a\uff1a $$ E((y-\\hat{f}(x))^2) = \\sigma^2 + Var[\\hat{f}(x))] + (Bias[\\hat{f}(x)])^2 $$ \u5176\u4e2d \u5373\uff1a \u8bef\u5dee\u7684\u671f\u671b\u503c = \u566a\u97f3\u7684\u65b9\u5dee + \u6a21\u578b\u9884\u6d4b\u503c\u7684\u65b9\u5dee + \u9884\u6d4b\u503c\u76f8\u5bf9\u771f\u5b9e\u503c\u7684\u504f\u5dee\u7684\u5e73\u65b9 \u5148\u770b\u4e00\u4e2a\u56fe\u6bd4\u8f83\u76f4\u89c2\u3002 \u56fe1 \u8bef\u5dee\u671f\u671b\u503c\u7684\u5206\u89e3 \u4f7f\u7528\u7279\u5b9a\u6a21\u578b\u5bf9\u4e00\u4e2a\u6d4b\u8bd5\u6837\u672c\u8fdb\u884c**\u9884\u6d4b**\uff0c\u5c31\u50cf\u6253\u9776\u4e00\u6837\u3002 \u9776\u5fc3\uff08\u7ea2\u70b9\uff09\u662f\u6d4b\u8bd5\u6837\u672c\u7684\u771f\u5b9e\u503c\uff0c\u6d4b\u8bd5\u6837\u672c\u7684y\uff08\u6a59\u8272\u70b9\uff09\u662f**\u771f\u5b9e\u503c**\u52a0\u4e0a**\u566a\u97f3**\uff0c\u7279\u5b9a\u6a21\u578b\u91cd\u590d\u591a\u6b21\u8bad\u7ec3\u4f1a\u5f97\u5230\u591a\u4e2a\u5177\u4f53\u7684\u6a21\u578b\uff0c\u6bcf\u4e00\u4e2a\u5177\u4f53\u6a21\u578b\u5bf9\u6d4b\u8bd5\u6837\u672c\u8fdb\u884c\u4e00\u6b21\u9884\u6d4b\uff0c\u5c31\u5728\u9776\u4e0a\u6253\u51fa\u4e00\u4e2a\u9884\u6d4b\u503c\uff08\u56fe\u4e0a\u84dd\u8272\u7684\u70b9\uff09\u3002\u6240\u6709\u9884\u6d4b\u503c\u7684**\u5e73\u5747**\u5c31\u662f**\u9884\u6d4b\u503c\u7684\u671f\u671b**\uff08\u8f83\u5927\u7684\u6d45\u84dd\u8272\u70b9\uff09\uff0c\u6d45\u84dd\u8272\u7684\u5706\u5708\u8868\u793a\u9884\u6d4b\u503c\u7684\u79bb\u6563\u7a0b\u5ea6\uff0c\u5373**\u9884\u6d4b\u503c\u7684\u65b9\u5dee**\u3002 \u6240\u4ee5\uff0c\u7279\u5b9a\u6a21\u578b\u7684\u9884\u6d4b\u503c \u4e0e \u771f\u5b9e\u503c \u7684\u8bef\u5dee\u7684 \u671f\u671b\u503c\uff0c\u5206\u89e3\u4e3a\u4e0a\u9762\u516c\u5f0f\u4e2d\u7684\u4e09\u4e2a\u90e8\u5206\uff0c\u5bf9\u5e94\u5230\u56fe\u4e0a\u7684\u4e09\u6761\u6a59\u8272\u7ebf\u6bb5\uff1a\u9884\u6d4b\u503c\u7684\u504f\u5dee\u3001\u9884\u6d4b\u503c\u7684\u65b9\u5dee\u3001\u6837\u672c\u566a\u97f3\u3002","title":"\u8bef\u5dee\u671f\u671b\u503c\u7684\u5206\u89e3"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_4","text":"\u56de\u987e\u4e00\u4e0b\uff0c \u671f\u671b\u503c**\u7684\u542b\u4e49\u662f\u6307\u5728**\u540c\u6837\u7684\u6761\u4ef6**\u4e0b**\u91cd\u590d\u591a\u6b21**\u968f\u673a\u8bd5\u9a8c\uff0c\u5f97\u5230\u7684\u6240\u6709\u53ef\u80fd\u72b6\u6001\u7684**\u5e73\u5747\u7ed3\u679c \uff08\u66f4\u8be6\u7ec6\u7684\u5b9a\u4e49\u53c2\u8003 \u7ef4\u57fa\u767e\u79d1-\u671f\u671b\u503c \uff09\u3002\u5bf9\u4e8e\u673a\u5668\u5b66\u4e60\u6765\u8bf4\uff0c\u8fd9\u79cd\u5b9e\u9a8c\u5c31\u662f\u6211\u4eec\u9009\u62e9\u4e00\u79cd\u7b97\u6cd5\uff08\u5e76\u9009\u5b9a\u8d85\u53c2\u6570\uff09\uff0c\u4ee5\u53ca\u8bbe\u7f6e\u4e00\u4e2a\u56fa\u5b9a\u7684\u8bad\u7ec3\u96c6\u5927\u5c0f\uff0c\u8fd9\u5c31\u662f\u540c\u6837\u7684\u6761\u4ef6\uff0c\u4e5f\u5c31\u662f\u4e0a\u6587\u6240\u8bf4\u7684**\u7279\u5b9a\u7684\u6a21\u578b**\u3002\u7136\u540e\u6bcf\u6b21\u8bad\u7ec3\u65f6\u4ece\u6837\u672c\u7a7a\u95f4\u4e2d\u9009\u62e9\u4e00\u6279\u6837\u672c\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c\u4f46\u6bcf\u6b21\u90fd\u968f\u673a\u62bd\u53d6\u4e0d\u540c\u7684\u6837\u672c\uff0c\u8fd9\u6837\u91cd\u590d\u8fdb\u884c\u591a\u6b21\u8bad\u7ec3\u3002\u6bcf\u6b21\u8bad\u7ec3\u4f1a\u5f97\u5230\u4e00\u4e2a\u5177\u4f53\u7684\u6a21\u578b\uff0c\u6bcf\u4e2a\u5177\u4f53\u6a21\u578b\u5bf9\u540c\u4e00\u4e2a\u672a\u89c1\u8fc7\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b\u53ef\u4ee5\u5f97\u5230**\u9884\u6d4b\u503c**\u3002\u4e0d\u65ad\u91cd\u590d\u8bad\u7ec3\u548c\u9884\u6d4b\uff0c\u5c31\u80fd\u5f97\u5230\u4e00\u7cfb\u5217\u9884\u6d4b\u503c\uff0c\u6839\u636e\u6837\u672c\u548c\u8fd9\u4e9b\u9884\u6d4b\u503c\u8ba1\u7b97\u51fa\u65b9\u5dee\u548c\u504f\u5dee\uff0c\u5c31\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u8003\u5bdf\u8be5\u7279\u5b9a\u6a21\u578b\u7684**\u9884\u6d4b\u8bef\u5dee\u7684\u671f\u671b\u503c**\uff0c\u4e5f\u5c31\u80fd\u8861\u91cf\u8be5\u7279\u5b9a\u6a21\u578b\u7684\u6027\u80fd\u3002\u5bf9\u6bd4\u591a\u4e2a\u7279\u5b9a\u6a21\u578b\u7684**\u8bef\u5dee\u7684\u671f\u671b\u503c**\uff0c\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002","title":"\u7406\u89e3\u8bef\u5dee\u671f\u671b\u503c"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_5","text":"\u518d\u770b\u4e00\u4e2a\u66f4\u63a5\u8fd1\u5b9e\u9645\u7684\u4f8b\u5b50\uff0c\u6765\u81ea Bias-Variance in Machine Learning \u6211\u4eec\u8bbe\u7f6e\u771f\u5b9e\u6a21\u578b \uff0c\u51fd\u6570\u56fe\u50cf\u5982\u4e0b\u56fe\u66f2\u7ebf\u6240\u793a\u3002 \u6837\u672c\u503c y \u5c31\u5728**\u771f\u5b9e\u503c**\u7684\u57fa\u7840\u4e0a\u53e0\u52a0\u4e00\u4e2a\u968f\u673a\u566a\u97f3 N(0, 0.2)\u3002 \u56fe2 \u6a21\u578b\u53ca\u6837\u672c \u73b0\u5728\u6211\u4eec\u7528\u7ebf\u6027\u51fd\u6570\u6765\u6784\u5efa\u6a21\u578b\uff0c\u8bad\u7ec3\u6837\u672c\u6765\u81ea\u968f\u673a\u91c7\u96c6\u7684\u4e00\u7ec4 y\uff0c\u7ecf\u8fc7\u591a\u6b21\u91cd\u590d\uff0c\u53ef\u4ee5\u5f97\u5230\u4e00\u7cfb\u5217\u5177\u4f53\u7684\u7ebf\u6027\u6a21\u578b\uff0c\u5982\u4e0b\u56fe\u4e2d\u90a3\u4e00\u7ec4\u805a\u96c6\u5728\u4e00\u8d77\u7684\u9ed1\u8272\u76f4\u7ebf\u6240\u793a\uff0c\u5176\u4e2d\u95f4\u6709\u4e00\u6761\u7ea2\u8272\u7ebf\u662f\u8fd9\u4e00\u7ec4\u7ebf\u6027\u51fd\u6570\u7684\u5e73\u5747\uff08\u671f\u671b\u503c\uff09\u3002\u8fd9\u5c31\u662f\u7279\u5b9a\u6a21\u578b\uff08\u7ebf\u6027\u51fd\u6570\uff09\u5728\u540c\u6837\u6761\u4ef6\u4e0b\uff08\u6bcf\u6b21\u53d620\u4e2a\u6837\u672c\u70b9\uff09\u91cd\u590d\u591a\u6b21\uff08\u5f97\u523050\u4e2a\u7ebf\u6027\u51fd\u6570\uff09\u3002 \u6839\u636e\u751f\u6210\u768450\u4e2a\u5177\u4f53\u7684\u7ebf\u6027\u51fd\u6570\u6765\u8003\u5bdf\u8be5\u7ebf\u6027\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u9009\u53d6\u4e00\u4e2a\u6837\u672c\u70b9\uff0c\u6bd4\u5982\u9009\u62e9 x=5 \u65f6\uff08\u4e0b\u56fe\u4e2d\u7ea2\u8272\u7ad6\u7ebf\u4f4d\u7f6e\uff09\uff0c\u771f\u5b9e\u503c f(x) = 6.876\uff0c\u6837\u672c \uff0cy \u4e0e f(x) \u7684\u504f\u5dee\u4f53\u73b0\u5728\u56fe\u7247\u53f3\u4e0b\u65b9\u7684**\u566a\u97f3\uff08noise\uff09** \u90e8\u5206\u3002\u7ea2\u8272\u7ebf\u6027\u51fd\u6570\u5728 x=5 \u4f4d\u7f6e\u7684\u503c\u662f\u8fd950\u4e2a\u7ebf\u6027\u51fd\u6570\u5728\u8be5\u4f4d\u7f6e\u7684\u671f\u671b\u503c\uff0c\u9ed1\u8272\u76f4\u7ebf\u5728 x=5 \u4f4d\u7f6e\u7684\u4e00\u7cfb\u5217\u503c\u7684\u5206\u5e03\u5219\u53cd\u6620\u4e86\u5b83\u4eec\u7684**\u65b9\u5dee\uff08Variance\uff09 \u300250\u4e2a\u9884\u6d4b\u7684\u671f\u671b\u503c\u4e0e\u771f\u5b9e\u503c f(x) \u4e4b\u95f4\u7684\u8ddd\u79bb\u4f53\u73b0\u4e86**\u504f\u5dee\uff08Bias\uff09 \u3002\uff08\u53c2\u8003\u4e0b\u56fe\u53f3\u4e0b\u90e8\u5206\u7684 variance \u548c bias\uff09\u3002 \u56fe3 \u504f\u5dee\u3001\u65b9\u5dee\u8ba1\u7b97 \u603b\u4e4b\uff0c\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u8003\u5bdf \u504f\u5dee \u548c \u65b9\u5dee\uff0c\u6700\u91cd\u8981\u7684\u662f\u8981\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u51fa\u4e00\u7ec4\u7279\u5b9a\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e00\u4e2a\u6d4b\u8bd5\u6837\u672c\u8fdb\u884c\u9884\u6d4b\uff0c\u8003\u5bdf\u8fd9\u4e00\u7ec4\u9884\u6d4b\u503c\u7684\u65b9\u5dee\u548c\u504f\u5dee\u3002","title":"\u8fdb\u4e00\u6b65\u7406\u89e3\u8bef\u5dee\u671f\u671b\u503c"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_6","text":"\u8bef\u5dee\u7684\u671f\u671b\u503c\u516c\u5f0f\u4e3a\u4ec0\u4e48\u53ef\u4ee5\u5206\u89e3\u4e3a \u566a\u97f3\u3001\u504f\u5dee\u548c\u65b9\u5dee\uff0c\u53ef\u4ee5\u4ece\u6570\u5b66\u4e0a\u63a8\u5bfc\u5f97\u6765\u3002\u5148\u51c6\u5907\u51e0\u4e2a\u63a8\u5bfc\u4e2d\u9700\u8981\u7528\u5230\u7684\u516c\u5f0f\uff0c\u4e3a\u4e86\u65b9\u4fbf\uff0c\u6211\u4eec\u7b80\u5316\u7b26\u53f7\uff0c\u8bb0\u4f5c \u65b9\u5dee\u7684\u5b9a\u4e49\u548c\u8ba1\u7b97\u516c\u5f0f \u5373 \u968f\u673a\u53d8\u91cfX\u7684\u65b9\u5dee = X\u5e73\u65b9\u7684\u671f\u671b - X\u671f\u671b\u7684\u5e73\u65b9\uff08\u53c2\u8003 \u7ef4\u57fa\u767e\u79d1-\u65b9\u5dee \uff09\uff0c\u79fb\u9879\u540e\u5f97\u5230 \u6d4b\u8bd5\u6837\u672cy\u7684\u671f\u671b\u503c \u56e0\u4e3a\u771f\u5b9e\u503c \u662f\u4e00\u4e2a\u786e\u5b9a\u7684\u503c\uff0c\u6240\u4ee5 \u53e6\u5916\u6839\u636e\u4e0a\u6587\u6d4b\u8bd5\u6837\u672c\u503c\u548c\u566a\u97f3\u7684\u5b9a\u4e49 \u6240\u4ee5 \uff0c\u5373 \u6d4b\u8bd5\u6837\u672cy\u7684\u65b9\u5dee $$ Var[y] = E[(y - E[y])^2] = E[(y-f)^2] \\ = E[(f+\\varepsilon-f)^2] = E[\\varepsilon^2] \\ = Var[\\varepsilon] + (E[\\varepsilon])^2 = \\sigma^2 $$ \u5373 \u6837\u672c\u566a\u97f3\u4e0e\u9884\u6d4b\u503c\u65e0\u5173 \u56e0\u4e3a \u4e0e \u4e0d\u76f8\u5173\uff0c\u6240\u4ee5 \uff08\u53c2\u8003 \u7ef4\u57fa\u767e\u79d1-\u671f\u671b\u503c ) \u8bef\u5dee\u7684\u671f\u671b \u516c\u5f0f\u63a8\u5bfc\u5982\u4e0b $$ E[(y-\\hat{f})^2] = E[y^2 + \\hat{f}^2 - 2y\\hat{f}] \\ = E[y^2] + E[\\hat{f}^2] - E[2y\\hat{f}] \\ = \\Big(Var[y] + (E[y]))^2 \\Big) + \\Big(Var[\\hat{f}] + (E[\\hat{f}])^2 \\Big) - E[2(f+\\varepsilon) \\hat{f}] \\ = Var[y] + Var[\\hat{f}] + (E[y])^2 + (E[\\hat{f}])^2 - E[2f\\hat{f} +2\\varepsilon \\hat{f}] \\ = Var[y] + Var[\\hat{f}] + f^2 + (E[\\hat{f}])^2 - E[2f\\hat{f}] -E[2\\varepsilon \\hat{f}] \\ = Var[y] + Var[\\hat{f}] + f^2 + (E[\\hat{f}])^2 - 2fE[\\hat{f}] -2E[\\varepsilon]E[\\hat{f}] \\ = Var[y] + Var[\\hat{f}] + \\Big(f^2 + (E[\\hat{f}])^2 - 2fE[\\hat{f}] \\Big) \\ = Var[y] + Var[\\hat{f}] + (f - E[\\hat{f}])^2 \\ = \\sigma^2 + Var[\\hat{f}] + (Bias[\\hat{f}])^2 $$ \u6700\u540e\u5f97\u5230\u7684\u4e09\u4e2a\u9879\u5206\u522b\u662f\uff1a\u566a\u97f3\u7684\u65b9\u5dee\u3001\u6a21\u578b\u9884\u6d4b\u503c\u7684\u65b9\u5dee\u3001\u9884\u6d4b\u503c\u76f8\u5bf9\u771f\u5b9e\u503c\u7684\u504f\u5dee\u7684\u5e73\u65b9\u3002","title":"\u8bef\u5dee\u7684\u671f\u671b\u503c\u516c\u5f0f\u63a8\u5bfc"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#-","text":"\u7406\u60f3\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u5f97\u5230\u4e00\u4e2a\u504f\u5dee\u548c\u65b9\u5dee\u90fd\u5f88\u5c0f\u7684\u6a21\u578b\uff08\u4e0b\u56fe\u5de6\u4e0a\uff09\uff0c\u4f46\u5b9e\u9645\u4e0a\u5f80\u5f80\u5f88\u56f0\u96be\u3002 image \u9009\u62e9\u76f8\u5bf9\u8f83\u597d\u7684\u6a21\u578b\u7684\u987a\u5e8f\uff1a\uff08\u65b9\u5dee\u5c0f\uff0c\u504f\u5dee\u5c0f\uff09 > \uff08\u65b9\u5dee\u5c0f\uff0c\u504f\u5dee\u5927\uff09 > \uff08\u65b9\u5dee\u5927\uff0c\u504f\u5dee\u5c0f\uff09 > \uff08\u65b9\u5dee\u5927\uff0c\u504f\u5dee\u5927\uff09\u3002 \u65b9\u5dee\u5c0f\uff0c\u504f\u5dee\u5927 \u4e4b\u6240\u4ee5\u5728\u5b9e\u9645\u4e2d\u6392\u4f4d\u76f8\u5bf9\u9760\u524d\uff0c\u662f\u56e0\u4e3a\u5b83\u6bd4\u8f83**\u7a33\u5b9a**\u3002\u5f88\u591a\u65f6\u5019\u5b9e\u9645\u4e2d\u65e0\u6cd5\u83b7\u5f97\u975e\u5e38\u5168\u9762\u7684**\u6570\u636e\u96c6**\uff0c\u90a3\u4e48\uff0c\u5982\u679c\u4e00\u4e2a\u6a21\u578b\u5728\u53ef\u83b7\u5f97\u7684\u6837\u672c\u4e0a\u6709\u8f83\u5c0f\u7684\u65b9\u5dee\uff0c\u8bf4\u660e\u5b83\u5bf9\u4e0d\u540c\u6570\u636e\u96c6\u7684\u654f\u611f\u5ea6\u4e0d\u9ad8\uff0c\u53ef\u4ee5\u671f\u671b\u5b83\u5bf9\u65b0\u6570\u636e\u96c6\u7684\u9884\u6d4b\u6548\u679c\u6bd4\u8f83\u7a33\u5b9a\u3002","title":"\u504f\u5dee - \u65b9\u5dee\u7684\u9009\u62e9"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_7","text":"\u5f88\u591a\u65f6\u5019\uff0c\u673a\u5668\u5b66\u4e60\u6240\u9762\u4e34\u7684\u95ee\u9898\uff0c\u6211\u4eec\u4e8b\u5148\u5e76\u4e0d\u786e\u5207\u7684\u77e5\u9053\u8981\u62df\u5408\u7684\u662f\u4e00\u4e2a\u600e\u6837\u5f62\u5f0f\u7684\u51fd\u6570\uff0c\u662f\u51e0\u6b21\u591a\u9879\u5f0f\uff0c\u662f\u51e0\u5c42\u795e\u7ecf\u7f51\u7edc\uff0c\u9009\u62e9\u6837\u672c\u7684\u54ea\u4e9b\u7279\u5f81\uff0c\u7b49\u7b49\uff0c\u90fd\u7f3a\u4e4f\u5148\u9a8c\u7684\u77e5\u8bc6\u6765\u5e2e\u52a9\u6211\u4eec\u9009\u62e9\u3002\u6211\u4eec\u5728\u4e00\u4e2a\u57fa\u672c\u4e0a\u65e0\u7a77\u5927\u7684**\u5047\u8bbe\uff08\u6a21\u578b\uff09\u96c6\u5408**\u4e2d\uff0c\u51ed\u501f\u6709\u9650\u7684\u7ecf\u9a8c\u8fdb\u884c\u5c1d\u8bd5\u548c\u9009\u62e9\u3002 \u673a\u5668\u5b66\u4e60\u6709\u591a\u79cd\u7b97\u6cd5\uff0c\u4ee5\u53ca\u6bcf\u79cd\u7b97\u6cd5\u4e2d\u7ecf\u5e38\u53c8\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u7684\u7ed3\u6784\u548c\u8d85\u53c2\u6570\u3002\u5b83\u4eec\u6240\u8986\u76d6\u7684\u5047\u8bbe\u96c6\u5408\u6709\u4e0d\u540c\u7684\u5927\u5c0f\u3002\u6240\u4ee5\uff0c\u9009\u62e9\u4e00\u79cd\u7b97\u6cd5\uff08\u5305\u62ec\u5176\u7ed3\u6784\u548c\u8d85\u53c2\u6570\uff09\uff0c\u5c31\u662f\u9009\u62e9\uff08\u9650\u5b9a\uff09\u4e86\u4e00\u4e2a**\u5047\u8bbe\u96c6\u5408**\u3002\u6211\u4eec\u671f\u671b\u771f\u5b9e\u6a21\u578b\u5b58\u5728\u4e8e\u6211\u4eec\u6240\u9009\u5b9a\u7684**\u5047\u8bbe\u96c6\u5408**\u8303\u56f4\u5185\uff0c\u5e76\u4e14\u8be5**\u5047\u8bbe\u96c6\u5408**\u8d8a\u5c0f\u8d8a\u597d\u3002 \u4e0b\u9762\u4e24\u5e45\u56fe\u7c97\u7565\u8868\u73b0\u4e86\u4e0d\u540c**\u5047\u8bbe\u96c6\u5408**\u7684\u5173\u7cfb \u4e0d\u540c\u7684**\u5047\u8bbe\u96c6\u5408** **\u6b63\u5219\u5316\u9879**\u5bf9\u5047\u8bbe\u96c6\u5408\u7684\u5f71\u54cd \u6211\u4eec\u601d\u8003\u4e00\u4e0b\u76d1\u7763\u5b66\u4e60\u7684\u6574\u4e2a\u6d41\u7a0b\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u4e0d\u65ad\u7f29\u5c0f**\u5047\u8bbe\u96c6\u5408**\u7684\u8fc7\u7a0b\u3002\u4ece\u5927\u7684\u65b9\u9762\u770b\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4\u3002 \u9009\u62e9\u4e00\u4e2a**\u5047\u8bbe\u96c6\u5408**\uff0c\u5305\u62ec\u6a21\u578b\u53ca\u76f8\u5173\u7ed3\u6784\u3001\u8d85\u53c2\u6570\u7b49\u3002 \u4f7f\u7528\u6837\u672c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f7f\u8be5\u6a21\u578b\u5c3d\u91cf\u62df\u5408\u6837\u672c\uff0c\u5c31\u662f\u4ece\u4e0a\u9762\u9009\u5b9a\u7684\u5047\u8bbe\u96c6\u5408\u4e2d\u627e\u5230\u4e00\u4e2a\u7279\u5b9a\u7684\u5047\u8bbe\uff08\u6a21\u578b\uff09\u3002 \u4e0a\u9762\u7b2c\u4e00\u4e2a\u6b65\u9aa4\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u4e00\u4e9b\u4e0d\u540c\u7684\u5047\u8bbe\u96c6\u5408\uff0c\u7136\u540e\u901a\u8fc7\u8003\u5bdf\u5b83\u4eec\u7684**\u504f\u5dee\u65b9\u5dee**\uff0c\u5bf9\u5404**\u5047\u8bbe\u96c6\u5408**\u7684**\u6027\u80fd**\u8fdb\u884c\u8bc4\u4f30\u3002\u6bd4\u5982\u591a\u9879\u5f0f\u7684\u6b21\u6570\uff0c\u4e0a\u56fe\u5047\u8bbe\u771f\u5b9e\u6a21\u578b\u662f\u4e00\u4e2a\u4e8c\u6b21\u591a\u9879\u5f0f\uff0c\u90a3\u4e48\u7ebf\u6027\u51fd\u6570\u96c6\u5408\u4e2d\u7684\u6a21\u578b\u4f1a**\u6b20\u62df\u5408**\uff08 \u65b9\u5dee\u4f4e \uff0c \u504f\u5dee\u592a\u9ad8 \uff09\uff0c\u9ad8\u6b21\u591a\u9879\u5f0f\u96c6\u5408\u4e2d\u7684\u6a21\u578b\u5bb9\u6613**\u8fc7\u62df\u5408**\uff08\u65b9\u5dee\u592a\u9ad8\uff0c\u504f\u5dee\u4f4e\uff09\uff0c\u4e8c\u9879\u5f0f\u96c6\u5408\u4e2d\u7684\u6a21\u578b\u80fd\u591f\u6709\u8f83\u597d\u7684\u6298\u4e2d\uff08\u65b9\u5dee\u548c\u504f\u5dee\u90fd\u76f8\u5bf9\u8f83\u4f4e\uff09\uff0c\u603b\u4f53**\u8bef\u5dee**\u6700\u5c0f\u3002","title":"\u9009\u62e9\u5047\u8bbe\u96c6\u5408"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#-_1","text":"\u591a\u9879\u5f0f\u56de\u5f52 \u591a\u9879\u5f0f\u56de\u5f52\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u7684\u591a\u9879\u5f0f\u7684\u6b21\u6570\uff0c\u5bf9\u6a21\u578b\u7684\u5f71\u54cd\u5982\u4e0b\u3002 \u591a\u9879\u5f0f\u6b21\u6570\u5bf9\u6a21\u578b\u504f\u5dee\u65b9\u5dee\u7684\u5f71\u54cd \u591a\u9879\u5f0f\u6b21\u6570 \u6a21\u578b\u590d\u6742\u5ea6 \u65b9\u5dee \u504f\u5dee \u8fc7/\u6b20\u62df\u5408 \u4f4e \u4f4e \u4f4e \u9ad8 \u6b20\u62df\u5408 \u4e2d \u4e2d \u4e2d \u4e2d \u9002\u5ea6 \u9ad8 \u9ad8 \u9ad8 \u4f4e \u8fc7\u62df\u5408 \u591a\u9879\u5f0f\u6b21\u6570\u5bf9\u8bad\u7ec3\u8bef\u5dee/\u6d4b\u8bd5\u8bef\u5dee\u7684\u5f71\u54cd \u591a\u9879\u5f0f\u6b21\u6570 \u6a21\u578b\u590d\u6742\u5ea6 \u8bad\u7ec3\u8bef\u5dee \u6d4b\u8bd5\u8bef\u5dee \u4f4e \u4f4e \u9ad8 \u9ad8 \u4e2d \u4e2d \u4e2d \u4f4e \u9ad8 \u9ad8 \u4f4e \u9ad8 \u6b63\u5219\u5316\u9879 \u6dfb\u52a0\u6b63\u5219\u5316\u9879\uff08Regularization\uff09\u76f8\u5f53\u4e8e\u5bf9\u6a21\u578b\u53c2\u6570\u65bd\u52a0\u60e9\u7f5a\uff0c\u538b\u7f29\u4e86\u53c2\u6570\u7684\u8303\u56f4\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u590d\u6742\u5ea6\uff0c\u4ece\u800c\u6709\u52a9\u4e8e\u7f13\u89e3\u6a21\u578b\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u9009\u62e9\u4e0d\u540c\u7684 \u6b63\u5219\u5316\u9879\u6743\u91cd\u03bb \u5bf9\u6a21\u578b\u7684\u5f71\u54cd\u5982\u4e0b\u3002 \u6b63\u5219\u5316\u9879\u5bf9\u6a21\u578b\u504f\u5dee\u65b9\u5dee\u7684\u5f71\u54cd \u6b63\u5219\u5316\u9879\u6743\u91cd\u03bb \u6a21\u578b\u590d\u6742\u5ea6 \u65b9\u5dee \u504f\u5dee \u8fc7/\u6b20\u62df\u5408 \u5927 \u4f4e \u4f4e \u9ad8 \u6b20\u62df\u5408 \u4e2d \u4e2d \u4e2d \u4e2d \u9002\u5ea6 \u5c0f \u9ad8 \u9ad8 \u4f4e \u8fc7\u62df\u5408 \u6b63\u5219\u5316\u9879\u5bf9\u8bad\u7ec3\u8bef\u5dee/\u6d4b\u8bd5\u8bef\u5dee\u7684\u5f71\u54cd \u6b63\u5219\u5316\u9879\u6743\u91cd\u03bb \u6a21\u578b\u590d\u6742\u5ea6 \u8bad\u7ec3\u8bef\u5dee \u6d4b\u8bd5\u8bef\u5dee \u5927 \u4f4e \u9ad8 \u9ad8 \u4e2d \u4e2d \u4e2d \u4f4e \u5c0f \u9ad8 \u4f4e \u9ad8 \u6837\u672c\u6570\u91cf \u4e00\u822c\u6765\u8bf4\uff0c\u6211\u4eec\u5e0c\u671b**\u6837\u672c\u6570\u91cf**\u8d8a\u591a\u8d8a\u597d\u3002\u968f\u7740**\u6837\u672c\u6570\u91cf**\u589e\u52a0\uff0c\u8bad\u7ec3\u8bef\u5dee\u4f1a\u9010\u6e10\u589e\u957f\uff0c\u6d4b\u8bd5\u8bef\u5dee\u4f1a\u9010\u6e10\u964d\u4f4e\u3002 \u6837\u672c\u6570\u91cf\u5bf9\u8bad\u7ec3\u8bef\u5dee/\u6d4b\u8bd5\u8bef\u5dee\u7684\u5f71\u54cd \u795e\u7ecf\u7f51\u7edc \u795e\u7ecf\u7f51\u7edc\u7ed3\u6784 \u795e\u7ecf\u7f51\u7edc\u7ed3\u6784 \u6a21\u578b\u590d\u6742\u5ea6 \u65b9\u5dee \u504f\u5dee \u8fc7/\u6b20\u62df\u5408 \u5c0f \u4f4e \u4f4e \u9ad8 \u6b20\u62df\u5408 \u4e2d \u4e2d \u4e2d \u4e2d \u9002\u5ea6 \u5927 \u9ad8 \u9ad8 \u4f4e \u8fc7\u62df\u5408","title":"\u504f\u5dee - \u65b9\u5dee\u6743\u8861"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#k-fold","text":"\u8ba1\u7b97\u504f\u5dee\u3001\u65b9\u5dee\u53ef\u4ee5\u5e2e\u52a9\u8bc4\u4f30\u4e0d\u540c\u7684\u5047\u8bbe\u96c6\u5408\uff0c\u4e0d\u8fc7\u5b83\u9700\u8981\u8f83\u591a\u7684\u6837\u672c\uff0c\u4ee5\u53ca\u91cd\u590d\u591a\u6b21\u62df\u5408\u6a21\u578b\uff0c\u9700\u8981\u6bd4\u8f83\u591a\u7684\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff08\u53c2\u8003\u4e0a\u9762\u56fe3\uff09\u3002 \u5b9e\u9645\u4e2d\uff0c\u6bd4\u8f83\u5e38\u7528\u7684\u65b9\u6cd5\u662fK-Fold\u4ea4\u53c9\u9a8c\u8bc1\u3002\u5b83\u4e0e\u6807\u51c6\u7684\u504f\u5dee\u3001\u65b9\u5dee\u8ba1\u7b97\u8fc7\u7a0b\u4e0d\u592a\u4e00\u6837\u3002\u7b80\u5355\u7684\u8bf4\uff0c\u5c31\u662f\u5c06\u8bad\u7ec3\u6837\u672c\u5206\u6210k\u4efd\uff0c\u6bcf\u6b21\u53d6\u5176\u4e2d\u4e00\u4efd\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u53e6\u5916 k-1 \u4efd\u4f5c\u8bad\u7ec3\u96c6\u3002\u8fd9\u6837\u8fdb\u884c k \u6b21\u8bad\u7ec3\u5f97\u5230 k \u4e2a\u6a21\u578b\u3002\u8fd9 k \u4e2a\u6a21\u578b\u5bf9\u5404\u81ea\u7684\u9a8c\u8bc1\u96c6\u8fdb\u884c\u9884\u6d4b\uff0c\u5f97\u5230 k \u4e2a\u8bc4\u4f30\u503c\uff08\u53ef\u4ee5\u662f\u8bef\u5dee\u3001\u51c6\u786e\u7387\uff0c\u6216\u6309\u67d0\u79cd\u89c4\u5219\u8ba1\u7b97\u7684\u5f97\u5206\u7b49\u7b49\uff09\u3002\u6ce8\u610f\u5230\u6bcf\u4e2a\u6837\u672c\u53c2\u4e0e\u4e86 k-1 \u4e2a\u6a21\u578b\u7684\u8bad\u7ec3\uff08\u5bfc\u81f4\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u5173\u8054\uff09\uff0c\u6bcf\u4e2a\u6837\u672c\u6709\u4e00\u6b21\u88ab\u7528\u4f5c\u6d4b\u8bd5\uff08\u6ca1\u6709\u7528\u53e6\u5916\u7684\u4ece\u672a\u89c1\u8fc7\u7684\u6d4b\u8bd5\u96c6\u6570\u636e\uff09\uff0c\u6240\u4ee5\u8fd9\u4e0e\u6807\u51c6\u7684\u8ba1\u7b97\u8fc7\u7a0b\u662f\u4e0d\u4e00\u6837\u7684\u3002 \u4e0d\u8fc7\uff0cK-Fold\u4f9d\u7136\u662f\u5f88\u6709\u4ef7\u503c\u7684\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\u3002\u53ef\u4ee5\u76f4\u63a5\u9488\u5bf9\u8fd9 k \u4e2a\u6a21\u578b\u7684\u8bc4\u4f30\u503c\uff08\u8bef\u5dee\u3001\u51c6\u786e\u7387\uff0c\u6216\u6309\u67d0\u79cd\u89c4\u5219\u8ba1\u7b97\u7684\u5f97\u5206\u7b49\u7b49\uff09\u8fdb\u884c\u5206\u6790\uff0c\u53d6\u5176\u5e73\u5747\u53ef\u4ee5\u4f53\u73b0\u8be5\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u5bf9\u8fd9 k \u4e2a\u503c\uff0c\u6bd4\u5982k\u4e2a\u8bef\u5dee\u503c\uff0c\u8ba1\u7b97**\u65b9\u5dee**\uff0c\u53ef\u4ee5\u53cd\u5e94\u8be5\u6a21\u578b\u7684\u9884\u6d4b\u8bef\u5dee\u7684\u79bb\u6563\u7a0b\u5ea6\uff0c\u5373\u540e\u7eed\u7528\u4e8e\u672a\u89c1\u8fc7\u7684\u6837\u672c\u6570\u636e\u65f6\uff0c\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u662f\u5426**\u7a33\u5b9a**\u3002","title":"K-Fold \u4ea4\u53c9\u9a8c\u8bc1"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/5.4-Estimators-Bias-and-Variance/#_8","text":"\u7ef4\u57fa\u767e\u79d1 - Bias\u2013variance tradeoff Bias-Variance in Machine Learning \u7ef4\u57fa\u767e\u79d1 - \u65b9\u5dee \u7ef4\u57fa\u767e\u79d1 - \u671f\u671b\u503c \u300aPattern Recognition and Machine Learning\u300b\u4e4b 3.2. The Bias-Variance Decomposition","title":"\u53c2\u8003"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/Bias%E2%80%93variance%20tradeoff/","text":"Bias\u2013variance tradeoff Bias\u2013variance tradeoff Understanding the Bias-Variance Tradeoff","title":"Bias\u2013variance tradeoff"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/Bias%E2%80%93variance%20tradeoff/#biasvariance#tradeoff","text":"","title":"Bias\u2013variance tradeoff"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/Bias%E2%80%93variance%20tradeoff/#biasvariance#tradeoff_1","text":"","title":"Bias\u2013variance tradeoff"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.4-Estimators-Bias-and-Variance/Bias%E2%80%93variance%20tradeoff/#understanding#the#bias-variance#tradeoff","text":"","title":"Understanding the Bias-Variance Tradeoff"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.5-Maximum-Likelihood-Estimation/5.5-Maximum-Likelihood-Estimation/","text":"5.5 Maximum Likelihood Estimation Previously, we have seen some definitions of common estimators and analyzed their properties. But where did these estimators come from? Rather than guessing that some function might make a good estimator and then analyzing its bias and variance , we would like to have some principle from which we can derive specific functions that are good estimators for different models. The most common such principle is the maximum likelihood principle . Consider a set of m examples \\mathbb{X}={x^{(1)}, \\ldots, x^{(m)}} \\mathbb{X}={x^{(1)}, \\ldots, x^{(m)}} drawn independently from the true but unknown data generating distribution $p_{data} (x) $. Let p_{model} ( x ; \\theta ) p_{model} ( x ; \\theta ) be a parametric family of probability distributions over the same space indexed by \\theta \\theta . In other words, p_{model} ( x ; \\theta ) p_{model} ( x ; \\theta ) maps any configuration x x to a real number estimating the true probability $p_{data} (x) $. The maximum likelihood estimator for \\theta \\theta is then defined as $$ \\theta_{ML} = \\argmax_\\theta p_{model}(\\mathbb{X};\\theta) \\qquad{(5.56)}\\ =\\argmax_\\theta \\prod_{i=1}^m p_{model}(x^{(i)};\\theta) \\qquad{(5.57)}\\ $$ SUMMARY : \u4e0a\u5f0f\u4e2d**ML**\u7684\u542b\u4e49\u662fmaximize likelihood\uff1b This product over many probabilities can be inconvenient for a variety of reasons. For example, it is prone to numerical underflow. To obtain a more convenient but equivalent optimization problem, we observe that taking the logarithm of the likelihood does not change its argmax but does conveniently transform a product into a sum: $$ \\theta_{ML} = \\argmax_\\theta \\sum_{i=1}^m \\log p_{model}(x^{(i)};\\theta) \\qquad{(5.58)}\\ $$ Because the argmax does not change when we rescale the cost function , we can divide by m to obtain a version of the criterion that is expressed as an expectation with respect to the empirical distribution \\hat p_{data} \\hat p_{data} defined by the training data: $$ \\theta_{ML} = \\argmax_\\theta \\mathbb{E} {X \\sim \\hat p {data}} \\log p_{model}(x;\\theta) \\qquad{(5.59)}\\ $$ SUMMARY : equation {(5.58)} {(5.58)} \u9664\u4ee5 m m \u5c31\u5f97\u5230\u4e86 equation {(5.59)} {(5.59)} SUMMARY : \\hat p_{data} \\hat p_{data} \u8868\u793a\u7684\u662f X X \u7684 empirical distribution defined by the training set One way to interpret maximum likelihood estimation is to view it as minimizing the dissimilarity between the empirical distribution \\hat p_{data} \\hat p_{data} defined by the training set and the model distribution, with the degree of dissimilarity between the two measured by the KL divergence . The KL divergence is given by $$ D_{KL}(\\hat p_{data} \\mid\\mid p_{model}) = \\mathbb{E} {X \\sim \\hat p {data}} [\\log \\hat p_{data}(x) - \\log p_{model}(x)] \\qquad{(5.60)} $$ The term on the left is a function only of the data generating process, not the model. This means when we train the model to minimize the KL divergence, we need only minimize $$ -\\mathbb{E} {X \\sim \\hat p {data}}[\\log p_{model}(x)] \\qquad{(5.61)} $$ which is of course the same as the maximization in equation {(5.59)} {(5.59)} . Minimizing this KL divergence corresponds exactly to minimizing the cross-entropy between the distributions. Many authors use the term \u201ccross-entropy\u201d to identify specifically the negative log-likelihood of a Bernoulli or softmax distribution, but that is a misnomer\uff08\u7528\u8bcd\u4e0d\u5f53\uff09. Any loss consisting of a negative log-likelihood is a cross-entropy between the empirical distribution defined by the training set and the probability distribution defined by model. For example, mean squared error is the cross-entropy between the empirical distribution and a Gaussian model . We can thus see maximum likelihood as an attempt to make the model distribution match the empirical distribution \\hat p_{data} \\hat p_{data} . Ideally, we would like to match the true data generating distribution p_{data} p_{data} , but we have no direct access to this distribution. While the optimal \\theta \\theta is the same regardless of whether we are maximizing the likelihood or minimizing the KL divergence , the values of the objective functions are different. In software, we often phrase both as minimizing a cost function. Maximum likelihood thus becomes minimization of the negative log-likelihood (NLL), or equivalently, minimization of the cross entropy . The perspective of maximum likelihood as minimum KL divergence becomes helpful in this case because the KL divergence has a known minimum value of zero. The negative log-likelihood can actually become negative when is real-valued. 5.5.1 Conditional Log-Likelihood and Mean Squared Error The maximum likelihood estimator can readily be generalized to the case where our goal is to estimate a conditional probability P ( y \\mid x ; \\theta ) P ( y \\mid x ; \\theta ) in order to predict y y given x x . This is actually the most common situation because it forms the basis for most supervised learning . If X X represents all our inputs and Y Y all our observed targets, then the conditional maximum likelihood estimator is $$ \\theta_{ML} = \\argmax_\\theta P({Y} \\mid X; \\theta) \\qquad{(5.62)}\\ $$ If the examples are assumed to be i.i.d., then this can be decomposed into $$ \\theta_{ML} = \\argmax_\\theta \\sum_{i=1}^m P({y^{(i)}} \\mid x^{(i)}; \\theta) \\qquad{(5.63)}\\ $$ 5.5.2 Properties of Maximum Likelihood The main appeal of the maximum likelihood estimator is that it can be shown to be the best estimator asymptotically, as the number of examples m \\to \\infty m \\to \\infty , in terms of its rate of convergence as m increases. Under appropriate conditions, the maximum likelihood estimator has the property of consistency (see section above), meaning that as the number 5.4.5 of training examples approaches infinity, the maximum likelihood estimate of a parameter converges to the true value of the parameter. These conditions are: The true distribution p_{data} p_{data} must lie within the model family p_{model} ( \u00b7 ; \\theta ) p_{model} ( \u00b7 ; \\theta ) . Otherwise, no estimator can recover p_{data} p_{data} . The true distribution p_{data} p_{data} must correspond to exactly one value of \\theta \\theta . Otherwise, maximum likelihood can recover the correct p_{data} p_{data} , but will not be able to determine which value of was used by the data generating processing. For these reasons (consistency and efficiency), maximum likelihood is often considered the preferred estimator to use for machine learning. When the number of examples is small enough to yield overfitting behavior, regularization strategies such as weight decay may be used to obtain a biased version of maximum likelihood that has less variance when training data is limited.","title":"5.5-Maximum-Likelihood-Estimation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.5-Maximum-Likelihood-Estimation/5.5-Maximum-Likelihood-Estimation/#55#maximum#likelihood#estimation","text":"Previously, we have seen some definitions of common estimators and analyzed their properties. But where did these estimators come from? Rather than guessing that some function might make a good estimator and then analyzing its bias and variance , we would like to have some principle from which we can derive specific functions that are good estimators for different models. The most common such principle is the maximum likelihood principle . Consider a set of m examples \\mathbb{X}={x^{(1)}, \\ldots, x^{(m)}} \\mathbb{X}={x^{(1)}, \\ldots, x^{(m)}} drawn independently from the true but unknown data generating distribution $p_{data} (x) $. Let p_{model} ( x ; \\theta ) p_{model} ( x ; \\theta ) be a parametric family of probability distributions over the same space indexed by \\theta \\theta . In other words, p_{model} ( x ; \\theta ) p_{model} ( x ; \\theta ) maps any configuration x x to a real number estimating the true probability $p_{data} (x) $. The maximum likelihood estimator for \\theta \\theta is then defined as $$ \\theta_{ML} = \\argmax_\\theta p_{model}(\\mathbb{X};\\theta) \\qquad{(5.56)}\\ =\\argmax_\\theta \\prod_{i=1}^m p_{model}(x^{(i)};\\theta) \\qquad{(5.57)}\\ $$ SUMMARY : \u4e0a\u5f0f\u4e2d**ML**\u7684\u542b\u4e49\u662fmaximize likelihood\uff1b This product over many probabilities can be inconvenient for a variety of reasons. For example, it is prone to numerical underflow. To obtain a more convenient but equivalent optimization problem, we observe that taking the logarithm of the likelihood does not change its argmax but does conveniently transform a product into a sum: $$ \\theta_{ML} = \\argmax_\\theta \\sum_{i=1}^m \\log p_{model}(x^{(i)};\\theta) \\qquad{(5.58)}\\ $$ Because the argmax does not change when we rescale the cost function , we can divide by m to obtain a version of the criterion that is expressed as an expectation with respect to the empirical distribution \\hat p_{data} \\hat p_{data} defined by the training data: $$ \\theta_{ML} = \\argmax_\\theta \\mathbb{E} {X \\sim \\hat p {data}} \\log p_{model}(x;\\theta) \\qquad{(5.59)}\\ $$ SUMMARY : equation {(5.58)} {(5.58)} \u9664\u4ee5 m m \u5c31\u5f97\u5230\u4e86 equation {(5.59)} {(5.59)} SUMMARY : \\hat p_{data} \\hat p_{data} \u8868\u793a\u7684\u662f X X \u7684 empirical distribution defined by the training set One way to interpret maximum likelihood estimation is to view it as minimizing the dissimilarity between the empirical distribution \\hat p_{data} \\hat p_{data} defined by the training set and the model distribution, with the degree of dissimilarity between the two measured by the KL divergence . The KL divergence is given by $$ D_{KL}(\\hat p_{data} \\mid\\mid p_{model}) = \\mathbb{E} {X \\sim \\hat p {data}} [\\log \\hat p_{data}(x) - \\log p_{model}(x)] \\qquad{(5.60)} $$ The term on the left is a function only of the data generating process, not the model. This means when we train the model to minimize the KL divergence, we need only minimize $$ -\\mathbb{E} {X \\sim \\hat p {data}}[\\log p_{model}(x)] \\qquad{(5.61)} $$ which is of course the same as the maximization in equation {(5.59)} {(5.59)} . Minimizing this KL divergence corresponds exactly to minimizing the cross-entropy between the distributions. Many authors use the term \u201ccross-entropy\u201d to identify specifically the negative log-likelihood of a Bernoulli or softmax distribution, but that is a misnomer\uff08\u7528\u8bcd\u4e0d\u5f53\uff09. Any loss consisting of a negative log-likelihood is a cross-entropy between the empirical distribution defined by the training set and the probability distribution defined by model. For example, mean squared error is the cross-entropy between the empirical distribution and a Gaussian model . We can thus see maximum likelihood as an attempt to make the model distribution match the empirical distribution \\hat p_{data} \\hat p_{data} . Ideally, we would like to match the true data generating distribution p_{data} p_{data} , but we have no direct access to this distribution. While the optimal \\theta \\theta is the same regardless of whether we are maximizing the likelihood or minimizing the KL divergence , the values of the objective functions are different. In software, we often phrase both as minimizing a cost function. Maximum likelihood thus becomes minimization of the negative log-likelihood (NLL), or equivalently, minimization of the cross entropy . The perspective of maximum likelihood as minimum KL divergence becomes helpful in this case because the KL divergence has a known minimum value of zero. The negative log-likelihood can actually become negative when is real-valued.","title":"5.5 Maximum Likelihood Estimation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.5-Maximum-Likelihood-Estimation/5.5-Maximum-Likelihood-Estimation/#551#conditional#log-likelihood#and#mean#squared#error","text":"The maximum likelihood estimator can readily be generalized to the case where our goal is to estimate a conditional probability P ( y \\mid x ; \\theta ) P ( y \\mid x ; \\theta ) in order to predict y y given x x . This is actually the most common situation because it forms the basis for most supervised learning . If X X represents all our inputs and Y Y all our observed targets, then the conditional maximum likelihood estimator is $$ \\theta_{ML} = \\argmax_\\theta P({Y} \\mid X; \\theta) \\qquad{(5.62)}\\ $$ If the examples are assumed to be i.i.d., then this can be decomposed into $$ \\theta_{ML} = \\argmax_\\theta \\sum_{i=1}^m P({y^{(i)}} \\mid x^{(i)}; \\theta) \\qquad{(5.63)}\\ $$","title":"5.5.1 Conditional Log-Likelihood and Mean Squared Error"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/5.5-Maximum-Likelihood-Estimation/5.5-Maximum-Likelihood-Estimation/#552#properties#of#maximum#likelihood","text":"The main appeal of the maximum likelihood estimator is that it can be shown to be the best estimator asymptotically, as the number of examples m \\to \\infty m \\to \\infty , in terms of its rate of convergence as m increases. Under appropriate conditions, the maximum likelihood estimator has the property of consistency (see section above), meaning that as the number 5.4.5 of training examples approaches infinity, the maximum likelihood estimate of a parameter converges to the true value of the parameter. These conditions are: The true distribution p_{data} p_{data} must lie within the model family p_{model} ( \u00b7 ; \\theta ) p_{model} ( \u00b7 ; \\theta ) . Otherwise, no estimator can recover p_{data} p_{data} . The true distribution p_{data} p_{data} must correspond to exactly one value of \\theta \\theta . Otherwise, maximum likelihood can recover the correct p_{data} p_{data} , but will not be able to determine which value of was used by the data generating processing. For these reasons (consistency and efficiency), maximum likelihood is often considered the preferred estimator to use for machine learning. When the number of examples is small enough to yield overfitting behavior, regularization strategies such as weight decay may be used to obtain a biased version of maximum likelihood that has less variance when training data is limited.","title":"5.5.2 Properties of Maximum Likelihood"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Pattern-recognition/","text":"Pattern recognition Sequence labeling","title":"Pattern-recognition"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Pattern-recognition/#pattern#recognition","text":"Sequence labeling","title":"Pattern recognition"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/","text":"Sequence Labeling: Generative and Discriminative Approaches Sequence labeling problem definition I Given a sequence of observations/feature vectors, determine an appropriate label/state for each observation We will assume the observations can be discrete or continuous, scalar or vector We assume the labels/states are discrete and from a finite set Try to reduce errors by considering the relations between the observations and states (observation-state) and the relation between neighboring states (state-state) Sequence labeling applications Speech recognition Part-of-speech tagging Shallow parsing Handwriting recognition Protein secondary structure prediction Video analysis Facial expression dynamic modeling Urns and balls example Assume there are two urns with black and white balls [Rabiner, 1989]. One urn has more black than white (90% vs 10%) and vice versa. Someone pulls out one ball at a time and shows us without revealing which urn he uses and puts it back into the urn. He is more likely to use the same urn (90% chance) once he starts using one We are looking only at the sequence of balls and recording them. Questions about the urns and balls example Questions of interest: Can we predict which urn is used at a given time? What is the probability of observing the sequence of balls shown to us? Can we estimate/learn the ratio of balls in each urn by looking at a long sequence of balls if we did not know the ratios beforehand? Jason Eisner\u2019s ice-cream example Try to guess whether the weather was hot or cold by observing only how many ice-creams (0, 1, 2 or 3+) Jason ate each day in a sequence of 30 days. Two states and observations with 4 distinct values (discrete observations). Question: Can we determine if a day was hot or cold given the sequence of ice-creams consumed by Jason? Example excel sheet online (illustrates forward backward algorithm). Example also adopted in [Jurafsky and Martin, 2008] Approach, notation and variables We will first analyze binary and multi-class classification with linear models. Multi-class classification will be the basis for understanding the sequence labeling problem . Then, we will introduce HMM, CRF, and structured SVM approaches for sequence labeling. Notation: x x is an observed feature vector, x_t x_t a feature vector at sequence position t t , x_{1:T} x_{1:T} a sequence of feature vectors. y y is a discrete label (or state), y \\in Y y \\in Y where Y = {\u22121, +1} Y = {\u22121, +1} for binary classification, Y = [M] = {1, 2, . . . , M} Y = [M] = {1, 2, . . . , M} for multi-class classification. y_t y_t is the label/state at sequence position t t , y_{1:T} y_{1:T} is a sequence of labels/states w w and w\u02dc are parameter vectors, w_j w_j is the j j th component. F(x_{1:T} , y_{1:T} ) F(x_{1:T} , y_{1:T} ) is a feature vector for CRF and structured SVM","title":"Sequence-Labeling-Generative-and-Discriminative"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/#sequence#labeling#generative#and#discriminative#approaches","text":"","title":"Sequence Labeling: Generative and Discriminative Approaches"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/#sequence#labeling#problem#definition#i","text":"Given a sequence of observations/feature vectors, determine an appropriate label/state for each observation We will assume the observations can be discrete or continuous, scalar or vector We assume the labels/states are discrete and from a finite set Try to reduce errors by considering the relations between the observations and states (observation-state) and the relation between neighboring states (state-state)","title":"Sequence labeling problem definition I"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/#sequence#labeling#applications","text":"Speech recognition Part-of-speech tagging Shallow parsing Handwriting recognition Protein secondary structure prediction Video analysis Facial expression dynamic modeling","title":"Sequence labeling applications"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/#urns#and#balls#example","text":"Assume there are two urns with black and white balls [Rabiner, 1989]. One urn has more black than white (90% vs 10%) and vice versa. Someone pulls out one ball at a time and shows us without revealing which urn he uses and puts it back into the urn. He is more likely to use the same urn (90% chance) once he starts using one We are looking only at the sequence of balls and recording them.","title":"Urns and balls example"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/#questions#about#the#urns#and#balls#example","text":"Questions of interest: Can we predict which urn is used at a given time? What is the probability of observing the sequence of balls shown to us? Can we estimate/learn the ratio of balls in each urn by looking at a long sequence of balls if we did not know the ratios beforehand?","title":"Questions about the urns and balls example"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/#jason#eisners#ice-cream#example","text":"Try to guess whether the weather was hot or cold by observing only how many ice-creams (0, 1, 2 or 3+) Jason ate each day in a sequence of 30 days. Two states and observations with 4 distinct values (discrete observations). Question: Can we determine if a day was hot or cold given the sequence of ice-creams consumed by Jason? Example excel sheet online (illustrates forward backward algorithm). Example also adopted in [Jurafsky and Martin, 2008]","title":"Jason Eisner\u2019s ice-cream example"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-Labeling-Generative-and-Discriminative/#approach#notation#and#variables","text":"We will first analyze binary and multi-class classification with linear models. Multi-class classification will be the basis for understanding the sequence labeling problem . Then, we will introduce HMM, CRF, and structured SVM approaches for sequence labeling. Notation: x x is an observed feature vector, x_t x_t a feature vector at sequence position t t , x_{1:T} x_{1:T} a sequence of feature vectors. y y is a discrete label (or state), y \\in Y y \\in Y where Y = {\u22121, +1} Y = {\u22121, +1} for binary classification, Y = [M] = {1, 2, . . . , M} Y = [M] = {1, 2, . . . , M} for multi-class classification. y_t y_t is the label/state at sequence position t t , y_{1:T} y_{1:T} is a sequence of labels/states w w and w\u02dc are parameter vectors, w_j w_j is the j j th component. F(x_{1:T} , y_{1:T} ) F(x_{1:T} , y_{1:T} ) is a feature vector for CRF and structured SVM","title":"Approach, notation and variables"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-labeling/","text":"Sequence labeling \u672c\u6587\u662f\u9605\u8bfb\u7ef4\u57fa\u767e\u79d1 Sequence labeling \u7684\u7b14\u8bb0\u3002 In machine learning , sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. \u663e\u7136\uff0csequence labeling\u6240\u5904\u7406\u7684\u662fsequence\u7ed3\u6784\u7684\u6570\u636e\uff0c\u663e\u7136\uff0c\u5b83\u7684\u8f93\u51fa\u4e5f\u662f\u4e00\u4e2asequence\u3002 \u751f\u6d3b\u4e2d\u54ea\u4e9b\u6570\u636e\u662f\u5177\u5907sequence\u7ed3\u6784\u7684\u5462\uff1f sentence\uff0c\u4e0e\u6b64\u76f8\u5173\u7684\u6709 part of speech tagging speech\uff0c\u53c2\u89c1 speech Sequence labeling can be treated as a set of independent classification tasks, one per member of the sequence. However, accuracy is generally improved by making the optimal label for a given element dependent on the choices of nearby elements, using special algorithms to choose the globally best set of labels for the entire sequence at once. \u8fd9\u6bb5\u8bdd\u5176\u5b9e\u63cf\u8ff0\u4e86\u89e3\u51b3sequence label\u95ee\u9898\u7684\u4e24\u79cd\u601d\u8def\uff1a independent\uff0c\u5373\u201clabeling one item at a time\u201d dependent\uff0c\u5373\u201cfinding the globally best label sequence\u201d \u539f\u6587\u7684\u4e0b\u4e00\u6bb5\u7ed3\u5408part-of-speech tagging\u5bf9\u8fd9\u4e24\u79cd\u65b9\u5f0f\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002 Most sequence labeling algorithms are probabilistic in nature, relying on statistical inference to find the best sequence. The most common statistical models in use for sequence labeling make a Markov assumption , i.e. that the choice of label for a particular word is directly dependent only on the immediately adjacent labels; hence the set of labels forms a Markov chain . This leads naturally to the hidden Markov model (HMM), one of the most common statistical models used for sequence labeling. Other common models in use are the maximum entropy Markov model and conditional random field . \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684**statistical models**\u53c2\u89c1 Statistical model \uff0c**Markov assumption**\u53c2\u89c1 Markov property \u3002","title":"Sequence-labeling"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-I-Applied-Math-and-Machine-Learning-Basics/5-Machine-Learning-Basics/Task/Sequence-labeling/Sequence-labeling/#sequence#labeling","text":"\u672c\u6587\u662f\u9605\u8bfb\u7ef4\u57fa\u767e\u79d1 Sequence labeling \u7684\u7b14\u8bb0\u3002 In machine learning , sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. \u663e\u7136\uff0csequence labeling\u6240\u5904\u7406\u7684\u662fsequence\u7ed3\u6784\u7684\u6570\u636e\uff0c\u663e\u7136\uff0c\u5b83\u7684\u8f93\u51fa\u4e5f\u662f\u4e00\u4e2asequence\u3002 \u751f\u6d3b\u4e2d\u54ea\u4e9b\u6570\u636e\u662f\u5177\u5907sequence\u7ed3\u6784\u7684\u5462\uff1f sentence\uff0c\u4e0e\u6b64\u76f8\u5173\u7684\u6709 part of speech tagging speech\uff0c\u53c2\u89c1 speech Sequence labeling can be treated as a set of independent classification tasks, one per member of the sequence. However, accuracy is generally improved by making the optimal label for a given element dependent on the choices of nearby elements, using special algorithms to choose the globally best set of labels for the entire sequence at once. \u8fd9\u6bb5\u8bdd\u5176\u5b9e\u63cf\u8ff0\u4e86\u89e3\u51b3sequence label\u95ee\u9898\u7684\u4e24\u79cd\u601d\u8def\uff1a independent\uff0c\u5373\u201clabeling one item at a time\u201d dependent\uff0c\u5373\u201cfinding the globally best label sequence\u201d \u539f\u6587\u7684\u4e0b\u4e00\u6bb5\u7ed3\u5408part-of-speech tagging\u5bf9\u8fd9\u4e24\u79cd\u65b9\u5f0f\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002 Most sequence labeling algorithms are probabilistic in nature, relying on statistical inference to find the best sequence. The most common statistical models in use for sequence labeling make a Markov assumption , i.e. that the choice of label for a particular word is directly dependent only on the immediately adjacent labels; hence the set of labels forms a Markov chain . This leads naturally to the hidden Markov model (HMM), one of the most common statistical models used for sequence labeling. Other common models in use are the maximum entropy Markov model and conditional random field . \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684**statistical models**\u53c2\u89c1 Statistical model \uff0c**Markov assumption**\u53c2\u89c1 Markov property \u3002","title":"Sequence labeling"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/Part-II-Deep-Networksb-Modern-Practice/","text":"Part II Deep Networks: Modern Practices These less-developed branches of deep learning appear in the final part of the book. This part focuses only on those approaches that are essentially working technologies that are already used heavily in industry. NOTE: Part II\u4ecb\u7ecd\u7684technology\u662f\u76f8\u5bf9\u6bd4\u8f83\u6210\u719f\u7684\uff0c\u800cpart III\u5219\u662fless-developed branches Modern deep learning provides a very powerful framework for supervised learning . By adding more layers and more units within a layer, a deep network can represent functions of increasing complexity. Most tasks that consist of mapping an input vector to an output vector , and that are easy for a person to do rapidly, can be accomplished via deep learning , given sufficiently large models and sufficiently large datasets of labeled training examples. Other tasks, that can not be described as associating one vector to another, or that are difficult enough that a person would require time to think and reflect in order to accomplish the task, remain beyond the scope of deep learning for now. This part of the book describes the core parametric function approximation \uff08\u53c2\u6570\u5316\u51fd\u6570\u8fd1\u4f3c\uff09technology that is behind nearly all modern practical applications of deep learning. NOTE: function\u3001mapping an input vector to an output vector \u3001 supervised learning \u3001statistical model\uff0c\u5b83\u4eec\u662f\u540c\u4e49\u8bcd\u3002 \u4ece\u66f4\u9ad8\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u6211\u4eec\u6240\u5b66\u4e60\u7684deep learning\u6280\u672f\uff0c\u672c\u8d28\u4e0a\u662f\uff1a parametric function approximation Next, we present advanced techniques for regularization and optimization of such models. Scaling these models to large inputs such as high resolution images or long temporal sequences requires specialization . We introduce the convolutional network for scaling to large images and the recurrent neural network for processing temporal sequences. NOTE: \u968f\u7740deep learning\u6280\u672f\u7684\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u8d8a\u6765\u8d8a\u591a\u7684specialization\u3002 Finally, we present general guidelines for the practical methodology involved in designing, building, and configuring an application involving deep learning, and review some of the applications of deep learning.","title":"Part-II-Deep-Networksb-Modern-Practice"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/Part-II-Deep-Networksb-Modern-Practice/#part#ii#deep#networks#modern#practices","text":"These less-developed branches of deep learning appear in the final part of the book. This part focuses only on those approaches that are essentially working technologies that are already used heavily in industry. NOTE: Part II\u4ecb\u7ecd\u7684technology\u662f\u76f8\u5bf9\u6bd4\u8f83\u6210\u719f\u7684\uff0c\u800cpart III\u5219\u662fless-developed branches Modern deep learning provides a very powerful framework for supervised learning . By adding more layers and more units within a layer, a deep network can represent functions of increasing complexity. Most tasks that consist of mapping an input vector to an output vector , and that are easy for a person to do rapidly, can be accomplished via deep learning , given sufficiently large models and sufficiently large datasets of labeled training examples. Other tasks, that can not be described as associating one vector to another, or that are difficult enough that a person would require time to think and reflect in order to accomplish the task, remain beyond the scope of deep learning for now. This part of the book describes the core parametric function approximation \uff08\u53c2\u6570\u5316\u51fd\u6570\u8fd1\u4f3c\uff09technology that is behind nearly all modern practical applications of deep learning. NOTE: function\u3001mapping an input vector to an output vector \u3001 supervised learning \u3001statistical model\uff0c\u5b83\u4eec\u662f\u540c\u4e49\u8bcd\u3002 \u4ece\u66f4\u9ad8\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u6211\u4eec\u6240\u5b66\u4e60\u7684deep learning\u6280\u672f\uff0c\u672c\u8d28\u4e0a\u662f\uff1a parametric function approximation Next, we present advanced techniques for regularization and optimization of such models. Scaling these models to large inputs such as high resolution images or long temporal sequences requires specialization . We introduce the convolutional network for scaling to large images and the recurrent neural network for processing temporal sequences. NOTE: \u968f\u7740deep learning\u6280\u672f\u7684\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u8d8a\u6765\u8d8a\u591a\u7684specialization\u3002 Finally, we present general guidelines for the practical methodology involved in designing, building, and configuring an application involving deep learning, and review some of the applications of deep learning.","title":"Part II Deep Networks: Modern Practices"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10-Sequence-Modeling-Recurrentand-Recursive-Nets/","text":"convolutional network grid of values X such as an image recurrent neural network is a neural network that is specialized for processing a sequence of values x (1) ,...,x ( ) SUMMARY :\u4e13\u6ce8\u4e8e\u4e0d\u540c\u9886\u57df\u7684\u6a21\u578b thinking : \u90a3\u4e0d\u540c\u7684\u9886\u57df\u8981\u9009\u62e9\u600e\u6837\u7684cost function\u624d\u5408\u9002\u5462\uff1f sharing parameters across different parts of a model. Parameter sharing makes it possible to extend and apply the model to examples of different forms (different lengths, here) and generalize across them. If we had separate parameters for each value of the time index\uff08\u8fd9\u662fMLP\u7684\u505a\u6cd5\uff09, we could not generalize to sequence lengths not seen during training, nor share statistical strength across different sequence lengths and across different positions in time. Such sharing is particularly important when a specific piece of information can occur at multiple positions within the sequence. For example, consider the two sentences \u201cI went to Nepal in 2009\u201d and \u201cIn 2009, I went to Nepal.\u201d If we ask a machine learning model to read each sentence and extract the year in which the narrator went to Nepal, we would like it to recognize the year 2009 as the relevant piece of information, whether it appears in the sixth word or the second word of the sentence. Suppose that we trained a feedforward network that processes sentences of fixed length. A traditional fully connected feedforward network would have separate parameters for each input feature, so it would need to learn all of the rules of the language separately at each position in the sentence. By comparison, a recurrent neural network shares the same weights across several time steps. SUMMARY : RNN\u7684\u4e00\u4e2a\u91cd\u8981\u601d\u60f3\uff0c\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u8fd9\u6837\u505a\uff1b SUMMARY : RNN\u4e0e\u4f20\u7edf\u7684feedforward network\u4e4b\u95f4\u7684\u5dee\u5f02\uff1b Recurrent networks share parameters in a different way. Each member of the output is a function of the previous members of the output. Each member of the output is produced using the same update rule applied to the previous outputs. This recurrent formulation results in the sharing of parameters through a very deep computational graph. This chapter extends the idea of a computational graph to include cycles. These cycles represent the influence of the present value of a variable on its own value at a future time step. Such computational graphs allow us to define recurrent neural networks. We then describe many different ways to construct, train, and use recurrent neural networks.","title":"10-Sequence-Modeling-Recurrentand-Recursive-Nets"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10.1-Unfolding-Computational-Graphs/","text":"10.1 Unfolding Computational Graphs A computational graph is a way to formalize the structure of a set of computations, such as those involved in mapping inputs and parameters to outputs and loss. Please refer to Sec 6.5.1. for a general introduction. In this section we explain the idea of a recursive or recurrent computation into a computational unfolding graph that has a repetitive structure, typically corresponding to a chain of events. Unfolding this graph results in the sharing of parameters across a deep network structure. Recurrent neural networks can be built in many different ways. Much as almost any function can be considered a feedforward neural network, essentially any function involving recurrence can be considered a recurrent neural network . Many recurrent neural networks use Eq 10.5 . or a similar equation to define the values of their hidden units . To indicate that the state is the hidden units of the network, we now rewrite Eq 10.4. using the variable to represent the state : typical RNNs will add extra architectural features such as output layers that read information out of the state to make predictions. When the recurrent network is trained to perform a task that requires predicting the future from the past, the network typically learns to use h ( t ) as a kind of lossy summary of the task-relevant aspects of the past sequence of inputs up to t . This summary is in general necessarily lossy, since it maps an arbitrary length sequence ( x ( t) ,x (t\u22121) ,x (t\u22122) ,...,x (2) ,x (1) ) to a fixed length vector h ( t ) . Depending on the training criterion, this summary might selectively keep some aspects of the past sequence with more precision than other aspects. For example, if the RNN is used in statistical language modeling, typically to predict the next word given previous words, it may not be necessary to store all of the information in the input sequence up to time t , but rather only enough information to predict the rest of the sentence. The most demanding situation is when we ask h ( t ) to be rich enough to allow one to approximately recover the input sequence, as in autoencoder frameworks (Chapter ) THINKING : state\u548clossy summary\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u4ec0\u4e48\uff1f","title":"10.1-Unfolding-Computational-Graphs"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10.1-Unfolding-Computational-Graphs/#101#unfolding#computational#graphs","text":"A computational graph is a way to formalize the structure of a set of computations, such as those involved in mapping inputs and parameters to outputs and loss. Please refer to Sec 6.5.1. for a general introduction. In this section we explain the idea of a recursive or recurrent computation into a computational unfolding graph that has a repetitive structure, typically corresponding to a chain of events. Unfolding this graph results in the sharing of parameters across a deep network structure. Recurrent neural networks can be built in many different ways. Much as almost any function can be considered a feedforward neural network, essentially any function involving recurrence can be considered a recurrent neural network . Many recurrent neural networks use Eq 10.5 . or a similar equation to define the values of their hidden units . To indicate that the state is the hidden units of the network, we now rewrite Eq 10.4. using the variable to represent the state : typical RNNs will add extra architectural features such as output layers that read information out of the state to make predictions. When the recurrent network is trained to perform a task that requires predicting the future from the past, the network typically learns to use h ( t ) as a kind of lossy summary of the task-relevant aspects of the past sequence of inputs up to t . This summary is in general necessarily lossy, since it maps an arbitrary length sequence ( x ( t) ,x (t\u22121) ,x (t\u22122) ,...,x (2) ,x (1) ) to a fixed length vector h ( t ) . Depending on the training criterion, this summary might selectively keep some aspects of the past sequence with more precision than other aspects. For example, if the RNN is used in statistical language modeling, typically to predict the next word given previous words, it may not be necessary to store all of the information in the input sequence up to time t , but rather only enough information to predict the rest of the sentence. The most demanding situation is when we ask h ( t ) to be rich enough to allow one to approximately recover the input sequence, as in autoencoder frameworks (Chapter ) THINKING : state\u548clossy summary\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u4ec0\u4e48\uff1f","title":"10.1 Unfolding Computational Graphs"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10.10-The-Long-Short-Term-Memory-and-Other-Gated/","text":"","title":"10.10-The-Long-Short-Term-Memory-and-Other-Gated"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10.3-Bidirectional-RNNs/","text":"10.3 Bidirectional RNNs However, in many applications we want to output a prediction of y^{(t)} y^{(t)} which may depend on the whole input sequence . For example, in speech recognition, the correct interpretation of the current sound as a phoneme may depend on the next few phonemes because of co-articulation and potentially may even depend on the next few words because of the linguistic dependencies between nearby words: if there are two interpretations of the current word that are both acoustically plausible, we may have to look far into the future (and the past) to disambiguate them. This is also true of handwriting recognition and many other sequence-to-sequence learning tasks , described in the next section. Bidirectional recurrent neural networks (or bidirectional RNNs ) were invented to address that need (Schuster and Paliwal 1997 , ). They have been extremely successful (Graves 2012 , ) in applications where that need arises, such as handwriting recognition (Graves 2008 Graves and Schmidhuber 2009 et al., ; , ), speech recognition (Graves and Schmidhuber 2005 Graves 2013 Baldi , ; et al., ) and bioinformatics\uff08\u751f\u7269\u4fe1\u606f\u5b66\uff09 (et al., ). As the name suggests, bidirectional RNNs combine an RNN that moves forward through time beginning from the start of the sequence with another RNN that moves backward through time beginning from the end of the sequence. Figure 10.11 illustrates the typical bidirectional RNN, with h (t) h (t) standing for the state of the sub-RNN that moves forward through time and g (t) g (t) standing for the state of the sub-RNN that moves backward through time. This allows the output units $o (t) $ to compute a representation that depends on both the past and the future but is most sensitive to the input values around time t t , without having to specify a fixed-size window around t t (as one would have to do with a feedforward network, a convolutional network, or a regular RNN with a fixed-size look-ahead buffer). This idea can be naturally extended to 2-dimensional input, such as images, by having RNNs, each one going in one of the four directions: up, down, left, four right. At each point ( i,j ) ( i,j ) of a 2-D grid, an output O( i,j) O( i,j) could then compute a representation that would capture mostly local information but could also depend on long-range inputs, if the RNN is able to learn to carry that information. Compared to a convolutional network, RNNs applied to images are typically more expensive but allow for long-range lateral interactions between features in the same feature map ( , ; Visin et al. 2015 Kalchbrenner 2015 et al., ). Indeed, the forward propagation equations for such RNNs may be written in a form that showst hey use a convolution that computes the bottom-up input to each layer, prior to the recurrent propagation across the feature map that incorporates the lateral interactions.","title":"10.3-Bidirectional-RNNs"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10.3-Bidirectional-RNNs/#103#bidirectional#rnns","text":"However, in many applications we want to output a prediction of y^{(t)} y^{(t)} which may depend on the whole input sequence . For example, in speech recognition, the correct interpretation of the current sound as a phoneme may depend on the next few phonemes because of co-articulation and potentially may even depend on the next few words because of the linguistic dependencies between nearby words: if there are two interpretations of the current word that are both acoustically plausible, we may have to look far into the future (and the past) to disambiguate them. This is also true of handwriting recognition and many other sequence-to-sequence learning tasks , described in the next section. Bidirectional recurrent neural networks (or bidirectional RNNs ) were invented to address that need (Schuster and Paliwal 1997 , ). They have been extremely successful (Graves 2012 , ) in applications where that need arises, such as handwriting recognition (Graves 2008 Graves and Schmidhuber 2009 et al., ; , ), speech recognition (Graves and Schmidhuber 2005 Graves 2013 Baldi , ; et al., ) and bioinformatics\uff08\u751f\u7269\u4fe1\u606f\u5b66\uff09 (et al., ). As the name suggests, bidirectional RNNs combine an RNN that moves forward through time beginning from the start of the sequence with another RNN that moves backward through time beginning from the end of the sequence. Figure 10.11 illustrates the typical bidirectional RNN, with h (t) h (t) standing for the state of the sub-RNN that moves forward through time and g (t) g (t) standing for the state of the sub-RNN that moves backward through time. This allows the output units $o (t) $ to compute a representation that depends on both the past and the future but is most sensitive to the input values around time t t , without having to specify a fixed-size window around t t (as one would have to do with a feedforward network, a convolutional network, or a regular RNN with a fixed-size look-ahead buffer). This idea can be naturally extended to 2-dimensional input, such as images, by having RNNs, each one going in one of the four directions: up, down, left, four right. At each point ( i,j ) ( i,j ) of a 2-D grid, an output O( i,j) O( i,j) could then compute a representation that would capture mostly local information but could also depend on long-range inputs, if the RNN is able to learn to carry that information. Compared to a convolutional network, RNNs applied to images are typically more expensive but allow for long-range lateral interactions between features in the same feature map ( , ; Visin et al. 2015 Kalchbrenner 2015 et al., ). Indeed, the forward propagation equations for such RNNs may be written in a form that showst hey use a convolution that computes the bottom-up input to each layer, prior to the recurrent propagation across the feature map that incorporates the lateral interactions.","title":"10.3 Bidirectional RNNs"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10.4-Encoder-Decoder-Sequence-to-Sequence-Architectures/","text":"10.4 Encoder-Decoder Sequence-to-Sequence Architectures We have seen in figure 10.5 how an RNN can map an input sequence to a fixed-size vector . We have seen in figure 10.9 how an RNN can map a fixed-size vector to a sequence. We have seen in figures 10.3, 10.4, 10.10, 10.11 , and how an RNN can map an input sequence to an output sequence of the same length. Figure 10.12: Example of an encoder-decoder or sequence-to-sequence RNN architecture, for learning to generate an output sequence ( y^{ (1)} ,...,y ^{(n_y )} ) ( y^{ (1)} ,...,y ^{(n_y )} ) given an input sequence ( x^{(1)} ,x^{(2)} ,...,x^{(n_x )} ) ( x^{(1)} ,x^{(2)} ,...,x^{(n_x )} ) . It is composed of an encoder RNN that reads the input sequence and a decoder RNN that generates the output sequence (or computes the probability of a given output sequence). The final hidden state of the encoder RNN is used to compute a generally fixed-size context variable C which represents a semantic summary of the input sequence and is given as input to the decoder RNN . Here we discuss how an RNN can be trained to map an input sequence to an output sequence which is not necessarily of the same length. This comes up in many applications, such as speech recognition, machine translation or question answering, where the input and output sequences in the training set are generally not of the same length (although their lengths might be related). We often call the input to the RNN the \u201ccontext.\u201d We want to produce a representation of this context, C . The context C might be a vector or sequence of vectors that summarize the input sequence X = ( x^{(1)} ,...,x^{(n_x )} ) X = ( x^{(1)} ,...,x^{(n_x )} ) . THINKING : Bidirectional RNNs\u5982\u4f55\u548cEncoder-Decoder Sequence-to-Sequence architecture\u7684LSTM\u76f8\u7ed3\u5408\uff1f The simplest RNN architecture for mapping a variable-length sequence to another variable-length sequence was first proposed by Cho et al(2014a) and shortly after by Sutskever et al. (2014 ), who independently developed that architecture and were the first to obtain state-of-the-art translation using this approach. The former system is based on scoring proposals generated by another machine translation system, while the latter uses a standalone recurrent network to generate the translations. These authors respectively called this architecture, illustrated in figure 10.12, the encoder-decoder or sequence-to-sequence architecture. The idea is very simple: (1) an encoder or reader or input RNN processes the input sequence. The encoder emits the context C , usually as a simple function of its final hidden state. (2) a decoder or writer or output RNN is conditioned on that fixed-length vector (just like in figure 10.9) to generate the output sequence Y = ( y^{(1)} ,...,y^{(n_y)} ) Y = ( y^{(1)} ,...,y^{(n_y)} ) . The innovation of this kind of architecture over those presented in earlier sections of this chapter is that the lengths n_x n_x and n_y n_y can vary from each other, while previous architectures constrained n_x = n_y = \u03c4 n_x = n_y = \u03c4 . In a sequence-to-sequence architecture, the two RNNs are trained jointly to maximize the average of log_P{ ( y^{(1)} ,...,y^{(n_y )} | x^{(1)} ,...,x^{(n_x )} )} log_P{ ( y^{(1)} ,...,y^{(n_y )} | x^{(1)} ,...,x^{(n_x )} )} over all the pairs of x x and y y sequences in the training set. The last state h_{n_x} h_{n_x} of the encoder RNN is typically used as a representation C of the input sequence that is provided as input to the decoder RNN . If the context C is a vector, then the decoder RNN is simply a vector-to-sequence RNN as described in section 10.2.4. As we have seen, there are at least two ways for a vector-to-sequence RNN to receive input. The input can be provided as the initial state of the RNN, or the input can be connected to the hidden units at each time step . These two ways can also be combined. There is no constraint that the encoder must have the same size of hidden layer as the decoder. One clear limitation of this architecture is when the context C output by the encoder RNN has a dimension that is too small to properly summarize a long sequence. This phenomenon was observed by Bahdanau et al( 2015). in the context of machine translation. They proposed to make C a variable-length sequence rather than a fixed-size vector . Additionally, they introduced an attention mechanism that learns to associate elements of the sequence C to elements of the output sequence. See section for more details.","title":"10.4-Encoder-Decoder-Sequence-to-Sequence-Architectures"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/10.4-Encoder-Decoder-Sequence-to-Sequence-Architectures/#104#encoder-decoder#sequence-to-sequence#architectures","text":"We have seen in figure 10.5 how an RNN can map an input sequence to a fixed-size vector . We have seen in figure 10.9 how an RNN can map a fixed-size vector to a sequence. We have seen in figures 10.3, 10.4, 10.10, 10.11 , and how an RNN can map an input sequence to an output sequence of the same length. Figure 10.12: Example of an encoder-decoder or sequence-to-sequence RNN architecture, for learning to generate an output sequence ( y^{ (1)} ,...,y ^{(n_y )} ) ( y^{ (1)} ,...,y ^{(n_y )} ) given an input sequence ( x^{(1)} ,x^{(2)} ,...,x^{(n_x )} ) ( x^{(1)} ,x^{(2)} ,...,x^{(n_x )} ) . It is composed of an encoder RNN that reads the input sequence and a decoder RNN that generates the output sequence (or computes the probability of a given output sequence). The final hidden state of the encoder RNN is used to compute a generally fixed-size context variable C which represents a semantic summary of the input sequence and is given as input to the decoder RNN . Here we discuss how an RNN can be trained to map an input sequence to an output sequence which is not necessarily of the same length. This comes up in many applications, such as speech recognition, machine translation or question answering, where the input and output sequences in the training set are generally not of the same length (although their lengths might be related). We often call the input to the RNN the \u201ccontext.\u201d We want to produce a representation of this context, C . The context C might be a vector or sequence of vectors that summarize the input sequence X = ( x^{(1)} ,...,x^{(n_x )} ) X = ( x^{(1)} ,...,x^{(n_x )} ) . THINKING : Bidirectional RNNs\u5982\u4f55\u548cEncoder-Decoder Sequence-to-Sequence architecture\u7684LSTM\u76f8\u7ed3\u5408\uff1f The simplest RNN architecture for mapping a variable-length sequence to another variable-length sequence was first proposed by Cho et al(2014a) and shortly after by Sutskever et al. (2014 ), who independently developed that architecture and were the first to obtain state-of-the-art translation using this approach. The former system is based on scoring proposals generated by another machine translation system, while the latter uses a standalone recurrent network to generate the translations. These authors respectively called this architecture, illustrated in figure 10.12, the encoder-decoder or sequence-to-sequence architecture. The idea is very simple: (1) an encoder or reader or input RNN processes the input sequence. The encoder emits the context C , usually as a simple function of its final hidden state. (2) a decoder or writer or output RNN is conditioned on that fixed-length vector (just like in figure 10.9) to generate the output sequence Y = ( y^{(1)} ,...,y^{(n_y)} ) Y = ( y^{(1)} ,...,y^{(n_y)} ) . The innovation of this kind of architecture over those presented in earlier sections of this chapter is that the lengths n_x n_x and n_y n_y can vary from each other, while previous architectures constrained n_x = n_y = \u03c4 n_x = n_y = \u03c4 . In a sequence-to-sequence architecture, the two RNNs are trained jointly to maximize the average of log_P{ ( y^{(1)} ,...,y^{(n_y )} | x^{(1)} ,...,x^{(n_x )} )} log_P{ ( y^{(1)} ,...,y^{(n_y )} | x^{(1)} ,...,x^{(n_x )} )} over all the pairs of x x and y y sequences in the training set. The last state h_{n_x} h_{n_x} of the encoder RNN is typically used as a representation C of the input sequence that is provided as input to the decoder RNN . If the context C is a vector, then the decoder RNN is simply a vector-to-sequence RNN as described in section 10.2.4. As we have seen, there are at least two ways for a vector-to-sequence RNN to receive input. The input can be provided as the initial state of the RNN, or the input can be connected to the hidden units at each time step . These two ways can also be combined. There is no constraint that the encoder must have the same size of hidden layer as the decoder. One clear limitation of this architecture is when the context C output by the encoder RNN has a dimension that is too small to properly summarize a long sequence. This phenomenon was observed by Bahdanau et al( 2015). in the context of machine translation. They proposed to make C a variable-length sequence rather than a fixed-size vector . Additionally, they introduced an attention mechanism that learns to associate elements of the sequence C to elements of the output sequence. See section for more details.","title":"10.4 Encoder-Decoder Sequence-to-Sequence Architectures"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/LSTM/","text":"Long short-term memory Long short-term memory ( LSTM ) is an artificial recurrent neural network (RNN) architecture[ 1] used in the field of deep learning . Unlike standard feedforward neural networks , LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition [ 2] or speech recognition .[ 3] [ 4] Bloomberg Business Week wrote: \"These powers make LSTM arguably the most commercial AI achievement, used for everything from predicting diseases to composing music.\"[ 5] A common LSTM unit is composed of a cell , an input gate , an output gate and a forget gate . The cell remembers values over arbitrary time intervals and the three gates regulate\uff08\u8c03\u8282\uff09 the flow of information into and out of the cell. LSTM networks are well-suited to classifying , processing and making predictions based on time series data, since there can be lags\uff08\u843d\u540e\uff09 of unknown duration between important events in a time series. LSTMs were developed to deal with the exploding and vanishing gradient problems that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models and other sequence learning methods in numerous applications.[ citation needed ]","title":"LSTM"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/LSTM/#long#short-term#memory","text":"Long short-term memory ( LSTM ) is an artificial recurrent neural network (RNN) architecture[ 1] used in the field of deep learning . Unlike standard feedforward neural networks , LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition [ 2] or speech recognition .[ 3] [ 4] Bloomberg Business Week wrote: \"These powers make LSTM arguably the most commercial AI achievement, used for everything from predicting diseases to composing music.\"[ 5] A common LSTM unit is composed of a cell , an input gate , an output gate and a forget gate . The cell remembers values over arbitrary time intervals and the three gates regulate\uff08\u8c03\u8282\uff09 the flow of information into and out of the cell. LSTM networks are well-suited to classifying , processing and making predictions based on time series data, since there can be lags\uff08\u843d\u540e\uff09 of unknown duration between important events in a time series. LSTMs were developed to deal with the exploding and vanishing gradient problems that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models and other sequence learning methods in numerous applications.[ citation needed ]","title":"Long short-term memory"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/RNN-and-LSTM-tutorial/","text":"Recurrent neural networks and LSTM tutorial in Python and TensorFlow In the deep learning journey so far on this website, I\u2019ve introduced dense neural networks and convolutional neural networks (CNNs) which explain how to perform classification tasks on static images. We\u2019ve seen good results, especially with CNN\u2019s. However, what happens if we want to analyze dynamic data? What about videos, voice recognition or sequences of text? There are ways to do some of this using CNN\u2019s, but the most popular method of performing classification and other analysis on sequences of data is recurrent neural networks. This tutorial will be a very comprehensive introduction to recurrent neural networks and a subset of such networks \u2013 long-short term memory networks (or LSTM networks). I\u2019ll also show you how to implement such networks in TensorFlow \u2013 including the data preparation step. It\u2019s going to be a long one, so settle in and enjoy these pivotal networks in deep learning \u2013 at the end of this post, you\u2019ll have a very solid understanding of recurrent neural networks and LSTMs. By the way, if you\u2019d like to learn how to build LSTM networks in Keras, see this tutorial . An introduction to recurrent neural networks A recurrent neural network, at its most fundamental level, is simply a type of densely connected neural network (for an introduction to such networks, see my tutorial ). However, the key difference to normal feed forward networks is the introduction of time \u2013 in particular, the output of the hidden layer in a recurrent neural network is fed back into itself . Diagrams help here, so observe: Recurrent neural network diagram with nodes shown In the diagram above, we have a simple recurrent neural network with three input nodes. These input nodes are fed into a hidden layer, with sigmoid activations, as per any normal densely connected neural network . What happens next is what is interesting \u2013 the output of the hidden layer is then fed back into the same hidden layer. As you can see the hidden layer outputs are passed through a conceptual delay block to allow the input of \\textbf{h}^{t-1} \\textbf{h}^{t-1} into the hidden layer. What is the point of this? Simply, the point is that we can now model time or sequence-dependent data. SUMMARY \uff1a \u8f93\u5165\u6570\u636e\u662f\u6309\u7167time\u5e8f\u5217\u800c\u7ec4\u7ec7\u7684\u591a\u6761\u8bb0\u5f55\uff0c\u8fd9\u4e9b\u6570\u636e\u4f1a\u6309\u7167**\u65f6\u95f4\u6b21\u5e8f**\u8f93\u5165\u5230\u5206\u591a\u6b21\u8f93\u5165\u5230model\u4e2d\u5462\u8fd8\u662f\u4e00\u6b21\u8f93\u5165\u591a\u6761\u8bb0\u5f55\uff0c\u5373\u8f93\u5165\u662f\u4e00\u4e2a\u5411\u91cf\u800c\u4e0d\u662f\u662f\u4e00\u4e2a\u6807\u91cf\uff1b A particularly good example of this is predicting text sequences. Consider the following text string: \u201cA girl walked into a bar, and she said \u2018Can I have a drink please?\u2019. The bartender said \u2018Certainly {}\u201d. There are many options for what could fill in the {} symbol in the above string, for instance, \u201cmiss\u201d, \u201cma\u2019am\u201d and so on. However, other words could also fit, such as \u201csir\u201d, \u201cMister\u201d etc. In order to get the correct gender of the noun, the neural network needs to \u201crecall\u201d that two previous words designating the likely gender (i.e. \u201cgirl\u201d and \u201cshe\u201d) were used. This type of flow of information through time (or sequence) in a recurrent neural network is shown in the diagram below, which unrolls the sequence: Unrolled recurrent neural network SUMMARY : t \u8868\u793a\u7684\u662ftime step On the left-hand side of the above diagram, we have basically the same diagram as the first (the one which shows all the nodes explicitly). What the previous diagram neglected to show explicitly was that we in fact only ever supply finite length sequences to such networks \u2013 therefore we can unroll the network as shown on the right-hand side of the diagram above. This unrolled network shows how we can supply a stream of data to the recurrent neural network. For instance, first, we supply the word vector for \u201cA\u201d (more about word vectors later) to the network F \u2013 the output of the nodes in F are fed into the \u201cnext\u201d network and also act as a stand-alone output ( h_0 h_0 ). The next network (though it is really the same network) F at time t=1 takes the next word vector for \u201cgirl\u201d and the previous output h_0 h_0 into its hidden nodes, producing the next output h_1 h_1 and so on. Creating an LSTM network in TensorFlow We are now going to create an LSTM network in TensorFlow. The code will loosely follow the TensorFlow team tutorial found here , but with updates and my own substantial modifications. The text dataset that will be used and is a common benchmarking corpus is the Penn Tree Bank (PTB) dataset. As usual, all the code for this post can be found on the AdventuresinML Github site . To run this code, you\u2019ll first have to download and extract the .tgz file from here . First off, we\u2019ll go through the data preparation part of the code. Preparing the data This code will use, verbatim\uff08\u9010\u5b57\u7684\uff09, the following functions from the previously mentioned TensorFlow tutorial : read_words, build_vocab and file_to_word_ids. I won\u2019t go into these functions in detail, but basically, they first split the given text file into separate words and sentence based characters (i.e. end-of-sentence ). Then, each unique word is identified and assigned a unique integer. Finally, the original text file is converted into a list of these unique integers, where each word is substituted with its new integer identifier. This allows the text data to be consumed in the neural network. Creating an input data pipeline As discussed in my TensorFlow queues and threads tutorial, the use of a feed dictionary to supply data to your model during training, while common in tutorials, is not efficient \u2013 as can be read here on the TensorFlow site. Rather, it is more efficient to use TensorFlow queues and threading. Note, that there is a new way of doing things, using the Dataset API, which won\u2019t be used in this tutorial, but I will perhaps update it in the future to include this new way of doing things. I\u2019ve packaged up this code in a function called batch_producer \u2013 this function extracts batches of x, y training data \u2013 the x batch is formatted as the time stepped text data. The y batch is the same data, except delayed one time step . So, for instance, a single x, y sample in a batch, with the number of time steps being 8, looks like: \u6b63\u5982\u5728\u6211\u7684TensorFlow\u961f\u5217\u548c\u7ebf\u7a0b\u6559\u7a0b\u4e2d\u6240\u8ba8\u8bba\u7684\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528feed\u5b57\u5178\u5411\u6a21\u578b\u63d0\u4f9b\u6570\u636e\uff0c\u867d\u7136\u5728\u6559\u7a0b\u4e2d\u5f88\u5e38\u89c1\uff0c\u4f46\u5e76\u4e0d\u6709\u6548\u2014\u2014\u53ef\u4ee5\u5728TensorFlow\u7ad9\u70b9\u4e0a\u9605\u8bfb\u3002\u76f8\u53cd\uff0c\u4f7f\u7528TensorFlow\u961f\u5217\u548c\u7ebf\u7a0b\u66f4\u6709\u6548\u3002\u6ce8\u610f\uff0c\u6709\u4e00\u79cd\u4f7f\u7528Dataset API\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u672c\u6559\u7a0b\u4e2d\u4e0d\u4f1a\u7528\u5230\uff0c\u4f46\u6211\u53ef\u80fd\u4f1a\u5728\u5c06\u6765\u66f4\u65b0\u5b83\uff0c\u4ee5\u5305\u62ec\u8fd9\u79cd\u65b0\u65b9\u6cd5\u3002\u6211\u5c06\u8fd9\u6bb5\u4ee3\u7801\u6253\u5305\u5230\u4e00\u4e2a\u540d\u4e3abatch_producer\u7684\u51fd\u6570\u4e2d\u2014\u2014\u8fd9\u4e2a\u51fd\u6570\u63d0\u53d6\u6210\u6279\u7684x\u3001y\u8bad\u7ec3\u6570\u636e\u2014\u2014x\u6279\u6570\u636e\u88ab\u683c\u5f0f\u5316\u4e3a\u65f6\u95f4\u6b65\u957f\u6587\u672c\u6570\u636e\u3002y\u6279\u5904\u7406\u662f\u76f8\u540c\u7684\u6570\u636e\uff0c\u53ea\u662f\u5ef6\u8fdf\u4e86\u4e00\u4e2a\u65f6\u95f4\u6b65\u957f\u3002\u4f8b\u5982\uff0c\u6279\u6b21\u4e2d\u7684\u5355\u4e2ax, y\u6837\u672c\uff0c\u65f6\u95f4\u6b65\u957f\u4e3a8\uff0c\u770b\u8d77\u6765\u50cf: x = \u201cA girl walked into a bar, and she\u201d y = \u201cgirl walked into a bar, and she said\u201d Remember that x and y will be batches of integer data, with the size ( batch_size , num_steps ), not text as shown above \u2013 however, I have shown the above x and y sample in text form to aid understanding. So, as demonstrated in the model architecture diagram above, we are producing a many-to-many LSTM model, where the model will be trained to predict the very next word in the sequence for each word in the number of time steps. SUMMARY : \u9700\u8981\u5c06\u6587\u672c\u6570\u636e\u5206\u6210*batch_size*\u6279\u6570\u636e\uff0c\u6bcf\u4e00\u6279\u4e2d\u5305\u542b*num_steps*\u4e2a\u5355\u8bcd\uff1b Here\u2019s what the code looks like: def batch_producer ( raw_data , batch_size , num_steps ): raw_data = tf . convert_to_tensor ( raw_data , name = \"raw_data\" , dtype = tf . int32 ) data_len = tf . size ( raw_data ) batch_len = data_len // batch_size # len of every batch data = tf . reshape ( raw_data [ 0 : batch_size * batch_len ], [ batch_size , batch_len ]) epoch_size = ( batch_len - 1 ) // num_steps i = tf . train . range_input_producer ( epoch_size , shuffle = False ) . dequeue () x = data [:, i * num_steps :( i + 1 ) * num_steps ] x . set_shape ([ batch_size , num_steps ]) y = data [:, i * num_steps + 1 : ( i + 1 ) * num_steps + 1 ] y . set_shape ([ batch_size , num_steps ]) return x , y In the code above, first, the raw text data is converted into an int32 tensor. Next, the length of the full data set is calculated and stored in data_len and this is then divided by the batch size in an integer division (//) to get the number of full batches of data available within the dataset. The next line reshapes the raw_data tensor (restricted in size to the number of full batches of data i.e. 0 to batch_size * batch_len ) into a ( batch_size, batch_len ) shape. The next line sets the number of iterations in each epoch \u2013 usually, this is set so that all the training data is passed through the algorithm in each epoch. This is what occurs here \u2013 the number of batches in the data ( batch_len ) is integer divided by the number of time steps \u2013 this gives the number of time-step-sized batches that are available to be iterated through in a single epoch. Creating the model In this code example, in order to have nice encapsulation and better-looking code, I\u2019ll be building the model in Python classes . The first class is a simple class that contains the input data: class Input ( object ): def __init__ ( self , batch_size , num_steps , data ): self . batch_size = batch_size self . num_steps = num_steps self . epoch_size = (( len ( data ) // batch_size ) - 1 ) // num_steps self . input_data , self . targets = batch_producer ( data , batch_size , num_steps ) We pass this object important input data information such as batch size , the number of recurrent time steps and finally the raw data file we wish to extract batch data from. The previously explained batch_producer function, when called, will return our input data batch x and the associated time step + 1 target data batch, y .","title":"RNN-and-LSTM-tutorial"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/RNN-and-LSTM-tutorial/#recurrent#neural#networks#and#lstm#tutorial#in#python#and#tensorflow","text":"In the deep learning journey so far on this website, I\u2019ve introduced dense neural networks and convolutional neural networks (CNNs) which explain how to perform classification tasks on static images. We\u2019ve seen good results, especially with CNN\u2019s. However, what happens if we want to analyze dynamic data? What about videos, voice recognition or sequences of text? There are ways to do some of this using CNN\u2019s, but the most popular method of performing classification and other analysis on sequences of data is recurrent neural networks. This tutorial will be a very comprehensive introduction to recurrent neural networks and a subset of such networks \u2013 long-short term memory networks (or LSTM networks). I\u2019ll also show you how to implement such networks in TensorFlow \u2013 including the data preparation step. It\u2019s going to be a long one, so settle in and enjoy these pivotal networks in deep learning \u2013 at the end of this post, you\u2019ll have a very solid understanding of recurrent neural networks and LSTMs. By the way, if you\u2019d like to learn how to build LSTM networks in Keras, see this tutorial .","title":"Recurrent neural networks and LSTM tutorial in Python and TensorFlow"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/RNN-and-LSTM-tutorial/#an#introduction#to#recurrent#neural#networks","text":"A recurrent neural network, at its most fundamental level, is simply a type of densely connected neural network (for an introduction to such networks, see my tutorial ). However, the key difference to normal feed forward networks is the introduction of time \u2013 in particular, the output of the hidden layer in a recurrent neural network is fed back into itself . Diagrams help here, so observe: Recurrent neural network diagram with nodes shown In the diagram above, we have a simple recurrent neural network with three input nodes. These input nodes are fed into a hidden layer, with sigmoid activations, as per any normal densely connected neural network . What happens next is what is interesting \u2013 the output of the hidden layer is then fed back into the same hidden layer. As you can see the hidden layer outputs are passed through a conceptual delay block to allow the input of \\textbf{h}^{t-1} \\textbf{h}^{t-1} into the hidden layer. What is the point of this? Simply, the point is that we can now model time or sequence-dependent data. SUMMARY \uff1a \u8f93\u5165\u6570\u636e\u662f\u6309\u7167time\u5e8f\u5217\u800c\u7ec4\u7ec7\u7684\u591a\u6761\u8bb0\u5f55\uff0c\u8fd9\u4e9b\u6570\u636e\u4f1a\u6309\u7167**\u65f6\u95f4\u6b21\u5e8f**\u8f93\u5165\u5230\u5206\u591a\u6b21\u8f93\u5165\u5230model\u4e2d\u5462\u8fd8\u662f\u4e00\u6b21\u8f93\u5165\u591a\u6761\u8bb0\u5f55\uff0c\u5373\u8f93\u5165\u662f\u4e00\u4e2a\u5411\u91cf\u800c\u4e0d\u662f\u662f\u4e00\u4e2a\u6807\u91cf\uff1b A particularly good example of this is predicting text sequences. Consider the following text string: \u201cA girl walked into a bar, and she said \u2018Can I have a drink please?\u2019. The bartender said \u2018Certainly {}\u201d. There are many options for what could fill in the {} symbol in the above string, for instance, \u201cmiss\u201d, \u201cma\u2019am\u201d and so on. However, other words could also fit, such as \u201csir\u201d, \u201cMister\u201d etc. In order to get the correct gender of the noun, the neural network needs to \u201crecall\u201d that two previous words designating the likely gender (i.e. \u201cgirl\u201d and \u201cshe\u201d) were used. This type of flow of information through time (or sequence) in a recurrent neural network is shown in the diagram below, which unrolls the sequence: Unrolled recurrent neural network SUMMARY : t \u8868\u793a\u7684\u662ftime step On the left-hand side of the above diagram, we have basically the same diagram as the first (the one which shows all the nodes explicitly). What the previous diagram neglected to show explicitly was that we in fact only ever supply finite length sequences to such networks \u2013 therefore we can unroll the network as shown on the right-hand side of the diagram above. This unrolled network shows how we can supply a stream of data to the recurrent neural network. For instance, first, we supply the word vector for \u201cA\u201d (more about word vectors later) to the network F \u2013 the output of the nodes in F are fed into the \u201cnext\u201d network and also act as a stand-alone output ( h_0 h_0 ). The next network (though it is really the same network) F at time t=1 takes the next word vector for \u201cgirl\u201d and the previous output h_0 h_0 into its hidden nodes, producing the next output h_1 h_1 and so on.","title":"An introduction to recurrent neural networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/RNN-and-LSTM-tutorial/#creating#an#lstm#network#in#tensorflow","text":"We are now going to create an LSTM network in TensorFlow. The code will loosely follow the TensorFlow team tutorial found here , but with updates and my own substantial modifications. The text dataset that will be used and is a common benchmarking corpus is the Penn Tree Bank (PTB) dataset. As usual, all the code for this post can be found on the AdventuresinML Github site . To run this code, you\u2019ll first have to download and extract the .tgz file from here . First off, we\u2019ll go through the data preparation part of the code.","title":"Creating an LSTM network in TensorFlow"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/RNN-and-LSTM-tutorial/#preparing#the#data","text":"This code will use, verbatim\uff08\u9010\u5b57\u7684\uff09, the following functions from the previously mentioned TensorFlow tutorial : read_words, build_vocab and file_to_word_ids. I won\u2019t go into these functions in detail, but basically, they first split the given text file into separate words and sentence based characters (i.e. end-of-sentence ). Then, each unique word is identified and assigned a unique integer. Finally, the original text file is converted into a list of these unique integers, where each word is substituted with its new integer identifier. This allows the text data to be consumed in the neural network.","title":"Preparing the data"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/RNN-and-LSTM-tutorial/#creating#an#input#data#pipeline","text":"As discussed in my TensorFlow queues and threads tutorial, the use of a feed dictionary to supply data to your model during training, while common in tutorials, is not efficient \u2013 as can be read here on the TensorFlow site. Rather, it is more efficient to use TensorFlow queues and threading. Note, that there is a new way of doing things, using the Dataset API, which won\u2019t be used in this tutorial, but I will perhaps update it in the future to include this new way of doing things. I\u2019ve packaged up this code in a function called batch_producer \u2013 this function extracts batches of x, y training data \u2013 the x batch is formatted as the time stepped text data. The y batch is the same data, except delayed one time step . So, for instance, a single x, y sample in a batch, with the number of time steps being 8, looks like: \u6b63\u5982\u5728\u6211\u7684TensorFlow\u961f\u5217\u548c\u7ebf\u7a0b\u6559\u7a0b\u4e2d\u6240\u8ba8\u8bba\u7684\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528feed\u5b57\u5178\u5411\u6a21\u578b\u63d0\u4f9b\u6570\u636e\uff0c\u867d\u7136\u5728\u6559\u7a0b\u4e2d\u5f88\u5e38\u89c1\uff0c\u4f46\u5e76\u4e0d\u6709\u6548\u2014\u2014\u53ef\u4ee5\u5728TensorFlow\u7ad9\u70b9\u4e0a\u9605\u8bfb\u3002\u76f8\u53cd\uff0c\u4f7f\u7528TensorFlow\u961f\u5217\u548c\u7ebf\u7a0b\u66f4\u6709\u6548\u3002\u6ce8\u610f\uff0c\u6709\u4e00\u79cd\u4f7f\u7528Dataset API\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u672c\u6559\u7a0b\u4e2d\u4e0d\u4f1a\u7528\u5230\uff0c\u4f46\u6211\u53ef\u80fd\u4f1a\u5728\u5c06\u6765\u66f4\u65b0\u5b83\uff0c\u4ee5\u5305\u62ec\u8fd9\u79cd\u65b0\u65b9\u6cd5\u3002\u6211\u5c06\u8fd9\u6bb5\u4ee3\u7801\u6253\u5305\u5230\u4e00\u4e2a\u540d\u4e3abatch_producer\u7684\u51fd\u6570\u4e2d\u2014\u2014\u8fd9\u4e2a\u51fd\u6570\u63d0\u53d6\u6210\u6279\u7684x\u3001y\u8bad\u7ec3\u6570\u636e\u2014\u2014x\u6279\u6570\u636e\u88ab\u683c\u5f0f\u5316\u4e3a\u65f6\u95f4\u6b65\u957f\u6587\u672c\u6570\u636e\u3002y\u6279\u5904\u7406\u662f\u76f8\u540c\u7684\u6570\u636e\uff0c\u53ea\u662f\u5ef6\u8fdf\u4e86\u4e00\u4e2a\u65f6\u95f4\u6b65\u957f\u3002\u4f8b\u5982\uff0c\u6279\u6b21\u4e2d\u7684\u5355\u4e2ax, y\u6837\u672c\uff0c\u65f6\u95f4\u6b65\u957f\u4e3a8\uff0c\u770b\u8d77\u6765\u50cf: x = \u201cA girl walked into a bar, and she\u201d y = \u201cgirl walked into a bar, and she said\u201d Remember that x and y will be batches of integer data, with the size ( batch_size , num_steps ), not text as shown above \u2013 however, I have shown the above x and y sample in text form to aid understanding. So, as demonstrated in the model architecture diagram above, we are producing a many-to-many LSTM model, where the model will be trained to predict the very next word in the sequence for each word in the number of time steps. SUMMARY : \u9700\u8981\u5c06\u6587\u672c\u6570\u636e\u5206\u6210*batch_size*\u6279\u6570\u636e\uff0c\u6bcf\u4e00\u6279\u4e2d\u5305\u542b*num_steps*\u4e2a\u5355\u8bcd\uff1b Here\u2019s what the code looks like: def batch_producer ( raw_data , batch_size , num_steps ): raw_data = tf . convert_to_tensor ( raw_data , name = \"raw_data\" , dtype = tf . int32 ) data_len = tf . size ( raw_data ) batch_len = data_len // batch_size # len of every batch data = tf . reshape ( raw_data [ 0 : batch_size * batch_len ], [ batch_size , batch_len ]) epoch_size = ( batch_len - 1 ) // num_steps i = tf . train . range_input_producer ( epoch_size , shuffle = False ) . dequeue () x = data [:, i * num_steps :( i + 1 ) * num_steps ] x . set_shape ([ batch_size , num_steps ]) y = data [:, i * num_steps + 1 : ( i + 1 ) * num_steps + 1 ] y . set_shape ([ batch_size , num_steps ]) return x , y In the code above, first, the raw text data is converted into an int32 tensor. Next, the length of the full data set is calculated and stored in data_len and this is then divided by the batch size in an integer division (//) to get the number of full batches of data available within the dataset. The next line reshapes the raw_data tensor (restricted in size to the number of full batches of data i.e. 0 to batch_size * batch_len ) into a ( batch_size, batch_len ) shape. The next line sets the number of iterations in each epoch \u2013 usually, this is set so that all the training data is passed through the algorithm in each epoch. This is what occurs here \u2013 the number of batches in the data ( batch_len ) is integer divided by the number of time steps \u2013 this gives the number of time-step-sized batches that are available to be iterated through in a single epoch.","title":"Creating an input data pipeline"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/RNN-and-LSTM-tutorial/#creating#the#model","text":"In this code example, in order to have nice encapsulation and better-looking code, I\u2019ll be building the model in Python classes . The first class is a simple class that contains the input data: class Input ( object ): def __init__ ( self , batch_size , num_steps , data ): self . batch_size = batch_size self . num_steps = num_steps self . epoch_size = (( len ( data ) // batch_size ) - 1 ) // num_steps self . input_data , self . targets = batch_producer ( data , batch_size , num_steps ) We pass this object important input data information such as batch size , the number of recurrent time steps and finally the raw data file we wish to extract batch data from. The previously explained batch_producer function, when called, will return our input data batch x and the associated time step + 1 target data batch, y .","title":"Creating the model"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/","text":"Understanding LSTM Networks Recurrent Neural Networks Humans don\u2019t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don\u2019t throw everything away and start thinking from scratch again. Your thoughts have persistence. Traditional neural networks can\u2019t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It\u2019s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones. Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist. Recurrent Neural Networks have loops. In the above diagram, a chunk of neural network, A A , looks at some input x_t x_t and outputs a value h_t h_t . A loop allows information to be passed from one step of the network to the next. These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren\u2019t all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop: An unrolled recurrent neural network. This chain-like nature reveals that recurrent neural networks are intimately\uff08\u4eb2\u5207\u7684\uff09 related to sequences and lists. They\u2019re the natural architecture of neural network to use for such data. And they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning\u2026 The list goes on. I\u2019ll leave discussion of the amazing feats\uff08\u529f\u52cb\uff09 one can achieve with RNNs to Andrej Karpathy\u2019s excellent blog post, The Unreasonable Effectiveness of Recurrent Neural Networks . But they really are pretty amazing. Essential to these successes is the use of \u201cLSTMs,\u201d a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. It\u2019s these LSTMs that this essay will explore. The Problem of Long-Term Dependencies One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they\u2019d be extremely useful. But can they? It depends. Sometimes, we only need to look at recent information to perform the present task . For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in \u201cthe clouds are in the sky ,\u201d we don\u2019t need any further context \u2013 it\u2019s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it\u2019s needed is small, RNNs can learn to use the past information. SUMMARY : [X_0, X_1, X_2, X_3, X_4] [X_0, X_1, X_2, X_3, X_4] \u5c31\u662f\u4e00\u4e2atime_step\u7684\u6570\u636e\uff0c\u663e\u7136LSTM cell\u4e2d\u7684\u53c2\u6570\u8fd8\u662f\u548c\u5b83\u7279\u5f81\u6709\u5173\u7684\uff1b But there are also cases where we need more context. Consider trying to predict the last word in the text \u201cI grew up in France\u2026 I speak fluent French .\u201d Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It\u2019s entirely possible for the gap between the relevant information and the point where it is needed to become very large. Unfortunately, as that gap grows, RNNs become unable to learn to connect the information. In theory, RNNs are absolutely capable of handling such \u201clong-term dependencies.\u201d A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don\u2019t seem to be able to learn them. The problem was explored in depth by [Hochreiter (1991) German] and Bengio, et al. (1994) , who found some pretty fundamental reasons why it might be difficult. SUMMARY : \u6240\u8c13\u7684long-term dependency\u5176\u5b9e\u5c31\u662fgap\u592a\u957f\u4e86\u3002 Thankfully, LSTMs don\u2019t have this problem! LSTM Networks Long Short Term Memory networks \u2013 usually just called \u201cLSTMs\u201d \u2013 are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997) , and were refined\uff08\u6539\u5584\uff09 and popularized by many people in following work. 1 They work tremendously\uff08\u975e\u5e38\u7684\uff09 well on a large variety of problems, and are now widely used. LSTMs are explicitly designed to avoid the long-term dependency problem . Remembering information for long periods of time is practically their default behavior, not something they struggle to learn! All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer . The repeating module in a standard RNN contains a single layer. LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four , interacting in a very special way. The repeating module in an LSTM contains four interacting layers. Don\u2019t worry about the details of what\u2019s going on. We\u2019ll walk through the LSTM diagram step by step later. For now, let\u2019s just try to get comfortable with the notation we\u2019ll be using. In the above diagram, each line carries\uff08\u643a\u5e26\uff09 an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers . Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations. SUMMARY : \u4e0a\u56fe\u5176\u5b9e\u662f\u975e\u5e38\u7c7b\u4f3c\u4e8eTensorFlow\u4e2d\u7684computational graph\u7684\uff1a\u4f7f\u7528\u8282\u70b9\u6765\u8868\u793aoperation\uff0c\u4f7f\u7528\u8fb9\u6765\u8868\u793atensor\u7684\u6d41\u52a8\uff1b SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u63d0\u53ca\uff1a the yellow boxes are learned neural network layers . \u5373\u4e0a\u8ff0yellow box\u662f\u6a21\u578b\u9700\u8981\u5b66\u4e60\u7684\uff0c\u5728MLP\u4e2d\uff0cmodel\u9700\u8981\u5b66\u4e60\u7684\u662fweight\u548cbias\uff0c\u90a3\u5728LSTM\u4e2d\uff0c\u662f\u5426\u4e5f\u6709weight\u548cbias\u5462\uff1f\u8fd9\u4e9b\u662f\u53ef\u4ee5\u6709\u7684\uff0c\u53c2\u770bdeep learning book chapter 10.2\u8282\u4e2d\u7684\u56fe10.3\u53ef\u4ee5\u770b\u51fa\uff0c\u662f\u5b58\u5728weight\u7684\uff1b\u5173\u4e8e\u8fd9\u4e2a\u95ee\u9898\uff0c\u8fd8\u53ef\u4ee5\u53c2\u770b\u5982\u4e0b\u5185\u5bb9\uff1a [How to interpret weights in a LSTM layer in Keras closed] How can calculate number of weights in LSTM Reading between the layers (LSTM Network) https://www.sciencedirect.com/science/article/pii/S187705091831439X/pdf?md5=dc105bed63a63592d9b0a0ff6af56553&pid=1-s2.0-S187705091831439X-main.pdf https://fairyonice.github.io/Extract-weights-from-Keras's-LSTM-and-calcualte-hidden-and-cell-states.html deep learning book chapter 10.10\u4e2d\u7ed9\u51fa\u7684\u516c\u5f0f\u4e5f\u662f\u5305\u542b\u6709weight\u548cbias\u7684\uff1b The Core Idea Behind LSTMs The key to LSTMs is the cell state , the horizontal line running through the top of the diagram. SUMMARY : \u5728 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention \u4e2d\uff0c\u5c06cell state\u79f0\u4e4b\u4e3amemory\uff0c\u5176\u5b9e\u8fd9\u5e94\u8be5\u5c31\u662f\u548cLSTM\u4e2dM\u5bf9\u5e94\u7684\uff1b The cell state is kind of like a conveyor belt\uff08\u4f20\u9001\u5e26\uff09. It runs straight down the entire chain, with only some minor linear interactions. It\u2019s very easy for information to just flow along it unchanged. SUMMARY\uff1a**cell state**\u5373\u4e0a\u56fe\u4e2d\u7684 C C The LSTM does have the ability to remove or add information to the cell state , carefully regulated\uff08\u8c03\u6574\uff09 by structures called gates . Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation. The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means \u201clet nothing through,\u201d while a value of one means \u201clet everything through!\u201d SUMMARY : \u4e0a\u9762\u6240\u63cf\u8ff0\u7684\u662fgate\u7684\u5b9e\u73b0\u65b9\u5f0f\uff1b An LSTM has three of these gates, to protect and control the cell state . Step-by-Step LSTM Walk Through forget gate layer The first step in our LSTM is to decide what information we\u2019re going to throw away from the cell state . This decision is made by a sigmoid layer called the \u201c forget gate layer .\u201d It looks at h_{t-1} h_{t-1} and x_t x_t , and outputs a number between 0 and 1 for each number in the cell state C_{t\u22121} C_{t\u22121} . A 1 represents \u201ccompletely keep this\u201d while a 0 represents \u201ccompletely get rid of this.\u201d Let\u2019s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject. f_t=\\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f) f_t=\\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f) input gate layer The next step is to decide what new information we\u2019re going to store in the cell state . This has two parts. First, a sigmoid layer called the \u201c input gate layer \u201d decides which values we\u2019ll update. Next, a tanh layer creates a vector of new candidate values, \\tilde{C}_t \\tilde{C}_t , that could be added to the state. In the next step, we\u2019ll combine these two to create an update to the state\uff08\u8868\u793a\u7684\u662f \\tilde{C}_t \\tilde{C}_t \uff09. In the example of our language model, we\u2019d want to add the gender of the new subject to the cell state , to replace the old one we\u2019re forgetting. update cell state It\u2019s now time to update the old cell state, C_{t\u22121} C_{t\u22121} , into the new cell state C_t C_t . The previous steps already decided what to do, we just need to actually do it. We multiply the old state by f_t f_t , forgetting the things we decided to forget earlier. Then we add i_t*\\tilde{C}_t i_t*\\tilde{C}_t . This is the new candidate values, scaled by how much we decided to update each state value. In the case of the language model, this is where we\u2019d actually drop the information about the old subject\u2019s gender and add the new information, as we decided in the previous steps. C_t = f_t * C_{t-1} + i_t*\\tilde{C}_t C_t = f_t * C_{t-1} + i_t*\\tilde{C}_t output Finally, we need to decide what we\u2019re going to output. This output will be based on our cell state , but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we\u2019re going to output. Then, we put the cell state through tanh tanh (to push the values to be between 1 ) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to. For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that\u2019s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that\u2019s what follows next. SUMMARY : \u4e0a\u8ff0\u8868\u793a\u975e\u5e38\u7c7b\u4f3c\u4e8eTensorFlow\u4e2d\u7684computational graph\uff1a\u4f7f\u7528\u8282\u70b9\u6765\u8868\u793aoperation\uff0c\u4f7f\u7528edge\u6765\u8868\u793aflow of tensor\uff1b Variants on Long Short Term Memory What I\u2019ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it\u2019s worth mentioning some of them. One popular LSTM variant, introduced by Gers & Schmidhuber (2000) , is adding \u201cpeephole connections.\u201d This means that we let the gate layers look at the cell state. The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others. Another variation is to use coupled forget and input gates. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we\u2019re going to input something in its place. We only input new values to the state when we forget something older. A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by Cho, et al. (2014) . It combines the forget and input gates into a single \u201cupdate gate.\u201d It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular. These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by Yao, et al. (2015) . There\u2019s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by Koutnik, et al. (2014) . Which of these variants is best? Do the differences matter? Greff, et al. (2015) do a nice comparison of popular variants, finding that they\u2019re all about the same. Jozefowicz, et al. (2015) tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks. Conclusion Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks! Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable. LSTMs were a big step in what we can accomplish with RNNs. It\u2019s natural to wonder: is there another big step? A common opinion among researchers is: \u201cYes! There is a next step and it\u2019s attention!\u201d The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, Xu, et al. (2015) do exactly this \u2013 it might be a fun starting point if you want to explore attention! There\u2019s been a number of really exciting results using attention, and it seems like a lot more are around the corner\u2026 Attention isn\u2019t the only exciting thread in RNN research. For example, Grid LSTMs by Kalchbrenner, et al. (2015) seem extremely promising. Work using RNNs in generative models \u2013 such as Gregor, et al. (2015) , Chung, et al. (2015) , or Bayer & Osendorfer (2015) \u2013 also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!","title":"colah-Understanding-LSTM-Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#understanding#lstm#networks","text":"","title":"Understanding LSTM Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#recurrent#neural#networks","text":"Humans don\u2019t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don\u2019t throw everything away and start thinking from scratch again. Your thoughts have persistence. Traditional neural networks can\u2019t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It\u2019s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones. Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist. Recurrent Neural Networks have loops. In the above diagram, a chunk of neural network, A A , looks at some input x_t x_t and outputs a value h_t h_t . A loop allows information to be passed from one step of the network to the next. These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren\u2019t all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop: An unrolled recurrent neural network. This chain-like nature reveals that recurrent neural networks are intimately\uff08\u4eb2\u5207\u7684\uff09 related to sequences and lists. They\u2019re the natural architecture of neural network to use for such data. And they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning\u2026 The list goes on. I\u2019ll leave discussion of the amazing feats\uff08\u529f\u52cb\uff09 one can achieve with RNNs to Andrej Karpathy\u2019s excellent blog post, The Unreasonable Effectiveness of Recurrent Neural Networks . But they really are pretty amazing. Essential to these successes is the use of \u201cLSTMs,\u201d a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. It\u2019s these LSTMs that this essay will explore.","title":"Recurrent Neural Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#the#problem#of#long-term#dependencies","text":"One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they\u2019d be extremely useful. But can they? It depends. Sometimes, we only need to look at recent information to perform the present task . For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in \u201cthe clouds are in the sky ,\u201d we don\u2019t need any further context \u2013 it\u2019s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it\u2019s needed is small, RNNs can learn to use the past information. SUMMARY : [X_0, X_1, X_2, X_3, X_4] [X_0, X_1, X_2, X_3, X_4] \u5c31\u662f\u4e00\u4e2atime_step\u7684\u6570\u636e\uff0c\u663e\u7136LSTM cell\u4e2d\u7684\u53c2\u6570\u8fd8\u662f\u548c\u5b83\u7279\u5f81\u6709\u5173\u7684\uff1b But there are also cases where we need more context. Consider trying to predict the last word in the text \u201cI grew up in France\u2026 I speak fluent French .\u201d Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It\u2019s entirely possible for the gap between the relevant information and the point where it is needed to become very large. Unfortunately, as that gap grows, RNNs become unable to learn to connect the information. In theory, RNNs are absolutely capable of handling such \u201clong-term dependencies.\u201d A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don\u2019t seem to be able to learn them. The problem was explored in depth by [Hochreiter (1991) German] and Bengio, et al. (1994) , who found some pretty fundamental reasons why it might be difficult. SUMMARY : \u6240\u8c13\u7684long-term dependency\u5176\u5b9e\u5c31\u662fgap\u592a\u957f\u4e86\u3002 Thankfully, LSTMs don\u2019t have this problem!","title":"The Problem of Long-Term Dependencies"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#lstm#networks","text":"Long Short Term Memory networks \u2013 usually just called \u201cLSTMs\u201d \u2013 are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997) , and were refined\uff08\u6539\u5584\uff09 and popularized by many people in following work. 1 They work tremendously\uff08\u975e\u5e38\u7684\uff09 well on a large variety of problems, and are now widely used. LSTMs are explicitly designed to avoid the long-term dependency problem . Remembering information for long periods of time is practically their default behavior, not something they struggle to learn! All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer . The repeating module in a standard RNN contains a single layer. LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four , interacting in a very special way. The repeating module in an LSTM contains four interacting layers. Don\u2019t worry about the details of what\u2019s going on. We\u2019ll walk through the LSTM diagram step by step later. For now, let\u2019s just try to get comfortable with the notation we\u2019ll be using. In the above diagram, each line carries\uff08\u643a\u5e26\uff09 an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers . Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations. SUMMARY : \u4e0a\u56fe\u5176\u5b9e\u662f\u975e\u5e38\u7c7b\u4f3c\u4e8eTensorFlow\u4e2d\u7684computational graph\u7684\uff1a\u4f7f\u7528\u8282\u70b9\u6765\u8868\u793aoperation\uff0c\u4f7f\u7528\u8fb9\u6765\u8868\u793atensor\u7684\u6d41\u52a8\uff1b SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u63d0\u53ca\uff1a the yellow boxes are learned neural network layers . \u5373\u4e0a\u8ff0yellow box\u662f\u6a21\u578b\u9700\u8981\u5b66\u4e60\u7684\uff0c\u5728MLP\u4e2d\uff0cmodel\u9700\u8981\u5b66\u4e60\u7684\u662fweight\u548cbias\uff0c\u90a3\u5728LSTM\u4e2d\uff0c\u662f\u5426\u4e5f\u6709weight\u548cbias\u5462\uff1f\u8fd9\u4e9b\u662f\u53ef\u4ee5\u6709\u7684\uff0c\u53c2\u770bdeep learning book chapter 10.2\u8282\u4e2d\u7684\u56fe10.3\u53ef\u4ee5\u770b\u51fa\uff0c\u662f\u5b58\u5728weight\u7684\uff1b\u5173\u4e8e\u8fd9\u4e2a\u95ee\u9898\uff0c\u8fd8\u53ef\u4ee5\u53c2\u770b\u5982\u4e0b\u5185\u5bb9\uff1a [How to interpret weights in a LSTM layer in Keras closed] How can calculate number of weights in LSTM Reading between the layers (LSTM Network) https://www.sciencedirect.com/science/article/pii/S187705091831439X/pdf?md5=dc105bed63a63592d9b0a0ff6af56553&pid=1-s2.0-S187705091831439X-main.pdf https://fairyonice.github.io/Extract-weights-from-Keras's-LSTM-and-calcualte-hidden-and-cell-states.html deep learning book chapter 10.10\u4e2d\u7ed9\u51fa\u7684\u516c\u5f0f\u4e5f\u662f\u5305\u542b\u6709weight\u548cbias\u7684\uff1b","title":"LSTM Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#the#core#idea#behind#lstms","text":"The key to LSTMs is the cell state , the horizontal line running through the top of the diagram. SUMMARY : \u5728 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention \u4e2d\uff0c\u5c06cell state\u79f0\u4e4b\u4e3amemory\uff0c\u5176\u5b9e\u8fd9\u5e94\u8be5\u5c31\u662f\u548cLSTM\u4e2dM\u5bf9\u5e94\u7684\uff1b The cell state is kind of like a conveyor belt\uff08\u4f20\u9001\u5e26\uff09. It runs straight down the entire chain, with only some minor linear interactions. It\u2019s very easy for information to just flow along it unchanged. SUMMARY\uff1a**cell state**\u5373\u4e0a\u56fe\u4e2d\u7684 C C The LSTM does have the ability to remove or add information to the cell state , carefully regulated\uff08\u8c03\u6574\uff09 by structures called gates . Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation. The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means \u201clet nothing through,\u201d while a value of one means \u201clet everything through!\u201d SUMMARY : \u4e0a\u9762\u6240\u63cf\u8ff0\u7684\u662fgate\u7684\u5b9e\u73b0\u65b9\u5f0f\uff1b An LSTM has three of these gates, to protect and control the cell state .","title":"The Core Idea Behind LSTMs"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#step-by-step#lstm#walk#through","text":"","title":"Step-by-Step LSTM Walk Through"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#forget#gate#layer","text":"The first step in our LSTM is to decide what information we\u2019re going to throw away from the cell state . This decision is made by a sigmoid layer called the \u201c forget gate layer .\u201d It looks at h_{t-1} h_{t-1} and x_t x_t , and outputs a number between 0 and 1 for each number in the cell state C_{t\u22121} C_{t\u22121} . A 1 represents \u201ccompletely keep this\u201d while a 0 represents \u201ccompletely get rid of this.\u201d Let\u2019s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject. f_t=\\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f) f_t=\\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)","title":"forget gate layer"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#input#gate#layer","text":"The next step is to decide what new information we\u2019re going to store in the cell state . This has two parts. First, a sigmoid layer called the \u201c input gate layer \u201d decides which values we\u2019ll update. Next, a tanh layer creates a vector of new candidate values, \\tilde{C}_t \\tilde{C}_t , that could be added to the state. In the next step, we\u2019ll combine these two to create an update to the state\uff08\u8868\u793a\u7684\u662f \\tilde{C}_t \\tilde{C}_t \uff09. In the example of our language model, we\u2019d want to add the gender of the new subject to the cell state , to replace the old one we\u2019re forgetting.","title":"input gate layer"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#update#cell#state","text":"It\u2019s now time to update the old cell state, C_{t\u22121} C_{t\u22121} , into the new cell state C_t C_t . The previous steps already decided what to do, we just need to actually do it. We multiply the old state by f_t f_t , forgetting the things we decided to forget earlier. Then we add i_t*\\tilde{C}_t i_t*\\tilde{C}_t . This is the new candidate values, scaled by how much we decided to update each state value. In the case of the language model, this is where we\u2019d actually drop the information about the old subject\u2019s gender and add the new information, as we decided in the previous steps. C_t = f_t * C_{t-1} + i_t*\\tilde{C}_t C_t = f_t * C_{t-1} + i_t*\\tilde{C}_t","title":"update cell state"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#output","text":"Finally, we need to decide what we\u2019re going to output. This output will be based on our cell state , but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we\u2019re going to output. Then, we put the cell state through tanh tanh (to push the values to be between 1 ) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to. For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that\u2019s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that\u2019s what follows next. SUMMARY : \u4e0a\u8ff0\u8868\u793a\u975e\u5e38\u7c7b\u4f3c\u4e8eTensorFlow\u4e2d\u7684computational graph\uff1a\u4f7f\u7528\u8282\u70b9\u6765\u8868\u793aoperation\uff0c\u4f7f\u7528edge\u6765\u8868\u793aflow of tensor\uff1b","title":"output"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#variants#on#long#short#term#memory","text":"What I\u2019ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it\u2019s worth mentioning some of them. One popular LSTM variant, introduced by Gers & Schmidhuber (2000) , is adding \u201cpeephole connections.\u201d This means that we let the gate layers look at the cell state. The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others. Another variation is to use coupled forget and input gates. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we\u2019re going to input something in its place. We only input new values to the state when we forget something older. A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by Cho, et al. (2014) . It combines the forget and input gates into a single \u201cupdate gate.\u201d It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular. These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by Yao, et al. (2015) . There\u2019s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by Koutnik, et al. (2014) . Which of these variants is best? Do the differences matter? Greff, et al. (2015) do a nice comparison of popular variants, finding that they\u2019re all about the same. Jozefowicz, et al. (2015) tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.","title":"Variants on Long Short Term Memory"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/LSTM/colah-Understanding-LSTM-Networks/#conclusion","text":"Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks! Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable. LSTMs were a big step in what we can accomplish with RNNs. It\u2019s natural to wonder: is there another big step? A common opinion among researchers is: \u201cYes! There is a next step and it\u2019s attention!\u201d The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, Xu, et al. (2015) do exactly this \u2013 it might be a fun starting point if you want to explore attention! There\u2019s been a number of really exciting results using attention, and it seems like a lot more are around the corner\u2026 Attention isn\u2019t the only exciting thread in RNN research. For example, Grid LSTMs by Kalchbrenner, et al. (2015) seem extremely promising. Work using RNNs in generative models \u2013 such as Gregor, et al. (2015) , Chung, et al. (2015) , or Bayer & Osendorfer (2015) \u2013 also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!","title":"Conclusion"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/RNN/","text":"Recurrent neural network \u5468\u671f\u795e\u7ecf\u7f51\u7edc A recurrent neural network ( RNN ) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks , RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition [ 1] or speech recognition .[ 2] [ 3] The term \"recurrent neural network\" is used indiscriminately to refer to two broad classes of networks with a similar general structure, where one is finite impulse and the other is infinite impulse . Both classes of networks exhibit temporal dynamic behavior .[ 4] A finite impulse recurrent network is a directed acyclic graph that can be unrolled\uff08\u5c55\u5f00\uff09 and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a directed cyclic graph that can not be unrolled. Both finite impulse and infinite impulse recurrent networks can have additional stored state, and the storage can be under direct control by the neural network. The storage can also be replaced by another network or graph, if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units . Architectures RNNs come in many variants. Fully recurrent Basic RNNs are a network of neuron-like nodes organized into successive \"layers.\" Each node in a given layer is connected with a directed (one-way) connection to every other node in the next successive layer.[ citation needed ] Each node (neuron) has a time-varying real-valued activation. Each connection (synapse) has a modifiable real-valued weight . Nodes are either input nodes (receiving data from outside the network), output nodes (yielding results), or hidden nodes (that modify the data en route from input to output). For supervised learning in discrete time settings, sequences of real-valued input vectors arrive at the input nodes, one vector at a time. At any given time step, each non-input unit computes its current activation (result) as a nonlinear function of the weighted sum of the activations of all units that connect to it. Supervisor-given target activations can be supplied for some output units at certain time steps. For example, if the input sequence is a speech signal corresponding to a spoken digit, the final target output at the end of the sequence may be a label classifying the digit. In reinforcement learning settings, no teacher provides target signals. Instead a fitness function or reward function is occasionally used to evaluate the RNN's performance, which influences its input stream through output units connected to actuators that affect the environment. This might be used to play a game in which progress is measured with the number of points won. Each sequence produces an error as the sum of the deviations of all target signals from the corresponding activations computed by the network. For a training set of numerous sequences, the total error is the sum of the errors of all individual sequences.","title":"Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/RNN/#recurrent#neural#network","text":"\u5468\u671f\u795e\u7ecf\u7f51\u7edc A recurrent neural network ( RNN ) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks , RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition [ 1] or speech recognition .[ 2] [ 3] The term \"recurrent neural network\" is used indiscriminately to refer to two broad classes of networks with a similar general structure, where one is finite impulse and the other is infinite impulse . Both classes of networks exhibit temporal dynamic behavior .[ 4] A finite impulse recurrent network is a directed acyclic graph that can be unrolled\uff08\u5c55\u5f00\uff09 and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a directed cyclic graph that can not be unrolled. Both finite impulse and infinite impulse recurrent networks can have additional stored state, and the storage can be under direct control by the neural network. The storage can also be replaced by another network or graph, if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units .","title":"Recurrent neural network"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/RNN/#architectures","text":"RNNs come in many variants.","title":"Architectures"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/10-Sequence-Modeling-Recurrent-and-Recursive-Nets/RNN/#fully#recurrent","text":"Basic RNNs are a network of neuron-like nodes organized into successive \"layers.\" Each node in a given layer is connected with a directed (one-way) connection to every other node in the next successive layer.[ citation needed ] Each node (neuron) has a time-varying real-valued activation. Each connection (synapse) has a modifiable real-valued weight . Nodes are either input nodes (receiving data from outside the network), output nodes (yielding results), or hidden nodes (that modify the data en route from input to output). For supervised learning in discrete time settings, sequences of real-valued input vectors arrive at the input nodes, one vector at a time. At any given time step, each non-input unit computes its current activation (result) as a nonlinear function of the weighted sum of the activations of all units that connect to it. Supervisor-given target activations can be supplied for some output units at certain time steps. For example, if the input sequence is a speech signal corresponding to a spoken digit, the final target output at the end of the sequence may be a label classifying the digit. In reinforcement learning settings, no teacher provides target signals. Instead a fitness function or reward function is occasionally used to evaluate the RNN's performance, which influences its input stream through output units connected to actuators that affect the environment. This might be used to play a game in which progress is measured with the number of points won. Each sequence produces an error as the sum of the deviations of all target signals from the corresponding activations computed by the network. For a training set of numerous sequences, the total error is the sum of the errors of all individual sequences.","title":"Fully recurrent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/12-Applications/12.4-Natural-Language-Processing/12.4.5-Neural-Machine-Translation/","text":"12.4.5 Neural Machine Translation Machine translation is the task of reading a sentence in one natural language and emitting a sentence with the equivalent meaning in another language. Machine translation systems often involve many components. At a high level, there is often one component that proposes many candidate translations. Many of these translations will not be grammatical due to differences between the languages. For example, many languages put adjectives after nouns, so when translated to English directly they yield phrases such as \u201capple red.\u201d The proposal mechanism suggests many variants of the suggested translation, ideally including \u201cred apple.\u201d A second component of the translation system, a language model, evaluates the proposed translations, and can score \u201cred apple\u201d as better than \u201capple red.\u201d The earliest use of neural networks for machine translation was to upgrade the language model of a translation system by using a neural language model (Schwenk et al., 2006; Schwenk 2010 , ). Previously, most machine translation systems had used an n -gram model for this component. The n -gram based models used for machine translation include not just traditional back-off n -gram models (Jelinek and Mercer 1980 Katz 1987 Chen and Goodman 1999 , ; , ; , ) but also maximum entropy language models (Berger et al. , 1996 ), in which an affine-softmax layer predicts the next word given the presence of frequent n-grams in the context. Traditional language models simply report the probability of a natural language sentence. Because machine translation involves producing an output sentence given an input sentence, it makes sense to extend the natural language model to be conditional . As described in section 6.2.1.1, it is straightforward to extend a model that defines a marginal distribution over some variable to define a conditional distribution over that variable given a context C , where C might be a single variable or a list of variables. Devlin et al. 2014 machine translation benchmarks by using an MLP to score a phrase t_1, t_2, \\ldots , t_k t_1, t_2, \\ldots , t_k in the target language given a phrase s_1, s_2, \\ldots , s_n s_1, s_2, \\ldots , s_n in the source language. The MLP estimates $$ P( t_1, t_2, \\ldots , t_k \\mid s_1, s_2, \\ldots , s_n ) $$ The estimate formed by this MLP replaces the estimate provided by conditional n-gram models. A drawback of the MLP-based approach is that it requires the sequences to be preprocessed to be of fixed length. To make the translation more flexible, we would like to use a model that can accommodate variable length inputs and variable length outputs . An RNN provides this ability. Section 10.2.4 describes several ways of constructing an RNN that represents a conditional distribution over a sequence given some input, and section 10.4 describes how to accomplish this conditioning when the input is a sequence. In all cases, one model first reads the input sequence and emits a data structure that summarizes the input sequence . We call this summary the \u201ccontext\u201d C . The context C may be a list of vectors, or it may be a vector or tensor. The model that reads the input to produce C may be an RNN ( , ; Cho et al. 2014a Sutskever 2014 Jean 2014 et al., ; et al., ) or a convolutional network (Kalchbrenner and Blunsom 2013 , ). A second model, usually an RNN, then reads the context C and generates a sentence in the target language. This general idea of an encoder-decoder framework for machine translation is illustrated in figure 12.5. 12.4.5.1 Using an Attention Mechanism and Aligning Pieces of Data Figure 12.6: A modern attention mechanism , as introduced by ( Bahdanau et al. 2015 ), is essentially a weighted average . A context vector c is formed by taking a weighted average of feature vectors h^{(t)} h^{(t)} with weights \u03b1^{(t)} \u03b1^{(t)} . In some applications, the feature vectors h h are hidden units of a neural network, but they may also be raw input to the model. The weights \u03b1^{(t)} \u03b1^{(t)} are produced by the model itself. They are usually values in the interval [0 , 1] and are intended to concentrate around just one h^{(t)} h^{(t)} so that the weighted average approximates reading that one specific time step precisely. The weights are \u03b1^{(t)} \u03b1^{(t)} usually produced by applying a softmax function to relevance scores emitted by another portion of the model. The attention mechanism is more expensive computationally than directly indexing the desired h^{(t)} h^{(t)} , but direct indexing cannot be trained with gradient descent. The attention mechanism based on weighted averages is a smooth, differentiable approximation that can be trained with existing optimization algorithms . We can think of an attention-based system as having three components: A process that \u201creads\u201d raw data (such as source words in a source sentence), and converts them into distributed representations , with one feature vector associated with each word position. A list of feature vectors storing the output of the reader. This can be understood as a \u201cmemory\u201d containing a sequence of facts, which can be retrieved later, not necessarily in the same order, without having to visit all of them. A process that \u201cexploits\u201d the content of the memory to sequentially perform a task, at each time step having the ability put attention on the content of one memory element (or a few, with a different weight). The third component generates the translated sentence. When words in a sentence written in one language are aligned with corresponding words in a translated sentence in another language, it becomes possible to relate the corresponding word embeddings . Earlier work showed that one could learn a kind of translation matrix relating the word embeddings in one language with the word embeddings in another (Ko\u010disk\u00fd., 2014 et al ), yielding lower alignment error rates than traditional approaches based on the frequency counts in the phrase table.There is even earlier work on learning cross-lingual word vectors (Klementiev et al., 2012). Many extensions to this approach are possible. For example, more efficient cross-lingual alignment ( , ) allows training on larger datasets.","title":"12.4.5-Neural-Machine-Translation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/12-Applications/12.4-Natural-Language-Processing/12.4.5-Neural-Machine-Translation/#1245#neural#machine#translation","text":"Machine translation is the task of reading a sentence in one natural language and emitting a sentence with the equivalent meaning in another language. Machine translation systems often involve many components. At a high level, there is often one component that proposes many candidate translations. Many of these translations will not be grammatical due to differences between the languages. For example, many languages put adjectives after nouns, so when translated to English directly they yield phrases such as \u201capple red.\u201d The proposal mechanism suggests many variants of the suggested translation, ideally including \u201cred apple.\u201d A second component of the translation system, a language model, evaluates the proposed translations, and can score \u201cred apple\u201d as better than \u201capple red.\u201d The earliest use of neural networks for machine translation was to upgrade the language model of a translation system by using a neural language model (Schwenk et al., 2006; Schwenk 2010 , ). Previously, most machine translation systems had used an n -gram model for this component. The n -gram based models used for machine translation include not just traditional back-off n -gram models (Jelinek and Mercer 1980 Katz 1987 Chen and Goodman 1999 , ; , ; , ) but also maximum entropy language models (Berger et al. , 1996 ), in which an affine-softmax layer predicts the next word given the presence of frequent n-grams in the context. Traditional language models simply report the probability of a natural language sentence. Because machine translation involves producing an output sentence given an input sentence, it makes sense to extend the natural language model to be conditional . As described in section 6.2.1.1, it is straightforward to extend a model that defines a marginal distribution over some variable to define a conditional distribution over that variable given a context C , where C might be a single variable or a list of variables. Devlin et al. 2014 machine translation benchmarks by using an MLP to score a phrase t_1, t_2, \\ldots , t_k t_1, t_2, \\ldots , t_k in the target language given a phrase s_1, s_2, \\ldots , s_n s_1, s_2, \\ldots , s_n in the source language. The MLP estimates $$ P( t_1, t_2, \\ldots , t_k \\mid s_1, s_2, \\ldots , s_n ) $$ The estimate formed by this MLP replaces the estimate provided by conditional n-gram models. A drawback of the MLP-based approach is that it requires the sequences to be preprocessed to be of fixed length. To make the translation more flexible, we would like to use a model that can accommodate variable length inputs and variable length outputs . An RNN provides this ability. Section 10.2.4 describes several ways of constructing an RNN that represents a conditional distribution over a sequence given some input, and section 10.4 describes how to accomplish this conditioning when the input is a sequence. In all cases, one model first reads the input sequence and emits a data structure that summarizes the input sequence . We call this summary the \u201ccontext\u201d C . The context C may be a list of vectors, or it may be a vector or tensor. The model that reads the input to produce C may be an RNN ( , ; Cho et al. 2014a Sutskever 2014 Jean 2014 et al., ; et al., ) or a convolutional network (Kalchbrenner and Blunsom 2013 , ). A second model, usually an RNN, then reads the context C and generates a sentence in the target language. This general idea of an encoder-decoder framework for machine translation is illustrated in figure 12.5.","title":"12.4.5 Neural Machine Translation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/12-Applications/12.4-Natural-Language-Processing/12.4.5-Neural-Machine-Translation/#12451#using#an#attention#mechanism#and#aligning#pieces#of#data","text":"Figure 12.6: A modern attention mechanism , as introduced by ( Bahdanau et al. 2015 ), is essentially a weighted average . A context vector c is formed by taking a weighted average of feature vectors h^{(t)} h^{(t)} with weights \u03b1^{(t)} \u03b1^{(t)} . In some applications, the feature vectors h h are hidden units of a neural network, but they may also be raw input to the model. The weights \u03b1^{(t)} \u03b1^{(t)} are produced by the model itself. They are usually values in the interval [0 , 1] and are intended to concentrate around just one h^{(t)} h^{(t)} so that the weighted average approximates reading that one specific time step precisely. The weights are \u03b1^{(t)} \u03b1^{(t)} usually produced by applying a softmax function to relevance scores emitted by another portion of the model. The attention mechanism is more expensive computationally than directly indexing the desired h^{(t)} h^{(t)} , but direct indexing cannot be trained with gradient descent. The attention mechanism based on weighted averages is a smooth, differentiable approximation that can be trained with existing optimization algorithms . We can think of an attention-based system as having three components: A process that \u201creads\u201d raw data (such as source words in a source sentence), and converts them into distributed representations , with one feature vector associated with each word position. A list of feature vectors storing the output of the reader. This can be understood as a \u201cmemory\u201d containing a sequence of facts, which can be retrieved later, not necessarily in the same order, without having to visit all of them. A process that \u201cexploits\u201d the content of the memory to sequentially perform a task, at each time step having the ability put attention on the content of one memory element (or a few, with a different weight). The third component generates the translated sentence. When words in a sentence written in one language are aligned with corresponding words in a translated sentence in another language, it becomes possible to relate the corresponding word embeddings . Earlier work showed that one could learn a kind of translation matrix relating the word embeddings in one language with the word embeddings in another (Ko\u010disk\u00fd., 2014 et al ), yielding lower alignment error rates than traditional approaches based on the frequency counts in the phrase table.There is even earlier work on learning cross-lingual word vectors (Klementiev et al., 2012). Many extensions to this approach are possible. For example, more efficient cross-lingual alignment ( , ) allows training on larger datasets.","title":"12.4.5.1 Using an Attention Mechanism and Aligning Pieces of Data"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6-Deep-Feedforward-Network/","text":"Deep Feedforward Networks Deep feedforward networks , also often called feedforward neural networks , or multi-layer perceptrons \uff08MLPs\uff09, are the quintessential\uff08\u5178\u578b\u7684\uff09 deep learning models. The goal of a feedforward network is to approximate some function f ^\u2217 f ^\u2217 . A feedforward networkd defines a mapping y = f ( x ; \u03b8 ) y = f ( x ; \u03b8 ) and learns the value of the parameters \u03b8 \u03b8 that result in the best function approximation . When feedforward neural networks are extended to include feedback connections , they are called recurrent neural networks , presented in Chapter 10. Feedforward neural networks are called because they are typically represented by composing together many different functions . The model is associated with a directed acyclic graph describing how the functions are composed together.For example, we might have three functions $f ^{(1)} $, f ^{(2)} f ^{(2)} , and $f ^{(3)} $connected in a chain , to form f ( x ) = f ^{(3)} ( f^{(2)} ( f^{(1)} ( x ))) f ( x ) = f ^{(3)} ( f^{(2)} ( f^{(1)} ( x ))) . These chain structures are the most commonly used structures of neural networks. In this case, f^{(1)} f^{(1)} is called the first layer of the network, f^{(2)} f^{(2)} is called the second layer, and so on. The overall length of the chain gives the depth of the model.It is from this terminology that the name \u201c deep learning \u201d arises. The final layer of a feedforward network is called the output layer . Because the training data does not show the desired output for each of these layers, these layers are called hidden layers . Each hidden layer of the network is typically vector-valued . The dimensionality of these hidden layers determines the width of the model.Each element of the vector may be interpreted as playing a role analogous to a neuron .Rather than thinking of the layer as representing a single vector-to-vector function , we can also think of the layer as consisting of many units that act in parallel, each representing a vector-to-scalar function . Each unit resembles a neuron in the sense that it receives input from many other units and computes its own activation value . SUMMARY : input-layer\u548coutput-layer\u7684\u7ef4\u5ea6\u5f80\u5f80\u662f\u7531\u6240\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u51b3\u5b9a\u7684\uff0c\u6bd4\u5982\u5bf9\u4e8eMNIST\u95ee\u9898\uff0coutput layer\u7684\u662f [10,1] \uff0c\u56e0\u4e3a\u9700\u8981\u8bc6\u522b\u7684\u662f10\u4e2a\u6570\u5b57\uff1binput layer\u7684\u7ef4\u5ea6\u7531\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u51b3\u5b9a\uff1b SUMMARY : \u4ece\u51fd\u6570\u7684\u89d2\u5ea6\u6765\u7406\u89e3layer\uff0cneuron\uff1b\u4e0a\u8ff0\u4f7f\u7528vector-to-scalar function\u6765\u63cf\u8ff0neuron\uff0c\u8fd9\u4e2ascalar\u5c31\u662f**activation value**\uff1b It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization , occasionally drawing some insights from what we know about the brain, rather than as models of brain function. This general principle of improving models by learning features extends beyond the feedforward networks described in this chapter. SUMMARY : \u8fd9\u662f\u6307\u5bfc\u5f97\u5230feedforward neural network\u7684\u601d\u60f3\uff1b First, training a feedforward network requires making many of the same design decisions as are necessary for a linear model: choosing the optimizer , the cost function , and the form of the output units. Feedforward networks have introduced the concept of a hidden layer , and this requires us to choose the activation functions that will be activation functions used to compute the hidden layer values . SUMMARY : \u6b64\u5904\u63d0\u51fa\u4e86hidden layer value\u7684\u6982\u5ff5\uff0c\u5176\u5b9e\u5728\u524d\u9762\u4ecb\u7ecd***unit***\uff08neuron\uff09\u7684\u65f6\u5019\u4e5f\u63d0\u53ca\u4e86activation value\u7684\u6982\u5ff5\uff1b We must also design the architecture of the network, including how many layers the network should contain, how these networks should be connected to each other, and how many units should be in each layer. Clearly, we must use a nonlinear function to describe the features. Most neural networks do so using an affine transformation controlled by learned parameters, followed by a fixed, nonlinear function called an activation function . We use that strategy here, by defining h = g ( W^{T} x+ c ) h = g ( W^{T} x+ c ) , where W W provides the weights of a linear transformation and c c the biases.Previously, to describe a linear regression model , we used a vector of weights and a scalar bias parameter to describe an affine transformation from an input vector to an output scalar . Now, we describe an affine transformation from a vector x x to vector h h , so an entire vector of bias parameters is needed. The activation function g g is typically chosen to be a function that is applied element-wise , with h_i = g(x^{T}W_{:,i} + c_i) h_i = g(x^{T}W_{:,i} + c_i) .. In modern neural networks,the default recommendation is to use the rectified linear unit or ReLU defined by the activation function \u8865\u5145 A Beginner's Guide to Multilayer Perceptrons (MLP) MULTI LAYER PERCEPTRON","title":"6-Deep-Feedforward-Network"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6-Deep-Feedforward-Network/#deep#feedforward#networks","text":"Deep feedforward networks , also often called feedforward neural networks , or multi-layer perceptrons \uff08MLPs\uff09, are the quintessential\uff08\u5178\u578b\u7684\uff09 deep learning models. The goal of a feedforward network is to approximate some function f ^\u2217 f ^\u2217 . A feedforward networkd defines a mapping y = f ( x ; \u03b8 ) y = f ( x ; \u03b8 ) and learns the value of the parameters \u03b8 \u03b8 that result in the best function approximation . When feedforward neural networks are extended to include feedback connections , they are called recurrent neural networks , presented in Chapter 10. Feedforward neural networks are called because they are typically represented by composing together many different functions . The model is associated with a directed acyclic graph describing how the functions are composed together.For example, we might have three functions $f ^{(1)} $, f ^{(2)} f ^{(2)} , and $f ^{(3)} $connected in a chain , to form f ( x ) = f ^{(3)} ( f^{(2)} ( f^{(1)} ( x ))) f ( x ) = f ^{(3)} ( f^{(2)} ( f^{(1)} ( x ))) . These chain structures are the most commonly used structures of neural networks. In this case, f^{(1)} f^{(1)} is called the first layer of the network, f^{(2)} f^{(2)} is called the second layer, and so on. The overall length of the chain gives the depth of the model.It is from this terminology that the name \u201c deep learning \u201d arises. The final layer of a feedforward network is called the output layer . Because the training data does not show the desired output for each of these layers, these layers are called hidden layers . Each hidden layer of the network is typically vector-valued . The dimensionality of these hidden layers determines the width of the model.Each element of the vector may be interpreted as playing a role analogous to a neuron .Rather than thinking of the layer as representing a single vector-to-vector function , we can also think of the layer as consisting of many units that act in parallel, each representing a vector-to-scalar function . Each unit resembles a neuron in the sense that it receives input from many other units and computes its own activation value . SUMMARY : input-layer\u548coutput-layer\u7684\u7ef4\u5ea6\u5f80\u5f80\u662f\u7531\u6240\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u51b3\u5b9a\u7684\uff0c\u6bd4\u5982\u5bf9\u4e8eMNIST\u95ee\u9898\uff0coutput layer\u7684\u662f [10,1] \uff0c\u56e0\u4e3a\u9700\u8981\u8bc6\u522b\u7684\u662f10\u4e2a\u6570\u5b57\uff1binput layer\u7684\u7ef4\u5ea6\u7531\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u51b3\u5b9a\uff1b SUMMARY : \u4ece\u51fd\u6570\u7684\u89d2\u5ea6\u6765\u7406\u89e3layer\uff0cneuron\uff1b\u4e0a\u8ff0\u4f7f\u7528vector-to-scalar function\u6765\u63cf\u8ff0neuron\uff0c\u8fd9\u4e2ascalar\u5c31\u662f**activation value**\uff1b It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization , occasionally drawing some insights from what we know about the brain, rather than as models of brain function. This general principle of improving models by learning features extends beyond the feedforward networks described in this chapter. SUMMARY : \u8fd9\u662f\u6307\u5bfc\u5f97\u5230feedforward neural network\u7684\u601d\u60f3\uff1b First, training a feedforward network requires making many of the same design decisions as are necessary for a linear model: choosing the optimizer , the cost function , and the form of the output units. Feedforward networks have introduced the concept of a hidden layer , and this requires us to choose the activation functions that will be activation functions used to compute the hidden layer values . SUMMARY : \u6b64\u5904\u63d0\u51fa\u4e86hidden layer value\u7684\u6982\u5ff5\uff0c\u5176\u5b9e\u5728\u524d\u9762\u4ecb\u7ecd***unit***\uff08neuron\uff09\u7684\u65f6\u5019\u4e5f\u63d0\u53ca\u4e86activation value\u7684\u6982\u5ff5\uff1b We must also design the architecture of the network, including how many layers the network should contain, how these networks should be connected to each other, and how many units should be in each layer. Clearly, we must use a nonlinear function to describe the features. Most neural networks do so using an affine transformation controlled by learned parameters, followed by a fixed, nonlinear function called an activation function . We use that strategy here, by defining h = g ( W^{T} x+ c ) h = g ( W^{T} x+ c ) , where W W provides the weights of a linear transformation and c c the biases.Previously, to describe a linear regression model , we used a vector of weights and a scalar bias parameter to describe an affine transformation from an input vector to an output scalar . Now, we describe an affine transformation from a vector x x to vector h h , so an entire vector of bias parameters is needed. The activation function g g is typically chosen to be a function that is applied element-wise , with h_i = g(x^{T}W_{:,i} + c_i) h_i = g(x^{T}W_{:,i} + c_i) .. In modern neural networks,the default recommendation is to use the rectified linear unit or ReLU defined by the activation function","title":"Deep Feedforward Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6-Deep-Feedforward-Network/#_1","text":"A Beginner's Guide to Multilayer Perceptrons (MLP) MULTI LAYER PERCEPTRON","title":"\u8865\u5145"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.2-Gradient-Based-Learning/","text":"","title":"6.2-Gradient-Based-Learning"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.4-Architecture-Design/6.4-Architecture-Design/","text":"6.4 Architecture Design Another key design consideration for neural networks is determining the architecture. The word architecture refers to the overall structure of the network: how many units it should have and how these units should be connected to each other. Most neural networks are organized into groups of units called layers . Most neural network architectures arrange these layers in a chain structure , with each layer being a function of the layer that preceded it. In this structure, the first layer is given by $$ h {(1)}:=g {(1)}(W^{(1)T}x) + b^{(1)}) $$ the second layer is given by $$ h {(2)}:=g {(2)}(W^{(2)T} h^{(1)}) + b^{(2)}) $$ and so on. In these chain-based architectures, the main architectural considerations are to choose the depth of the network and the width of each layer. 6.4.1 Universal Approximation Properties and Depth NOTE: \u53c2\u89c1 Universal-approximation-theorem 6.4.2 Other Architectural Considerations So far we have described neural networks as being simple chains of layers, with the main considerations being the depth of the network and the width of each layer. In practice, neural networks show considerably more diversity. Many neural network architectures have been developed for specific tasks. Specialized architectures for computer vision called convolutional networks are described in chapter 9. Feedforward networks may also be generalized to the recurrent neural networks for sequence processing, described in chapter 10, which have their own architectural considerations. In general, the layers need not be connected in a chain, even though this is the most common practice. Many architectures build a main chain but then add extra architectural features to it, such as skip connections going from layer i i to layer i +2 i +2 or higher. These skip connections make it easier for the gradient to flow from output layers to layers nearer the input. Another key consideration of architecture design is exactly how to connect a pair of layers to each other. In the default neural network layer described by a linear transformation via a matrix W W , every input unit is connected to every output unit. Many specialized networks in the chapters ahead have fewer connections, so that each unit in the input layer is connected to only a small subset of units in the output layer . These strategies for reducing the number of connections reduce the number of parameters and the amount of computation required to evaluate the network, but are often highly problem-dependent. For example, convolutional networks , described in chapter 9 , use specialized patterns of sparse connections that are very effective for computer vision problems. In this chapter, it is difficult to give much more specific advice concerning the architecture of a generic neural network. Subsequent chapters develop the particular architectural strategies that have been found to work well for different application domains.","title":"6.4-Architecture-Design"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.4-Architecture-Design/6.4-Architecture-Design/#64#architecture#design","text":"Another key design consideration for neural networks is determining the architecture. The word architecture refers to the overall structure of the network: how many units it should have and how these units should be connected to each other. Most neural networks are organized into groups of units called layers . Most neural network architectures arrange these layers in a chain structure , with each layer being a function of the layer that preceded it. In this structure, the first layer is given by $$ h {(1)}:=g {(1)}(W^{(1)T}x) + b^{(1)}) $$ the second layer is given by $$ h {(2)}:=g {(2)}(W^{(2)T} h^{(1)}) + b^{(2)}) $$ and so on. In these chain-based architectures, the main architectural considerations are to choose the depth of the network and the width of each layer.","title":"6.4 Architecture Design"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.4-Architecture-Design/6.4-Architecture-Design/#641#universal#approximation#properties#and#depth","text":"NOTE: \u53c2\u89c1 Universal-approximation-theorem","title":"6.4.1 Universal Approximation Properties and Depth"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.4-Architecture-Design/6.4-Architecture-Design/#642#other#architectural#considerations","text":"So far we have described neural networks as being simple chains of layers, with the main considerations being the depth of the network and the width of each layer. In practice, neural networks show considerably more diversity. Many neural network architectures have been developed for specific tasks. Specialized architectures for computer vision called convolutional networks are described in chapter 9. Feedforward networks may also be generalized to the recurrent neural networks for sequence processing, described in chapter 10, which have their own architectural considerations. In general, the layers need not be connected in a chain, even though this is the most common practice. Many architectures build a main chain but then add extra architectural features to it, such as skip connections going from layer i i to layer i +2 i +2 or higher. These skip connections make it easier for the gradient to flow from output layers to layers nearer the input. Another key consideration of architecture design is exactly how to connect a pair of layers to each other. In the default neural network layer described by a linear transformation via a matrix W W , every input unit is connected to every output unit. Many specialized networks in the chapters ahead have fewer connections, so that each unit in the input layer is connected to only a small subset of units in the output layer . These strategies for reducing the number of connections reduce the number of parameters and the amount of computation required to evaluate the network, but are often highly problem-dependent. For example, convolutional networks , described in chapter 9 , use specialized patterns of sparse connections that are very effective for computer vision problems. In this chapter, it is difficult to give much more specific advice concerning the architecture of a generic neural network. Subsequent chapters develop the particular architectural strategies that have been found to work well for different application domains.","title":"6.4.2 Other Architectural Considerations"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.4-Architecture-Design/Universal-approximation-theorem/","text":"Universal approximation theorem In the mathematical theory of artificial neural networks , the universal approximation theorem states[ 1] that a feed-forward network with a single hidden layer containing a finite number of neurons can approximate continuous functions on compact subsets of **R***n* , under mild assumptions on the activation function. The theorem thus states that simple neural networks can represent a wide variety of interesting functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters. One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid activation functions.[ 2] Kurt Hornik showed in 1991[ 3] that it is not the specific choice of the activation function, but rather the multilayer feedforward architecture itself which gives neural networks the potential of being universal approximators. The output units are always assumed to be linear. Although feed-forward networks with a single hidden layer are universal approximators, the width of such networks has to be exponentially large. In 2017 Lu et al.[ 4] proved universal approximation theorem for width-bounded deep neural networks . In particular, they showed that width- n+4 networks with ReLU activation functions can approximate any Lebesgue integrable function on n -dimensional input space with respect to $ L^{1} $distance if network depth is allowed to grow. They also showed the limited expressive power if the width is less than or equal to n . All Lebesgue integrable functions except for a zero measure set cannot be approximated by width- n ReLU networks. Later Hanin improved the earlier result,[ 4] showing that ReLU networks with width n+1 is sufficient to approximate any continuous convex function of n -dimensional input variables.[ 5] Universal approximation theorem and representational capacity and effective capacity \u5728chapter 5.2\u4e2d\u63d0\u51fa\u4e86representational capacity \u548c effective capacity\u7684\u6982\u5ff5\uff0c\u8fd9\u4e24\u4e2a\u6982\u5ff5\u548cuniversal approximation theorem\u975e\u5e38\u5bc6\u5207\uff1b","title":"Universal-approximation-theorem"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.4-Architecture-Design/Universal-approximation-theorem/#universal#approximation#theorem","text":"In the mathematical theory of artificial neural networks , the universal approximation theorem states[ 1] that a feed-forward network with a single hidden layer containing a finite number of neurons can approximate continuous functions on compact subsets of **R***n* , under mild assumptions on the activation function. The theorem thus states that simple neural networks can represent a wide variety of interesting functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters. One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid activation functions.[ 2] Kurt Hornik showed in 1991[ 3] that it is not the specific choice of the activation function, but rather the multilayer feedforward architecture itself which gives neural networks the potential of being universal approximators. The output units are always assumed to be linear. Although feed-forward networks with a single hidden layer are universal approximators, the width of such networks has to be exponentially large. In 2017 Lu et al.[ 4] proved universal approximation theorem for width-bounded deep neural networks . In particular, they showed that width- n+4 networks with ReLU activation functions can approximate any Lebesgue integrable function on n -dimensional input space with respect to $ L^{1} $distance if network depth is allowed to grow. They also showed the limited expressive power if the width is less than or equal to n . All Lebesgue integrable functions except for a zero measure set cannot be approximated by width- n ReLU networks. Later Hanin improved the earlier result,[ 4] showing that ReLU networks with width n+1 is sufficient to approximate any continuous convex function of n -dimensional input variables.[ 5]","title":"Universal approximation theorem"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.4-Architecture-Design/Universal-approximation-theorem/#universal#approximation#theorem#and#representational#capacity#and#effective#capacity","text":"\u5728chapter 5.2\u4e2d\u63d0\u51fa\u4e86representational capacity \u548c effective capacity\u7684\u6982\u5ff5\uff0c\u8fd9\u4e24\u4e2a\u6982\u5ff5\u548cuniversal approximation theorem\u975e\u5e38\u5bc6\u5207\uff1b","title":"Universal approximation theorem and representational capacity and effective capacity"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/","text":"\u5173\u4e8e\u672c\u7ae0 \u539f\u4e66\u76846.5\u8282\u300aBack-Propagation and Other Differentiation Algorithms\u300b\u63cf\u8ff0Back-Propagation algorithm\uff0c\u8fd9\u4e2a\u7b97\u6cd5\u662f\u4e0d\u5bb9\u6613\u7406\u89e3\uff0c\u4e3a\u4e86\u4fbf\u4e8e\u7406\u89e3\uff0c\u53ef\u4ee5\u5148\u9605\u8bfb\u79d1\u666e\u6027\u7684\u8bfb\u7269\uff1a Back-Propagation \uff1b\u5728\u521d\u6b65\u4e86\u89e3\u8be5\u7b97\u6cd5\u540e\uff0c\u6b63\u5f0f\u8fdb\u5165 6.5-Back-Propagation-and-Other-Differentiation \uff0c\u5176\u4e2d\u7684\u63cf\u8ff0\u662f\u975e\u5e38\u4e25\u8c28\u3001\u4e13\u4e1a\u7684\uff1b\u638c\u63e1\u8be5\u7b97\u6cd5\u540e\uff0c\u6211\u4eec\u9700\u8981\u8003\u8651\u5982\u4f55\u5b9e\u73b0back propagation\uff1a Implementation \u3002 computational-graph and chain-of-calculus and back-propagation computational-graph\u662f\u5bf9math function\uff08\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2aexpression\uff09\u7684structure representation\uff1b chain of calculus\u662f\u8ba1\u7b97math function\u7684\u516c\u5f0f\uff1b \u601d\u8003: \u5982\u4f55\u6839\u636e\u51fd\u6570\u8868\u8fbe\u5f0f\u6765\u6784\u9020computational-graph \u8fd9\u4e2a\u8fc7\u7a0b\u8ddfcompiler parse program\u662f\u7c7b\u4f3c\u7684\uff1b math expression\u548cprogram\u662fcontext free language\uff0c\u90fd\u662f\u9075\u5faacontext free grammar\uff1b compiler\u6839\u636egrammar\uff08\u5f80\u5f80\u4f7f\u7528production\u7684\u65b9\u5f0f\u6765\u8868\u8fbe\uff09\u4f7f\u7528grammar tree\u6765\u8868\u793a\u6211\u4eec\u7684program\uff1b \u76f8\u5e94\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636emath expression\u7684grammar\u6784\u9020\u51fa\u5b83\u7684computational graph\uff1b \u5176\u5b9ecomputational graph\u975e\u5e38\u7c7b\u4f3c\u4e8eabstract syntax tree\u7684\uff1b computational graph\u7684\u6784\u9020\u6784\u6210\u662f\u53ef\u4ee5\u53c2\u8003parsing\u7684\u8fc7\u7a0b\u7684\u3002 Computation graph VS parse tree NOTE: parse tree\u5728\u5de5\u7a0bcompiler-principle # \u4e2d\u4ecb\u7ecd \u4e24\u8005\u90fd\u9700\u8981\u9075\u5faagrammar\uff1a computation graph\u7684\u6784\u5efa\u9700\u8981\u9075\u5faa\u7684\u5404\u79cdoperation\u7684grammar\uff1b parse tree\u7684\u6784\u5efa\u9700\u8981\u9075\u5faa\u7684\u662fcontext free grammar\uff1b \u5728\u5de5\u7a0bcompiler-principle # \u4e2d\uff0cparse tree\u7684\u6784\u5efa\u53ef\u4ee5\u662ftop-down\u3001bottom-up\u7684\u3002 \u5728tensorflow whitepaper 2015\u4e2d\uff0ccomputation graph\u7684\u6784\u5efa\u662fbottom-up\u7684\u3002 Function composition and CFG \u590d\u5408\u51fd\u6570\u662f\u663e\u7136\u7684containing/nesting\u5173\u7cfb\uff0c\u8fd9\u548cCFG\u662f\u4e00\u81f4\u7684\uff0c\u8fd9\u5c31\u51b3\u5b9a\u4e86\u5b83\u4eec\u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3c\u7684\u65b9\u5f0f\u6765\u8fdb\u884cparsing\u3002programming language\u3001math\u90fd\u662fCFG\u3002 \u601d\u8003\uff1a\u4e3a\u4ec0\u4e48\u4f7f\u7528computational graph\uff1f \u7b80\u800c\u8a00\u4e4b\uff1a\u4f7f\u7528\u8fd9\u79cdrepresentation\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5b9e\u73b0back-propagation\u3002 \u4ece\u201c\u7ed3\u6784\u5316\u601d\u7ef4\u201d\u7684\u89d2\u5ea6\u6765\u5206\u6790\uff1acomputational-graph \u548c chain-of-calculus \u6709\u7740\u76f8\u4f3c\u7684\u7ed3\u6784\uff1ahierarchy\u3001containing\u5173\u7cfb\uff0crewrite rule\uff0crecursion\u3002\u4e24\u8005\u7ed3\u6784\u7684\u76f8\u4f3c\uff0c\u51b3\u5b9a\u4e86\u5f53\u6cbf\u7740computational-graph\u7684edge\uff0c\u53ef\u4ee5\u975e\u5e38\u81ea\u7136\u5730\u4f7f\u7528chain-of-calculus\uff0c\u8fdb\u800c\u975e\u5e38\u5bb9\u6613\u5730\u4f7f\u7528back-propagation\u3002\u7531\u6b64\u53ef\u4ee5\u770b\u5230\uff0c\u91c7\u7528\u5408\u9002\u7684representation\u5bf9\u4e8e\u89e3\u51b3\u5404\u79cdcomputational problem\u7684\u610f\u4e49\u3002 Structure of chain-of-calculus chain-of-calculus\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u4e2aformula\uff0c\u548c\u666e\u901a\u7684math expression\u7c7b\u4f3c\u3002 \u663e\u7136\uff0ccomputational-graph\u5bf9\u4e8e\u5b9e\u73b0back-propagation\u7684\u91cd\u8981\u610f\u4e49\uff0c\u51b3\u5b9a\u4e86tensorflow\u3001torch\u7684\u5e95\u5c42\u90fd\u4f7f\u7528computational graph\u6765\u5b9e\u73b0\u7684\u539f\u56e0\u3002 back-propagation\u662f\u5bf9chain-of-calculus\u7684\u8fd0\u7528\uff0c\u5728","title":"Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/#_1","text":"\u539f\u4e66\u76846.5\u8282\u300aBack-Propagation and Other Differentiation Algorithms\u300b\u63cf\u8ff0Back-Propagation algorithm\uff0c\u8fd9\u4e2a\u7b97\u6cd5\u662f\u4e0d\u5bb9\u6613\u7406\u89e3\uff0c\u4e3a\u4e86\u4fbf\u4e8e\u7406\u89e3\uff0c\u53ef\u4ee5\u5148\u9605\u8bfb\u79d1\u666e\u6027\u7684\u8bfb\u7269\uff1a Back-Propagation \uff1b\u5728\u521d\u6b65\u4e86\u89e3\u8be5\u7b97\u6cd5\u540e\uff0c\u6b63\u5f0f\u8fdb\u5165 6.5-Back-Propagation-and-Other-Differentiation \uff0c\u5176\u4e2d\u7684\u63cf\u8ff0\u662f\u975e\u5e38\u4e25\u8c28\u3001\u4e13\u4e1a\u7684\uff1b\u638c\u63e1\u8be5\u7b97\u6cd5\u540e\uff0c\u6211\u4eec\u9700\u8981\u8003\u8651\u5982\u4f55\u5b9e\u73b0back propagation\uff1a Implementation \u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/#computational-graph#and#chain-of-calculus#and#back-propagation","text":"computational-graph\u662f\u5bf9math function\uff08\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2aexpression\uff09\u7684structure representation\uff1b chain of calculus\u662f\u8ba1\u7b97math function\u7684\u516c\u5f0f\uff1b","title":"computational-graph and chain-of-calculus and back-propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/#computational-graph","text":"\u8fd9\u4e2a\u8fc7\u7a0b\u8ddfcompiler parse program\u662f\u7c7b\u4f3c\u7684\uff1b math expression\u548cprogram\u662fcontext free language\uff0c\u90fd\u662f\u9075\u5faacontext free grammar\uff1b compiler\u6839\u636egrammar\uff08\u5f80\u5f80\u4f7f\u7528production\u7684\u65b9\u5f0f\u6765\u8868\u8fbe\uff09\u4f7f\u7528grammar tree\u6765\u8868\u793a\u6211\u4eec\u7684program\uff1b \u76f8\u5e94\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636emath expression\u7684grammar\u6784\u9020\u51fa\u5b83\u7684computational graph\uff1b \u5176\u5b9ecomputational graph\u975e\u5e38\u7c7b\u4f3c\u4e8eabstract syntax tree\u7684\uff1b computational graph\u7684\u6784\u9020\u6784\u6210\u662f\u53ef\u4ee5\u53c2\u8003parsing\u7684\u8fc7\u7a0b\u7684\u3002","title":"\u601d\u8003: \u5982\u4f55\u6839\u636e\u51fd\u6570\u8868\u8fbe\u5f0f\u6765\u6784\u9020computational-graph"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/#computation#graph#vs#parse#tree","text":"NOTE: parse tree\u5728\u5de5\u7a0bcompiler-principle # \u4e2d\u4ecb\u7ecd \u4e24\u8005\u90fd\u9700\u8981\u9075\u5faagrammar\uff1a computation graph\u7684\u6784\u5efa\u9700\u8981\u9075\u5faa\u7684\u5404\u79cdoperation\u7684grammar\uff1b parse tree\u7684\u6784\u5efa\u9700\u8981\u9075\u5faa\u7684\u662fcontext free grammar\uff1b \u5728\u5de5\u7a0bcompiler-principle # \u4e2d\uff0cparse tree\u7684\u6784\u5efa\u53ef\u4ee5\u662ftop-down\u3001bottom-up\u7684\u3002 \u5728tensorflow whitepaper 2015\u4e2d\uff0ccomputation graph\u7684\u6784\u5efa\u662fbottom-up\u7684\u3002","title":"Computation graph VS parse tree"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/#function#composition#and#cfg","text":"\u590d\u5408\u51fd\u6570\u662f\u663e\u7136\u7684containing/nesting\u5173\u7cfb\uff0c\u8fd9\u548cCFG\u662f\u4e00\u81f4\u7684\uff0c\u8fd9\u5c31\u51b3\u5b9a\u4e86\u5b83\u4eec\u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3c\u7684\u65b9\u5f0f\u6765\u8fdb\u884cparsing\u3002programming language\u3001math\u90fd\u662fCFG\u3002","title":"Function composition and CFG"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/#computational#graph","text":"\u7b80\u800c\u8a00\u4e4b\uff1a\u4f7f\u7528\u8fd9\u79cdrepresentation\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5b9e\u73b0back-propagation\u3002 \u4ece\u201c\u7ed3\u6784\u5316\u601d\u7ef4\u201d\u7684\u89d2\u5ea6\u6765\u5206\u6790\uff1acomputational-graph \u548c chain-of-calculus \u6709\u7740\u76f8\u4f3c\u7684\u7ed3\u6784\uff1ahierarchy\u3001containing\u5173\u7cfb\uff0crewrite rule\uff0crecursion\u3002\u4e24\u8005\u7ed3\u6784\u7684\u76f8\u4f3c\uff0c\u51b3\u5b9a\u4e86\u5f53\u6cbf\u7740computational-graph\u7684edge\uff0c\u53ef\u4ee5\u975e\u5e38\u81ea\u7136\u5730\u4f7f\u7528chain-of-calculus\uff0c\u8fdb\u800c\u975e\u5e38\u5bb9\u6613\u5730\u4f7f\u7528back-propagation\u3002\u7531\u6b64\u53ef\u4ee5\u770b\u5230\uff0c\u91c7\u7528\u5408\u9002\u7684representation\u5bf9\u4e8e\u89e3\u51b3\u5404\u79cdcomputational problem\u7684\u610f\u4e49\u3002","title":"\u601d\u8003\uff1a\u4e3a\u4ec0\u4e48\u4f7f\u7528computational graph\uff1f"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/#structure#of#chain-of-calculus","text":"chain-of-calculus\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u4e2aformula\uff0c\u548c\u666e\u901a\u7684math expression\u7c7b\u4f3c\u3002 \u663e\u7136\uff0ccomputational-graph\u5bf9\u4e8e\u5b9e\u73b0back-propagation\u7684\u91cd\u8981\u610f\u4e49\uff0c\u51b3\u5b9a\u4e86tensorflow\u3001torch\u7684\u5e95\u5c42\u90fd\u4f7f\u7528computational graph\u6765\u5b9e\u73b0\u7684\u539f\u56e0\u3002 back-propagation\u662f\u5bf9chain-of-calculus\u7684\u8fd0\u7528\uff0c\u5728","title":"Structure of chain-of-calculus"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/","text":"6.5 Back-Propagation and Other Differentiation Algorithms When we use a feedforward neural network to accept an input x x and produce an output \\hat{y} \\hat{y} , information flows forward through the network. The inputs x x provide the initial information that then propagates up to the hidden units at each layer and finally produces \\hat{y} \\hat{y} . This is called forward propagation . During training, forward propagation can continue onward until it produces a scalar cost J( \\theta ) J( \\theta ) . The back-propagation algorithm ( Rumelhart et al. 1986a ), often simply called backprop , allows the information from the cost to then flow backwards through the network, in order to compute the gradient. Computing an analytical expression for the gradient is straightforward, but numerically evaluating such an expression can be computationally expensive. The back-propagation algorithm does so using a simple and inexpensive procedure. The term back-propagation is often misunderstood as meaning the whole learning algorithm for multi-layer neural networks. Actually, back-propagation refers only to the method for computing the gradient , while another algorithm, such as stochastic gradient descent , is used to perform learning using this gradient . Furthermore, back-propagation is often misunderstood as being specific to multi-layer neural networks, but in principle it can compute derivatives of any function (for some functions, the correct response is to report that the derivative of the function is undefined). Specifically, we will describe how to compute the gradient \\nabla_x {f(x, y)} \\nabla_x {f(x, y)} for an arbitrary function f f , where x x is a set of variables whose derivatives are desired, and y y is an additional set of variables that are inputs to the function but whose derivatives are not required. In learning algorithms, the gradient we most often require is the gradient of the cost function with respect to the parameters , \\nabla_{\\theta} J(\\theta) \\nabla_{\\theta} J(\\theta) . Many machine learning tasks involve computing other derivatives, either as part of the learning process, or to analyze the learned model. The back-propagation algorithm can be applied to these tasks as well, and is not restricted to computing the gradient of the cost function with respect to the parameters . The idea of computing derivatives by propagating information through a network is very general, and can be used to compute values such as the Jacobian of a function f with multiple outputs. We restrict our description here to the most commonly used case where has a single output. 6.5.1 Computational Graphs NOTE: Computational Graph\u662f\u975e\u5e38\u6838\u5fc3\u7684\u6982\u5ff5\uff0c\u540e\u7eed\u7684\u5185\u5bb9\u57fa\u672c\u4e0a\u90fd\u662f\u57fa\u4e8e\u5b83\u7684\uff0c\u5b83\u662f\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u8868\u793a\u65b9\u5f0f\u3002 So far we have discussed neural networks with a relatively informal graph language. To describe the back-propagation algorithm more precisely, it is helpful to have a more precise computational graph language. Many ways of formalizing computation as graphs are possible. Node Here, we use each node in the graph to indicate a variable. The variable may be a scalar, vector, matrix, tensor, or even a variable of another type. Operation NOTE: operation\u7684\u6982\u5ff5\u5341\u5206\u91cd\u8981\uff0c\u57286.5.6 General Back-Propagation\u8fd8\u4f1a\u8bf4\u660eoperation\u3002 To formalize our graphs, we also need to introduce the idea of an operation . An operation is a simple function of one or more variables. Our graph language is accompanied by a set of allowable operations. Functions more complicated than the operations in this set may be described by composing many operations together. Without loss of generality, we define an operation to return only a single output variable. This does not lose generality because the output variable can have multiple entries, such as a vector. Software implementations of back-propagation usually support operations with multiple outputs, but we avoid this case in our description because it introduces many extra details that are not important to conceptual understanding. Construction of computational graph If a variable y y is computed by applying an operation to a variable x x , then we draw a directed edge from x x to y y . We sometimes annotate the output node with the name of the operation applied, and other times omit this label when the operation is clear from context. Examples of computational graphs are shown in figure 6.8. 6.5.2 Chain Rule of Calculus NOTE: \u4f5c\u8005\u5bf9\u672c\u7ae0\u5185\u5bb9\u7684\u7ec4\u7ec7\u662f\u5faa\u5e8f\u6e10\u8fdb\u7684\uff1a\u9996\u5148\u63cf\u8ff0Chain Rule of Calculus\u7684scalar\u5f62\u5f0f\uff0c\u7136\u540e\u63cf\u8ff0\u5b83\u7684vector\u5f62\u5f0f\uff0c\u7136\u540e\u63cf\u8ff0\u5b83\u7684tensor\u5f62\u5f0f\u3002 scalar\u5f62\u5f0f Formula 6.44 vector\u5f62\u5f0f Formula 6.46 tensor\u5f62\u5f0f Formula 6.47 \u57286.5.6 General Back-Propagation\u4e2d\uff0c\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a Tensor can in general have any number of dimensions. They subsume\uff08\u5305\u62ec\uff09 scalars, vectors, and matrices. \u6240\u4ee5\u4f7f\u7528tensor\u7684\u63cf\u8ff0\u662f\u6700\u6700general\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u770b\u5230\uff0c\u672c\u6587\u7684\u6240\u6709algorithm\u3001formula\uff0c\u6700\u7ec8\u90fd\u9700\u8981\u4ee5tensor\u6765\u8fdb\u884c\u63cf\u8ff0\u3002 The chain rule of calculus (not to be confused with the chain rule of probability) is used to compute the derivatives of functions formed by composing other functions whose derivatives are known. Back-propagation is an algorithm that computes the chain rule, with a specific order of operations that is highly efficient. Let x x be a real number, and let f f and g g both be functions mapping from a real number to a real number. Suppose that y = g ( x ) y = g ( x ) and z = f ( g ( x )) = f ( y ) z = f ( g ( x )) = f ( y ) . Then the chain rule states that Formula 6.44 gradient of scalar \\frac {dz} {dx} = \\frac {dz} {dy} \\frac {dy} {dx} \\tag {6.44} \\frac {dz} {dx} = \\frac {dz} {dy} \\frac {dy} {dx} \\tag {6.44} We can generalize this beyond the scalar case. Suppose that \\boldsymbol x \\in \\mathbb R^m \\boldsymbol x \\in \\mathbb R^m , \\boldsymbol y \\in \\mathbb R^n \\boldsymbol y \\in \\mathbb R^n , g g maps from \\mathbb R^m \\mathbb R^m to $ \\mathbb R^n$ , and f f maps from \\mathbb R^n \\mathbb R^n to \\mathbb R \\mathbb R . If \\boldsymbol y = g ( \\boldsymbol x ) \\boldsymbol y = g ( \\boldsymbol x ) and z = f ( \\boldsymbol y ) z = f ( \\boldsymbol y ) , then NOTE: \u9700\u8981\u6ce8\u610f\uff0c\u7c97\u4f53\u8c03\u8bd5\u7684\u662f\u5411\u91cf\uff0c\u6240\u4ee5 z z \u662fscalar\uff0c \\boldsymbol x \\boldsymbol x \u3001 \\boldsymbol y \\boldsymbol y \u662fvector\uff1b Formula 6.45 \\frac {\\partial z} {\\partial x_i} = \\sum_j \\frac {\\partial z} {\\partial y_j} \\frac {\\partial y_j} {\\partial dx_i} \\tag {6.45} \\frac {\\partial z} {\\partial x_i} = \\sum_j \\frac {\\partial z} {\\partial y_j} \\frac {\\partial y_j} {\\partial dx_i} \\tag {6.45} In vector notation, this may be equivalently written as NOTE: \u5f0f 6.45 6.45 \u867d\u7136\u7cbe\u7b80\uff0c\u4f46\u662f\u5185\u6db5\u4e30\u5bcc\uff0c\u8fd9\u4e5f\u4f53\u73b0\u4e86\u6570\u5b66\u516c\u5f0f\u7684expressive\uff0c\u5b83\u6240\u63cf\u8ff0\u7684\u662f\u4e0b\u9762\u7684computational graph\uff1a z z \u53ef\u4ee5\u901a\u8fc7\u6240\u6709\u7684 y y \u5230\u8fbe x_i x_i \uff0c\u6240\u4ee5\u4f7f\u7528 \\sum_j \\sum_j Formula 6.46 gradient of vector {\\displaystyle \\nabla _{x}z=(\\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x})\\nabla_{\\boldsymbol y}\\boldsymbol z.} \\tag {6.46} {\\displaystyle \\nabla _{x}z=(\\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x})\\nabla_{\\boldsymbol y}\\boldsymbol z.} \\tag {6.46} where \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} is the Jacobian matrix of g g . NOTE: \u5f0f(6.45)\u548c\u5f0f(6.46)\uff0c\u53ef\u4ee5\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Chain rule#General rule \u4ece\u5f0f6.45\u5230\u5f0f6.46\u5b58\u5728\u7740\u4e00\u5b9a\u7684\u8df3\u8dc3\u6027\uff1a \u5f0f6.45\u6240\u63cf\u8ff0\u7684\u662fpartial derivative\uff0c\u662fscalar\uff0c\u662f\u5bf9\u67d0\u4e00\u7ef4\u5ea6\u7684 x x ; \u5b83\u7684\u8fd0\u7b97\u662fsum of product\uff1b \u5f0f6.46\u6240\u63cf\u8ff0\u7684\u662fgradient\uff0c\u662fvector\uff0c\u662f\u5bf9\u6240\u6709\u7ef4\u5ea6\u7684 \\boldsymbol x \\boldsymbol x ; \u5b83\u7684\u8fd0\u7b97\u662f\u77e9\u9635\u4e58\u6cd5\uff1b \u53ea\u6709\u6c42\u5f97\u4e86gradient\uff08\u5373 z z \u5bf9\u6bcf\u4e00\u7ef4\u5ea6 x x \u7684partial derivative\uff09\uff0c\u624d\u80fd\u591f\u8fdb\u884cgradient descend\uff1b NOTE: \u5f0f6.45\u548c\u5f0f6.46\u90fd\u662f\u9012\u5f52\u5b9a\u4e49\u3002 \u5bf9\u4e8e\u5f0f6.46\uff0c\u6c42 \\nabla _{x}Z \\nabla _{x}Z \uff0c\u53ef\u4ee5\u8f6c\u6362\u4e3a\u6c42 \\nabla_{\\boldsymbol y}\\boldsymbol z \\nabla_{\\boldsymbol y}\\boldsymbol z \u548c\u4e00\u4e2aJacobian matrix of g g \uff0c\u6211\u4eec\u9700\u8981\u7ed3\u5408computational graph\u6765\u601d\u8003\u5f0f6.46\uff1a\u53f3\u4fa7\u53ef\u4ee5\u770b\u505a\u662f\u6cbf\u7740computational graph\u7684\u8fb9**\u53cd\u5411**\u3001**\u9010\u7ea7**\u4f20\u64ad\u3002 \u5bf9\u4e8e\u5f0f6.45\uff0c\u4e0e\u5f0f6.46\u7c7b\u4f3c NOTE: \u5f0f(6.45)\u6240\u63cf\u8ff0\u7684\u662f z z \u5bf9\u67d0\u4e00\u7ef4\uff0c\u5f0f(6.46)\u6240\u63cf\u8ff0\u7684\u662f\u901a\u7528\u7684\u5f62\u5f0f\uff0c\u5b83\u63cf\u8ff0\u7684\u662f\u6240\u6709\u7684\u7ef4\u5ea6\uff0c\u4ece\u6b64\u53ef\u4ee5\u770b\u51fatensor\u8868\u8ff0\u7684\u5a01\u529b\uff0c\u663e\u7136tensor\u662f\u4e00\u79cd\u66f4\u52a0\u5f3a\u5927\u7684\u8868\u8ff0\u65b9\u5f0f\u3002 From this we see that the gradient of a variable \\boldsymbol x \\boldsymbol x can be obtained by multiplying a Jacobian matrix \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} by a gradient \\nabla _{\\boldsymbol y}z \\nabla _{\\boldsymbol y}z . The back-propagation algorithm consists of performing such a Jacobian-gradient product for each operation in the graph. Usually we do not apply the back-propagation algorithm merely to vectors , but rather to tensors of arbitrary dimensionality. Conceptually, this is exactly the same as back-propagation with vectors. The only difference is how the numbers are arranged in a grid to form a tensor. We could imagine flattening each tensor into a vector before we run back-propagation, computing a vector-valued gradient, and then reshaping the gradient back into a tensor. In this rearranged view, back-propagation is still just multiplying Jacobians by gradients. To denote the gradient of a value z z with respect to a tensor \\rm \\textbf X \\rm \\textbf X , we write \\nabla _{\\rm \\textbf X}z \\nabla _{\\rm \\textbf X}z , just as if \\rm \\textbf X \\rm \\textbf X were a vector. The indices into \\rm \\textbf X \\rm \\textbf X now have multiple coordinates\u2014for example, a 3-D tensor is indexed by three coordinates. We can abstract this away by using a single variable i i to represent the complete tuple of indices. For all possible index tuples i i , ( \\nabla _{\\rm \\textbf X}z )_i ( \\nabla _{\\rm \\textbf X}z )_i gives \\frac {\\partial z} {\\partial \\boldsymbol X_i} \\frac {\\partial z} {\\partial \\boldsymbol X_i} . This is exactly the same as how for all possible integer indices i i into a vector, (\\nabla _{\\boldsymbol x}z)_i (\\nabla _{\\boldsymbol x}z)_i gives \\frac {\\partial z} {\\partial x_i} \\frac {\\partial z} {\\partial x_i} . Using this notation, we can write the chain rule as it applies to tensors. If $ {\\rm \\textbf Y} = g({\\rm \\textbf X})$ and z = f({\\rm \\textbf Y}) z = f({\\rm \\textbf Y}) , then Formula 6.47 gradient of tensor \\nabla_{\\rm \\textbf X}z = \\sum_j (\\nabla_{\\rm \\textbf X} \\boldsymbol Y_j ) \\frac {\\partial z} {\\partial \\boldsymbol Y_j} \\tag {6.47} \\nabla_{\\rm \\textbf X}z = \\sum_j (\\nabla_{\\rm \\textbf X} \\boldsymbol Y_j ) \\frac {\\partial z} {\\partial \\boldsymbol Y_j} \\tag {6.47} NOTE: \u4e0a\u5f0f\u6240\u6c42\u7684\u7ed3\u679c\u662f\u4e00\u4e2atensor\uff0c\u800c\u975e\u4e00\u4e2ascalar\uff0c\u5b83\u7684\u7ef4\u5ea6\u548ctensor \\rm \\textbf X \\rm \\textbf X \u7684\u7ef4\u5ea6\u76f8\u540c\uff1b \\nabla_{\\rm \\textbf X} \\boldsymbol Y_j \\nabla_{\\rm \\textbf X} \\boldsymbol Y_j \u7684\u7ef4\u5ea6\u80af\u5b9a\u548ctensor \\rm \\textbf X \\rm \\textbf X \u7684\u7ef4\u5ea6\u76f8\u540c\uff0c\u6240\u4ee5\u8fd9\u5c31\u51b3\u5b9a\u4e86\u4e0a\u5f0f\u5de6\u53f3\u4e24\u8fb9\u7ef4\u5ea6\u7684\u4e00\u81f4\uff1b\u4e0a\u5f0f\u7684\u8fd0\u884c\u8fc7\u7a0b\u53ef\u4ee5\u8fd9\u6837\u7406\u89e3\uff1a \\textbf Y \\textbf Y \u7684\u6700\u540e\u4e00\u7ef4\u4e3a j j \uff0c\u904d\u5386\u6700\u540e\u4e00\u7ef4\uff0c\u5373\u5bf9\u5e94\u4e0a\u5f0f\u7684 \\sum_j \\sum_j \uff0c \\nabla_{\\rm \\textbf X}z \\nabla_{\\rm \\textbf X}z \u53ef\u4ee5\u770b\u505a z z \u5206\u522b\u901a\u8fc7 \\textbf Y_1 \\to \\textbf Y_j \\textbf Y_1 \\to \\textbf Y_j \u7684\u6240\u6709\u7684partial derivative\u4e4b\u548c\u3002 NOTE: \u4e0a\u8ff0\u5f0f\u5b50\u4ec5\u4ec5\u7ed9\u51fa\u4e86\u975e\u5e38\u7b80\u5355\u7684\u590d\u5408\u51fd\u6570\uff0c\u5b9e\u9645\u7684full-connected network\u8fdc\u6bd4\u5b83\u8981\u590d\u6742\u3002\u6240\u4ee5\u9700\u8981\u4f7f\u7528\u66f4\u52a0\u9ad8\u7ea7\u3001\u66f4\u52a0general\u7684\u63cf\u8ff0\u65b9\u5f0f\uff1a Vector calculus \uff0c\u6240\u6709\u7684\u90fd\u8981\u4ee5 tensor \u4e3a\u5355\u4f4d\uff0c\u4e0e\u6b64\u76f8\u5173\u7684\u6982\u5ff5\u6709\uff1a Jacobian matrix 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop Using the chain rule, it is straightforward to write down an algebraic expression for the gradient of a scalar with respect to any node in the computational graph that produced that scalar. However, actually evaluating that expression in a computer introduces some extra considerations. NOTE: \u5bf9\u4e8eneural network\uff0c\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684scalar\u6240\u6307\u4e3acost Specifically, many subexpressions may be repeated several times within the overall expression for the gradient. Any procedure that computes the gradient will need to choose whether to store these subexpressions or to recompute them several times. An example of how these repeated subexpressions arise is given in figure 6.9. In some cases, computing the same subexpression twice would simply be wasteful. For complicated graphs, there can be exponentially many of these wasted computations, making a naive implementation of the chain rule infeasible. In other cases, computing the same subexpression twice could be a valid way to reduce memory consumption at the cost of higher runtime. NOTE: tradeoff We first begin by a version of the back-propagation algorithm that specifies the actual gradient computation directly (algorithm 6.2 along with algorithm 6.1 for the associated forward computation), in the order it will actually be done and according to the recursive application of chain rule . One could either directly perform these computations or view the description of the algorithm as a symbolic specification of the computational graph for computing the back-propagation. However, this formulation does not make explicit the manipulation and the construction of the symbolic graph that performs the gradient computation . Such a formulation is presented below in section 6.5.6, with algorithm 6.5, where we also generalize to nodes that contain arbitrary tensors. NOTE: \u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u4ece\u8fd9\u6837\u7684\u95ee\u9898\u51fa\u53d1\uff1a\u7ed9\u5b9a\u4e00\u4e2afunction\uff0c\u6211\u4eec\u53ef\u4ee5\u753b\u51fa\u5b83\u7684computational graph\uff0c\u90a3\u5982\u4f55\u6765\u8ba1\u7b97\u5b83\u7684\u68af\u5ea6\u5462\uff1f\u663e\u7136\uff0c\u5bf9\u4e8ecomputer\u800c\u8a00\u7684\uff0c\u6211\u4eec\u9700\u8981\u603b\u7ed3\u51faalgorithm: algorithm 6.2 \u662f\u8ba1\u7b97gradient\u7684algorithm\uff1b\u7b97\u6cd56.1\u662fforward computation\u3002 \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u540e\u9762\u4e24\u6bb5\u662f\u5bf9algorithm 6.2 \u7684\u63cf\u8ff0\uff1a \u6211\u4eec\u53ef\u4ee5\u5c06algorithm 6.2\u770b\u505a\u662f: a symbolic specification of the computational graph for computing the back-propagation algorithm 6.2\u5e76\u6ca1\u6709\u544a\u8bc9\u6211\u4eec: the manipulation and the construction of the symbolic graph that performs the gradient computation . \u201csymbolic graph\u201d\u662f\u4ec0\u4e48\uff1f\u6211\u8ba4\u4e3a\u5b83\u662f\u8ba1\u7b97gradient\u7684computational graph\u3002 First consider a computational graph describing how to compute a single scalar u^{(n)} u^{(n)} (say the loss on a training example). This scalar is the quantity whose gradient we want to obtain, with respect to the n_i n_i input nodes u^{(1)} u^{(1)} to u^{(n_i )} u^{(n_i )} . In other words we wish to compute $ \\frac { \\partial u^{(n)} } { \\partial u^{(i)} }$ for all i \\in \\{ 1 , 2 ,...,n_i \\} i \\in \\{ 1 , 2 ,...,n_i \\} . In the application of back-propagation to computing gradients for gradient descent over parameters, u^{ ( n ) } u^{ ( n ) } will be the cost associated with an example or a minibatch, while u^{(1)} u^{(1)} to u^{(n_i )} u^{(n_i )} correspond to the parameters of the model. We will assume that the nodes of the graph have been ordered in such a way that we can compute their output one after the other, starting at u^{(n_i +1)} u^{(n_i +1)} and going up to u^{n} u^{n} . As defined in algorithm 6.1, each node u ^{( i )} u ^{( i )} is associated with an operation f^{( i )} f^{( i )} and is computed by evaluating the function $$ u^{(i)} = f(\\mathbb A^{(i)}) \\tag {6.48} $$ where \\mathbb A^{( i )} \\mathbb A^{( i )} is the set of all nodes that are parents of u^{(i)} u^{(i)} . NOTE: \u539f\u6587\u4f5c\u8005\u53d8\u91cf\u547d\u540d\u7684\u65b9\u5f0f\u662f\u975e\u5e38\u4e0d\u6613\u61c2\u7684\u3002\u641e\u61c2\u8fd9\u4e9b\u53d8\u91cf\u547d\u540d\u7684\u524d\u63d0\u662f\u4e86\u89e3\u4f5c\u8005\u7684\u547d\u540d\u89c4\u5219\uff1a\u4f5c\u8005\u662f\u4ee5graph\u7684node\u4e3a\u5355\u4f4d\u6765\u8fdb\u884c\u547d\u540d\u7684\uff0c\u5373 n_i n_i \u662f\u5bf9node\u7684\u7f16\u53f7\uff0c u^{(i)} u^{(i)} \u5bf9\u5e94\u7684\u662fnode\u7684output\u3002 \u4e00\u4e2agraph\u662f\u6709input nodes\u7684\uff1a n_i n_i input nodes u^{(1)} u^{(1)} to u^{(n_i )} u^{(n_i )} \uff1b\u663e\u7136input nodes\u7684\u503c\u662f\u53ef\u4ee5\u76f4\u63a5\u83b7\u53d6\u7684\uff1b\u5176\u4ed6\u7684node\u7684output\u662f\u901a\u8fc7\u5f0f (6.48) (6.48) \u8ba1\u7b97\u5f97\u5230\u7684\u3002 \u5f0f(6.48)\u6240\u63cf\u8ff0\u7684\u662f\u524d\u9988\u8fc7\u7a0b\uff0c\u5373 forward propagation computation\uff0c\u5b83\u6240\u63cf\u8ff0\u7684\u662f\u4e00\u4e2anode\u7684\u8ba1\u7b97\u3002 Algorithm 6.1 forward propagation NOTE: \u4e0a\u8ff0\u7b97\u6cd5\u4e2d\uff0c Pa Pa \u662f Parent Parent \u7684\u7f29\u5199\uff1b Pa(u^{(i)}) Pa(u^{(i)}) \u8868\u793a\u8282\u70b9 u^{(i)} u^{(i)} \u7684\u7236\u8282\u70b9\u3002 Algorithm 6.2 back-propagation That algorithm specifies the forward propagation computation , which we could put in a graph \\mathcal{G} \\mathcal{G} . In order to perform back-propagation , we can construct a computational graph that depends on \\mathcal{G} \\mathcal{G} and adds to it an extra set of nodes. These form a subgraph \\mathcal{B} \\mathcal{B} with one node per node of \\mathcal{G} \\mathcal{G} . Computation in \\mathcal{B} \\mathcal{B} proceeds in exactly the reverse of the order of computation in \\mathcal{G} \\mathcal{G} , and each node of \\mathcal{B} \\mathcal{B} computes the derivative \\frac { \\partial u^{(n)} } { \\partial u^{(i)} } \\frac { \\partial u^{(n)} } { \\partial u^{(i)} } associated with the forward graph node u^{(i)} u^{(i)} . This is done using the chain rule with respect to scalar output u ^ { (n) } u ^ { (n) } : NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u63cf\u8ff0\u7684\u5728graph \\mathcal{G} \\mathcal{G} \u4e2d\u6dfb\u52a0 back-propagation \u7684 subgraph \\mathcal{B} \\mathcal{B} \u7684\u601d\u60f3\uff0c\u5728\u201c6.5.5 Symbol-to-Symbol Derivatives\u201d\u8282\u4e2d\u8fd8\u4f1a\u8fdb\u884c\u63cf\u8ff0\uff0c \u901a\u8fc7\u8be5\u7ae0\u8282\u7684\u5b66\u4e60\uff0c\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\uff0c\u8fd9\u79cd\u601d\u60f3\u53eb\u505a\uff1asymbol-to-symbol derivative\u3002 NOTE: \\rm grad\\_table[u^{(n)}] \\leftarrow 1 \\rm grad\\_table[u^{(n)}] \\leftarrow 1 \u8868\u793a\u5c06 node u^{(n)} u^{(n)} \u7684gradient\u521d\u59cb\u5316\u4e3a1\uff1b \u8981\u8ba1\u7b97 \\rm grad\\_table[u^{(j)}] \\rm grad\\_table[u^{(j)}] \u7684\u503c\uff0c\u9700\u8981\u77e5\u9053 u^{(j)} u^{(j)} \u7684\u6240\u6709\u7684\u5b50\u8282\u70b9\uff0c\u5373\u4e0a\u8ff0\u7b97\u6cd5\u4e2d\u7684 u^{(i)} u^{(i)} \uff0c \\rm gra d\\_table[u^{(i)}] \\rm gra d\\_table[u^{(i)}] \u7684\u503c\u5df2\u7ecf\u8ba1\u7b97\u5f97\u5230\uff0c\u56e0\u4e3a\u662f\u65b9\u5411\u662fback\uff08\u4ece\u540e\u5f80\u524d\uff09\uff0c \\frac {u^{(i)}} {u^{(j)}} \\frac {u^{(i)}} {u^{(j)}} \u5176\u5b9e\u53ef\u4ee5\u770b\u505a\u662f u^{(j)} u^{(j)} \u5230 u^{(i)} u^{(i)} \u7684\u8fb9\uff0c\u6709\u4e86\u8fd9\u4e9b\u8ba4\u77e5\uff0c\u5c31\u53ef\u4ee5\u4e0a\u8ff0 for \u5faa\u73af\u7684\u5faa\u73af\u4f53\u4e86\u3002 \u4e0a\u8ff0\u4f7f\u7528 i:j \\in Pa(u^{(i)}) i:j \\in Pa(u^{(i)}) \u6765\u8868\u793a u^{(j)} u^{(j)} \u7684\u6240\u6709\u7684\u5b50\u8282\u70b9\uff0c\u5b83\u7684\u8868\u9762\u610f\u601d\u662f\u4e0d\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u5b83\u7684\u8868\u9762\u610f\u601d\u662f\uff1a j j \u5728 Pa(u^{(i)}) Pa(u^{(i)}) \u4e2d\uff0c\u5f15\u7533\u4e00\u4e0b\u5c31\u662f j j \u662f u^{(i)} u^{(i)} \u7684\u7236\u8282\u70b9\uff1b Back-propagation thus avoids the exponential explosion in repeated subexpressions. However, other algorithms may be able to avoid more subexpressions by performing simplifications on the computational graph, or may be able to conserve memory by recomputing rather than storing some subexpressions. We will revisit these ideas after describing the back-propagation algorithm itself. NOTE: \u5982\u4f55\u6765\u6784\u9020computational graph\u6765\u4f7fcommon subexpression\u79f0\u4e3acommon node in the graph\uff1f\u539f\u4e66\u5e76\u6ca1\u6709\u7ed9\u51faalgorithm\u3002 6.5.4 Back-Propagation Computation in Fully-Connected MLP To clarify the above definition of the back-propagation computation, let us consider the specific graph associated with a fully-connected multi-layer MLP. Algorithm 6.3 first shows the forward propagation , which maps parameters to the supervised loss L( \\hat y, y) L( \\hat y, y) , associated with a single (input,target) training example $(x, y) $ , with \\hat y \\hat y the output of the neural network when is provided in input. Algorithm 6.4 then shows the corresponding computation to be done for applying the back-propagation algorithm to this graph. Algorithms 6.3 and 6.4 are demonstrations that are chosen to be simple and straightforward to understand. However, they are specialized to one specific problem. Modern software implementations are based on the generalized form of back-propagation described in section 6.5.6 below, which can accommodate any computational graph by explicitly manipulating a data structure for representing symbolic computation . Algorithm 6.3 forward propagation NOTE: f f \u662factivation function\u3002 Algorithm 6.4 back-propagation NOTE: \u4e0a\u8ff0\u76f4\u63a5\u4ecealgorithm 6.3\u8fc7\u6e21\u5230algorithm 6.4\uff0c\u4e00\u65f6\u534a\u4f1a\u53ef\u80fd\u65e0\u6cd5\u7406\u89e3\u3002 \u7ef4\u57fa\u767e\u79d1Backpropagation\uff1a Note the distinction: during model evaluation, the weights are fixed, while the inputs vary (and the target output may be unknown), and the network ends with the output layer (it does not include the loss function). During model training, the input\u2013output pair is fixed, while the weights vary, and the network ends with the loss function. algorithm 6.3\u5bf9\u5e94\u7684\u662fmodel evaluation\uff1balgorithm 6.4\u5bf9\u5e94\u7684\u662fmodel training\u3002 Gradient descent algorithm 6.4\u7ed9\u51fa\u7684\u662f\u8ba1\u7b97gradient\u7684algorithm\uff0c\u8981\u5145\u5206\u7406\u89e3\u5b83\uff0c\u6211\u4eec\u9700\u8981\u9996\u5148\u4ece\u76ee\u7684\u51fa\u53d1\u6765\u601d\u8003\uff1a\u4e3a\u4ec0\u4e48\u8981\u8ba1\u7b97gradient\uff1f\u76ee\u7684\u662f\u4f7f\u7528gradient descend algorithm\u6765\u4f7fcost function\u8fbe\u5230\u6781\u503c\uff0c\u4ece\u800c\u201c\u5b66\u4e60\u201d\u5230\u4f7f\u6a21\u578b\u62df\u5408\u6548\u679c\u6700\u4f73\u7684**parameter**\uff1b\u5bf9\u4e8ecost function\u800c\u8a00\uff0c\u5b83\u7684\u81ea\u53d8\u91cf\u662fparameter\uff0c\u5982\u679c\u7528\u6211\u4eec\u5728\u9ad8\u4e2d\u6570\u5b66\u4e2d\u7684\u95ee\u9898\u6765\u7c7b\u6bd4\u7684\u8bdd\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e8c\u6b21\u51fd\u6570 y = a x^2 + b x + c y = a x^2 + b x + c \uff0c\u7ed9\u5b9a a, b, c a, b, c \uff0c\u4e5f\u5c31\u786e\u5b9a\u4e86\u4e00\u4e2a\u4e8c\u6b21\u51fd\u6570\uff0c\u4ee4\u5b83\u7684\u5012\u6570\u4e3a0\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u5b83\u7684\u6781\u503c\u70b9\uff0c\u4ece\u800c\u5f97\u5230 x x \u7684\u503c\uff1b\u4f46\u662f\u5bf9\u4e8eneural model\u800c\u8a00\uff0c\u5b83\u7684cost function\u662f\u975e\u51f8\u7684\uff0c\u6240\u4ee5training\u7684\u8fc7\u7a0b\u662f\u5faa\u5e8f\u6e10\u8fdb\uff08\u4f7f\u7528gradient descend\u9010\u6b65\u66f4\u65b0parameter\u76f4\u5230cost function\u6536\u655b\uff09\uff0c\u800c\u975e\u4e00\u8e74\u800c\u5c31\uff08\u5bf9\u4e8e\u51f8\u51fd\u6570\uff0c\u76f4\u63a5\u4ee4\u5bfc\u6570\u4e3a0\uff0c\u4ece\u800c\u627e\u5230\u6781\u503c\u70b9\uff09\uff1b \u5f53\u6211\u4eec\u51b3\u5b9a\u91c7\u7528\u4e00\u4e2aneural model\uff0c\u6211\u4eec\u4f1a\u786e\u5b9a\u5b83\u7684hyper parameter\uff0c\u4f1ainitialize\u5b83\u7684parameter\uff08\u4e00\u822c\u662f\u4e00\u4e2arandom\u503c\uff09\uff0c\u4f1a\u6307\u5b9a\u5b83\u7684activation function\uff0c\u7b80\u800c\u8a00\u4e4b\uff0c\u4f1a\u5b8c\u5168\u7684\u786e\u5b9a\u4e00\u4e2afunction\uff08model function\uff09\uff0c\u8fdb\u800c\u5b8c\u5168\u5730\u786e\u5b9a\u5bf9\u5e94\u7684cost function\uff1b \u6211\u4eec\u9996\u5148\u6267\u884cforward propagation\uff08evaluation\u7684\u8fc7\u7a0b\uff09\uff0c\u6211\u4eec\u91c7\u7528algorithm 6.3\uff0c\u8fdb\u800c\u8ba1\u7b97\u5f97\u5230cost function\u7684\u503c\uff1b \u7136\u540e\u6267\u884cback-propagation\uff08training\u7684\u8fc7\u7a0b\uff09\uff0c\u6211\u4eec\u9996\u5148\u8981\u8ba1\u7b97\u5f97\u5230cost function\u5728\u67d0\u70b9\u7684gradient\uff08\u7ecf\u8fc7\u4e0a\u9762\u7684\u5206\u6790\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86\uff0c\u6b64\u65f6\u7684cost function\u662f\u56fa\u5b9a\u7684\uff0c\u901a\u8fc7\u5bf9\u4e8e\u7ed9\u5b9aexample\uff0c\u6211\u4eec\u662f\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u5b83\u7684\u5bf9\u5e94\u7684cost function\u7684\u4e00\u4e2a\u70b9\u7684\uff09\uff0c\u7531\u4e8ecost function\u5df2\u77e5\uff0c\u6240\u4ee5\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528**\u94fe\u5f0f\u6cd5\u5219**\u8ba1\u7b97\u5f97\u5230gradient\u7684\u503c\uff0c\u7136\u540e\u7528\u8ba1\u7b97\u5f97\u5230\u7684gradient\u6765\u66f4\u65b0cost function\u7684\u81ea\u53d8\u91cf\u5373model function\u7684parameter\u7684\u503c\uff0c\u663e\u7136\u6211\u4eec\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u671f\u671bcost function\u8d70\u5411\u4e00\u4e2a\u6781\u503c\u70b9\u3002 \u6309\u7167\u4e0a\u8ff0\u8fc7\u7a0b\u5faa\u73af\u5f80\u590d\uff0c\u77e5\u9053cost function\u6536\u655b\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a\u5728training\u8fc7\u7a0b\u4e2d\uff0c\u6574\u4e2a\u6837\u672c\u6570\u636e\u662f\u4f1a\u5212\u5206\u4e3a\u5404\u4e2abatch\u7684\uff0c\u7136\u540e\u9010\u4e2abatch\u3001\u9010\u4e2abatch\u5730feed\u5230model\u4e2d\uff0c\u6bcf\u4e2abatch\u7684\u8bad\u7ec3\u4e2d\uff0c\u91c7\u7528\u7684\u4e0d\u662f\u540c\u4e00\u4e2acost function\uff08\u4f46\u662f\u662f\u540c\u4e00\u7c7b\u578b\u7684\uff09\uff0c\u5728\u6bcf\u4e2abatch\u4e2d\uff0c\u90fd\u4f1a\u66f4\u65b0\u4e00\u6b21parameter\uff0c\u5e76\u4e14\u6bcf\u4e2abatch\u7684\u6570\u636e\u4e5f\u4e0d\u540c\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u5305\u542b\u4e86\u975e\u5e38\u591a\u7684\u566a\u58f0\u7684\u6570\u636e\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u9519\u8bef\u7684\u66f4\u65b0\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6536\u655b\uff0c\u65e0\u6cd5\u62df\u5408\uff0c\u6240\u4ee5\u8fd9\u5c31\u9700\u8981\u91c7\u7528\u66f4\u52a0\u9ad8\u7ea7\u7684\u4f18\u5316\u7b97\u6cd5\u3001\u91c7\u7528\u6b63\u5219\u5316\u3002 NOTE: \u5bf9\u6bd4\u601d\u8003\uff1a Algorithm 6.1 and algorithm 6.3 Algorithm 6.2 and algorithm 6.4 \u4e24\u8005\u63cf\u8ff0\u7684\u90fd\u662fback-propagation\u3002 algorithm 6.4\u91c7\u7528\u7684\u8fd8\u662f\u201c\u9010\u5c42\u5265\u79bb\u201d\uff08rewrite\uff09\u7684\u601d\u8def\uff0c\u9996\u5148\u6c42\u5916\u5c42 \\nabla_{a^{(i)}} J \\nabla_{a^{(i)}} J \uff0c\u518d\u6c42\u5185\u5c42\uff1a \\nabla_{b^{(k)}} J \\nabla_{b^{(k)}} J \u3001 \\nabla_{W^{(i)}} J \\nabla_{W^{(i)}} J \uff0c\u56e0\u4e3a\u4e24\u8005\u90fd\u662f a^{(i)} a^{(i)} \u7684\u51fd\u6570\u3002 6.5.5 Symbol-to-Symbol Derivatives Algebraic expressions and computational graphs both operate on symbols , or variables that do not have specific values. These algebraic and graph-based representations are called symbolic representations . When we actually use or train a neural network, we must assign specific values to these symbols. We replace a symbolic input to the network x x with a specific numeric value, such as [1.2,3.765,-1.8] [1.2,3.765,-1.8] . NOTE: symbolic representation\u662f\u4e00\u79cd\u62bd\u8c61\uff0c\u6b63\u5982algebraic expression\u4e5f\u662f\u5982\u6b64\uff1b\u5728\u6570\u5b66\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u51fd\u6570\u8868\u8fbe\u5f0f\u5c31\u662f\u4e0a\u8ff0algebraic expression\uff0c\u5373\u201c\u4ee3\u6570\u8868\u8fbe\u5f0f\u201d\uff1b\u4e0a\u8ff0\u201csymbolic\u201d\u5373\u201c\u7b26\u53f7\u201d\uff0c\u5b83\u5176\u5b9e\u7c7b\u4f3c\u4e8e variable\u3002 Some approaches to back-propagation take a computational graph and a set of numerical values for the inputs to the graph\uff08the graph\u6240\u6307\u4ee3\u7684\u662f\u524d\u9762\u6240\u8bf4\u7684computational graph\uff09, then return a set of numerical values describing the gradient at those input values. We call this approach \u201c symbol-to-number \u201d differentiation. This is the approach used by libraries such as Torch( Collobert et al. , 2011b ) and Caffe (Jia, 2013). Another approach is to take a computational graph and add additional nodes to the graph that provide a symbolic description of the desired derivatives. This is the approach taken by Theano (Bergstra et al. 2010 Bastien et al. 2012 ) and TensorFlow ( Abadi et al. 2015 ). An example of how this approach works is illustrated in figure 6.10. The primary advantage of this approach is that the derivatives are described in the same language as the original expression. Because the derivatives are just another computational graph, it is possible to run back-propagation again, differentiating the derivatives in order to obtain higher derivatives. Computation of higher-order derivatives is described in section 6.5.10. NOTE: \u5173\u4e8etensorflow\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u53ef\u4ee5\u53c2\u89c1 tensorflow white paper \uff0c\u5176\u4e2d\u5bf9\u8fd9\u4e2a\u95ee\u9898\u8fdb\u884c\u4e86\u4e13\u95e8\u7684\u63cf\u8ff0\u3002 We will use the latter approach and describe the back-propagation algorithm in terms of constructing a computational graph for the derivatives. Any subset of the graph may then be evaluated using specific numerical values at a later time. This allows us to avoid specifying exactly when each operation should be computed. Instead, a generic graph evaluation engine can evaluate every node as soon as its parents\u2019 values are available. The description of the symbol-to-symbol based approach subsumes\uff08\u5305\u62ec\uff09 the symbol-to-number approach. The symbol-to-number approach can be understood as performing exactly the same computations as are done in the graph built by the symbol-to-symbol approach. The key difference is that the symbol-to-number approach does not expose the graph. 6.5.6 General Back-Propagation Unformal description of back-propagation algorithm The back-propagation algorithm is very simple. To compute the gradient of some scalar z z with respect to one of its ancestors x x in the graph, we begin by observing that the gradient with respect to z z is given by \\frac {dz} {dz} = 1 \\frac {dz} {dz} = 1 . We can then compute the gradient with respect to each parent of z z in the graph by multiplying the current gradient by the Jacobian of the operation that produced z z . We continue multiplying by Jacobians traveling backwards through the graph in this way until we reach x x . For any node that may be reached by going backwards from z z through two or more paths, we simply sum the gradients arriving from different paths at that node. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u5bf9computational graph\u4e2d\uff0c\u901a\u8fc7back-propagation\u6765\u5b9e\u73b0chain of calculus\u7684\u5f62\u8c61\u5316\u603b\u7ed3\uff0c\u5b83\u548c\u5728 Formal description of back-propagation algorithm More formally, each node in the graph \\mathcal {G} \\mathcal {G} corresponds to a variable. To achieve maximum generality, we describe this variable as being a tensor \\rm \\textbf{V} \\rm \\textbf{V} . Tensor can in general have any number of dimensions. They subsume\uff08\u5305\u62ec\uff09 scalars, vectors, and matrices. We assume that each variable \\rm \\textbf{V} \\rm \\textbf{V} is associated with the following subroutines: subroutine explanation \u6ce8\u89e3 \\rm get\\_operation( \\textbf{V}) \\rm get\\_operation( \\textbf{V}) This returns the operation that computes \\rm \\textbf{V} \\rm \\textbf{V} , represented by the edges coming into \\rm \\textbf{V} \\rm \\textbf{V} in the computational graph. For example, there may be a Python or C++ class representing the matrix multiplication operation , and the get_operation function. Suppose we have a variable that is created by matrix multiplication, C = AB C = AB . Then \\rm get\\_operation( \\textbf{V}) \\rm get\\_operation( \\textbf{V}) returns a pointer to an instance of the corresponding C++ class. operation\u63cf\u8ff0\u4e86computational graph\u7684node\u4e4b\u95f4\u7684\u51fd\u6570\u5173\u7cfb\uff0c\u6bd4\u5982\u5728computational graph\u4e2d\uff0c C = AB C = AB \u5bf9\u5e94\u7684graph\u4e2d\uff0c A A \u3001 B B \u662f C C \u7684parent node\uff0c\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfbmatrix multiplication\u3002 \\rm get\\_consumers( \\textbf{V}, \\mathcal {G}) \\rm get\\_consumers( \\textbf{V}, \\mathcal {G}) This returns the list of variables that are children of \\rm \\textbf{V} \\rm \\textbf{V} in the computational graph \\mathcal {G} \\mathcal {G} . \\rm get\\_inputs( \\textbf{V}, \\mathcal {G}) \\rm get\\_inputs( \\textbf{V}, \\mathcal {G}) This returns the list of variables that are parents of \\rm \\textbf{V} \\rm \\textbf{V} in the computational graph \\mathcal {G} \\mathcal {G} . NOTE: \u9700\u8981\u7ed3\u5408computational graph\u6765\u7406\u89e3\u4e0a\u8ff0\u5185\u5bb9\uff0c6.5.1 Computational Graphs\u4e2d\u63cf\u8ff0\u4e86computational graph\u7684\u5185\u5bb9\uff0c\u4e0a\u8ff0\u4e09\u4e2a\u51fd\u6570\u9700\u8981\u548c\u5b83\u7ed3\u5408\u4e00\u8d77\u9605\u8bfb\u3002 Operation and \\rm bprop \\rm bprop operation Each operation \\rm op \\rm op is also associated with a \\rm bprop \\rm bprop operation. This \\rm bprop \\rm bprop operation can compute a Jacobian-vector product as described by equation 6.47. This is how the back-propagation algorithm is able to achieve great generality. Each operation is responsible for knowing how to back-propagate through the edges in the graph that it participates in. For example, we might use a matrix multiplication operation to create a variable $C = AB $. Suppose that the gradient of a scalar z z with respect to C C is given by G G . The matrix multiplication operation is responsible for defining two back-propagation rules, one for each of its input arguments. If we call the \\rm bprop \\rm bprop method to request the gradient with respect to A A given that the gradient on the output is G G , then the $ \\rm bprop$ method of the matrix multiplication operation must state that the gradient with respect to A A is given by $G B^\\mathrm{T} $ . Likewise, if we call the $ \\rm bprop$ method to request the gradient with respect to B B , then the matrix operation is responsible for implementing the $ \\rm bprop$ method and specifying that the desired gradient is given by A^\\mathrm{T} G A^\\mathrm{T} G . The back-propagation algorithm itself does not need to know any differentiation rules. It only needs to call each operation\u2019s \\rm bprop \\rm bprop rules with the right arguments. Formally, $ \\rm op.bprop(inputs, \\textbf X, \\textbf G)$ must return Formula 6.54 \\rm op.bprop \\rm op.bprop \\rm \\sum_i { (\\nabla_{\\textbf X} op.f(inputs)_i) \\mathbf G_i} \\tag {6.54} \\rm \\sum_i { (\\nabla_{\\textbf X} op.f(inputs)_i) \\mathbf G_i} \\tag {6.54} \u4e3a\u4fbf\u4e8e\u7406\u89e3\uff0c\u5bf9\u6bd4\u6765\u9605\u8bfb\uff1a $$ \\nabla_{\\rm \\textbf X}z = \\sum_j (\\nabla_{\\rm \\textbf X} \\boldsymbol Y_i ) \\frac {\\partial z} {\\partial \\boldsymbol Y_j} \\tag {6.47} $$ which is just an implementation of the chain rule as expressed in equation 6.47. Here, \\rm inputs \\rm inputs is a list of inputs that are supplied to the operation , \\rm op.f \\rm op.f is the mathematical function that the operation implements, \\textbf X \\textbf X is the input whose gradient we wish to compute, and \\textbf G \\textbf G is the gradient on the output of the operation. The \\rm op.bprop \\rm op.bprop method should always pretend that all of its inputs are distinct from each other, even if they are not. For example, if the \\rm mul \\rm mul operator is passed two copies of x x to compute x^2 x^2 , the \\rm op.bprop \\rm op.bprop method should still return x x as the derivative with respect to both inputs. The back-propagation algorithm will later add both of these arguments together to obtain 2 x 2 x , which is the correct total derivative on x x . Software implementations of back-propagation usually provide both the operations and their \\rm bprop \\rm bprop methods, so that users of deep learning software libraries are able to back-propagate through graphs built using common operations like matrix multiplication, exponents, logarithms, and so on. Software engineers who build a new implementation of back-propagation or advanced users who need to add their own operation to an existing library must usually derive the \\rm op.bprop \\rm op.bprop method for any new operations manually. The back-propagation algorithm is formally described in algorithm 6.5. Algorithm 6.5 back-propagation The back-propagation algorithm is formally described in algorithm 6.5. Algorithm 6.6 build_grad In section 6.5.2, we explained that back-propagation was developed in order to avoid computing the same subexpression in the chain rule multiple times. The naive algorithm could have exponential runtime due to these repeated subexpressions. Now that we have specified the back-propagation algorithm, we can understand its computational cost. If we assume that each operation evaluation has roughly the same cost, then we may analyze the computational cost in terms of the number of operations executed. Keep in mind here that we refer to an operation as the fundamental unit of our computational graph, which might actually consist of very many arithmetic operations (for example, we might have a graph that treats matrix multiplication as a single operation). Computing a gradient in a graph with n n nodes will never execute more than O ( n^2 ) O ( n^2 ) operations or store the output of more than O ( n^2 ) O ( n^2 ) operations. Here we are counting operations in the computational graph, not individual operations executed by the underlying hardware, so it is important to remember that the runtime of each operation may be highly variable. For example, multiplying two matrices that each contain millions of entries might correspond to a single operation in the graph. We can see that computing the gradient requires as most O ( n^2 ) O ( n^2 ) operations because the forward propagation stage will at worst execute all n n nodes in the original graph (depending on which values we want to compute, we may not need to execute the entire graph). The back-propagation algorithm adds one Jacobian-vector product, which should be expressed with O (1) O (1) nodes, per edge in the original graph. Because the computational graph is a directed acyclic graph it has at most O ( n^2 ) O ( n^2 ) edges. For the kinds of graphs that are commonly used in practice, the situation is even better. Most neural network cost functions are roughly chain-structured , causing back-propagation to have O ( n ) O ( n ) cost. This is far better than the naive approach, which might need to execute exponentially many nodes. This potentially exponential cost can be seen by expanding and rewriting the recursive chain rule (equation ) non-recursively: This table-filling strategy is sometimes called dynamic programming . 6.5.7 Example: Back-Propagation for MLP Training 6.5.8 Complications 6.5.9 Differentiation outside the Deep Learning Community automatic differentiation reverse mode accumulation\uff1a https://rufflewind.com/2016-12-30/reverse-mode-automatic-differentiation https://stats.stackexchange.com/questions/224140/step-by-step-example-of-reverse-mode-automatic-differentiation","title":"6.5-Back-Propagation-and-Other-Differentiation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#65#back-propagation#and#other#differentiation#algorithms","text":"When we use a feedforward neural network to accept an input x x and produce an output \\hat{y} \\hat{y} , information flows forward through the network. The inputs x x provide the initial information that then propagates up to the hidden units at each layer and finally produces \\hat{y} \\hat{y} . This is called forward propagation . During training, forward propagation can continue onward until it produces a scalar cost J( \\theta ) J( \\theta ) . The back-propagation algorithm ( Rumelhart et al. 1986a ), often simply called backprop , allows the information from the cost to then flow backwards through the network, in order to compute the gradient. Computing an analytical expression for the gradient is straightforward, but numerically evaluating such an expression can be computationally expensive. The back-propagation algorithm does so using a simple and inexpensive procedure. The term back-propagation is often misunderstood as meaning the whole learning algorithm for multi-layer neural networks. Actually, back-propagation refers only to the method for computing the gradient , while another algorithm, such as stochastic gradient descent , is used to perform learning using this gradient . Furthermore, back-propagation is often misunderstood as being specific to multi-layer neural networks, but in principle it can compute derivatives of any function (for some functions, the correct response is to report that the derivative of the function is undefined). Specifically, we will describe how to compute the gradient \\nabla_x {f(x, y)} \\nabla_x {f(x, y)} for an arbitrary function f f , where x x is a set of variables whose derivatives are desired, and y y is an additional set of variables that are inputs to the function but whose derivatives are not required. In learning algorithms, the gradient we most often require is the gradient of the cost function with respect to the parameters , \\nabla_{\\theta} J(\\theta) \\nabla_{\\theta} J(\\theta) . Many machine learning tasks involve computing other derivatives, either as part of the learning process, or to analyze the learned model. The back-propagation algorithm can be applied to these tasks as well, and is not restricted to computing the gradient of the cost function with respect to the parameters . The idea of computing derivatives by propagating information through a network is very general, and can be used to compute values such as the Jacobian of a function f with multiple outputs. We restrict our description here to the most commonly used case where has a single output.","title":"6.5 Back-Propagation and Other Differentiation Algorithms"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#651#computational#graphs","text":"NOTE: Computational Graph\u662f\u975e\u5e38\u6838\u5fc3\u7684\u6982\u5ff5\uff0c\u540e\u7eed\u7684\u5185\u5bb9\u57fa\u672c\u4e0a\u90fd\u662f\u57fa\u4e8e\u5b83\u7684\uff0c\u5b83\u662f\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u8868\u793a\u65b9\u5f0f\u3002 So far we have discussed neural networks with a relatively informal graph language. To describe the back-propagation algorithm more precisely, it is helpful to have a more precise computational graph language. Many ways of formalizing computation as graphs are possible.","title":"6.5.1 Computational Graphs"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#node","text":"Here, we use each node in the graph to indicate a variable. The variable may be a scalar, vector, matrix, tensor, or even a variable of another type.","title":"Node"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#operation","text":"NOTE: operation\u7684\u6982\u5ff5\u5341\u5206\u91cd\u8981\uff0c\u57286.5.6 General Back-Propagation\u8fd8\u4f1a\u8bf4\u660eoperation\u3002 To formalize our graphs, we also need to introduce the idea of an operation . An operation is a simple function of one or more variables. Our graph language is accompanied by a set of allowable operations. Functions more complicated than the operations in this set may be described by composing many operations together. Without loss of generality, we define an operation to return only a single output variable. This does not lose generality because the output variable can have multiple entries, such as a vector. Software implementations of back-propagation usually support operations with multiple outputs, but we avoid this case in our description because it introduces many extra details that are not important to conceptual understanding.","title":"Operation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#construction#of#computational#graph","text":"If a variable y y is computed by applying an operation to a variable x x , then we draw a directed edge from x x to y y . We sometimes annotate the output node with the name of the operation applied, and other times omit this label when the operation is clear from context. Examples of computational graphs are shown in figure 6.8.","title":"Construction of computational graph"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#652#chain#rule#of#calculus","text":"NOTE: \u4f5c\u8005\u5bf9\u672c\u7ae0\u5185\u5bb9\u7684\u7ec4\u7ec7\u662f\u5faa\u5e8f\u6e10\u8fdb\u7684\uff1a\u9996\u5148\u63cf\u8ff0Chain Rule of Calculus\u7684scalar\u5f62\u5f0f\uff0c\u7136\u540e\u63cf\u8ff0\u5b83\u7684vector\u5f62\u5f0f\uff0c\u7136\u540e\u63cf\u8ff0\u5b83\u7684tensor\u5f62\u5f0f\u3002 scalar\u5f62\u5f0f Formula 6.44 vector\u5f62\u5f0f Formula 6.46 tensor\u5f62\u5f0f Formula 6.47 \u57286.5.6 General Back-Propagation\u4e2d\uff0c\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a Tensor can in general have any number of dimensions. They subsume\uff08\u5305\u62ec\uff09 scalars, vectors, and matrices. \u6240\u4ee5\u4f7f\u7528tensor\u7684\u63cf\u8ff0\u662f\u6700\u6700general\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u770b\u5230\uff0c\u672c\u6587\u7684\u6240\u6709algorithm\u3001formula\uff0c\u6700\u7ec8\u90fd\u9700\u8981\u4ee5tensor\u6765\u8fdb\u884c\u63cf\u8ff0\u3002 The chain rule of calculus (not to be confused with the chain rule of probability) is used to compute the derivatives of functions formed by composing other functions whose derivatives are known. Back-propagation is an algorithm that computes the chain rule, with a specific order of operations that is highly efficient. Let x x be a real number, and let f f and g g both be functions mapping from a real number to a real number. Suppose that y = g ( x ) y = g ( x ) and z = f ( g ( x )) = f ( y ) z = f ( g ( x )) = f ( y ) . Then the chain rule states that","title":"6.5.2 Chain Rule of Calculus"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#formula#644#gradient#of#scalar","text":"\\frac {dz} {dx} = \\frac {dz} {dy} \\frac {dy} {dx} \\tag {6.44} \\frac {dz} {dx} = \\frac {dz} {dy} \\frac {dy} {dx} \\tag {6.44} We can generalize this beyond the scalar case. Suppose that \\boldsymbol x \\in \\mathbb R^m \\boldsymbol x \\in \\mathbb R^m , \\boldsymbol y \\in \\mathbb R^n \\boldsymbol y \\in \\mathbb R^n , g g maps from \\mathbb R^m \\mathbb R^m to $ \\mathbb R^n$ , and f f maps from \\mathbb R^n \\mathbb R^n to \\mathbb R \\mathbb R . If \\boldsymbol y = g ( \\boldsymbol x ) \\boldsymbol y = g ( \\boldsymbol x ) and z = f ( \\boldsymbol y ) z = f ( \\boldsymbol y ) , then NOTE: \u9700\u8981\u6ce8\u610f\uff0c\u7c97\u4f53\u8c03\u8bd5\u7684\u662f\u5411\u91cf\uff0c\u6240\u4ee5 z z \u662fscalar\uff0c \\boldsymbol x \\boldsymbol x \u3001 \\boldsymbol y \\boldsymbol y \u662fvector\uff1b","title":"Formula 6.44 gradient of scalar"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#formula#645","text":"\\frac {\\partial z} {\\partial x_i} = \\sum_j \\frac {\\partial z} {\\partial y_j} \\frac {\\partial y_j} {\\partial dx_i} \\tag {6.45} \\frac {\\partial z} {\\partial x_i} = \\sum_j \\frac {\\partial z} {\\partial y_j} \\frac {\\partial y_j} {\\partial dx_i} \\tag {6.45} In vector notation, this may be equivalently written as NOTE: \u5f0f 6.45 6.45 \u867d\u7136\u7cbe\u7b80\uff0c\u4f46\u662f\u5185\u6db5\u4e30\u5bcc\uff0c\u8fd9\u4e5f\u4f53\u73b0\u4e86\u6570\u5b66\u516c\u5f0f\u7684expressive\uff0c\u5b83\u6240\u63cf\u8ff0\u7684\u662f\u4e0b\u9762\u7684computational graph\uff1a z z \u53ef\u4ee5\u901a\u8fc7\u6240\u6709\u7684 y y \u5230\u8fbe x_i x_i \uff0c\u6240\u4ee5\u4f7f\u7528 \\sum_j \\sum_j","title":"Formula 6.45"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#formula#646#gradient#of#vector","text":"{\\displaystyle \\nabla _{x}z=(\\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x})\\nabla_{\\boldsymbol y}\\boldsymbol z.} \\tag {6.46} {\\displaystyle \\nabla _{x}z=(\\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x})\\nabla_{\\boldsymbol y}\\boldsymbol z.} \\tag {6.46} where \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} is the Jacobian matrix of g g . NOTE: \u5f0f(6.45)\u548c\u5f0f(6.46)\uff0c\u53ef\u4ee5\u53c2\u89c1\u7ef4\u57fa\u767e\u79d1 Chain rule#General rule \u4ece\u5f0f6.45\u5230\u5f0f6.46\u5b58\u5728\u7740\u4e00\u5b9a\u7684\u8df3\u8dc3\u6027\uff1a \u5f0f6.45\u6240\u63cf\u8ff0\u7684\u662fpartial derivative\uff0c\u662fscalar\uff0c\u662f\u5bf9\u67d0\u4e00\u7ef4\u5ea6\u7684 x x ; \u5b83\u7684\u8fd0\u7b97\u662fsum of product\uff1b \u5f0f6.46\u6240\u63cf\u8ff0\u7684\u662fgradient\uff0c\u662fvector\uff0c\u662f\u5bf9\u6240\u6709\u7ef4\u5ea6\u7684 \\boldsymbol x \\boldsymbol x ; \u5b83\u7684\u8fd0\u7b97\u662f\u77e9\u9635\u4e58\u6cd5\uff1b \u53ea\u6709\u6c42\u5f97\u4e86gradient\uff08\u5373 z z \u5bf9\u6bcf\u4e00\u7ef4\u5ea6 x x \u7684partial derivative\uff09\uff0c\u624d\u80fd\u591f\u8fdb\u884cgradient descend\uff1b NOTE: \u5f0f6.45\u548c\u5f0f6.46\u90fd\u662f\u9012\u5f52\u5b9a\u4e49\u3002 \u5bf9\u4e8e\u5f0f6.46\uff0c\u6c42 \\nabla _{x}Z \\nabla _{x}Z \uff0c\u53ef\u4ee5\u8f6c\u6362\u4e3a\u6c42 \\nabla_{\\boldsymbol y}\\boldsymbol z \\nabla_{\\boldsymbol y}\\boldsymbol z \u548c\u4e00\u4e2aJacobian matrix of g g \uff0c\u6211\u4eec\u9700\u8981\u7ed3\u5408computational graph\u6765\u601d\u8003\u5f0f6.46\uff1a\u53f3\u4fa7\u53ef\u4ee5\u770b\u505a\u662f\u6cbf\u7740computational graph\u7684\u8fb9**\u53cd\u5411**\u3001**\u9010\u7ea7**\u4f20\u64ad\u3002 \u5bf9\u4e8e\u5f0f6.45\uff0c\u4e0e\u5f0f6.46\u7c7b\u4f3c NOTE: \u5f0f(6.45)\u6240\u63cf\u8ff0\u7684\u662f z z \u5bf9\u67d0\u4e00\u7ef4\uff0c\u5f0f(6.46)\u6240\u63cf\u8ff0\u7684\u662f\u901a\u7528\u7684\u5f62\u5f0f\uff0c\u5b83\u63cf\u8ff0\u7684\u662f\u6240\u6709\u7684\u7ef4\u5ea6\uff0c\u4ece\u6b64\u53ef\u4ee5\u770b\u51fatensor\u8868\u8ff0\u7684\u5a01\u529b\uff0c\u663e\u7136tensor\u662f\u4e00\u79cd\u66f4\u52a0\u5f3a\u5927\u7684\u8868\u8ff0\u65b9\u5f0f\u3002 From this we see that the gradient of a variable \\boldsymbol x \\boldsymbol x can be obtained by multiplying a Jacobian matrix \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} \\frac {\\partial \\boldsymbol y} {\\partial \\boldsymbol x} by a gradient \\nabla _{\\boldsymbol y}z \\nabla _{\\boldsymbol y}z . The back-propagation algorithm consists of performing such a Jacobian-gradient product for each operation in the graph. Usually we do not apply the back-propagation algorithm merely to vectors , but rather to tensors of arbitrary dimensionality. Conceptually, this is exactly the same as back-propagation with vectors. The only difference is how the numbers are arranged in a grid to form a tensor. We could imagine flattening each tensor into a vector before we run back-propagation, computing a vector-valued gradient, and then reshaping the gradient back into a tensor. In this rearranged view, back-propagation is still just multiplying Jacobians by gradients. To denote the gradient of a value z z with respect to a tensor \\rm \\textbf X \\rm \\textbf X , we write \\nabla _{\\rm \\textbf X}z \\nabla _{\\rm \\textbf X}z , just as if \\rm \\textbf X \\rm \\textbf X were a vector. The indices into \\rm \\textbf X \\rm \\textbf X now have multiple coordinates\u2014for example, a 3-D tensor is indexed by three coordinates. We can abstract this away by using a single variable i i to represent the complete tuple of indices. For all possible index tuples i i , ( \\nabla _{\\rm \\textbf X}z )_i ( \\nabla _{\\rm \\textbf X}z )_i gives \\frac {\\partial z} {\\partial \\boldsymbol X_i} \\frac {\\partial z} {\\partial \\boldsymbol X_i} . This is exactly the same as how for all possible integer indices i i into a vector, (\\nabla _{\\boldsymbol x}z)_i (\\nabla _{\\boldsymbol x}z)_i gives \\frac {\\partial z} {\\partial x_i} \\frac {\\partial z} {\\partial x_i} . Using this notation, we can write the chain rule as it applies to tensors. If $ {\\rm \\textbf Y} = g({\\rm \\textbf X})$ and z = f({\\rm \\textbf Y}) z = f({\\rm \\textbf Y}) , then","title":"Formula 6.46 gradient of vector"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#formula#647#gradient#of#tensor","text":"\\nabla_{\\rm \\textbf X}z = \\sum_j (\\nabla_{\\rm \\textbf X} \\boldsymbol Y_j ) \\frac {\\partial z} {\\partial \\boldsymbol Y_j} \\tag {6.47} \\nabla_{\\rm \\textbf X}z = \\sum_j (\\nabla_{\\rm \\textbf X} \\boldsymbol Y_j ) \\frac {\\partial z} {\\partial \\boldsymbol Y_j} \\tag {6.47} NOTE: \u4e0a\u5f0f\u6240\u6c42\u7684\u7ed3\u679c\u662f\u4e00\u4e2atensor\uff0c\u800c\u975e\u4e00\u4e2ascalar\uff0c\u5b83\u7684\u7ef4\u5ea6\u548ctensor \\rm \\textbf X \\rm \\textbf X \u7684\u7ef4\u5ea6\u76f8\u540c\uff1b \\nabla_{\\rm \\textbf X} \\boldsymbol Y_j \\nabla_{\\rm \\textbf X} \\boldsymbol Y_j \u7684\u7ef4\u5ea6\u80af\u5b9a\u548ctensor \\rm \\textbf X \\rm \\textbf X \u7684\u7ef4\u5ea6\u76f8\u540c\uff0c\u6240\u4ee5\u8fd9\u5c31\u51b3\u5b9a\u4e86\u4e0a\u5f0f\u5de6\u53f3\u4e24\u8fb9\u7ef4\u5ea6\u7684\u4e00\u81f4\uff1b\u4e0a\u5f0f\u7684\u8fd0\u884c\u8fc7\u7a0b\u53ef\u4ee5\u8fd9\u6837\u7406\u89e3\uff1a \\textbf Y \\textbf Y \u7684\u6700\u540e\u4e00\u7ef4\u4e3a j j \uff0c\u904d\u5386\u6700\u540e\u4e00\u7ef4\uff0c\u5373\u5bf9\u5e94\u4e0a\u5f0f\u7684 \\sum_j \\sum_j \uff0c \\nabla_{\\rm \\textbf X}z \\nabla_{\\rm \\textbf X}z \u53ef\u4ee5\u770b\u505a z z \u5206\u522b\u901a\u8fc7 \\textbf Y_1 \\to \\textbf Y_j \\textbf Y_1 \\to \\textbf Y_j \u7684\u6240\u6709\u7684partial derivative\u4e4b\u548c\u3002 NOTE: \u4e0a\u8ff0\u5f0f\u5b50\u4ec5\u4ec5\u7ed9\u51fa\u4e86\u975e\u5e38\u7b80\u5355\u7684\u590d\u5408\u51fd\u6570\uff0c\u5b9e\u9645\u7684full-connected network\u8fdc\u6bd4\u5b83\u8981\u590d\u6742\u3002\u6240\u4ee5\u9700\u8981\u4f7f\u7528\u66f4\u52a0\u9ad8\u7ea7\u3001\u66f4\u52a0general\u7684\u63cf\u8ff0\u65b9\u5f0f\uff1a Vector calculus \uff0c\u6240\u6709\u7684\u90fd\u8981\u4ee5 tensor \u4e3a\u5355\u4f4d\uff0c\u4e0e\u6b64\u76f8\u5173\u7684\u6982\u5ff5\u6709\uff1a Jacobian matrix","title":"Formula 6.47 gradient of tensor"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#653#recursively#applying#the#chain#rule#to#obtain#backprop","text":"Using the chain rule, it is straightforward to write down an algebraic expression for the gradient of a scalar with respect to any node in the computational graph that produced that scalar. However, actually evaluating that expression in a computer introduces some extra considerations. NOTE: \u5bf9\u4e8eneural network\uff0c\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u7684scalar\u6240\u6307\u4e3acost Specifically, many subexpressions may be repeated several times within the overall expression for the gradient. Any procedure that computes the gradient will need to choose whether to store these subexpressions or to recompute them several times. An example of how these repeated subexpressions arise is given in figure 6.9. In some cases, computing the same subexpression twice would simply be wasteful. For complicated graphs, there can be exponentially many of these wasted computations, making a naive implementation of the chain rule infeasible. In other cases, computing the same subexpression twice could be a valid way to reduce memory consumption at the cost of higher runtime. NOTE: tradeoff We first begin by a version of the back-propagation algorithm that specifies the actual gradient computation directly (algorithm 6.2 along with algorithm 6.1 for the associated forward computation), in the order it will actually be done and according to the recursive application of chain rule . One could either directly perform these computations or view the description of the algorithm as a symbolic specification of the computational graph for computing the back-propagation. However, this formulation does not make explicit the manipulation and the construction of the symbolic graph that performs the gradient computation . Such a formulation is presented below in section 6.5.6, with algorithm 6.5, where we also generalize to nodes that contain arbitrary tensors. NOTE: \u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u53ef\u4ee5\u4ece\u8fd9\u6837\u7684\u95ee\u9898\u51fa\u53d1\uff1a\u7ed9\u5b9a\u4e00\u4e2afunction\uff0c\u6211\u4eec\u53ef\u4ee5\u753b\u51fa\u5b83\u7684computational graph\uff0c\u90a3\u5982\u4f55\u6765\u8ba1\u7b97\u5b83\u7684\u68af\u5ea6\u5462\uff1f\u663e\u7136\uff0c\u5bf9\u4e8ecomputer\u800c\u8a00\u7684\uff0c\u6211\u4eec\u9700\u8981\u603b\u7ed3\u51faalgorithm: algorithm 6.2 \u662f\u8ba1\u7b97gradient\u7684algorithm\uff1b\u7b97\u6cd56.1\u662fforward computation\u3002 \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u540e\u9762\u4e24\u6bb5\u662f\u5bf9algorithm 6.2 \u7684\u63cf\u8ff0\uff1a \u6211\u4eec\u53ef\u4ee5\u5c06algorithm 6.2\u770b\u505a\u662f: a symbolic specification of the computational graph for computing the back-propagation algorithm 6.2\u5e76\u6ca1\u6709\u544a\u8bc9\u6211\u4eec: the manipulation and the construction of the symbolic graph that performs the gradient computation . \u201csymbolic graph\u201d\u662f\u4ec0\u4e48\uff1f\u6211\u8ba4\u4e3a\u5b83\u662f\u8ba1\u7b97gradient\u7684computational graph\u3002 First consider a computational graph describing how to compute a single scalar u^{(n)} u^{(n)} (say the loss on a training example). This scalar is the quantity whose gradient we want to obtain, with respect to the n_i n_i input nodes u^{(1)} u^{(1)} to u^{(n_i )} u^{(n_i )} . In other words we wish to compute $ \\frac { \\partial u^{(n)} } { \\partial u^{(i)} }$ for all i \\in \\{ 1 , 2 ,...,n_i \\} i \\in \\{ 1 , 2 ,...,n_i \\} . In the application of back-propagation to computing gradients for gradient descent over parameters, u^{ ( n ) } u^{ ( n ) } will be the cost associated with an example or a minibatch, while u^{(1)} u^{(1)} to u^{(n_i )} u^{(n_i )} correspond to the parameters of the model. We will assume that the nodes of the graph have been ordered in such a way that we can compute their output one after the other, starting at u^{(n_i +1)} u^{(n_i +1)} and going up to u^{n} u^{n} . As defined in algorithm 6.1, each node u ^{( i )} u ^{( i )} is associated with an operation f^{( i )} f^{( i )} and is computed by evaluating the function $$ u^{(i)} = f(\\mathbb A^{(i)}) \\tag {6.48} $$ where \\mathbb A^{( i )} \\mathbb A^{( i )} is the set of all nodes that are parents of u^{(i)} u^{(i)} . NOTE: \u539f\u6587\u4f5c\u8005\u53d8\u91cf\u547d\u540d\u7684\u65b9\u5f0f\u662f\u975e\u5e38\u4e0d\u6613\u61c2\u7684\u3002\u641e\u61c2\u8fd9\u4e9b\u53d8\u91cf\u547d\u540d\u7684\u524d\u63d0\u662f\u4e86\u89e3\u4f5c\u8005\u7684\u547d\u540d\u89c4\u5219\uff1a\u4f5c\u8005\u662f\u4ee5graph\u7684node\u4e3a\u5355\u4f4d\u6765\u8fdb\u884c\u547d\u540d\u7684\uff0c\u5373 n_i n_i \u662f\u5bf9node\u7684\u7f16\u53f7\uff0c u^{(i)} u^{(i)} \u5bf9\u5e94\u7684\u662fnode\u7684output\u3002 \u4e00\u4e2agraph\u662f\u6709input nodes\u7684\uff1a n_i n_i input nodes u^{(1)} u^{(1)} to u^{(n_i )} u^{(n_i )} \uff1b\u663e\u7136input nodes\u7684\u503c\u662f\u53ef\u4ee5\u76f4\u63a5\u83b7\u53d6\u7684\uff1b\u5176\u4ed6\u7684node\u7684output\u662f\u901a\u8fc7\u5f0f (6.48) (6.48) \u8ba1\u7b97\u5f97\u5230\u7684\u3002 \u5f0f(6.48)\u6240\u63cf\u8ff0\u7684\u662f\u524d\u9988\u8fc7\u7a0b\uff0c\u5373 forward propagation computation\uff0c\u5b83\u6240\u63cf\u8ff0\u7684\u662f\u4e00\u4e2anode\u7684\u8ba1\u7b97\u3002","title":"6.5.3 Recursively Applying the Chain Rule to Obtain Backprop"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#61#forward#propagation","text":"NOTE: \u4e0a\u8ff0\u7b97\u6cd5\u4e2d\uff0c Pa Pa \u662f Parent Parent \u7684\u7f29\u5199\uff1b Pa(u^{(i)}) Pa(u^{(i)}) \u8868\u793a\u8282\u70b9 u^{(i)} u^{(i)} \u7684\u7236\u8282\u70b9\u3002","title":"Algorithm 6.1 forward propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#62#back-propagation","text":"That algorithm specifies the forward propagation computation , which we could put in a graph \\mathcal{G} \\mathcal{G} . In order to perform back-propagation , we can construct a computational graph that depends on \\mathcal{G} \\mathcal{G} and adds to it an extra set of nodes. These form a subgraph \\mathcal{B} \\mathcal{B} with one node per node of \\mathcal{G} \\mathcal{G} . Computation in \\mathcal{B} \\mathcal{B} proceeds in exactly the reverse of the order of computation in \\mathcal{G} \\mathcal{G} , and each node of \\mathcal{B} \\mathcal{B} computes the derivative \\frac { \\partial u^{(n)} } { \\partial u^{(i)} } \\frac { \\partial u^{(n)} } { \\partial u^{(i)} } associated with the forward graph node u^{(i)} u^{(i)} . This is done using the chain rule with respect to scalar output u ^ { (n) } u ^ { (n) } : NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u4e2d\u63cf\u8ff0\u7684\u5728graph \\mathcal{G} \\mathcal{G} \u4e2d\u6dfb\u52a0 back-propagation \u7684 subgraph \\mathcal{B} \\mathcal{B} \u7684\u601d\u60f3\uff0c\u5728\u201c6.5.5 Symbol-to-Symbol Derivatives\u201d\u8282\u4e2d\u8fd8\u4f1a\u8fdb\u884c\u63cf\u8ff0\uff0c \u901a\u8fc7\u8be5\u7ae0\u8282\u7684\u5b66\u4e60\uff0c\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\uff0c\u8fd9\u79cd\u601d\u60f3\u53eb\u505a\uff1asymbol-to-symbol derivative\u3002 NOTE: \\rm grad\\_table[u^{(n)}] \\leftarrow 1 \\rm grad\\_table[u^{(n)}] \\leftarrow 1 \u8868\u793a\u5c06 node u^{(n)} u^{(n)} \u7684gradient\u521d\u59cb\u5316\u4e3a1\uff1b \u8981\u8ba1\u7b97 \\rm grad\\_table[u^{(j)}] \\rm grad\\_table[u^{(j)}] \u7684\u503c\uff0c\u9700\u8981\u77e5\u9053 u^{(j)} u^{(j)} \u7684\u6240\u6709\u7684\u5b50\u8282\u70b9\uff0c\u5373\u4e0a\u8ff0\u7b97\u6cd5\u4e2d\u7684 u^{(i)} u^{(i)} \uff0c \\rm gra d\\_table[u^{(i)}] \\rm gra d\\_table[u^{(i)}] \u7684\u503c\u5df2\u7ecf\u8ba1\u7b97\u5f97\u5230\uff0c\u56e0\u4e3a\u662f\u65b9\u5411\u662fback\uff08\u4ece\u540e\u5f80\u524d\uff09\uff0c \\frac {u^{(i)}} {u^{(j)}} \\frac {u^{(i)}} {u^{(j)}} \u5176\u5b9e\u53ef\u4ee5\u770b\u505a\u662f u^{(j)} u^{(j)} \u5230 u^{(i)} u^{(i)} \u7684\u8fb9\uff0c\u6709\u4e86\u8fd9\u4e9b\u8ba4\u77e5\uff0c\u5c31\u53ef\u4ee5\u4e0a\u8ff0 for \u5faa\u73af\u7684\u5faa\u73af\u4f53\u4e86\u3002 \u4e0a\u8ff0\u4f7f\u7528 i:j \\in Pa(u^{(i)}) i:j \\in Pa(u^{(i)}) \u6765\u8868\u793a u^{(j)} u^{(j)} \u7684\u6240\u6709\u7684\u5b50\u8282\u70b9\uff0c\u5b83\u7684\u8868\u9762\u610f\u601d\u662f\u4e0d\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u5b83\u7684\u8868\u9762\u610f\u601d\u662f\uff1a j j \u5728 Pa(u^{(i)}) Pa(u^{(i)}) \u4e2d\uff0c\u5f15\u7533\u4e00\u4e0b\u5c31\u662f j j \u662f u^{(i)} u^{(i)} \u7684\u7236\u8282\u70b9\uff1b Back-propagation thus avoids the exponential explosion in repeated subexpressions. However, other algorithms may be able to avoid more subexpressions by performing simplifications on the computational graph, or may be able to conserve memory by recomputing rather than storing some subexpressions. We will revisit these ideas after describing the back-propagation algorithm itself. NOTE: \u5982\u4f55\u6765\u6784\u9020computational graph\u6765\u4f7fcommon subexpression\u79f0\u4e3acommon node in the graph\uff1f\u539f\u4e66\u5e76\u6ca1\u6709\u7ed9\u51faalgorithm\u3002","title":"Algorithm 6.2 back-propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#654#back-propagation#computation#in#fully-connected#mlp","text":"To clarify the above definition of the back-propagation computation, let us consider the specific graph associated with a fully-connected multi-layer MLP. Algorithm 6.3 first shows the forward propagation , which maps parameters to the supervised loss L( \\hat y, y) L( \\hat y, y) , associated with a single (input,target) training example $(x, y) $ , with \\hat y \\hat y the output of the neural network when is provided in input. Algorithm 6.4 then shows the corresponding computation to be done for applying the back-propagation algorithm to this graph. Algorithms 6.3 and 6.4 are demonstrations that are chosen to be simple and straightforward to understand. However, they are specialized to one specific problem. Modern software implementations are based on the generalized form of back-propagation described in section 6.5.6 below, which can accommodate any computational graph by explicitly manipulating a data structure for representing symbolic computation .","title":"6.5.4 Back-Propagation Computation in Fully-Connected MLP"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#63#forward#propagation","text":"NOTE: f f \u662factivation function\u3002","title":"Algorithm 6.3 forward propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#64#back-propagation","text":"NOTE: \u4e0a\u8ff0\u76f4\u63a5\u4ecealgorithm 6.3\u8fc7\u6e21\u5230algorithm 6.4\uff0c\u4e00\u65f6\u534a\u4f1a\u53ef\u80fd\u65e0\u6cd5\u7406\u89e3\u3002 \u7ef4\u57fa\u767e\u79d1Backpropagation\uff1a Note the distinction: during model evaluation, the weights are fixed, while the inputs vary (and the target output may be unknown), and the network ends with the output layer (it does not include the loss function). During model training, the input\u2013output pair is fixed, while the weights vary, and the network ends with the loss function. algorithm 6.3\u5bf9\u5e94\u7684\u662fmodel evaluation\uff1balgorithm 6.4\u5bf9\u5e94\u7684\u662fmodel training\u3002","title":"Algorithm 6.4 back-propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#gradient#descent","text":"algorithm 6.4\u7ed9\u51fa\u7684\u662f\u8ba1\u7b97gradient\u7684algorithm\uff0c\u8981\u5145\u5206\u7406\u89e3\u5b83\uff0c\u6211\u4eec\u9700\u8981\u9996\u5148\u4ece\u76ee\u7684\u51fa\u53d1\u6765\u601d\u8003\uff1a\u4e3a\u4ec0\u4e48\u8981\u8ba1\u7b97gradient\uff1f\u76ee\u7684\u662f\u4f7f\u7528gradient descend algorithm\u6765\u4f7fcost function\u8fbe\u5230\u6781\u503c\uff0c\u4ece\u800c\u201c\u5b66\u4e60\u201d\u5230\u4f7f\u6a21\u578b\u62df\u5408\u6548\u679c\u6700\u4f73\u7684**parameter**\uff1b\u5bf9\u4e8ecost function\u800c\u8a00\uff0c\u5b83\u7684\u81ea\u53d8\u91cf\u662fparameter\uff0c\u5982\u679c\u7528\u6211\u4eec\u5728\u9ad8\u4e2d\u6570\u5b66\u4e2d\u7684\u95ee\u9898\u6765\u7c7b\u6bd4\u7684\u8bdd\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e8c\u6b21\u51fd\u6570 y = a x^2 + b x + c y = a x^2 + b x + c \uff0c\u7ed9\u5b9a a, b, c a, b, c \uff0c\u4e5f\u5c31\u786e\u5b9a\u4e86\u4e00\u4e2a\u4e8c\u6b21\u51fd\u6570\uff0c\u4ee4\u5b83\u7684\u5012\u6570\u4e3a0\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u5b83\u7684\u6781\u503c\u70b9\uff0c\u4ece\u800c\u5f97\u5230 x x \u7684\u503c\uff1b\u4f46\u662f\u5bf9\u4e8eneural model\u800c\u8a00\uff0c\u5b83\u7684cost function\u662f\u975e\u51f8\u7684\uff0c\u6240\u4ee5training\u7684\u8fc7\u7a0b\u662f\u5faa\u5e8f\u6e10\u8fdb\uff08\u4f7f\u7528gradient descend\u9010\u6b65\u66f4\u65b0parameter\u76f4\u5230cost function\u6536\u655b\uff09\uff0c\u800c\u975e\u4e00\u8e74\u800c\u5c31\uff08\u5bf9\u4e8e\u51f8\u51fd\u6570\uff0c\u76f4\u63a5\u4ee4\u5bfc\u6570\u4e3a0\uff0c\u4ece\u800c\u627e\u5230\u6781\u503c\u70b9\uff09\uff1b \u5f53\u6211\u4eec\u51b3\u5b9a\u91c7\u7528\u4e00\u4e2aneural model\uff0c\u6211\u4eec\u4f1a\u786e\u5b9a\u5b83\u7684hyper parameter\uff0c\u4f1ainitialize\u5b83\u7684parameter\uff08\u4e00\u822c\u662f\u4e00\u4e2arandom\u503c\uff09\uff0c\u4f1a\u6307\u5b9a\u5b83\u7684activation function\uff0c\u7b80\u800c\u8a00\u4e4b\uff0c\u4f1a\u5b8c\u5168\u7684\u786e\u5b9a\u4e00\u4e2afunction\uff08model function\uff09\uff0c\u8fdb\u800c\u5b8c\u5168\u5730\u786e\u5b9a\u5bf9\u5e94\u7684cost function\uff1b \u6211\u4eec\u9996\u5148\u6267\u884cforward propagation\uff08evaluation\u7684\u8fc7\u7a0b\uff09\uff0c\u6211\u4eec\u91c7\u7528algorithm 6.3\uff0c\u8fdb\u800c\u8ba1\u7b97\u5f97\u5230cost function\u7684\u503c\uff1b \u7136\u540e\u6267\u884cback-propagation\uff08training\u7684\u8fc7\u7a0b\uff09\uff0c\u6211\u4eec\u9996\u5148\u8981\u8ba1\u7b97\u5f97\u5230cost function\u5728\u67d0\u70b9\u7684gradient\uff08\u7ecf\u8fc7\u4e0a\u9762\u7684\u5206\u6790\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e86\uff0c\u6b64\u65f6\u7684cost function\u662f\u56fa\u5b9a\u7684\uff0c\u901a\u8fc7\u5bf9\u4e8e\u7ed9\u5b9aexample\uff0c\u6211\u4eec\u662f\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u5b83\u7684\u5bf9\u5e94\u7684cost function\u7684\u4e00\u4e2a\u70b9\u7684\uff09\uff0c\u7531\u4e8ecost function\u5df2\u77e5\uff0c\u6240\u4ee5\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528**\u94fe\u5f0f\u6cd5\u5219**\u8ba1\u7b97\u5f97\u5230gradient\u7684\u503c\uff0c\u7136\u540e\u7528\u8ba1\u7b97\u5f97\u5230\u7684gradient\u6765\u66f4\u65b0cost function\u7684\u81ea\u53d8\u91cf\u5373model function\u7684parameter\u7684\u503c\uff0c\u663e\u7136\u6211\u4eec\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u671f\u671bcost function\u8d70\u5411\u4e00\u4e2a\u6781\u503c\u70b9\u3002 \u6309\u7167\u4e0a\u8ff0\u8fc7\u7a0b\u5faa\u73af\u5f80\u590d\uff0c\u77e5\u9053cost function\u6536\u655b\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a\u5728training\u8fc7\u7a0b\u4e2d\uff0c\u6574\u4e2a\u6837\u672c\u6570\u636e\u662f\u4f1a\u5212\u5206\u4e3a\u5404\u4e2abatch\u7684\uff0c\u7136\u540e\u9010\u4e2abatch\u3001\u9010\u4e2abatch\u5730feed\u5230model\u4e2d\uff0c\u6bcf\u4e2abatch\u7684\u8bad\u7ec3\u4e2d\uff0c\u91c7\u7528\u7684\u4e0d\u662f\u540c\u4e00\u4e2acost function\uff08\u4f46\u662f\u662f\u540c\u4e00\u7c7b\u578b\u7684\uff09\uff0c\u5728\u6bcf\u4e2abatch\u4e2d\uff0c\u90fd\u4f1a\u66f4\u65b0\u4e00\u6b21parameter\uff0c\u5e76\u4e14\u6bcf\u4e2abatch\u7684\u6570\u636e\u4e5f\u4e0d\u540c\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u5305\u542b\u4e86\u975e\u5e38\u591a\u7684\u566a\u58f0\u7684\u6570\u636e\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u9519\u8bef\u7684\u66f4\u65b0\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6536\u655b\uff0c\u65e0\u6cd5\u62df\u5408\uff0c\u6240\u4ee5\u8fd9\u5c31\u9700\u8981\u91c7\u7528\u66f4\u52a0\u9ad8\u7ea7\u7684\u4f18\u5316\u7b97\u6cd5\u3001\u91c7\u7528\u6b63\u5219\u5316\u3002 NOTE: \u5bf9\u6bd4\u601d\u8003\uff1a","title":"Gradient descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#61#and#algorithm#63","text":"","title":"Algorithm 6.1 and algorithm 6.3"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#62#and#algorithm#64","text":"\u4e24\u8005\u63cf\u8ff0\u7684\u90fd\u662fback-propagation\u3002 algorithm 6.4\u91c7\u7528\u7684\u8fd8\u662f\u201c\u9010\u5c42\u5265\u79bb\u201d\uff08rewrite\uff09\u7684\u601d\u8def\uff0c\u9996\u5148\u6c42\u5916\u5c42 \\nabla_{a^{(i)}} J \\nabla_{a^{(i)}} J \uff0c\u518d\u6c42\u5185\u5c42\uff1a \\nabla_{b^{(k)}} J \\nabla_{b^{(k)}} J \u3001 \\nabla_{W^{(i)}} J \\nabla_{W^{(i)}} J \uff0c\u56e0\u4e3a\u4e24\u8005\u90fd\u662f a^{(i)} a^{(i)} \u7684\u51fd\u6570\u3002","title":"Algorithm 6.2 and algorithm 6.4"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#655#symbol-to-symbol#derivatives","text":"Algebraic expressions and computational graphs both operate on symbols , or variables that do not have specific values. These algebraic and graph-based representations are called symbolic representations . When we actually use or train a neural network, we must assign specific values to these symbols. We replace a symbolic input to the network x x with a specific numeric value, such as [1.2,3.765,-1.8] [1.2,3.765,-1.8] . NOTE: symbolic representation\u662f\u4e00\u79cd\u62bd\u8c61\uff0c\u6b63\u5982algebraic expression\u4e5f\u662f\u5982\u6b64\uff1b\u5728\u6570\u5b66\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u51fd\u6570\u8868\u8fbe\u5f0f\u5c31\u662f\u4e0a\u8ff0algebraic expression\uff0c\u5373\u201c\u4ee3\u6570\u8868\u8fbe\u5f0f\u201d\uff1b\u4e0a\u8ff0\u201csymbolic\u201d\u5373\u201c\u7b26\u53f7\u201d\uff0c\u5b83\u5176\u5b9e\u7c7b\u4f3c\u4e8e variable\u3002 Some approaches to back-propagation take a computational graph and a set of numerical values for the inputs to the graph\uff08the graph\u6240\u6307\u4ee3\u7684\u662f\u524d\u9762\u6240\u8bf4\u7684computational graph\uff09, then return a set of numerical values describing the gradient at those input values. We call this approach \u201c symbol-to-number \u201d differentiation. This is the approach used by libraries such as Torch( Collobert et al. , 2011b ) and Caffe (Jia, 2013). Another approach is to take a computational graph and add additional nodes to the graph that provide a symbolic description of the desired derivatives. This is the approach taken by Theano (Bergstra et al. 2010 Bastien et al. 2012 ) and TensorFlow ( Abadi et al. 2015 ). An example of how this approach works is illustrated in figure 6.10. The primary advantage of this approach is that the derivatives are described in the same language as the original expression. Because the derivatives are just another computational graph, it is possible to run back-propagation again, differentiating the derivatives in order to obtain higher derivatives. Computation of higher-order derivatives is described in section 6.5.10. NOTE: \u5173\u4e8etensorflow\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u53ef\u4ee5\u53c2\u89c1 tensorflow white paper \uff0c\u5176\u4e2d\u5bf9\u8fd9\u4e2a\u95ee\u9898\u8fdb\u884c\u4e86\u4e13\u95e8\u7684\u63cf\u8ff0\u3002 We will use the latter approach and describe the back-propagation algorithm in terms of constructing a computational graph for the derivatives. Any subset of the graph may then be evaluated using specific numerical values at a later time. This allows us to avoid specifying exactly when each operation should be computed. Instead, a generic graph evaluation engine can evaluate every node as soon as its parents\u2019 values are available. The description of the symbol-to-symbol based approach subsumes\uff08\u5305\u62ec\uff09 the symbol-to-number approach. The symbol-to-number approach can be understood as performing exactly the same computations as are done in the graph built by the symbol-to-symbol approach. The key difference is that the symbol-to-number approach does not expose the graph.","title":"6.5.5 Symbol-to-Symbol Derivatives"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#656#general#back-propagation","text":"","title":"6.5.6 General Back-Propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#unformal#description#of#back-propagation#algorithm","text":"The back-propagation algorithm is very simple. To compute the gradient of some scalar z z with respect to one of its ancestors x x in the graph, we begin by observing that the gradient with respect to z z is given by \\frac {dz} {dz} = 1 \\frac {dz} {dz} = 1 . We can then compute the gradient with respect to each parent of z z in the graph by multiplying the current gradient by the Jacobian of the operation that produced z z . We continue multiplying by Jacobians traveling backwards through the graph in this way until we reach x x . For any node that may be reached by going backwards from z z through two or more paths, we simply sum the gradients arriving from different paths at that node. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u5bf9computational graph\u4e2d\uff0c\u901a\u8fc7back-propagation\u6765\u5b9e\u73b0chain of calculus\u7684\u5f62\u8c61\u5316\u603b\u7ed3\uff0c\u5b83\u548c\u5728","title":"Unformal description of back-propagation algorithm"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#formal#description#of#back-propagation#algorithm","text":"More formally, each node in the graph \\mathcal {G} \\mathcal {G} corresponds to a variable. To achieve maximum generality, we describe this variable as being a tensor \\rm \\textbf{V} \\rm \\textbf{V} . Tensor can in general have any number of dimensions. They subsume\uff08\u5305\u62ec\uff09 scalars, vectors, and matrices. We assume that each variable \\rm \\textbf{V} \\rm \\textbf{V} is associated with the following subroutines: subroutine explanation \u6ce8\u89e3 \\rm get\\_operation( \\textbf{V}) \\rm get\\_operation( \\textbf{V}) This returns the operation that computes \\rm \\textbf{V} \\rm \\textbf{V} , represented by the edges coming into \\rm \\textbf{V} \\rm \\textbf{V} in the computational graph. For example, there may be a Python or C++ class representing the matrix multiplication operation , and the get_operation function. Suppose we have a variable that is created by matrix multiplication, C = AB C = AB . Then \\rm get\\_operation( \\textbf{V}) \\rm get\\_operation( \\textbf{V}) returns a pointer to an instance of the corresponding C++ class. operation\u63cf\u8ff0\u4e86computational graph\u7684node\u4e4b\u95f4\u7684\u51fd\u6570\u5173\u7cfb\uff0c\u6bd4\u5982\u5728computational graph\u4e2d\uff0c C = AB C = AB \u5bf9\u5e94\u7684graph\u4e2d\uff0c A A \u3001 B B \u662f C C \u7684parent node\uff0c\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfbmatrix multiplication\u3002 \\rm get\\_consumers( \\textbf{V}, \\mathcal {G}) \\rm get\\_consumers( \\textbf{V}, \\mathcal {G}) This returns the list of variables that are children of \\rm \\textbf{V} \\rm \\textbf{V} in the computational graph \\mathcal {G} \\mathcal {G} . \\rm get\\_inputs( \\textbf{V}, \\mathcal {G}) \\rm get\\_inputs( \\textbf{V}, \\mathcal {G}) This returns the list of variables that are parents of \\rm \\textbf{V} \\rm \\textbf{V} in the computational graph \\mathcal {G} \\mathcal {G} . NOTE: \u9700\u8981\u7ed3\u5408computational graph\u6765\u7406\u89e3\u4e0a\u8ff0\u5185\u5bb9\uff0c6.5.1 Computational Graphs\u4e2d\u63cf\u8ff0\u4e86computational graph\u7684\u5185\u5bb9\uff0c\u4e0a\u8ff0\u4e09\u4e2a\u51fd\u6570\u9700\u8981\u548c\u5b83\u7ed3\u5408\u4e00\u8d77\u9605\u8bfb\u3002","title":"Formal description of back-propagation algorithm"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#operation#and#rm#bproprm#bprop#operation","text":"Each operation \\rm op \\rm op is also associated with a \\rm bprop \\rm bprop operation. This \\rm bprop \\rm bprop operation can compute a Jacobian-vector product as described by equation 6.47. This is how the back-propagation algorithm is able to achieve great generality. Each operation is responsible for knowing how to back-propagate through the edges in the graph that it participates in. For example, we might use a matrix multiplication operation to create a variable $C = AB $. Suppose that the gradient of a scalar z z with respect to C C is given by G G . The matrix multiplication operation is responsible for defining two back-propagation rules, one for each of its input arguments. If we call the \\rm bprop \\rm bprop method to request the gradient with respect to A A given that the gradient on the output is G G , then the $ \\rm bprop$ method of the matrix multiplication operation must state that the gradient with respect to A A is given by $G B^\\mathrm{T} $ . Likewise, if we call the $ \\rm bprop$ method to request the gradient with respect to B B , then the matrix operation is responsible for implementing the $ \\rm bprop$ method and specifying that the desired gradient is given by A^\\mathrm{T} G A^\\mathrm{T} G . The back-propagation algorithm itself does not need to know any differentiation rules. It only needs to call each operation\u2019s \\rm bprop \\rm bprop rules with the right arguments. Formally, $ \\rm op.bprop(inputs, \\textbf X, \\textbf G)$ must return","title":"Operation and \\rm bprop\\rm bprop operation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#formula#654#rm#opbproprm#opbprop","text":"\\rm \\sum_i { (\\nabla_{\\textbf X} op.f(inputs)_i) \\mathbf G_i} \\tag {6.54} \\rm \\sum_i { (\\nabla_{\\textbf X} op.f(inputs)_i) \\mathbf G_i} \\tag {6.54} \u4e3a\u4fbf\u4e8e\u7406\u89e3\uff0c\u5bf9\u6bd4\u6765\u9605\u8bfb\uff1a $$ \\nabla_{\\rm \\textbf X}z = \\sum_j (\\nabla_{\\rm \\textbf X} \\boldsymbol Y_i ) \\frac {\\partial z} {\\partial \\boldsymbol Y_j} \\tag {6.47} $$ which is just an implementation of the chain rule as expressed in equation 6.47. Here, \\rm inputs \\rm inputs is a list of inputs that are supplied to the operation , \\rm op.f \\rm op.f is the mathematical function that the operation implements, \\textbf X \\textbf X is the input whose gradient we wish to compute, and \\textbf G \\textbf G is the gradient on the output of the operation. The \\rm op.bprop \\rm op.bprop method should always pretend that all of its inputs are distinct from each other, even if they are not. For example, if the \\rm mul \\rm mul operator is passed two copies of x x to compute x^2 x^2 , the \\rm op.bprop \\rm op.bprop method should still return x x as the derivative with respect to both inputs. The back-propagation algorithm will later add both of these arguments together to obtain 2 x 2 x , which is the correct total derivative on x x . Software implementations of back-propagation usually provide both the operations and their \\rm bprop \\rm bprop methods, so that users of deep learning software libraries are able to back-propagate through graphs built using common operations like matrix multiplication, exponents, logarithms, and so on. Software engineers who build a new implementation of back-propagation or advanced users who need to add their own operation to an existing library must usually derive the \\rm op.bprop \\rm op.bprop method for any new operations manually. The back-propagation algorithm is formally described in algorithm 6.5.","title":"Formula 6.54 \\rm op.bprop\\rm op.bprop"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#65#back-propagation","text":"The back-propagation algorithm is formally described in algorithm 6.5.","title":"Algorithm 6.5 back-propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#algorithm#66#build_grad","text":"In section 6.5.2, we explained that back-propagation was developed in order to avoid computing the same subexpression in the chain rule multiple times. The naive algorithm could have exponential runtime due to these repeated subexpressions. Now that we have specified the back-propagation algorithm, we can understand its computational cost. If we assume that each operation evaluation has roughly the same cost, then we may analyze the computational cost in terms of the number of operations executed. Keep in mind here that we refer to an operation as the fundamental unit of our computational graph, which might actually consist of very many arithmetic operations (for example, we might have a graph that treats matrix multiplication as a single operation). Computing a gradient in a graph with n n nodes will never execute more than O ( n^2 ) O ( n^2 ) operations or store the output of more than O ( n^2 ) O ( n^2 ) operations. Here we are counting operations in the computational graph, not individual operations executed by the underlying hardware, so it is important to remember that the runtime of each operation may be highly variable. For example, multiplying two matrices that each contain millions of entries might correspond to a single operation in the graph. We can see that computing the gradient requires as most O ( n^2 ) O ( n^2 ) operations because the forward propagation stage will at worst execute all n n nodes in the original graph (depending on which values we want to compute, we may not need to execute the entire graph). The back-propagation algorithm adds one Jacobian-vector product, which should be expressed with O (1) O (1) nodes, per edge in the original graph. Because the computational graph is a directed acyclic graph it has at most O ( n^2 ) O ( n^2 ) edges. For the kinds of graphs that are commonly used in practice, the situation is even better. Most neural network cost functions are roughly chain-structured , causing back-propagation to have O ( n ) O ( n ) cost. This is far better than the naive approach, which might need to execute exponentially many nodes. This potentially exponential cost can be seen by expanding and rewriting the recursive chain rule (equation ) non-recursively: This table-filling strategy is sometimes called dynamic programming .","title":"Algorithm 6.6 build_grad"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#657#example#back-propagation#for#mlp#training","text":"","title":"6.5.7 Example: Back-Propagation for MLP Training"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#658#complications","text":"","title":"6.5.8 Complications"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/6.5-Back-Propagation-and-Other-Differentiation/#659#differentiation#outside#the#deep#learning#community","text":"automatic differentiation reverse mode accumulation\uff1a https://rufflewind.com/2016-12-30/reverse-mode-automatic-differentiation https://stats.stackexchange.com/questions/224140/step-by-step-example-of-reverse-mode-automatic-differentiation","title":"6.5.9 Differentiation outside the Deep Learning Community"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Backpropagation-through-time/","text":"Backpropagation through time","title":"Backpropagation-through-time"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Backpropagation-through-time/#backpropagation#through#time","text":"","title":"Backpropagation through time"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Implementation/","text":"How to Code a Neural Network with Backpropagation In Python The backpropagation algorithm is used in the classical feed-forward\uff08\u524d\u9988\u7684\uff09 artificial neural network. It is the technique still used to train large deep learning networks. In this tutorial, you will discover how to implement the backpropagation algorithm for a neural network from scratch with Python. After completing this tutorial, you will know: How to forward-propagate an input to calculate an output. How to back-propagate error and train a network. How to apply the backpropagation algorithm to a real-world predictive modeling problem. SUMMARY : forward-propagate\u548cback-Propagate Discover how to code ML algorithms from scratch including kNN , decision trees, neural nets, ensembles and much more in my new book , with full Python code and no fancy libraries. Let\u2019s get started. Update Nov/2016 : Fixed a bug in the activate() function. Thanks Alex! Update Jan/2017 : Fixes issues with Python 3. Update Jan/2017 : Updated small bug in update_weights(). Thanks Tomasz! Update Apr/2018 : Added direct link to CSV dataset. Update Aug/2018 : Tested and updated to work with Python 3.6. Description This section provides a brief introduction to the Backpropagation Algorithm and the Wheat Seeds dataset that we will be using in this tutorial. Backpropagation Algorithm The Backpropagation algorithm is a supervised learning method for **multilayer feed-forward networks **from the field of Artificial Neural Networks. Feed-forward neural networks are inspired by the information processing of one or more neural cells, called a neuron . A neuron accepts input signals via its dendrites\uff08\u6811\u7a81\uff09, which pass the electrical signal down to the cell body. The axon\uff08\u8f74\u7a81\uff09 carries the signal out to synapses, which are the connections of a cell\u2019s axon to other cell\u2019s dendrites. \u524d\u9988\u795e\u7ecf\u7f51\u7edc\u53d7\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u795e\u7ecf\u7ec6\u80de\uff08\u79f0\u4e3a\u795e\u7ecf\u5143\uff09\u7684\u4fe1\u606f\u5904\u7406\u7684\u542f\u53d1\u3002 \u795e\u7ecf\u5143\u901a\u8fc7\u5176\u6811\u7a81\u63a5\u53d7\u8f93\u5165\u4fe1\u53f7\uff0c\u6811\u7a81\u5c06\u7535\u4fe1\u53f7\u4f20\u9012\u5230\u7ec6\u80de\u4f53\u3002 \u8f74\u7a81\u5c06\u4fe1\u53f7\u4f20\u9012\u7ed9\u7a81\u89e6\uff0c\u7a81\u89e6\u662f\u7ec6\u80de\u8f74\u7a81\u4e0e\u5176\u4ed6\u7ec6\u80de\u6811\u7a81\u7684\u8fde\u63a5\u3002 The principle of the backpropagation approach is to model a given function by modifying internal weightings of input signals to produce an expected output signal . The system is trained using a supervised learning method, where the error between the system\u2019s output and a known expected output is presented to the system and used to modify its internal state . Technically, the backpropagation algorithm is a method for training the weights in a multilayer feed-forward neural network . As such, it requires a network structure to be defined of one or more layers where one layer is fully connected to the next layer. A standard network structure is one input layer, one hidden layer, and one output layer. Backpropagation can be used for both classification and regression problems, but we will focus on classification in this tutorial. In classification problems, best results are achieved when the network has one neuron in the output layer for each class value. For example, a 2-class or binary classification problem with the class values of A and B. These expected outputs would have to be transformed into binary vectors with one column for each class value. Such as [1, 0] and [0, 1] for A and B respectively. This is called a one hot encoding. Wheat Seeds Dataset The seeds dataset involves the prediction of species given measurements seeds from different varieties of wheat. There are 201 records and 7 numerical input variables. It is a classification problem with 3 output classes. The scale for each numeric input value vary, so some data normalization may be required for use with algorithms that weight inputs like the backpropagation algorithm. Below is a sample of the first 5 rows of the dataset. 15.26,14.84,0.871,5.763,3.312,2.221,5.22,1 14.88,14.57,0.8811,5.554,3.333,1.018,4.956,1 14.29,14.09,0.905,5.291,3.337,2.699,4.825,1 13.84,13.94,0.8955,5.324,3.379,2.259,4.805,1 16.14,14.99,0.9034,5.658,3.562,1.355,5.175,1 Using the Zero Rule algorithm that predicts the most common class value, the baseline accuracy for the problem is 28.095%. You can learn more and download the seeds dataset from the UCI Machine Learning Repository . Download the seeds dataset and place it into your current working directory with the filename seeds_dataset.csv . The dataset is in tab-separated format, so you must convert it to CSV using a text editor or a spreadsheet program. Update, download the dataset in CSV format directly: Download Wheat Seeds Dataset Tutorial This tutorial is broken down into 6 parts: Initialize Network. Forward Propagate. Back Propagate Error. Train Network. Predict. Seeds Dataset Case Study. These steps will provide the foundation that you need to implement the backpropagation algorithm from scratch and apply it to your own predictive modeling problems. 1. Initialize Network Let\u2019s start with something easy, the creation of a new network ready for training. Each neuron has a set of weights that need to be maintained. One weight for each input connection and an additional weight for the bias. We will need to store additional properties for a neuron during training, therefore we will use a dictionary to represent each neuron and store properties by names such as \u2018 weights \u2018 for the weights. A network is organized into layers. The input layer is really just a row from our training dataset. The first real layer is the hidden layer. This is followed by the output layer that has one neuron for each class value. We will organize layers as arrays of dictionaries and treat the whole network as an array of layers. It is good practice to initialize the network weights to small random numbers. In this case, will we use random numbers in the range of 0 to 1. Below is a function named initialize_network() that creates a new neural network ready for training. It accepts three parameters, the number of inputs, the number of neurons to have in the hidden layer and the number of outputs. You can see that for the hidden layer we create n_hidden neurons and each neuron in the hidden layer has n_inputs + 1 weights, one for each input column in a dataset and an additional one for the bias. You can also see that the output layer that connects to the hidden layer has n_outputs**neurons, each with **n_hidden + 1 weights. This means that each neuron in the output layer connects to (has a weight for) each neuron in the hidden layer.","title":"Implementation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Implementation/#how#to#code#a#neural#network#with#backpropagation#in#python","text":"The backpropagation algorithm is used in the classical feed-forward\uff08\u524d\u9988\u7684\uff09 artificial neural network. It is the technique still used to train large deep learning networks. In this tutorial, you will discover how to implement the backpropagation algorithm for a neural network from scratch with Python. After completing this tutorial, you will know: How to forward-propagate an input to calculate an output. How to back-propagate error and train a network. How to apply the backpropagation algorithm to a real-world predictive modeling problem. SUMMARY : forward-propagate\u548cback-Propagate Discover how to code ML algorithms from scratch including kNN , decision trees, neural nets, ensembles and much more in my new book , with full Python code and no fancy libraries. Let\u2019s get started. Update Nov/2016 : Fixed a bug in the activate() function. Thanks Alex! Update Jan/2017 : Fixes issues with Python 3. Update Jan/2017 : Updated small bug in update_weights(). Thanks Tomasz! Update Apr/2018 : Added direct link to CSV dataset. Update Aug/2018 : Tested and updated to work with Python 3.6.","title":"How to Code a Neural Network with Backpropagation In Python"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Implementation/#description","text":"This section provides a brief introduction to the Backpropagation Algorithm and the Wheat Seeds dataset that we will be using in this tutorial.","title":"Description"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Implementation/#backpropagation#algorithm","text":"The Backpropagation algorithm is a supervised learning method for **multilayer feed-forward networks **from the field of Artificial Neural Networks. Feed-forward neural networks are inspired by the information processing of one or more neural cells, called a neuron . A neuron accepts input signals via its dendrites\uff08\u6811\u7a81\uff09, which pass the electrical signal down to the cell body. The axon\uff08\u8f74\u7a81\uff09 carries the signal out to synapses, which are the connections of a cell\u2019s axon to other cell\u2019s dendrites. \u524d\u9988\u795e\u7ecf\u7f51\u7edc\u53d7\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u795e\u7ecf\u7ec6\u80de\uff08\u79f0\u4e3a\u795e\u7ecf\u5143\uff09\u7684\u4fe1\u606f\u5904\u7406\u7684\u542f\u53d1\u3002 \u795e\u7ecf\u5143\u901a\u8fc7\u5176\u6811\u7a81\u63a5\u53d7\u8f93\u5165\u4fe1\u53f7\uff0c\u6811\u7a81\u5c06\u7535\u4fe1\u53f7\u4f20\u9012\u5230\u7ec6\u80de\u4f53\u3002 \u8f74\u7a81\u5c06\u4fe1\u53f7\u4f20\u9012\u7ed9\u7a81\u89e6\uff0c\u7a81\u89e6\u662f\u7ec6\u80de\u8f74\u7a81\u4e0e\u5176\u4ed6\u7ec6\u80de\u6811\u7a81\u7684\u8fde\u63a5\u3002 The principle of the backpropagation approach is to model a given function by modifying internal weightings of input signals to produce an expected output signal . The system is trained using a supervised learning method, where the error between the system\u2019s output and a known expected output is presented to the system and used to modify its internal state . Technically, the backpropagation algorithm is a method for training the weights in a multilayer feed-forward neural network . As such, it requires a network structure to be defined of one or more layers where one layer is fully connected to the next layer. A standard network structure is one input layer, one hidden layer, and one output layer. Backpropagation can be used for both classification and regression problems, but we will focus on classification in this tutorial. In classification problems, best results are achieved when the network has one neuron in the output layer for each class value. For example, a 2-class or binary classification problem with the class values of A and B. These expected outputs would have to be transformed into binary vectors with one column for each class value. Such as [1, 0] and [0, 1] for A and B respectively. This is called a one hot encoding.","title":"Backpropagation Algorithm"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Implementation/#wheat#seeds#dataset","text":"The seeds dataset involves the prediction of species given measurements seeds from different varieties of wheat. There are 201 records and 7 numerical input variables. It is a classification problem with 3 output classes. The scale for each numeric input value vary, so some data normalization may be required for use with algorithms that weight inputs like the backpropagation algorithm. Below is a sample of the first 5 rows of the dataset. 15.26,14.84,0.871,5.763,3.312,2.221,5.22,1 14.88,14.57,0.8811,5.554,3.333,1.018,4.956,1 14.29,14.09,0.905,5.291,3.337,2.699,4.825,1 13.84,13.94,0.8955,5.324,3.379,2.259,4.805,1 16.14,14.99,0.9034,5.658,3.562,1.355,5.175,1 Using the Zero Rule algorithm that predicts the most common class value, the baseline accuracy for the problem is 28.095%. You can learn more and download the seeds dataset from the UCI Machine Learning Repository . Download the seeds dataset and place it into your current working directory with the filename seeds_dataset.csv . The dataset is in tab-separated format, so you must convert it to CSV using a text editor or a spreadsheet program. Update, download the dataset in CSV format directly: Download Wheat Seeds Dataset","title":"Wheat Seeds Dataset"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Implementation/#tutorial","text":"This tutorial is broken down into 6 parts: Initialize Network. Forward Propagate. Back Propagate Error. Train Network. Predict. Seeds Dataset Case Study. These steps will provide the foundation that you need to implement the backpropagation algorithm from scratch and apply it to your own predictive modeling problems.","title":"Tutorial"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Implementation/#1#initialize#network","text":"Let\u2019s start with something easy, the creation of a new network ready for training. Each neuron has a set of weights that need to be maintained. One weight for each input connection and an additional weight for the bias. We will need to store additional properties for a neuron during training, therefore we will use a dictionary to represent each neuron and store properties by names such as \u2018 weights \u2018 for the weights. A network is organized into layers. The input layer is really just a row from our training dataset. The first real layer is the hidden layer. This is followed by the output layer that has one neuron for each class value. We will organize layers as arrays of dictionaries and treat the whole network as an array of layers. It is good practice to initialize the network weights to small random numbers. In this case, will we use random numbers in the range of 0 to 1. Below is a function named initialize_network() that creates a new neural network ready for training. It accepts three parameters, the number of inputs, the number of neurons to have in the hidden layer and the number of outputs. You can see that for the hidden layer we create n_hidden neurons and each neuron in the hidden layer has n_inputs + 1 weights, one for each input column in a dataset and an additional one for the bias. You can also see that the output layer that connects to the hidden layer has n_outputs**neurons, each with **n_hidden + 1 weights. This means that each neuron in the output layer connects to (has a weight for) each neuron in the hidden layer.","title":"1. Initialize Network"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/","text":"\u5173\u4e8e\u672c\u7ae0 \u201cback propagation\u201d\u5373\u201c\u65b9\u5411\u4f20\u64ad\u201d\u662fmachine learning\u7684\u4e3b\u8981\u6280\u672f\uff0c\u672c\u6587\u5bf9\u5b83\u8fdb\u884c\u8bf4\u660e\u3002\u7f51\u7edc\u4e0a\u5bf9\u8bb2\u8ff0\u5b83\u7684\u6587\u7ae0\u975e\u5e38\u591a\uff0c\u4e0b\u9762\u662f\u6211\u53c2\u8003\u7684\u6587\u7ae0\uff1a \u7b80\u5355\u6613\u61c2\u7684\u5165\u95e8\u8bfb\u7269\uff1azhihu \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f \u6df1\u5165\u6d45\u51fa\u7684\u6587\u7ae0\uff1a\u7ef4\u57fa\u767e\u79d1 Backpropagation","title":"Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/#_1","text":"\u201cback propagation\u201d\u5373\u201c\u65b9\u5411\u4f20\u64ad\u201d\u662fmachine learning\u7684\u4e3b\u8981\u6280\u672f\uff0c\u672c\u6587\u5bf9\u5b83\u8fdb\u884c\u8bf4\u660e\u3002\u7f51\u7edc\u4e0a\u5bf9\u8bb2\u8ff0\u5b83\u7684\u6587\u7ae0\u975e\u5e38\u591a\uff0c\u4e0b\u9762\u662f\u6211\u53c2\u8003\u7684\u6587\u7ae0\uff1a \u7b80\u5355\u6613\u61c2\u7684\u5165\u95e8\u8bfb\u7269\uff1azhihu \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f \u6df1\u5165\u6d45\u51fa\u7684\u6587\u7ae0\uff1a\u7ef4\u57fa\u767e\u79d1 Backpropagation","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/","text":"\u6df1\u5ea6\u5b66\u4e60 Jacobian\u77e9\u9635 http://jacoxu.com/jacobian%E7%9F%A9%E9%98%B5%E5%92%8Chessian%E7%9F%A9%E9%98%B5/ \u5fae\u79ef\u5206\u7684\u94fe\u5f0f\u6cd5\u5219\u4ece\u4e00\u7ef4\u5230\u65e0\u9650\u7ef4\u7684\u63a8\u5e7f \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u7684\u76f4\u89c2\u7406\u89e3 https://blog.csdn.net/mao_xiao_feng/article/details/53048213 \u5df2\u7ecf\u9605\u8bfb\uff1a https://www.zhihu.com/question/27239198?rf=24827633 \u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\uff1a http://www.cnblogs.com/charlotte77/p/5629865.html \u6df1\u5ea6\u5b66\u4e60\u4e4b\u7236Hinton\u5907\u53d7\u77a9\u76ee\u7684Capsule\u8bba\u6587\u4eca\u6b63\u5f0f\u516c\u5e03 http://baijiahao.baidu.com/s?id=1582664648449055726&wfr=spider&for=pc \u65af\u5766\u798f\u674e\u98de\u98de-\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u673a\u89c6\u89c9 http://study.163.com/course/introduction/1003223001.htm brilliant Backpropagation","title":"\u6df1\u5ea6\u5b66\u4e60"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/#_1","text":"","title":"\u6df1\u5ea6\u5b66\u4e60"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/#jacobian","text":"http://jacoxu.com/jacobian%E7%9F%A9%E9%98%B5%E5%92%8Chessian%E7%9F%A9%E9%98%B5/","title":"Jacobian\u77e9\u9635"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/#_2","text":"","title":"\u5fae\u79ef\u5206\u7684\u94fe\u5f0f\u6cd5\u5219\u4ece\u4e00\u7ef4\u5230\u65e0\u9650\u7ef4\u7684\u63a8\u5e7f"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/#_3","text":"https://blog.csdn.net/mao_xiao_feng/article/details/53048213 \u5df2\u7ecf\u9605\u8bfb\uff1a https://www.zhihu.com/question/27239198?rf=24827633 \u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\uff1a http://www.cnblogs.com/charlotte77/p/5629865.html","title":"\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u7684\u76f4\u89c2\u7406\u89e3"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/#hintoncapsule","text":"http://baijiahao.baidu.com/s?id=1582664648449055726&wfr=spider&for=pc","title":"\u6df1\u5ea6\u5b66\u4e60\u4e4b\u7236Hinton\u5907\u53d7\u77a9\u76ee\u7684Capsule\u8bba\u6587\u4eca\u6b63\u5f0f\u516c\u5e03"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/#-","text":"http://study.163.com/course/introduction/1003223001.htm","title":"\u65af\u5766\u798f\u674e\u98de\u98de-\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u673a\u89c6\u89c9"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/TO-READ/#brilliant#backpropagation","text":"","title":"brilliant Backpropagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/wikipedia-Backpropagation/","text":"\u7ef4\u57fa\u767e\u79d1 Backpropagation The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule , computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming .[ 3] NOTE: chain rule and dynamic programming \uff0c\u4e0e\u6b64\u7c7b\u4f3c\u7684\u4f8b\u5b50\u8fd8\u6709\uff1a Markov chain Backpropagation requires the derivatives of activation functions to be known at network design time. Automatic differentiation is a technique that can automatically and analytically provide the derivatives to the training algorithm. In the context of learning, backpropagation is commonly used by the gradient descent optimization algorithm to adjust the weight of neurons by calculating the gradient of the loss function ; backpropagation computes the gradient(s), whereas (stochastic) gradient descent uses the gradients for training the model (via optimization). NOTE: backpropagation \u548cgradient descent\u4e4b\u95f4\u7684\u5173\u7cfb Overview Backpropagation computes the gradient in weight space of a feedforward neural network, with respect to a loss function . Denote: x x input (vector of features) y y target output For classification, output will be a vector of class probabilities (e.g., $ (0.1,0.7,0.2)$ ), and target output is a specific class, encoded by the one-hot / dummy variable (e.g., (0,1,0) (0,1,0) ). C C loss function or \"cost function\" For classification, this is usually cross entropy (XC, log loss ), while for regression it is usually squared error loss (SEL). L L the number of layers W^{l}=(w_{jk}^{l}) W^{l}=(w_{jk}^{l}) : the weights between layer l-1 l-1 and l, l, where w_{jk}^{l} w_{jk}^{l} is the weight between the k k -th node in layer l-1 l-1 and the j j -th node in layer l l b] $ f^{l}$ activation functions at layer l l For classification the last layer is usually the logistic function for binary classification, and softmax (softargmax) for multi-class classification, while for the hidden layers this was traditionally a sigmoid function (logistic function or others) on each node (coordinate), but today is more varied, with rectifier ( ramp , ReLU ) being common. The overall network is a combination of function composition and matrix multiplication : $$ g(x):=f {L}(W {L}f {L-1}(W {L-1}\\cdots f {1}(W {1}x)\\cdots )) $$ NOTE: \u6570\u5b66\u7684\u7b80\u6d01 For a training set there will be a set of input\u2013output pairs, \\left\\{(x_{i},y_{i})\\right\\} \\left\\{(x_{i},y_{i})\\right\\} . For each input\u2013output pair $ (x_{i},y_{i})$ in the training set, the loss of the model on that pair is the cost of the difference between the predicted output g(x_{i}) g(x_{i}) and the target output y_{i} y_{i} C(y_{i},g(x_{i})) C(y_{i},g(x_{i})) Note the distinction: During model evaluation , the weights are fixed, while the inputs vary (and the target output may be unknown), and the network ends with the output layer (it does not include the loss function). During model training , the input\u2013output pair is fixed, while the weights vary, and the network ends with the loss function. NOTE: evaluation\u9636\u6bb5\u548ctraining\u9636\u6bb5\u7684\u5bf9\u6bd4 Backpropagation computes the gradient for a fixed input\u2013output pair (x_{i},y_{i}) (x_{i},y_{i}) , where the weights w_{jk}^{l} w_{jk}^{l} can vary. Each individual component of the gradient, \\partial C/\\partial w_{jk}^{l} \\partial C/\\partial w_{jk}^{l} can be computed by the chain rule; however, doing this separately for each weight is inefficient. Backpropagation efficiently computes the gradient by avoiding duplicate calculations and not computing unnecessary intermediate values, by computing the gradient of each layer \u2013 specifically, the gradient of the weighted input of each layer, denoted by \\delta ^{l} \\delta ^{l} \u2013 from back to front. NOTE: \\delta ^{l} \\delta ^{l} \u8868\u793a\u7684\u662f\u7b2c l l \u5c42\u7684gradient NOTE: \u4e3a\u4ec0\u4e48\u662ffront back to front\uff1f\u4e0b\u9762\u8fd9\u4e00\u6bb5\u5bf9\u6b64\u8fdb\u884c\u4e86\u76f4\u89c2\u7684\u89e3\u91ca\uff0c\u5982\u4e0b\u662f\u6211\u7ed3\u5408\u6574\u4f53\u7684\u7406\u89e3\uff1a \u6574\u4e2a\u6a21\u578b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a g(x):=f^{L}(W^{L}f^{L-1}(W^{L-1}\\cdots f^{1}(W^{1}x)\\cdots )) g(x):=f^{L}(W^{L}f^{L-1}(W^{L-1}\\cdots f^{1}(W^{1}x)\\cdots )) \uff0c\u663e\u7136\u9010\u5c42\u7684\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u5b83\u662f\u4e00\u4e2anesting\u7ed3\u6784\uff0c\u663e\u7136\u5b83\u662f\u4e00\u4e2a\u7ebf\u6027\u7684\u7ed3\u6784\uff0c\u8fd9\u6837\u7684\u7ed3\u6784\u5c31\u51b3\u5b9a\u4e86\uff1a the only way a weight in W^{l} W^{l} affects the loss is through its effect on the next layer, and it does so linearly \u8fd9\u8ba9\u6211\u60f3\u8d77\u6765\uff1a\u7ed3\u6784\u51b3\u5b9a\u5c5e\u6027\uff08\u53c2\u89c1 discrete-math\\docs\\Guide\\Relation-structure-computation \uff09 \u663e\u7136\uff0c\u5728\u6700\u540e\u4e00\u5c42\uff0c\u5b83\u7684weight\u5373 W^{l} W^{l} \u76f4\u63a5\u201caffects the loss\u201d\uff0c\u5373\u5b83\u65e0\u9700\u901a\u8fc7\u4e2d\u95f4\u5c42\u800c\u76f4\u63a5\u4f5c\u7528\u4e8eloss\uff0c\u6240\u4ee5 \\delta ^{l} \\delta ^{l} \u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97\u5f97\u5230\u3002\u5728\u8ba1\u7b97\u5f97\u5230\u4e86 \\delta ^{l} \\delta ^{l} \u540e\uff0c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u76f4\u63a5\u4f9d\u8d56\u4e8e\u5b83\u7684 \\delta ^{l-1} \\delta ^{l-1} \uff1b\u4f9d\u6b21\u53ef\u4ee5\u9012\u5f52\u8fdb\u884c\u76f4\u5230\u7b2c\u4e00\u5c42\uff0c\u4ece\u800c\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u6240\u6709\u7684gradient\uff1b Informally, the key point is that since the only way a weight in W^{l} W^{l} affects the loss is through its effect on the next layer, and it does so linearly, \\delta ^{l} \\delta ^{l} are the only data you need to compute the gradients of the weights at layer l l , and then you can compute the previous layer \\delta ^{l-1} \\delta ^{l-1} and repeat recursively. This avoids inefficiency in two ways. Firstly, it avoids duplication because when computing the gradient at layer l l , you do not need to recompute all the derivatives on later layers $l+1,l+2,\\ldots $ each time. Secondly, it avoids unnecessary intermediate calculations because at each stage it directly computes the gradient of the weights with respect to the ultimate output (the loss), rather than unnecessarily computing the derivatives of the values of hidden layers with respect to changes in weights \\partial a_{j'}^{l'}/\\partial w_{jk}^{l}. \\partial a_{j'}^{l'}/\\partial w_{jk}^{l}. NOTE: \u4e0a\u9762\u4ecb\u7ecd\u4e86backpropagation\u9ad8\u6548\u6027\u7684\u539f\u56e0 Backpropagation can be expressed for simple feedforward networks in terms of matrix multiplication , or more generally in terms of the adjoint graph . Matrix multiplication Given an input\u2013output pair $ (x,y) $, the loss is: $$ C(y,f {L}(W {L}f {L-1}(W {L-1}\\cdots f {1}(W {1}x)\\cdots ))) $$ To compute this, one starts with the input x x and works forward; denote the weighted input of each layer as z^{l} z^{l} and the output of layer l l as the activation a^{l} a^{l} . For backpropagation, the activation a^{l} a^{l} as well as the derivatives (f^{l})' (f^{l})' (evaluated at z^{l} z^{l} ) must be cached for use during the backwards pass. NOTE: \u6240\u8c13 z^{l} z^{l} \u65e2weighted input\uff0c\u5176\u5b9e\u5c31\u662f\u5b83\u7684input dot product weight\uff1b\u6240\u8c13 a^{l} a^{l} \uff0c\u5176\u5b9e\u5c31\u662f\u8fd9\u4e00\u5c42\u7684output\u3002 The derivative of the loss in terms of the inputs is given by the chain rule; note that each term is a total derivative , evaluated at the value of the network (at each node) on the input x x $$ {\\displaystyle {\\frac {dC}{da^{L}}}\\cdot {\\frac {da {L}}{dz {L}}}\\cdot {\\frac {dz {L}}{da {L-1}}}\\cdot {\\frac {da {L-1}}{dz {L-1}}}\\cdot {\\frac {dz {L-1}}{da {L-2}}}\\cdots {\\frac {da {1}}{dz {1}}}\\cdot {\\frac {\\partial z^{1}}{\\partial x}}.} $$ These terms are: the derivative of the loss function;[ d] the derivatives of the activation functions;[ e] and the matrices of weights:[ f] $$ {\\displaystyle {\\frac {dC}{da^{L}}}\\cdot (f^{L})'\\cdot W^{L}\\cdot (f^{L-1})'\\cdot W^{L-1}\\cdots (f^{1})'\\cdot W^{1}.} $$ The gradient {\\displaystyle \\nabla } {\\displaystyle \\nabla } is the transpose \uff08\u8f6c\u7f6e\uff09 of the derivative of the output in terms of the input, so the matrices are transposed and the order of multiplication is reversed, but the entries are the same: $$ {\\displaystyle \\nabla _{x}C=(W {1}) {T}\\cdot (f^{1})'\\cdots \\cdot (W {L-1}) {T}\\cdot (f^{L-1})'\\cdot (W {L}) {T}\\cdot (f^{L})'\\cdot \\nabla _{a^{L}}C.} $$ Backpropagation then consists essentially of evaluating this expression from right to left (equivalently, multiplying the previous expression for the derivative from left to right), computing the gradient at each layer on the way; there is an added step, because the gradient of the weights isn't just a subexpression: there's an extra multiplication.","title":"wikipedia-Backpropagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/wikipedia-Backpropagation/#backpropagation","text":"The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule , computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming .[ 3] NOTE: chain rule and dynamic programming \uff0c\u4e0e\u6b64\u7c7b\u4f3c\u7684\u4f8b\u5b50\u8fd8\u6709\uff1a Markov chain Backpropagation requires the derivatives of activation functions to be known at network design time. Automatic differentiation is a technique that can automatically and analytically provide the derivatives to the training algorithm. In the context of learning, backpropagation is commonly used by the gradient descent optimization algorithm to adjust the weight of neurons by calculating the gradient of the loss function ; backpropagation computes the gradient(s), whereas (stochastic) gradient descent uses the gradients for training the model (via optimization). NOTE: backpropagation \u548cgradient descent\u4e4b\u95f4\u7684\u5173\u7cfb","title":"\u7ef4\u57fa\u767e\u79d1Backpropagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/wikipedia-Backpropagation/#overview","text":"Backpropagation computes the gradient in weight space of a feedforward neural network, with respect to a loss function . Denote: x x input (vector of features) y y target output For classification, output will be a vector of class probabilities (e.g., $ (0.1,0.7,0.2)$ ), and target output is a specific class, encoded by the one-hot / dummy variable (e.g., (0,1,0) (0,1,0) ). C C loss function or \"cost function\" For classification, this is usually cross entropy (XC, log loss ), while for regression it is usually squared error loss (SEL). L L the number of layers W^{l}=(w_{jk}^{l}) W^{l}=(w_{jk}^{l}) : the weights between layer l-1 l-1 and l, l, where w_{jk}^{l} w_{jk}^{l} is the weight between the k k -th node in layer l-1 l-1 and the j j -th node in layer l l b] $ f^{l}$ activation functions at layer l l For classification the last layer is usually the logistic function for binary classification, and softmax (softargmax) for multi-class classification, while for the hidden layers this was traditionally a sigmoid function (logistic function or others) on each node (coordinate), but today is more varied, with rectifier ( ramp , ReLU ) being common. The overall network is a combination of function composition and matrix multiplication : $$ g(x):=f {L}(W {L}f {L-1}(W {L-1}\\cdots f {1}(W {1}x)\\cdots )) $$ NOTE: \u6570\u5b66\u7684\u7b80\u6d01 For a training set there will be a set of input\u2013output pairs, \\left\\{(x_{i},y_{i})\\right\\} \\left\\{(x_{i},y_{i})\\right\\} . For each input\u2013output pair $ (x_{i},y_{i})$ in the training set, the loss of the model on that pair is the cost of the difference between the predicted output g(x_{i}) g(x_{i}) and the target output y_{i} y_{i} C(y_{i},g(x_{i})) C(y_{i},g(x_{i})) Note the distinction: During model evaluation , the weights are fixed, while the inputs vary (and the target output may be unknown), and the network ends with the output layer (it does not include the loss function). During model training , the input\u2013output pair is fixed, while the weights vary, and the network ends with the loss function. NOTE: evaluation\u9636\u6bb5\u548ctraining\u9636\u6bb5\u7684\u5bf9\u6bd4 Backpropagation computes the gradient for a fixed input\u2013output pair (x_{i},y_{i}) (x_{i},y_{i}) , where the weights w_{jk}^{l} w_{jk}^{l} can vary. Each individual component of the gradient, \\partial C/\\partial w_{jk}^{l} \\partial C/\\partial w_{jk}^{l} can be computed by the chain rule; however, doing this separately for each weight is inefficient. Backpropagation efficiently computes the gradient by avoiding duplicate calculations and not computing unnecessary intermediate values, by computing the gradient of each layer \u2013 specifically, the gradient of the weighted input of each layer, denoted by \\delta ^{l} \\delta ^{l} \u2013 from back to front. NOTE: \\delta ^{l} \\delta ^{l} \u8868\u793a\u7684\u662f\u7b2c l l \u5c42\u7684gradient NOTE: \u4e3a\u4ec0\u4e48\u662ffront back to front\uff1f\u4e0b\u9762\u8fd9\u4e00\u6bb5\u5bf9\u6b64\u8fdb\u884c\u4e86\u76f4\u89c2\u7684\u89e3\u91ca\uff0c\u5982\u4e0b\u662f\u6211\u7ed3\u5408\u6574\u4f53\u7684\u7406\u89e3\uff1a \u6574\u4e2a\u6a21\u578b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a g(x):=f^{L}(W^{L}f^{L-1}(W^{L-1}\\cdots f^{1}(W^{1}x)\\cdots )) g(x):=f^{L}(W^{L}f^{L-1}(W^{L-1}\\cdots f^{1}(W^{1}x)\\cdots )) \uff0c\u663e\u7136\u9010\u5c42\u7684\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u5b83\u662f\u4e00\u4e2anesting\u7ed3\u6784\uff0c\u663e\u7136\u5b83\u662f\u4e00\u4e2a\u7ebf\u6027\u7684\u7ed3\u6784\uff0c\u8fd9\u6837\u7684\u7ed3\u6784\u5c31\u51b3\u5b9a\u4e86\uff1a the only way a weight in W^{l} W^{l} affects the loss is through its effect on the next layer, and it does so linearly \u8fd9\u8ba9\u6211\u60f3\u8d77\u6765\uff1a\u7ed3\u6784\u51b3\u5b9a\u5c5e\u6027\uff08\u53c2\u89c1 discrete-math\\docs\\Guide\\Relation-structure-computation \uff09 \u663e\u7136\uff0c\u5728\u6700\u540e\u4e00\u5c42\uff0c\u5b83\u7684weight\u5373 W^{l} W^{l} \u76f4\u63a5\u201caffects the loss\u201d\uff0c\u5373\u5b83\u65e0\u9700\u901a\u8fc7\u4e2d\u95f4\u5c42\u800c\u76f4\u63a5\u4f5c\u7528\u4e8eloss\uff0c\u6240\u4ee5 \\delta ^{l} \\delta ^{l} \u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97\u5f97\u5230\u3002\u5728\u8ba1\u7b97\u5f97\u5230\u4e86 \\delta ^{l} \\delta ^{l} \u540e\uff0c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u76f4\u63a5\u4f9d\u8d56\u4e8e\u5b83\u7684 \\delta ^{l-1} \\delta ^{l-1} \uff1b\u4f9d\u6b21\u53ef\u4ee5\u9012\u5f52\u8fdb\u884c\u76f4\u5230\u7b2c\u4e00\u5c42\uff0c\u4ece\u800c\u53ef\u4ee5\u8ba1\u7b97\u5f97\u5230\u6240\u6709\u7684gradient\uff1b Informally, the key point is that since the only way a weight in W^{l} W^{l} affects the loss is through its effect on the next layer, and it does so linearly, \\delta ^{l} \\delta ^{l} are the only data you need to compute the gradients of the weights at layer l l , and then you can compute the previous layer \\delta ^{l-1} \\delta ^{l-1} and repeat recursively. This avoids inefficiency in two ways. Firstly, it avoids duplication because when computing the gradient at layer l l , you do not need to recompute all the derivatives on later layers $l+1,l+2,\\ldots $ each time. Secondly, it avoids unnecessary intermediate calculations because at each stage it directly computes the gradient of the weights with respect to the ultimate output (the loss), rather than unnecessarily computing the derivatives of the values of hidden layers with respect to changes in weights \\partial a_{j'}^{l'}/\\partial w_{jk}^{l}. \\partial a_{j'}^{l'}/\\partial w_{jk}^{l}. NOTE: \u4e0a\u9762\u4ecb\u7ecd\u4e86backpropagation\u9ad8\u6548\u6027\u7684\u539f\u56e0 Backpropagation can be expressed for simple feedforward networks in terms of matrix multiplication , or more generally in terms of the adjoint graph .","title":"Overview"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/wikipedia-Backpropagation/#matrix#multiplication","text":"Given an input\u2013output pair $ (x,y) $, the loss is: $$ C(y,f {L}(W {L}f {L-1}(W {L-1}\\cdots f {1}(W {1}x)\\cdots ))) $$ To compute this, one starts with the input x x and works forward; denote the weighted input of each layer as z^{l} z^{l} and the output of layer l l as the activation a^{l} a^{l} . For backpropagation, the activation a^{l} a^{l} as well as the derivatives (f^{l})' (f^{l})' (evaluated at z^{l} z^{l} ) must be cached for use during the backwards pass. NOTE: \u6240\u8c13 z^{l} z^{l} \u65e2weighted input\uff0c\u5176\u5b9e\u5c31\u662f\u5b83\u7684input dot product weight\uff1b\u6240\u8c13 a^{l} a^{l} \uff0c\u5176\u5b9e\u5c31\u662f\u8fd9\u4e00\u5c42\u7684output\u3002 The derivative of the loss in terms of the inputs is given by the chain rule; note that each term is a total derivative , evaluated at the value of the network (at each node) on the input x x $$ {\\displaystyle {\\frac {dC}{da^{L}}}\\cdot {\\frac {da {L}}{dz {L}}}\\cdot {\\frac {dz {L}}{da {L-1}}}\\cdot {\\frac {da {L-1}}{dz {L-1}}}\\cdot {\\frac {dz {L-1}}{da {L-2}}}\\cdots {\\frac {da {1}}{dz {1}}}\\cdot {\\frac {\\partial z^{1}}{\\partial x}}.} $$ These terms are: the derivative of the loss function;[ d] the derivatives of the activation functions;[ e] and the matrices of weights:[ f] $$ {\\displaystyle {\\frac {dC}{da^{L}}}\\cdot (f^{L})'\\cdot W^{L}\\cdot (f^{L-1})'\\cdot W^{L-1}\\cdots (f^{1})'\\cdot W^{1}.} $$ The gradient {\\displaystyle \\nabla } {\\displaystyle \\nabla } is the transpose \uff08\u8f6c\u7f6e\uff09 of the derivative of the output in terms of the input, so the matrices are transposed and the order of multiplication is reversed, but the entries are the same: $$ {\\displaystyle \\nabla _{x}C=(W {1}) {T}\\cdot (f^{1})'\\cdots \\cdot (W {L-1}) {T}\\cdot (f^{L-1})'\\cdot (W {L}) {T}\\cdot (f^{L})'\\cdot \\nabla _{a^{L}}C.} $$ Backpropagation then consists essentially of evaluating this expression from right to left (equivalently, multiplying the previous expression for the derivative from left to right), computing the gradient at each layer on the way; there is an added step, because the gradient of the weights isn't just a subexpression: there's an extra multiplication.","title":"Matrix multiplication"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/zhihu-Back-Propagation/","text":"zhihu \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f Anonymous\u7684\u56de\u7b54 BackPropagation\u7b97\u6cd5\u662f\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u4e2d\u4e3e\u8db3\u8f7b\u91cd\u7684\u7b97\u6cd5\u3002 \u7b80\u5355\u7684\u7406\u89e3\uff0c\u5b83\u7684\u786e\u5c31\u662f**\u590d\u5408\u51fd\u6570\u7684\u5fae\u79ef\u5206\u94fe\u5f0f\u6cd5\u5219**\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u8fd0\u7b97\u4e2d\u7684\u610f\u4e49\u6bd4**\u94fe\u5f0f\u6cd5\u5219**\u8981\u5927\u7684\u591a\u3002 \u8981\u56de\u7b54\u9898\u4e3b\u8fd9\u4e2a\u95ee\u9898\u201c\u5982\u4f55\u76f4\u89c2\u7684\u89e3\u91caback propagation\u7b97\u6cd5\uff1f\u201d \u9700\u8981\u5148\u76f4\u89c2\u7406\u89e3**\u591a\u5c42\u795e\u7ecf\u7f51\u7edc**\u7684\u8bad\u7ec3\u3002 \u673a\u5668\u5b66\u4e60**\u53ef\u4ee5\u770b\u505a\u662f**\u6570\u7406\u7edf\u8ba1**\u7684\u4e00\u4e2a\u5e94\u7528\uff0c\u5728**\u6570\u7406\u7edf\u8ba1**\u4e2d\u4e00\u4e2a\u5e38\u89c1\u7684\u4efb\u52a1\u5c31\u662f**\u62df\u5408 \uff0c\u4e5f\u5c31\u662f\u7ed9\u5b9a\u4e00\u4e9b\u6837\u672c\u70b9\uff0c\u7528\u5408\u9002\u7684\u66f2\u7ebf\u63ed\u793a\u8fd9\u4e9b\u6837\u672c\u70b9\u968f\u7740\u81ea\u53d8\u91cf\u7684\u53d8\u5316\u5173\u7cfb\u3002 \u6df1\u5ea6\u5b66\u4e60**\u540c\u6837\u4e5f\u662f\u4e3a\u4e86\u8fd9\u4e2a\u76ee\u7684\uff0c\u53ea\u4e0d\u8fc7\u6b64\u65f6\uff0c**\u6837\u672c\u70b9**\u4e0d\u518d\u9650\u5b9a\u4e3a (x, y) (x, y) \u70b9\u5bf9\uff0c\u800c\u53ef\u4ee5\u662f\u7531\u5411\u91cf\u3001\u77e9\u9635\u7b49\u7b49\u7ec4\u6210\u7684\u5e7f\u4e49\u70b9\u5bf9 (X,Y) (X,Y) \u3002\u800c\u6b64\u65f6\uff0c (X,Y) (X,Y) \u4e4b\u95f4\u7684\u5173\u7cfb\u4e5f\u53d8\u5f97\u5341\u5206\u590d\u6742\uff0c\u4e0d\u592a\u53ef\u80fd\u7528\u4e00\u4e2a\u7b80\u5355\u51fd\u6570\u8868\u793a\u3002\u7136\u800c\uff0c\u4eba\u4eec\u53d1\u73b0\u53ef\u4ee5\u7528**\u591a\u5c42\u795e\u7ecf\u7f51\u7edc**\u6765\u8868\u793a\u8fd9\u6837\u7684\u5173\u7cfb\uff0c\u800c**\u591a\u5c42\u795e\u7ecf\u7f51\u7edc**\u7684\u672c\u8d28\u5c31\u662f\u4e00\u4e2a**\u591a\u5c42\u590d\u5408\u7684\u51fd\u6570 \u3002\u501f\u7528\u7f51\u4e0a\u627e\u5230\u7684\u4e00\u5e45\u56fe[1]\uff0c\u6765\u76f4\u89c2\u63cf\u7ed8\u4e00\u4e0b\u8fd9\u79cd\u590d\u5408\u5173\u7cfb\u3002 \u601d\u8003\uff1a\u8fd9\u4e2a\u56fe\u662f\u5b58\u5728\u9519\u8bef\u7684\uff0c\u56fe\u4e2d a_1^{(2)} a_1^{(2)} \u5176\u5b9e\u5e94\u8be5\u753b\u5728\u5706\u5708\u4e2d\uff0c\u800c\u4e0d\u662f\u753b\u5728\u8fde\u7ebf\u4e0a\u3002\u8fd9\u5176\u5b9e\u662f\u8ba1\u7b97\u56fe\u3002 \u5176\u5bf9\u5e94\u7684\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a \u4e0a\u9762\u5f0f\u4e2d\u7684 W_{ij} W_{ij} \u5c31\u662f\u76f8\u90bb\u4e24\u5c42\u795e\u7ecf\u5143\u4e4b\u95f4\u7684\u6743\u503c\uff0c\u5b83\u4eec\u5c31\u662f\u6df1\u5ea6\u5b66\u4e60\u9700\u8981\u5b66\u4e60\u7684**\u53c2\u6570**\uff0c\u4e5f\u5c31\u76f8\u5f53\u4e8e\u76f4\u7ebf\u62df\u5408 y=k*x+b y=k*x+b \u4e2d\u7684\u5f85\u6c42\u53c2\u6570 k k \u548c b b \u3002 \u548c**\u76f4\u7ebf\u62df\u5408**\u4e00\u6837\uff0c \u6df1\u5ea6\u5b66\u4e60**\u7684\u8bad\u7ec3\u4e5f\u6709\u4e00\u4e2a**\u76ee\u6807\u51fd\u6570 \uff0c\u8fd9\u4e2a**\u76ee\u6807\u51fd\u6570**\u5b9a\u4e49\u4e86\u4ec0\u4e48\u6837\u7684\u53c2\u6570\u624d\u7b97\u4e00\u7ec4\u201c\u597d\u53c2\u6570\u201d\uff0c\u4e0d\u8fc7\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u4e00\u822c\u662f\u91c7\u7528**\u6210\u672c\u51fd\u6570\uff08cost function\uff09 \uff0c\u7136\u540e\uff0c\u8bad\u7ec3\u76ee\u6807\u5c31\u662f\u901a\u8fc7\u8c03\u6574\u6bcf\u4e00\u4e2a\u6743\u503c W_{ij} W_{ij} \u6765\u4f7f\u5f97**cost**\u8fbe\u5230\u6700\u5c0f\u3002**cost\u51fd\u6570**\u4e5f\u53ef\u4ee5\u770b\u6210\u662f\u7531\u6240\u6709\u5f85\u6c42\u6743\u503c W_{ij} W_{ij} \u4e3a\u81ea\u53d8\u91cf\u7684**\u590d\u5408\u51fd\u6570 \uff0c\u800c\u4e14\u57fa\u672c\u4e0a\u662f\u975e\u51f8\u7684\uff0c\u5373\u542b\u6709\u8bb8\u591a**\u5c40\u90e8\u6700\u5c0f\u503c**\u3002\u4f46\u5b9e\u9645\u4e2d\u53d1\u73b0\uff0c\u91c7\u7528\u6211\u4eec\u5e38\u7528\u7684**\u68af\u5ea6\u4e0b\u964d\u6cd5**\u5c31\u53ef\u4ee5\u6709\u6548\u7684\u6c42\u89e3\u6700\u5c0f\u5316cost\u51fd\u6570\u7684\u95ee\u9898\u3002 \u68af\u5ea6\u4e0b\u964d\u6cd5\u9700\u8981\u7ed9\u5b9a\u4e00\u4e2a\u521d\u59cb\u70b9\uff0c\u5e76\u6c42\u51fa\u8be5\u70b9\u7684**\u68af\u5ea6\u5411\u91cf**\uff0c\u7136\u540e\u4ee5**\u8d1f\u68af\u5ea6\u65b9\u5411**\u4e3a\u641c\u7d22\u65b9\u5411\uff0c\u4ee5\u4e00\u5b9a\u7684**\u6b65\u957f**\u8fdb\u884c\u641c\u7d22\uff0c\u4ece\u800c\u786e\u5b9a\u4e0b\u4e00\u4e2a\u8fed\u4ee3\u70b9\uff0c\u518d\u8ba1\u7b97\u8be5\u65b0\u7684\u68af\u5ea6\u65b9\u5411\uff0c\u5982\u6b64\u91cd\u590d\u76f4\u5230cost\u6536\u655b\u3002\u90a3\u4e48\u5982\u4f55\u8ba1\u7b97\u68af\u5ea6\u5462\uff1f \u5047\u8bbe\u6211\u4eec\u628a**cost\u51fd\u6570**\u8868\u793a\u4e3a H(W_{11},W_{12}, \\dots ,W_{ij}, \\dots, W_{mn}) H(W_{11},W_{12}, \\dots ,W_{ij}, \\dots, W_{mn}) , \u90a3\u4e48\u5b83\u7684\u68af\u5ea6\u5411\u91cf[2]\u5c31\u7b49\u4e8e , \u5176\u4e2d \u8868\u793a\u6b63\u4ea4\u5355\u4f4d\u5411\u91cf\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u6c42\u51facost\u51fd\u6570H\u5bf9\u6bcf\u4e00\u4e2a\u6743\u503cWij\u7684**\u504f\u5bfc\u6570**\u3002\u800c**BP\u7b97\u6cd5\u6b63\u662f\u7528\u6765\u6c42\u89e3\u8fd9\u79cd\u591a\u5c42\u590d\u5408\u51fd\u6570\u7684\u6240\u6709\u53d8\u91cf\u7684\u504f\u5bfc\u6570\u7684\u5229\u5668**\u3002 \u6211\u4eec\u4ee5\u6c42 e=(a+b)*(b+1) e=(a+b)*(b+1) \u7684\u504f\u5bfc[3]\u4e3a\u4f8b\u3002 \u5b83\u7684\u590d\u5408\u5173\u7cfb\u753b\u51fa\u56fe\u53ef\u4ee5\u8868\u793a\u5982\u4e0b\uff1a NOTE: e=(a+b)*(b+1) e=(a+b)*(b+1) \u662f\u4e00\u4e2a\u4e8c\u5143\u51fd\u6570\uff0c\u81ea\u53d8\u91cf\u4e3a a \uff0c b \uff0c\u5b83\u53ef\u4ee5\u770b\u51fa\u662f\u7531\u4e24\u4e2a\u51fd\u6570\u590d\u5408\u800c\u6210\uff1a c=a+b c=a+b \uff0c\u548c d=b+1 d=b+1 NOTE: \u5728machine learning\u4e2d\uff0c\u9700\u8981\u4f7f\u7528\u7ed3\u6784\u5316\u601d\u7ef4\u6765\u601d\u8003\u51fd\u6570\uff0c\u6bd4\u5982 e=(a+b)*(b+1) e=(a+b)*(b+1) \uff0c\u4e0a\u56fe\u5c31\u662f\u5b83\u7684\u56fe\u7ed3\u6784\u3002\u8fd9\u79cd\u56fe\u7ed3\u6784\u5c31\u662f\u57286.5.1 Computational Graphs\u4e2d\u63cf\u8ff0\u7684computational graph\u3002 \u5728\u56fe\u4e2d\uff0c\u5f15\u5165\u4e86\u4e2d\u95f4\u53d8\u91cf c c , d d \u3002 \u4e3a\u4e86\u6c42\u51fa a=2, b=1 a=2, b=1 \u65f6\uff0c e e \u7684\u68af\u5ea6\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u5229\u7528\u504f\u5bfc\u6570\u7684\u5b9a\u4e49\u6c42\u51fa\u4e0d\u540c\u5c42\u4e4b\u95f4\u76f8\u90bb\u8282\u70b9\u7684\u504f\u5bfc\u5173\u7cfb\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002 NOTE: \u51fd\u6570 e=c*d e=c*d \uff0c\u5f53 a=2,b=1 a=2,b=1 \uff0c\u5219 d=b+1=2 d=b+1=2 \uff0c\u5219\u6b64\u65f6\u51fd\u6570\u7684\u8868\u8fbe\u5f0f\u4e3a e=2*c e=2*c \uff0c\u5219 e e \u5bf9 c c \u7684\u5bfc\u6570\u4e3a2\uff08\u6b64\u65f6e\u7684\u521d\u59cb\u503c\u4e3a1\uff0c\u8fd9\u5728\u4e0b\u9762\u7684\u6bb5\u843d\u4e2d\u6709\u4ea4\u4ee3\uff09 \u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u6211\u4eec\u77e5\u9053\uff1a \u4ee5\u53ca \u3002 \u94fe\u5f0f\u6cd5\u5219\u5728\u4e0a\u56fe\u4e2d\u7684\u610f\u4e49\u662f\u4ec0\u4e48\u5462\uff1f\u5176\u5b9e\u4e0d\u96be\u53d1\u73b0\uff0c \u7684\u503c\u7b49\u4e8e\u4ecea\u5230e\u7684\u8def\u5f84\u4e0a\u7684\u504f\u5bfc\u503c\u7684\u4e58\u79ef\uff0c\u800c \u7684\u503c\u7b49\u4e8e\u4eceb\u5230e\u7684\u8def\u5f841( b-c-e )\u4e0a\u7684\u504f\u5bfc\u503c\u7684\u4e58\u79ef**\u52a0\u4e0a**\u8def\u5f842( b-d-e )\u4e0a\u7684\u504f\u5bfc\u503c\u7684\u4e58\u79ef\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u4e0a\u5c42\u8282\u70b9p\u548c\u4e0b\u5c42\u8282\u70b9q\uff0c\u8981\u6c42\u5f97 \uff0c\u9700\u8981\u627e\u5230\u4eceq\u8282\u70b9\u5230p\u8282\u70b9\u7684\u6240\u6709\u8def\u5f84\uff0c\u5e76\u4e14\u5bf9\u6bcf\u6761\u8def\u5f84\uff0c\u6c42\u5f97\u8be5\u8def\u5f84\u4e0a\u7684\u6240\u6709\u504f\u5bfc\u6570\u4e4b\u4e58\u79ef\uff0c\u7136\u540e\u5c06\u6240\u6709\u8def\u5f84\u7684 \u201c\u4e58\u79ef\u201d \u7d2f\u52a0\u8d77\u6765\u624d\u80fd\u5f97\u5230 \u7684\u503c\u3002 NOTE: chain rule\u548ccomputational graph\u7684\u5bf9\u5e94\u5173\u7cfb\u3002\u8fd9\u79cd\u5bf9\u5e94\u5173\u7cfb\u662f\u975e\u5e38\u5de7\u5999\u7684\uff0c\u5b83\u662fbackprop\u5b9e\u73b0\u7684\u5173\u952e\u6240\u5728\uff1a\u5c42\u4e0e\u5c42\u4e4b\u95f4\u662f\u4e58\u6cd5\u5173\u7cfb\uff0c\u540c\u5c42\u4e4b\u95f4\u662f\u76f8\u52a0\u5173\u7cfb\uff1b \u5927\u5bb6\u4e5f\u8bb8\u5df2\u7ecf\u6ce8\u610f\u5230\uff0c\u8fd9\u6837\u505a\u662f\u5341\u5206\u5197\u4f59\u7684\uff0c\u56e0\u4e3a\u5f88\u591a**\u8def\u5f84\u88ab\u91cd\u590d\u8bbf\u95ee\u4e86**\u3002\u6bd4\u5982\u4e0a\u56fe\u4e2d\uff0c a-c-e \u548c b-c-e \u5c31\u90fd\u8d70\u4e86\u8def\u5f84 c-e \u3002\u5bf9\u4e8e\u6743\u503c\u52a8\u5219\u6570\u4e07\u7684\u6df1\u5ea6\u6a21\u578b\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u6837\u7684\u5197\u4f59\u6240\u5bfc\u81f4\u7684\u8ba1\u7b97\u91cf\u662f\u76f8\u5f53\u5927\u7684\u3002 NOTE: \u81ea\u5e95\u5411\u4e0a\u7684\u65b9\u5f0f\u8fdb\u884c\u8ba1\u7b97\uff0c\u5219\u80af\u5b9a\u4f1a\u5bfc\u81f4\u5197\u4f59\u8def\u5f84\u3002 \u540c\u6837\u662f\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\uff0cBP\u7b97\u6cd5\u5219\u673a\u667a\u5730\u907f\u5f00\u4e86\u8fd9\u79cd\u5197\u4f59\uff0c\u5b83\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u8def\u5f84\u53ea\u8bbf\u95ee\u4e00\u6b21\u5c31\u80fd\u6c42\u9876\u70b9\u5bf9\u6240\u6709\u4e0b\u5c42\u8282\u70b9\u7684\u504f\u5bfc\u503c\u3002 \u6b63\u5982\u53cd\u5411\u4f20\u64ad(BP)\u7b97\u6cd5\u7684\u540d\u5b57\u8bf4\u7684\u90a3\u6837\uff0cBP\u7b97\u6cd5\u662f**\u53cd\u5411(\u81ea\u4e0a\u5f80\u4e0b)**\u6765\u5bfb\u627e\u8def\u5f84\u7684\u3002 \u4ece\u6700\u4e0a\u5c42\u7684\u8282\u70b9e\u5f00\u59cb\uff0c \u521d\u59cb\u503c**\u4e3a1\uff0c\u4ee5\u5c42\u4e3a\u5355\u4f4d\u8fdb\u884c\u5904\u7406\u3002\u5bf9\u4e8ee\u7684\u4e0b\u4e00\u5c42\u7684\u6240\u6709\u5b50\u8282\u70b9\uff0c\u5c061\u4e58\u4ee5e\u5230\u67d0\u4e2a\u8282\u70b9\u8def\u5f84\u4e0a\u7684**\u504f\u5bfc\u503c \uff0c\u5e76\u5c06\u7ed3\u679c\u201c \u5806\u653e \u201d\u5728\u8be5\u5b50\u8282\u70b9\u4e2d\u3002\u7b49e\u6240\u5728\u7684\u5c42\u6309\u7167\u8fd9\u6837\u4f20\u64ad\u5b8c\u6bd5\u540e\uff0c\u7b2c\u4e8c\u5c42\u7684\u6bcf\u4e00\u4e2a\u8282\u70b9\u90fd\u201c\u5806\u653e\"\u4e9b\u503c\uff0c\u7136\u540e\u6211\u4eec\u9488\u5bf9\u6bcf\u4e2a\u8282\u70b9\uff0c\u628a\u5b83\u91cc\u9762\u6240\u6709\u201c\u5806\u653e\u201d\u7684\u503c\u6c42\u548c\uff08\u56e0\u4e3a\u8fd9\u4e2a\u8282\u70b9\u662f\u53ef\u80fd\u6709\u591a\u4e2aproceeding node\u7684\uff09\uff0c\u5c31\u5f97\u5230\u4e86\u9876\u70b9e\u5bf9\u8be5\u8282\u70b9\u7684\u504f\u5bfc\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u7b2c\u4e8c\u5c42\u7684\u8282\u70b9\u5404\u81ea\u4f5c\u4e3a\u8d77\u59cb\u9876\u70b9\uff0c \u521d\u59cb\u503c**\u8bbe\u4e3a\u9876\u70b9e\u5bf9\u5b83\u4eec\u7684**\u504f\u5bfc\u503c \uff0c\u4ee5\"\u5c42\"\u4e3a\u5355\u4f4d\u91cd\u590d\u4e0a\u8ff0\u4f20\u64ad\u8fc7\u7a0b\uff0c\u5373\u53ef\u6c42\u51fa\u9876\u70b9e\u5bf9\u6bcf\u4e00\u5c42\u8282\u70b9\u7684\u504f\u5bfc\u6570\u3002 \u4ee5\u4e0a\u56fe\u4e3a\u4f8b\uff0c**\u8282\u70b9c**\u63a5\u53d7**e**\u53d1\u9001\u7684 1*2 1*2 \u5e76\u5806\u653e\u8d77\u6765\uff0c**\u8282\u70b9d**\u63a5\u53d7**e**\u53d1\u9001\u7684 1*3 1*3 \u5e76\u5806\u653e\u8d77\u6765\uff0c\u81f3\u6b64\u7b2c\u4e8c\u5c42\u5b8c\u6bd5\uff0c\u6c42\u51fa\u5404\u8282\u70b9\u603b\u5806\u653e\u91cf\u5e76\u7ee7\u7eed\u5411\u4e0b\u4e00\u5c42\u53d1\u9001\u3002**\u8282\u70b9c**\u5411**a**\u53d1\u9001 2*1 2*1 \u5e76\u5bf9\u5806\u653e\u8d77\u6765\uff0c**\u8282\u70b9c**\u5411**b**\u53d1\u9001 2*1 2*1 \u5e76\u5806\u653e\u8d77\u6765\uff0c**\u8282\u70b9d**\u5411**b**\u53d1\u9001 3*1 3*1 \u5e76\u5806\u653e\u8d77\u6765\uff0c\u81f3\u6b64\u7b2c\u4e09\u5c42\u5b8c\u6bd5\uff0c**\u8282\u70b9a**\u5806\u653e\u8d77\u6765\u7684\u91cf\u4e3a2\uff0c**\u8282\u70b9b**\u5806\u653e\u8d77\u6765\u7684\u91cf\u4e3a 2*1+3*1=5 2*1+3*1=5 , \u5373**\u9876\u70b9e**\u5bf9**b**\u7684\u504f\u5bfc\u6570\u4e3a5. \u4e3e\u4e2a\u4e0d\u592a\u6070\u5f53\u7684\u4f8b\u5b50\uff0c\u5982\u679c\u628a\u4e0a\u56fe\u4e2d\u7684\u7bad\u5934\u8868\u793a\u6b20\u94b1\u7684\u5173\u7cfb\uff0c\u5373c\u2192e\u8868\u793ae\u6b20c\u7684\u94b1\u3002\u4ee5a, b\u4e3a\u4f8b\uff0c\u76f4\u63a5\u8ba1\u7b97e\u5bf9\u5b83\u4eec\u4fe9\u7684\u504f\u5bfc\u76f8\u5f53\u4e8ea, b\u5404\u81ea\u53bb\u8ba8\u85aa\u3002a\u5411c\u8ba8\u85aa\uff0cc\u8bf4e\u6b20\u6211\u94b1\uff0c\u4f60\u5411\u4ed6\u8981\u3002\u4e8e\u662fa\u53c8\u8de8\u8fc7c\u53bb\u627ee\u3002b\u5148\u5411c\u8ba8\u85aa\uff0c\u540c\u6837\u53c8\u8f6c\u5411e\uff0cb\u53c8\u5411d\u8ba8\u85aa\uff0c\u518d\u6b21\u8f6c\u5411e\u3002\u53ef\u4ee5\u770b\u5230\uff0c\u8ffd\u6b3e\u4e4b\u8def\uff0c\u5145\u6ee1\u8270\u8f9b\uff0c\u800c\u4e14\u8fd8\u6709\u91cd\u590d\uff0c\u5373a, b \u90fd\u4ecec\u8f6c\u5411e\u3002 \u800cBP\u7b97\u6cd5\u5c31\u662f\u4e3b\u52a8\u8fd8\u6b3e\u3002e\u628a\u6240\u6b20\u4e4b\u94b1\u8fd8\u7ed9c\uff0cd\u3002c\uff0cd\u6536\u5230\u94b1\uff0c\u4e50\u5475\u5730\u628a\u94b1\u8f6c\u53d1\u7ed9\u4e86a\uff0cb\uff0c\u7686\u5927\u6b22\u559c\u3002 \u3010\u53c2\u8003\u6587\u732e\u3011 [1] \u6280\u672f\u5411\uff1a\u4e00\u6587\u8bfb\u61c2\u5377\u79ef\u795e\u7ecf\u7f51\u7edcCNN [2] Gradient [3] http://colah.github.io/posts/2015-08-Backprop/ \u5176\u4ed6\u63a8\u8350\u7f51\u9875\uff1a \\1. tensorflow.org \u7684\u9875\u9762 \\2. Neural networks and deep learning YE Y\u7684\u56de\u7b54 \u9996\u5148\u8bf4\u8fd9\u4e2a\u56fe\u89e3\u7684\u4f18\u70b9\uff1a\u5148\u5f62\u8c61\u8bf4\u660e\u4e86**forward-propagation**\uff0c\u7136\u540e\u8bf4\u660e\u4e86**error backward-propagation**\uff0c\u6700\u540e\u6839\u636e**\u8bef\u5dee**\u548c**\u68af\u5ea6**\u66f4\u65b0\u6743\u91cd\u3002\u6ca1\u9519\u8fd9\u662f**backprop**\uff0c\u53c8\u975e\u5e38\u76f4\u89c2\uff0c\u4f46\u662f\u4ece\u524d\u7684backprop\u4e86\u3002 backprop\u7684\u53d1\u5c55\u8def\u7ebf\u5927\u6982\u662f\uff0c1974\u5e74\u6709\u4e2aHarvard\u535a\u58eb\u751fPaul Werbos\u9996\u6b21\u63d0\u51fa\u4e86backprop\uff0c\u4e0d\u8fc7\u6ca1\u4eba\u7406\u4ed6\uff0c1986\u5e74Rumelhart\u548cHinton\u4e00\u8d77\u91cd\u65b0\u53d1\u73b0\u4e86backprop\uff0c\u5e76\u4e14\u6709\u6548\u8bad\u7ec3\u4e86\u4e00\u4e9b\u6d45\u5c42\u7f51\u7edc\uff0c\u4e00\u4e0b\u5b50\u5f00\u59cb\u6709\u4e86\u540d\u6c14\u3002\u90a3\u4e2a\u65f6\u5019\u7684backprop\u4ece\u73b0\u5728\u770b\u6765\u5e76\u4e0d\u662f\u4e2a\u5f88\u6e05\u6670\u7684\u6982\u5ff5\uff0c\u628a\u68af\u5ea6\u548c\u66f4\u65b0\u4e00\u5757\u6253\u5305\u4e86\uff0c\u4ece\u8fd9\u70b9\u770b\u6765\u548c\u6211\u8d34\u51fa\u6765\u7684\u56fe\u662f\u4e00\u56de\u4e8b\u3002\u5982\u679c\u6709\u770b\u8fc7mitchell\u673a\u5668\u5b66\u4e60\u6559\u6750\u7684\u540c\u5b66\u53ef\u80fd\u4e5f\u4f1a\u89c9\u5f97\u4e0b\u9762\u7684\u56fe\u773c\u719f\u3002 \u968f\u7740\u795e\u7ecf\u7f51\u7edc\u7684\u7ee7\u7eed\u53d1\u5c55\uff0c\u5230\u4e86\u6df1\u5ea6\u5b66\u4e60\u5927\u884c\u5176\u9053\u7684\u4eca\u5929\uff0c\u66f4\u65b0\u6743\u503c\u7684\u601d\u8def\u5176\u5b9e\u53d8\u5f97\u66f4\u7b80\u5355\u7c97\u66b4\u4e86\u3002\u6982\u62ec\u4e00\u4e0b\u5c31\u662f\uff0c\u628a\u539f\u6765\u6253\u5305\u5f0f\u7684\u505a\u6cd5\u62c6\u5f00\u6210\u4e86**1\uff09\u6c42\u68af\u5ea6**\uff1b2\uff09\u68af\u5ea6\u4e0b\u964d\u3002\u6240\u4ee5\u73b0\u5728\u6211\u4eec\u518d\u63d0\u5230backprop\uff0c \u4e00\u822c\u53ea\u662f\u6307\u7b2c\u4e00\u6b65\uff1a\u6c42\u68af\u5ea6 \u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u597d\u591a\u7b54\u6848\u76f4\u63a5\u8bf4\u5c31\u662f\u4e2a\u94fe\u5f0f\u6cd5\u5219\uff0c\u56e0\u4e3a\u786e\u5b9e\u5c31\u662f\u94fe\u5f0f\u6cd5\u5219\u3002 \u4e0d\u8fc7\u4e2a\u4eba\u89c9\u5f97\u8fd8\u662f\u6709\u53ef\u4ee5\u76f4\u89c2\u7406\u89e3\u7684\u4e00\u4e9b\u70b9\uff1a 1\uff09\u94fe\u5f0f\u6cd5\u5219\u7684\u76f4\u89c2\u7406\u89e3\u7684\uff0c\u4e4b\u6240\u4ee5\u53ef\u4ee5\u94fe\u5f0f\u6cd5\u5219\uff0c\u662f\u56e0\u4e3a\u68af\u5ea6\u76f4\u89c2\u4e0a\u7406\u89e3\u5c31\u662f\u4e00\u9636\u8fd1\u4f3c\uff0c\u6240\u4ee5\u68af\u5ea6\u53ef\u4ee5\u7406\u89e3\u6210\u67d0\u4e2a\u53d8\u91cf\u6216\u67d0\u4e2a\u4e2d\u95f4\u53d8\u91cf**\u5bf9\u8f93\u51fa\u5f71\u54cd\u7684\u654f\u611f\u5ea6\u7684\u7cfb\u6570** \uff0c\u8fd9\u79cd\u7406\u89e3\u5728\u4e00\u7ef4\u60c5\u51b5\u4e0b\u7684\u76f4\u89c2\u5e2e\u52a9\u53ef\u80fd\u5e76\u4e0d\u662f\u5f88\u5927\uff0c\u4f46\u662f\u5230\u4e86\u9ad8\u7ef4\u60c5\u51b5\uff0c\u5f53**\u94fe\u5f0f\u6cd5\u5219**\u4ece\u4e58\u6cd5\u53d8\u6210\u4e86**Jacobian\u77e9\u9635\u4e58\u6cd5**\u7684\u65f6\u5019\uff0c\u8fd9\u4e2a\u7406\u89e3\u8d77\u6765\u5c31\u5f62\u8c61\u591a\u4e86\u3002\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u94fe\u5f0f\u6cd5\u5219\u6070\u597d\u90fd\u51e0\u4e4e\u662f\u9ad8\u7ef4\u7684\u3002 2\uff09Computational graph\u3002\u6700\u9ad8\u7968\u7b54\u6848\u548c @\u9f9a\u79b9pangolulu \u7684\u7b54\u6848\u4e2d\u90fd\u6709\u63d0\u5230\uff0c\u5c31\u4e0d\u8d58\u8ff0\uff0c\u5176\u5b9e\u5c31\u662f**\u8ba1\u7b97\u4ee3\u6570**\u4e2d\u7684\u4e00\u4e2a\u6700\u57fa\u7840\u529e\u6cd5\uff0c\u4ece\u8ba1\u7b97\u673a\u7684\u89d2\u5ea6\u6765\u770b\u8fd8\u6709\u70b9**\u52a8\u6001\u89c4\u5212**\u7684\u610f\u601d\u3002\u5176\u4f18\u70b9\u662f\u8868\u8fbe\u5f0f\u7ed9\u5b9a\u7684\u60c5\u51b5\u4e0b\u5bf9**\u590d\u5408\u51fd\u6570**\u4e2d\u6240\u6709\u53d8\u91cf\u8fdb\u884c**\u5feb\u901f\u6c42\u5bfc**\uff0c\u8fd9\u6b63\u597d\u662f\u795e\u7ecf\u7f51\u7edc\u5c24\u5176\u662f\u6df1\u5ea6\u5b66\u4e60\u7684\u573a\u666f\u3002\u73b0\u5728\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u91cc\u7684\u6c42\u5bfc\u4e5f\u90fd\u662f\u57fa\u4e8eComputational Graph\uff0c\u6bd4\u5982theano\uff0ctorch\u548ctensorflow\uff0cCaffe\u4e5f\u53ef\u4ee5\u770b\u505a\u662fcomputaiona graph\uff0c\u53ea\u4e0d\u8fc7node\u662flayer\u3002 \u603b\u7ed3\uff1a\u56fe\u4e2d\u7684\u786e\u5b9e\u662fbackprop\uff0c\u4f46\u4e0d\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684backprop\uff0c\u4e0d\u8fc7backward\u7684\u5927\u4f53\u601d\u60f3\u662f\u4e00\u6837\u7684\uff0c\u6bd5\u7adf\u8bef\u5dee\u6ca1\u6cd5\u4ece\u524d\u5f80\u540e\u8ba1\u7b97\u554a\u3002 \u4ee5\u4e0b\u662f\u539f\u56de\u7b54\uff1a In the next algorithm step the output signal of the network y is compared with the desired output value (the target), which is found in training data set. The difference is called error signal \\delta \\delta of output layer neuron . It is impossible to compute error signal for internal neurons directly, because output values of these neurons are unknown. For many years the effective method for training multiplayer networks has been unknown. Only in the middle eighties the backpropagation algorithm has been worked out. The idea is to propagate error signal d (computed in single teaching step) back to all neurons, which output signals were input for discussed neuron. The weights' coefficients w_{mn} w_{mn} used to propagate errors back are equal to this used during computing output value. Only the direction of data flow is changed (signals are propagated from output to inputs one after the other). This technique is used for all network layers. If propagated errors came from few neurons they are added. The illustration is below: When the error signal for each neuron is computed, the weights coefficients of each neuron input node may be modified. In formulas below df(e)/de represents derivative of neuron activation function (which weights are modified). Coefficient \\eta \\eta affects network teaching speed. There are a few techniques to select this parameter. The first method is to start teaching process with large value of the parameter. While weights coefficients are being established the parameter is being decreased gradually. The second, more complicated, method starts teaching with small parameter value. During the teaching process the parameter is being increased when the teaching is advanced and then decreased again in the final stage. Starting teaching process with low parameter value enables to determine weights coefficients signs. References Ryszard Tadeusiewcz \"Sieci neuronowe\", Krak\u00f3w 1992 http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html","title":"zhihu-Back-Propagation"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/zhihu-Back-Propagation/#zhihu#backpropagation","text":"","title":"zhihu \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/zhihu-Back-Propagation/#anonymous","text":"BackPropagation\u7b97\u6cd5\u662f\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u4e2d\u4e3e\u8db3\u8f7b\u91cd\u7684\u7b97\u6cd5\u3002 \u7b80\u5355\u7684\u7406\u89e3\uff0c\u5b83\u7684\u786e\u5c31\u662f**\u590d\u5408\u51fd\u6570\u7684\u5fae\u79ef\u5206\u94fe\u5f0f\u6cd5\u5219**\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u8fd0\u7b97\u4e2d\u7684\u610f\u4e49\u6bd4**\u94fe\u5f0f\u6cd5\u5219**\u8981\u5927\u7684\u591a\u3002 \u8981\u56de\u7b54\u9898\u4e3b\u8fd9\u4e2a\u95ee\u9898\u201c\u5982\u4f55\u76f4\u89c2\u7684\u89e3\u91caback propagation\u7b97\u6cd5\uff1f\u201d \u9700\u8981\u5148\u76f4\u89c2\u7406\u89e3**\u591a\u5c42\u795e\u7ecf\u7f51\u7edc**\u7684\u8bad\u7ec3\u3002 \u673a\u5668\u5b66\u4e60**\u53ef\u4ee5\u770b\u505a\u662f**\u6570\u7406\u7edf\u8ba1**\u7684\u4e00\u4e2a\u5e94\u7528\uff0c\u5728**\u6570\u7406\u7edf\u8ba1**\u4e2d\u4e00\u4e2a\u5e38\u89c1\u7684\u4efb\u52a1\u5c31\u662f**\u62df\u5408 \uff0c\u4e5f\u5c31\u662f\u7ed9\u5b9a\u4e00\u4e9b\u6837\u672c\u70b9\uff0c\u7528\u5408\u9002\u7684\u66f2\u7ebf\u63ed\u793a\u8fd9\u4e9b\u6837\u672c\u70b9\u968f\u7740\u81ea\u53d8\u91cf\u7684\u53d8\u5316\u5173\u7cfb\u3002 \u6df1\u5ea6\u5b66\u4e60**\u540c\u6837\u4e5f\u662f\u4e3a\u4e86\u8fd9\u4e2a\u76ee\u7684\uff0c\u53ea\u4e0d\u8fc7\u6b64\u65f6\uff0c**\u6837\u672c\u70b9**\u4e0d\u518d\u9650\u5b9a\u4e3a (x, y) (x, y) \u70b9\u5bf9\uff0c\u800c\u53ef\u4ee5\u662f\u7531\u5411\u91cf\u3001\u77e9\u9635\u7b49\u7b49\u7ec4\u6210\u7684\u5e7f\u4e49\u70b9\u5bf9 (X,Y) (X,Y) \u3002\u800c\u6b64\u65f6\uff0c (X,Y) (X,Y) \u4e4b\u95f4\u7684\u5173\u7cfb\u4e5f\u53d8\u5f97\u5341\u5206\u590d\u6742\uff0c\u4e0d\u592a\u53ef\u80fd\u7528\u4e00\u4e2a\u7b80\u5355\u51fd\u6570\u8868\u793a\u3002\u7136\u800c\uff0c\u4eba\u4eec\u53d1\u73b0\u53ef\u4ee5\u7528**\u591a\u5c42\u795e\u7ecf\u7f51\u7edc**\u6765\u8868\u793a\u8fd9\u6837\u7684\u5173\u7cfb\uff0c\u800c**\u591a\u5c42\u795e\u7ecf\u7f51\u7edc**\u7684\u672c\u8d28\u5c31\u662f\u4e00\u4e2a**\u591a\u5c42\u590d\u5408\u7684\u51fd\u6570 \u3002\u501f\u7528\u7f51\u4e0a\u627e\u5230\u7684\u4e00\u5e45\u56fe[1]\uff0c\u6765\u76f4\u89c2\u63cf\u7ed8\u4e00\u4e0b\u8fd9\u79cd\u590d\u5408\u5173\u7cfb\u3002 \u601d\u8003\uff1a\u8fd9\u4e2a\u56fe\u662f\u5b58\u5728\u9519\u8bef\u7684\uff0c\u56fe\u4e2d a_1^{(2)} a_1^{(2)} \u5176\u5b9e\u5e94\u8be5\u753b\u5728\u5706\u5708\u4e2d\uff0c\u800c\u4e0d\u662f\u753b\u5728\u8fde\u7ebf\u4e0a\u3002\u8fd9\u5176\u5b9e\u662f\u8ba1\u7b97\u56fe\u3002 \u5176\u5bf9\u5e94\u7684\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a \u4e0a\u9762\u5f0f\u4e2d\u7684 W_{ij} W_{ij} \u5c31\u662f\u76f8\u90bb\u4e24\u5c42\u795e\u7ecf\u5143\u4e4b\u95f4\u7684\u6743\u503c\uff0c\u5b83\u4eec\u5c31\u662f\u6df1\u5ea6\u5b66\u4e60\u9700\u8981\u5b66\u4e60\u7684**\u53c2\u6570**\uff0c\u4e5f\u5c31\u76f8\u5f53\u4e8e\u76f4\u7ebf\u62df\u5408 y=k*x+b y=k*x+b \u4e2d\u7684\u5f85\u6c42\u53c2\u6570 k k \u548c b b \u3002 \u548c**\u76f4\u7ebf\u62df\u5408**\u4e00\u6837\uff0c \u6df1\u5ea6\u5b66\u4e60**\u7684\u8bad\u7ec3\u4e5f\u6709\u4e00\u4e2a**\u76ee\u6807\u51fd\u6570 \uff0c\u8fd9\u4e2a**\u76ee\u6807\u51fd\u6570**\u5b9a\u4e49\u4e86\u4ec0\u4e48\u6837\u7684\u53c2\u6570\u624d\u7b97\u4e00\u7ec4\u201c\u597d\u53c2\u6570\u201d\uff0c\u4e0d\u8fc7\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u4e00\u822c\u662f\u91c7\u7528**\u6210\u672c\u51fd\u6570\uff08cost function\uff09 \uff0c\u7136\u540e\uff0c\u8bad\u7ec3\u76ee\u6807\u5c31\u662f\u901a\u8fc7\u8c03\u6574\u6bcf\u4e00\u4e2a\u6743\u503c W_{ij} W_{ij} \u6765\u4f7f\u5f97**cost**\u8fbe\u5230\u6700\u5c0f\u3002**cost\u51fd\u6570**\u4e5f\u53ef\u4ee5\u770b\u6210\u662f\u7531\u6240\u6709\u5f85\u6c42\u6743\u503c W_{ij} W_{ij} \u4e3a\u81ea\u53d8\u91cf\u7684**\u590d\u5408\u51fd\u6570 \uff0c\u800c\u4e14\u57fa\u672c\u4e0a\u662f\u975e\u51f8\u7684\uff0c\u5373\u542b\u6709\u8bb8\u591a**\u5c40\u90e8\u6700\u5c0f\u503c**\u3002\u4f46\u5b9e\u9645\u4e2d\u53d1\u73b0\uff0c\u91c7\u7528\u6211\u4eec\u5e38\u7528\u7684**\u68af\u5ea6\u4e0b\u964d\u6cd5**\u5c31\u53ef\u4ee5\u6709\u6548\u7684\u6c42\u89e3\u6700\u5c0f\u5316cost\u51fd\u6570\u7684\u95ee\u9898\u3002 \u68af\u5ea6\u4e0b\u964d\u6cd5\u9700\u8981\u7ed9\u5b9a\u4e00\u4e2a\u521d\u59cb\u70b9\uff0c\u5e76\u6c42\u51fa\u8be5\u70b9\u7684**\u68af\u5ea6\u5411\u91cf**\uff0c\u7136\u540e\u4ee5**\u8d1f\u68af\u5ea6\u65b9\u5411**\u4e3a\u641c\u7d22\u65b9\u5411\uff0c\u4ee5\u4e00\u5b9a\u7684**\u6b65\u957f**\u8fdb\u884c\u641c\u7d22\uff0c\u4ece\u800c\u786e\u5b9a\u4e0b\u4e00\u4e2a\u8fed\u4ee3\u70b9\uff0c\u518d\u8ba1\u7b97\u8be5\u65b0\u7684\u68af\u5ea6\u65b9\u5411\uff0c\u5982\u6b64\u91cd\u590d\u76f4\u5230cost\u6536\u655b\u3002\u90a3\u4e48\u5982\u4f55\u8ba1\u7b97\u68af\u5ea6\u5462\uff1f \u5047\u8bbe\u6211\u4eec\u628a**cost\u51fd\u6570**\u8868\u793a\u4e3a H(W_{11},W_{12}, \\dots ,W_{ij}, \\dots, W_{mn}) H(W_{11},W_{12}, \\dots ,W_{ij}, \\dots, W_{mn}) , \u90a3\u4e48\u5b83\u7684\u68af\u5ea6\u5411\u91cf[2]\u5c31\u7b49\u4e8e , \u5176\u4e2d \u8868\u793a\u6b63\u4ea4\u5355\u4f4d\u5411\u91cf\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u6c42\u51facost\u51fd\u6570H\u5bf9\u6bcf\u4e00\u4e2a\u6743\u503cWij\u7684**\u504f\u5bfc\u6570**\u3002\u800c**BP\u7b97\u6cd5\u6b63\u662f\u7528\u6765\u6c42\u89e3\u8fd9\u79cd\u591a\u5c42\u590d\u5408\u51fd\u6570\u7684\u6240\u6709\u53d8\u91cf\u7684\u504f\u5bfc\u6570\u7684\u5229\u5668**\u3002 \u6211\u4eec\u4ee5\u6c42 e=(a+b)*(b+1) e=(a+b)*(b+1) \u7684\u504f\u5bfc[3]\u4e3a\u4f8b\u3002 \u5b83\u7684\u590d\u5408\u5173\u7cfb\u753b\u51fa\u56fe\u53ef\u4ee5\u8868\u793a\u5982\u4e0b\uff1a NOTE: e=(a+b)*(b+1) e=(a+b)*(b+1) \u662f\u4e00\u4e2a\u4e8c\u5143\u51fd\u6570\uff0c\u81ea\u53d8\u91cf\u4e3a a \uff0c b \uff0c\u5b83\u53ef\u4ee5\u770b\u51fa\u662f\u7531\u4e24\u4e2a\u51fd\u6570\u590d\u5408\u800c\u6210\uff1a c=a+b c=a+b \uff0c\u548c d=b+1 d=b+1 NOTE: \u5728machine learning\u4e2d\uff0c\u9700\u8981\u4f7f\u7528\u7ed3\u6784\u5316\u601d\u7ef4\u6765\u601d\u8003\u51fd\u6570\uff0c\u6bd4\u5982 e=(a+b)*(b+1) e=(a+b)*(b+1) \uff0c\u4e0a\u56fe\u5c31\u662f\u5b83\u7684\u56fe\u7ed3\u6784\u3002\u8fd9\u79cd\u56fe\u7ed3\u6784\u5c31\u662f\u57286.5.1 Computational Graphs\u4e2d\u63cf\u8ff0\u7684computational graph\u3002 \u5728\u56fe\u4e2d\uff0c\u5f15\u5165\u4e86\u4e2d\u95f4\u53d8\u91cf c c , d d \u3002 \u4e3a\u4e86\u6c42\u51fa a=2, b=1 a=2, b=1 \u65f6\uff0c e e \u7684\u68af\u5ea6\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u5229\u7528\u504f\u5bfc\u6570\u7684\u5b9a\u4e49\u6c42\u51fa\u4e0d\u540c\u5c42\u4e4b\u95f4\u76f8\u90bb\u8282\u70b9\u7684\u504f\u5bfc\u5173\u7cfb\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002 NOTE: \u51fd\u6570 e=c*d e=c*d \uff0c\u5f53 a=2,b=1 a=2,b=1 \uff0c\u5219 d=b+1=2 d=b+1=2 \uff0c\u5219\u6b64\u65f6\u51fd\u6570\u7684\u8868\u8fbe\u5f0f\u4e3a e=2*c e=2*c \uff0c\u5219 e e \u5bf9 c c \u7684\u5bfc\u6570\u4e3a2\uff08\u6b64\u65f6e\u7684\u521d\u59cb\u503c\u4e3a1\uff0c\u8fd9\u5728\u4e0b\u9762\u7684\u6bb5\u843d\u4e2d\u6709\u4ea4\u4ee3\uff09 \u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u6211\u4eec\u77e5\u9053\uff1a \u4ee5\u53ca \u3002 \u94fe\u5f0f\u6cd5\u5219\u5728\u4e0a\u56fe\u4e2d\u7684\u610f\u4e49\u662f\u4ec0\u4e48\u5462\uff1f\u5176\u5b9e\u4e0d\u96be\u53d1\u73b0\uff0c \u7684\u503c\u7b49\u4e8e\u4ecea\u5230e\u7684\u8def\u5f84\u4e0a\u7684\u504f\u5bfc\u503c\u7684\u4e58\u79ef\uff0c\u800c \u7684\u503c\u7b49\u4e8e\u4eceb\u5230e\u7684\u8def\u5f841( b-c-e )\u4e0a\u7684\u504f\u5bfc\u503c\u7684\u4e58\u79ef**\u52a0\u4e0a**\u8def\u5f842( b-d-e )\u4e0a\u7684\u504f\u5bfc\u503c\u7684\u4e58\u79ef\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u4e0a\u5c42\u8282\u70b9p\u548c\u4e0b\u5c42\u8282\u70b9q\uff0c\u8981\u6c42\u5f97 \uff0c\u9700\u8981\u627e\u5230\u4eceq\u8282\u70b9\u5230p\u8282\u70b9\u7684\u6240\u6709\u8def\u5f84\uff0c\u5e76\u4e14\u5bf9\u6bcf\u6761\u8def\u5f84\uff0c\u6c42\u5f97\u8be5\u8def\u5f84\u4e0a\u7684\u6240\u6709\u504f\u5bfc\u6570\u4e4b\u4e58\u79ef\uff0c\u7136\u540e\u5c06\u6240\u6709\u8def\u5f84\u7684 \u201c\u4e58\u79ef\u201d \u7d2f\u52a0\u8d77\u6765\u624d\u80fd\u5f97\u5230 \u7684\u503c\u3002 NOTE: chain rule\u548ccomputational graph\u7684\u5bf9\u5e94\u5173\u7cfb\u3002\u8fd9\u79cd\u5bf9\u5e94\u5173\u7cfb\u662f\u975e\u5e38\u5de7\u5999\u7684\uff0c\u5b83\u662fbackprop\u5b9e\u73b0\u7684\u5173\u952e\u6240\u5728\uff1a\u5c42\u4e0e\u5c42\u4e4b\u95f4\u662f\u4e58\u6cd5\u5173\u7cfb\uff0c\u540c\u5c42\u4e4b\u95f4\u662f\u76f8\u52a0\u5173\u7cfb\uff1b \u5927\u5bb6\u4e5f\u8bb8\u5df2\u7ecf\u6ce8\u610f\u5230\uff0c\u8fd9\u6837\u505a\u662f\u5341\u5206\u5197\u4f59\u7684\uff0c\u56e0\u4e3a\u5f88\u591a**\u8def\u5f84\u88ab\u91cd\u590d\u8bbf\u95ee\u4e86**\u3002\u6bd4\u5982\u4e0a\u56fe\u4e2d\uff0c a-c-e \u548c b-c-e \u5c31\u90fd\u8d70\u4e86\u8def\u5f84 c-e \u3002\u5bf9\u4e8e\u6743\u503c\u52a8\u5219\u6570\u4e07\u7684\u6df1\u5ea6\u6a21\u578b\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u6837\u7684\u5197\u4f59\u6240\u5bfc\u81f4\u7684\u8ba1\u7b97\u91cf\u662f\u76f8\u5f53\u5927\u7684\u3002 NOTE: \u81ea\u5e95\u5411\u4e0a\u7684\u65b9\u5f0f\u8fdb\u884c\u8ba1\u7b97\uff0c\u5219\u80af\u5b9a\u4f1a\u5bfc\u81f4\u5197\u4f59\u8def\u5f84\u3002 \u540c\u6837\u662f\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\uff0cBP\u7b97\u6cd5\u5219\u673a\u667a\u5730\u907f\u5f00\u4e86\u8fd9\u79cd\u5197\u4f59\uff0c\u5b83\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u8def\u5f84\u53ea\u8bbf\u95ee\u4e00\u6b21\u5c31\u80fd\u6c42\u9876\u70b9\u5bf9\u6240\u6709\u4e0b\u5c42\u8282\u70b9\u7684\u504f\u5bfc\u503c\u3002 \u6b63\u5982\u53cd\u5411\u4f20\u64ad(BP)\u7b97\u6cd5\u7684\u540d\u5b57\u8bf4\u7684\u90a3\u6837\uff0cBP\u7b97\u6cd5\u662f**\u53cd\u5411(\u81ea\u4e0a\u5f80\u4e0b)**\u6765\u5bfb\u627e\u8def\u5f84\u7684\u3002 \u4ece\u6700\u4e0a\u5c42\u7684\u8282\u70b9e\u5f00\u59cb\uff0c \u521d\u59cb\u503c**\u4e3a1\uff0c\u4ee5\u5c42\u4e3a\u5355\u4f4d\u8fdb\u884c\u5904\u7406\u3002\u5bf9\u4e8ee\u7684\u4e0b\u4e00\u5c42\u7684\u6240\u6709\u5b50\u8282\u70b9\uff0c\u5c061\u4e58\u4ee5e\u5230\u67d0\u4e2a\u8282\u70b9\u8def\u5f84\u4e0a\u7684**\u504f\u5bfc\u503c \uff0c\u5e76\u5c06\u7ed3\u679c\u201c \u5806\u653e \u201d\u5728\u8be5\u5b50\u8282\u70b9\u4e2d\u3002\u7b49e\u6240\u5728\u7684\u5c42\u6309\u7167\u8fd9\u6837\u4f20\u64ad\u5b8c\u6bd5\u540e\uff0c\u7b2c\u4e8c\u5c42\u7684\u6bcf\u4e00\u4e2a\u8282\u70b9\u90fd\u201c\u5806\u653e\"\u4e9b\u503c\uff0c\u7136\u540e\u6211\u4eec\u9488\u5bf9\u6bcf\u4e2a\u8282\u70b9\uff0c\u628a\u5b83\u91cc\u9762\u6240\u6709\u201c\u5806\u653e\u201d\u7684\u503c\u6c42\u548c\uff08\u56e0\u4e3a\u8fd9\u4e2a\u8282\u70b9\u662f\u53ef\u80fd\u6709\u591a\u4e2aproceeding node\u7684\uff09\uff0c\u5c31\u5f97\u5230\u4e86\u9876\u70b9e\u5bf9\u8be5\u8282\u70b9\u7684\u504f\u5bfc\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u7b2c\u4e8c\u5c42\u7684\u8282\u70b9\u5404\u81ea\u4f5c\u4e3a\u8d77\u59cb\u9876\u70b9\uff0c \u521d\u59cb\u503c**\u8bbe\u4e3a\u9876\u70b9e\u5bf9\u5b83\u4eec\u7684**\u504f\u5bfc\u503c \uff0c\u4ee5\"\u5c42\"\u4e3a\u5355\u4f4d\u91cd\u590d\u4e0a\u8ff0\u4f20\u64ad\u8fc7\u7a0b\uff0c\u5373\u53ef\u6c42\u51fa\u9876\u70b9e\u5bf9\u6bcf\u4e00\u5c42\u8282\u70b9\u7684\u504f\u5bfc\u6570\u3002 \u4ee5\u4e0a\u56fe\u4e3a\u4f8b\uff0c**\u8282\u70b9c**\u63a5\u53d7**e**\u53d1\u9001\u7684 1*2 1*2 \u5e76\u5806\u653e\u8d77\u6765\uff0c**\u8282\u70b9d**\u63a5\u53d7**e**\u53d1\u9001\u7684 1*3 1*3 \u5e76\u5806\u653e\u8d77\u6765\uff0c\u81f3\u6b64\u7b2c\u4e8c\u5c42\u5b8c\u6bd5\uff0c\u6c42\u51fa\u5404\u8282\u70b9\u603b\u5806\u653e\u91cf\u5e76\u7ee7\u7eed\u5411\u4e0b\u4e00\u5c42\u53d1\u9001\u3002**\u8282\u70b9c**\u5411**a**\u53d1\u9001 2*1 2*1 \u5e76\u5bf9\u5806\u653e\u8d77\u6765\uff0c**\u8282\u70b9c**\u5411**b**\u53d1\u9001 2*1 2*1 \u5e76\u5806\u653e\u8d77\u6765\uff0c**\u8282\u70b9d**\u5411**b**\u53d1\u9001 3*1 3*1 \u5e76\u5806\u653e\u8d77\u6765\uff0c\u81f3\u6b64\u7b2c\u4e09\u5c42\u5b8c\u6bd5\uff0c**\u8282\u70b9a**\u5806\u653e\u8d77\u6765\u7684\u91cf\u4e3a2\uff0c**\u8282\u70b9b**\u5806\u653e\u8d77\u6765\u7684\u91cf\u4e3a 2*1+3*1=5 2*1+3*1=5 , \u5373**\u9876\u70b9e**\u5bf9**b**\u7684\u504f\u5bfc\u6570\u4e3a5. \u4e3e\u4e2a\u4e0d\u592a\u6070\u5f53\u7684\u4f8b\u5b50\uff0c\u5982\u679c\u628a\u4e0a\u56fe\u4e2d\u7684\u7bad\u5934\u8868\u793a\u6b20\u94b1\u7684\u5173\u7cfb\uff0c\u5373c\u2192e\u8868\u793ae\u6b20c\u7684\u94b1\u3002\u4ee5a, b\u4e3a\u4f8b\uff0c\u76f4\u63a5\u8ba1\u7b97e\u5bf9\u5b83\u4eec\u4fe9\u7684\u504f\u5bfc\u76f8\u5f53\u4e8ea, b\u5404\u81ea\u53bb\u8ba8\u85aa\u3002a\u5411c\u8ba8\u85aa\uff0cc\u8bf4e\u6b20\u6211\u94b1\uff0c\u4f60\u5411\u4ed6\u8981\u3002\u4e8e\u662fa\u53c8\u8de8\u8fc7c\u53bb\u627ee\u3002b\u5148\u5411c\u8ba8\u85aa\uff0c\u540c\u6837\u53c8\u8f6c\u5411e\uff0cb\u53c8\u5411d\u8ba8\u85aa\uff0c\u518d\u6b21\u8f6c\u5411e\u3002\u53ef\u4ee5\u770b\u5230\uff0c\u8ffd\u6b3e\u4e4b\u8def\uff0c\u5145\u6ee1\u8270\u8f9b\uff0c\u800c\u4e14\u8fd8\u6709\u91cd\u590d\uff0c\u5373a, b \u90fd\u4ecec\u8f6c\u5411e\u3002 \u800cBP\u7b97\u6cd5\u5c31\u662f\u4e3b\u52a8\u8fd8\u6b3e\u3002e\u628a\u6240\u6b20\u4e4b\u94b1\u8fd8\u7ed9c\uff0cd\u3002c\uff0cd\u6536\u5230\u94b1\uff0c\u4e50\u5475\u5730\u628a\u94b1\u8f6c\u53d1\u7ed9\u4e86a\uff0cb\uff0c\u7686\u5927\u6b22\u559c\u3002 \u3010\u53c2\u8003\u6587\u732e\u3011 [1] \u6280\u672f\u5411\uff1a\u4e00\u6587\u8bfb\u61c2\u5377\u79ef\u795e\u7ecf\u7f51\u7edcCNN [2] Gradient [3] http://colah.github.io/posts/2015-08-Backprop/ \u5176\u4ed6\u63a8\u8350\u7f51\u9875\uff1a \\1. tensorflow.org \u7684\u9875\u9762 \\2. Neural networks and deep learning","title":"Anonymous\u7684\u56de\u7b54"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/6-Deep-Feedforward-Networks/6.5-Back-Propagation-and-Other-Differentiation-algorithms/Back-Propagation/zhihu-Back-Propagation/#ye#y","text":"\u9996\u5148\u8bf4\u8fd9\u4e2a\u56fe\u89e3\u7684\u4f18\u70b9\uff1a\u5148\u5f62\u8c61\u8bf4\u660e\u4e86**forward-propagation**\uff0c\u7136\u540e\u8bf4\u660e\u4e86**error backward-propagation**\uff0c\u6700\u540e\u6839\u636e**\u8bef\u5dee**\u548c**\u68af\u5ea6**\u66f4\u65b0\u6743\u91cd\u3002\u6ca1\u9519\u8fd9\u662f**backprop**\uff0c\u53c8\u975e\u5e38\u76f4\u89c2\uff0c\u4f46\u662f\u4ece\u524d\u7684backprop\u4e86\u3002 backprop\u7684\u53d1\u5c55\u8def\u7ebf\u5927\u6982\u662f\uff0c1974\u5e74\u6709\u4e2aHarvard\u535a\u58eb\u751fPaul Werbos\u9996\u6b21\u63d0\u51fa\u4e86backprop\uff0c\u4e0d\u8fc7\u6ca1\u4eba\u7406\u4ed6\uff0c1986\u5e74Rumelhart\u548cHinton\u4e00\u8d77\u91cd\u65b0\u53d1\u73b0\u4e86backprop\uff0c\u5e76\u4e14\u6709\u6548\u8bad\u7ec3\u4e86\u4e00\u4e9b\u6d45\u5c42\u7f51\u7edc\uff0c\u4e00\u4e0b\u5b50\u5f00\u59cb\u6709\u4e86\u540d\u6c14\u3002\u90a3\u4e2a\u65f6\u5019\u7684backprop\u4ece\u73b0\u5728\u770b\u6765\u5e76\u4e0d\u662f\u4e2a\u5f88\u6e05\u6670\u7684\u6982\u5ff5\uff0c\u628a\u68af\u5ea6\u548c\u66f4\u65b0\u4e00\u5757\u6253\u5305\u4e86\uff0c\u4ece\u8fd9\u70b9\u770b\u6765\u548c\u6211\u8d34\u51fa\u6765\u7684\u56fe\u662f\u4e00\u56de\u4e8b\u3002\u5982\u679c\u6709\u770b\u8fc7mitchell\u673a\u5668\u5b66\u4e60\u6559\u6750\u7684\u540c\u5b66\u53ef\u80fd\u4e5f\u4f1a\u89c9\u5f97\u4e0b\u9762\u7684\u56fe\u773c\u719f\u3002 \u968f\u7740\u795e\u7ecf\u7f51\u7edc\u7684\u7ee7\u7eed\u53d1\u5c55\uff0c\u5230\u4e86\u6df1\u5ea6\u5b66\u4e60\u5927\u884c\u5176\u9053\u7684\u4eca\u5929\uff0c\u66f4\u65b0\u6743\u503c\u7684\u601d\u8def\u5176\u5b9e\u53d8\u5f97\u66f4\u7b80\u5355\u7c97\u66b4\u4e86\u3002\u6982\u62ec\u4e00\u4e0b\u5c31\u662f\uff0c\u628a\u539f\u6765\u6253\u5305\u5f0f\u7684\u505a\u6cd5\u62c6\u5f00\u6210\u4e86**1\uff09\u6c42\u68af\u5ea6**\uff1b2\uff09\u68af\u5ea6\u4e0b\u964d\u3002\u6240\u4ee5\u73b0\u5728\u6211\u4eec\u518d\u63d0\u5230backprop\uff0c \u4e00\u822c\u53ea\u662f\u6307\u7b2c\u4e00\u6b65\uff1a\u6c42\u68af\u5ea6 \u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u597d\u591a\u7b54\u6848\u76f4\u63a5\u8bf4\u5c31\u662f\u4e2a\u94fe\u5f0f\u6cd5\u5219\uff0c\u56e0\u4e3a\u786e\u5b9e\u5c31\u662f\u94fe\u5f0f\u6cd5\u5219\u3002 \u4e0d\u8fc7\u4e2a\u4eba\u89c9\u5f97\u8fd8\u662f\u6709\u53ef\u4ee5\u76f4\u89c2\u7406\u89e3\u7684\u4e00\u4e9b\u70b9\uff1a 1\uff09\u94fe\u5f0f\u6cd5\u5219\u7684\u76f4\u89c2\u7406\u89e3\u7684\uff0c\u4e4b\u6240\u4ee5\u53ef\u4ee5\u94fe\u5f0f\u6cd5\u5219\uff0c\u662f\u56e0\u4e3a\u68af\u5ea6\u76f4\u89c2\u4e0a\u7406\u89e3\u5c31\u662f\u4e00\u9636\u8fd1\u4f3c\uff0c\u6240\u4ee5\u68af\u5ea6\u53ef\u4ee5\u7406\u89e3\u6210\u67d0\u4e2a\u53d8\u91cf\u6216\u67d0\u4e2a\u4e2d\u95f4\u53d8\u91cf**\u5bf9\u8f93\u51fa\u5f71\u54cd\u7684\u654f\u611f\u5ea6\u7684\u7cfb\u6570** \uff0c\u8fd9\u79cd\u7406\u89e3\u5728\u4e00\u7ef4\u60c5\u51b5\u4e0b\u7684\u76f4\u89c2\u5e2e\u52a9\u53ef\u80fd\u5e76\u4e0d\u662f\u5f88\u5927\uff0c\u4f46\u662f\u5230\u4e86\u9ad8\u7ef4\u60c5\u51b5\uff0c\u5f53**\u94fe\u5f0f\u6cd5\u5219**\u4ece\u4e58\u6cd5\u53d8\u6210\u4e86**Jacobian\u77e9\u9635\u4e58\u6cd5**\u7684\u65f6\u5019\uff0c\u8fd9\u4e2a\u7406\u89e3\u8d77\u6765\u5c31\u5f62\u8c61\u591a\u4e86\u3002\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u94fe\u5f0f\u6cd5\u5219\u6070\u597d\u90fd\u51e0\u4e4e\u662f\u9ad8\u7ef4\u7684\u3002 2\uff09Computational graph\u3002\u6700\u9ad8\u7968\u7b54\u6848\u548c @\u9f9a\u79b9pangolulu \u7684\u7b54\u6848\u4e2d\u90fd\u6709\u63d0\u5230\uff0c\u5c31\u4e0d\u8d58\u8ff0\uff0c\u5176\u5b9e\u5c31\u662f**\u8ba1\u7b97\u4ee3\u6570**\u4e2d\u7684\u4e00\u4e2a\u6700\u57fa\u7840\u529e\u6cd5\uff0c\u4ece\u8ba1\u7b97\u673a\u7684\u89d2\u5ea6\u6765\u770b\u8fd8\u6709\u70b9**\u52a8\u6001\u89c4\u5212**\u7684\u610f\u601d\u3002\u5176\u4f18\u70b9\u662f\u8868\u8fbe\u5f0f\u7ed9\u5b9a\u7684\u60c5\u51b5\u4e0b\u5bf9**\u590d\u5408\u51fd\u6570**\u4e2d\u6240\u6709\u53d8\u91cf\u8fdb\u884c**\u5feb\u901f\u6c42\u5bfc**\uff0c\u8fd9\u6b63\u597d\u662f\u795e\u7ecf\u7f51\u7edc\u5c24\u5176\u662f\u6df1\u5ea6\u5b66\u4e60\u7684\u573a\u666f\u3002\u73b0\u5728\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u91cc\u7684\u6c42\u5bfc\u4e5f\u90fd\u662f\u57fa\u4e8eComputational Graph\uff0c\u6bd4\u5982theano\uff0ctorch\u548ctensorflow\uff0cCaffe\u4e5f\u53ef\u4ee5\u770b\u505a\u662fcomputaiona graph\uff0c\u53ea\u4e0d\u8fc7node\u662flayer\u3002 \u603b\u7ed3\uff1a\u56fe\u4e2d\u7684\u786e\u5b9e\u662fbackprop\uff0c\u4f46\u4e0d\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684backprop\uff0c\u4e0d\u8fc7backward\u7684\u5927\u4f53\u601d\u60f3\u662f\u4e00\u6837\u7684\uff0c\u6bd5\u7adf\u8bef\u5dee\u6ca1\u6cd5\u4ece\u524d\u5f80\u540e\u8ba1\u7b97\u554a\u3002 \u4ee5\u4e0b\u662f\u539f\u56de\u7b54\uff1a In the next algorithm step the output signal of the network y is compared with the desired output value (the target), which is found in training data set. The difference is called error signal \\delta \\delta of output layer neuron . It is impossible to compute error signal for internal neurons directly, because output values of these neurons are unknown. For many years the effective method for training multiplayer networks has been unknown. Only in the middle eighties the backpropagation algorithm has been worked out. The idea is to propagate error signal d (computed in single teaching step) back to all neurons, which output signals were input for discussed neuron. The weights' coefficients w_{mn} w_{mn} used to propagate errors back are equal to this used during computing output value. Only the direction of data flow is changed (signals are propagated from output to inputs one after the other). This technique is used for all network layers. If propagated errors came from few neurons they are added. The illustration is below: When the error signal for each neuron is computed, the weights coefficients of each neuron input node may be modified. In formulas below df(e)/de represents derivative of neuron activation function (which weights are modified). Coefficient \\eta \\eta affects network teaching speed. There are a few techniques to select this parameter. The first method is to start teaching process with large value of the parameter. While weights coefficients are being established the parameter is being decreased gradually. The second, more complicated, method starts teaching with small parameter value. During the teaching process the parameter is being increased when the teaching is advanced and then decreased again in the final stage. Starting teaching process with low parameter value enables to determine weights coefficients signs. References Ryszard Tadeusiewcz \"Sieci neuronowe\", Krak\u00f3w 1992 http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html","title":"YE Y\u7684\u56de\u7b54"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/7-Regularization-for-Deep-Learning/7.8-Early-Stopping/","text":"7.8 Early Stopping SUMMARY : early stopping\u7684\u63d0\u51fa\u662f\u57fa\u4e8e\u5982\u4e0b\u7684\u4e8b\u5b9e\u7684\uff1a When training large models with sufficient representational capacity to overfit the task, we often observe that training error decreases steadily over time, but validation set error begins to rise again. See figure for an example of this 7.3 behavior. This behavior occurs very reliably. This means we can obtain a model with better validation set error (and thus, hopefully better test set error ) by returning to the parameter setting at the point in time with the lowest validation set error . Every time the error on the validation set improves, we store a copy of the model parameters . When the training algorithm terminates, we return these parameters, rather than the latest parameters. The algorithm terminates when no parameters have improved over the best recorded validation error for some pre-specified number of iterations. This procedure is specified more formally in algorithm . 7.1 SUMMARY : \u901a\u8fc7validation set error\u6765\u9009\u62e9\u6700\u4f18\u7684model parameters\u3002 Algorithm 7.1 The early stopping meta-algorithm for determining the best amount of time to train. This meta-algorithm is a general strategy that works well with a variety of training algorithms and ways of quantifying error on the validation set. Let n be the number of steps between evaluations. n // \u8fd0\u884c\u591a\u5c11step\u7684\u8bad\u7ec3\u540e\u518d\u8fdb\u884cevaluate Let p be the \u201cpatience,\u201d the number of times to observe worsening validation set error before giving up. Let \u03b8_0 \u03b8_0 be the initial parameters. \u03b8 \u2190 \u03b8_0 \u03b8_0 # \u03b8\u662fmodel parameters i \u2190 0 # number of step to train j \u2190 0 v \u2190 \u221e # validation set error \u03b8^\u2217 \u03b8^\u2217 \u2190 \u03b8 i^\u2217 i^\u2217 \u2190 i // best number of step to train while j < p do Update \u03b8 by running the training algorithm for n steps. \u200b i \u2190 i + n \u200b v^{'} v^{'} \u2190 ValidationSetError( \u03b8 ) # \u6b64\u65f6\u6a21\u578b\u7684validation set error \u200b if v^{'} v^{'} < v then # validation set error improved\uff0cso update the best value \u200b j \u2190 0 \u200b \u03b8^\u2217 \u03b8^\u2217 \u2190 \u03b8 \u200b i^\u2217 i^\u2217 \u2190 i \u200b v \u2190 v^{'} v^{'} \u200b else \u200b j \u2190 j + 1 \u200b end if end while Best parameters are \u03b8^\u2217 \u03b8^\u2217 , best number of training steps is i^\u2217 i^\u2217 SUMMARY : \u5176\u5b9e\u4e0a\u8ff0\u7b97\u6cd5\u6240\u786e\u5b9a\u7684\u662f\u6700\u4f18\u7684\u8bad\u7ec3step\u6570\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e2astep\u6570\u7684\u65f6\u5019\uff0c\u6a21\u578b\u7684\u8868\u73b0\u662f\u6700\u4f18\u7684\u3002\u8bad\u7ec3\u7684number of step\u4e5f\u662f\u4e00\u4e2ahyperparameter\u3002 THINKING : \u4e3a\u4ec0\u4e48\u6b64\u5904\u4f7f\u7528\u7684\u662fvalidation set\uff1f\u67e5\u9605deep learning book chapter 5.3 Hyperparameters and Validation Sets This strategy is known as early stopping . It is probably the most commonly used form of regularization in deep learning . Its popularity is due both to its effectiveness and its simplicity. One way to think of early stopping is as a very efficient hyperparameter selection algorithm . In this view, the number of training steps is just another hyperparameter. We can see in figure 5.3 that this hyperparameter has a U-shaped validation set performance curve . Most hyperparameters that control model capacity have such a U-shaped validation set performance curve , as illustrated in figure 5.3. In the case of early stopping , we are controlling the effective capacity of the model by determining how many steps it can take to fit the training set . Most hyperparameters must be chosen using an expensive guess and check process, where we set a hyperparameter at the start of training, then run training for several steps to see its effect. The \u201ctraining time\u201d hyperparameter is unique in that by definition a single run of training tries out many values of the hyperparameter. The only significant cost to choosing this hyperparameter automatically via early stopping is running the validation set evaluation periodically during training. Ideally, this is done in parallel to the training process on a separate machine, separate CPU, or separate GPU from the main training process. If such resources are not available, then the cost of these periodic evaluations may be reduced by using a validation set that is small compared to the training set or by evaluating the validation set error less frequently and obtaining a lower resolution estimate of the optimal training time. SUMMARY : The \u201ctraining time\u201d hyperparameter is unique in that by definition a single run of training tries out many values of the hyperparameter.\u8fd9\u53e5\u8bdd\u8981\u5982\u4f55\u7406\u89e3\uff1f\u6309\u7167\u6211\u7684\u7406\u89e3\uff0c\u5728early stop\u4e2d\uff0c\u53ea\u6d89\u53ca\u5230\u4e86training steps\u8d85\u53c2\u6570\u3002","title":"7.8-Early-Stopping"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/7-Regularization-for-Deep-Learning/7.8-Early-Stopping/#78#early#stopping","text":"SUMMARY : early stopping\u7684\u63d0\u51fa\u662f\u57fa\u4e8e\u5982\u4e0b\u7684\u4e8b\u5b9e\u7684\uff1a When training large models with sufficient representational capacity to overfit the task, we often observe that training error decreases steadily over time, but validation set error begins to rise again. See figure for an example of this 7.3 behavior. This behavior occurs very reliably. This means we can obtain a model with better validation set error (and thus, hopefully better test set error ) by returning to the parameter setting at the point in time with the lowest validation set error . Every time the error on the validation set improves, we store a copy of the model parameters . When the training algorithm terminates, we return these parameters, rather than the latest parameters. The algorithm terminates when no parameters have improved over the best recorded validation error for some pre-specified number of iterations. This procedure is specified more formally in algorithm . 7.1 SUMMARY : \u901a\u8fc7validation set error\u6765\u9009\u62e9\u6700\u4f18\u7684model parameters\u3002 Algorithm 7.1 The early stopping meta-algorithm for determining the best amount of time to train. This meta-algorithm is a general strategy that works well with a variety of training algorithms and ways of quantifying error on the validation set. Let n be the number of steps between evaluations. n // \u8fd0\u884c\u591a\u5c11step\u7684\u8bad\u7ec3\u540e\u518d\u8fdb\u884cevaluate Let p be the \u201cpatience,\u201d the number of times to observe worsening validation set error before giving up. Let \u03b8_0 \u03b8_0 be the initial parameters. \u03b8 \u2190 \u03b8_0 \u03b8_0 # \u03b8\u662fmodel parameters i \u2190 0 # number of step to train j \u2190 0 v \u2190 \u221e # validation set error \u03b8^\u2217 \u03b8^\u2217 \u2190 \u03b8 i^\u2217 i^\u2217 \u2190 i // best number of step to train while j < p do Update \u03b8 by running the training algorithm for n steps. \u200b i \u2190 i + n \u200b v^{'} v^{'} \u2190 ValidationSetError( \u03b8 ) # \u6b64\u65f6\u6a21\u578b\u7684validation set error \u200b if v^{'} v^{'} < v then # validation set error improved\uff0cso update the best value \u200b j \u2190 0 \u200b \u03b8^\u2217 \u03b8^\u2217 \u2190 \u03b8 \u200b i^\u2217 i^\u2217 \u2190 i \u200b v \u2190 v^{'} v^{'} \u200b else \u200b j \u2190 j + 1 \u200b end if end while Best parameters are \u03b8^\u2217 \u03b8^\u2217 , best number of training steps is i^\u2217 i^\u2217 SUMMARY : \u5176\u5b9e\u4e0a\u8ff0\u7b97\u6cd5\u6240\u786e\u5b9a\u7684\u662f\u6700\u4f18\u7684\u8bad\u7ec3step\u6570\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e2astep\u6570\u7684\u65f6\u5019\uff0c\u6a21\u578b\u7684\u8868\u73b0\u662f\u6700\u4f18\u7684\u3002\u8bad\u7ec3\u7684number of step\u4e5f\u662f\u4e00\u4e2ahyperparameter\u3002 THINKING : \u4e3a\u4ec0\u4e48\u6b64\u5904\u4f7f\u7528\u7684\u662fvalidation set\uff1f\u67e5\u9605deep learning book chapter 5.3 Hyperparameters and Validation Sets This strategy is known as early stopping . It is probably the most commonly used form of regularization in deep learning . Its popularity is due both to its effectiveness and its simplicity. One way to think of early stopping is as a very efficient hyperparameter selection algorithm . In this view, the number of training steps is just another hyperparameter. We can see in figure 5.3 that this hyperparameter has a U-shaped validation set performance curve . Most hyperparameters that control model capacity have such a U-shaped validation set performance curve , as illustrated in figure 5.3. In the case of early stopping , we are controlling the effective capacity of the model by determining how many steps it can take to fit the training set . Most hyperparameters must be chosen using an expensive guess and check process, where we set a hyperparameter at the start of training, then run training for several steps to see its effect. The \u201ctraining time\u201d hyperparameter is unique in that by definition a single run of training tries out many values of the hyperparameter. The only significant cost to choosing this hyperparameter automatically via early stopping is running the validation set evaluation periodically during training. Ideally, this is done in parallel to the training process on a separate machine, separate CPU, or separate GPU from the main training process. If such resources are not available, then the cost of these periodic evaluations may be reduced by using a validation set that is small compared to the training set or by evaluating the validation set error less frequently and obtaining a lower resolution estimate of the optimal training time. SUMMARY : The \u201ctraining time\u201d hyperparameter is unique in that by definition a single run of training tries out many values of the hyperparameter.\u8fd9\u53e5\u8bdd\u8981\u5982\u4f55\u7406\u89e3\uff1f\u6309\u7167\u6211\u7684\u7406\u89e3\uff0c\u5728early stop\u4e2d\uff0c\u53ea\u6d89\u53ca\u5230\u4e86training steps\u8d85\u53c2\u6570\u3002","title":"7.8 Early Stopping"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/8-Optimization-for-Training-Deep-Models/","text":"\u672c\u7ae0\u6240\u8bb2\u8ff0\u7684Optimization for Training Deep Models\u5176\u5b9e\u5728\u5b66\u672f\u4e0a\u662f\u53eb\u505a Mathematical optimization \uff0c\u8fd9\u90e8\u5206\u5185\u5bb9\u5728\u300aOptimization-Algorithms, methods, and heuristics\u300b\u4e2d\u6536\u5f55\u4e86\u3002","title":"8-Optimization-for-Training-Deep-Models"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/5.9-Stochastic-Gradient-Descent/","text":"5.9 Stochastic Gradient Descent Nearly all of deep learning is powered by one very important algorithm: stochastic gradient descent SGD or . Stochastic gradient descent is an extension of the gradient descent algorithm introduced in Sec. 4.3 A recurring problem in machine learning is that large training sets are necessary for good generalization , but large training sets are also more computationally expensive. The cost function used by a machine learning algorithm often decomposes as a sum over training examples of some per-example loss function. For example, the negative conditional log-likelihood of the training data can be written as For these additive cost functions , gradient descent requires computing The computational cost of this operation is O ( m ) O ( m ) \uff08m\u8868\u793a\u7684\u662f\u6837\u672c\u7684\u4e2a\u6570\uff09. As the training set size grows to billions of examples, the time to take a single gradient step becomes prohibitively long. The insight of stochastic gradient descent is that the gradient is an expectation \uff08\u671f\u671b\uff09. The expectation may be approximately estimated using a small set of samples. Specifically, on each step of the algorithm, we can sample a minibatch of examples B = {x ,...,x_m} B = {x ,...,x_m} drawn uniformly\uff08\u7edf\u4e00\u7684\uff09 from the training set. The minibatch size m \uff08\u5c31\u662f\u6211\u4eec\u6240\u8bf4\u7684 batch_size \uff09 is typically chosen to be a relatively small number of examples, ranging from 1 to a few hundred. Crucially, m is usually held fixed as the training set size m grows. We may fit a training set with billions of examples using updates computed on only a hundred examples. The estimate\uff08\u4f30\u8ba1\uff09 of the gradient is formed as Gradient descent in general has often been regarded as slow or unreliable. In the past, the application of gradient descent to non-convex optimization problems was regarded as foolhardy or unprincipled. Today, we know that the machine learning models described in Part work very well when trained with gradient II descent. The optimization algorithm may not be guaranteed to arrive at even a local minimum in a reasonable amount of time, but it often finds a very low value of the cost function quickly enough to be useful.","title":"5.9-Stochastic-Gradient-Descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/5.9-Stochastic-Gradient-Descent/#59#stochastic#gradient#descent","text":"Nearly all of deep learning is powered by one very important algorithm: stochastic gradient descent SGD or . Stochastic gradient descent is an extension of the gradient descent algorithm introduced in Sec. 4.3 A recurring problem in machine learning is that large training sets are necessary for good generalization , but large training sets are also more computationally expensive. The cost function used by a machine learning algorithm often decomposes as a sum over training examples of some per-example loss function. For example, the negative conditional log-likelihood of the training data can be written as For these additive cost functions , gradient descent requires computing The computational cost of this operation is O ( m ) O ( m ) \uff08m\u8868\u793a\u7684\u662f\u6837\u672c\u7684\u4e2a\u6570\uff09. As the training set size grows to billions of examples, the time to take a single gradient step becomes prohibitively long. The insight of stochastic gradient descent is that the gradient is an expectation \uff08\u671f\u671b\uff09. The expectation may be approximately estimated using a small set of samples. Specifically, on each step of the algorithm, we can sample a minibatch of examples B = {x ,...,x_m} B = {x ,...,x_m} drawn uniformly\uff08\u7edf\u4e00\u7684\uff09 from the training set. The minibatch size m \uff08\u5c31\u662f\u6211\u4eec\u6240\u8bf4\u7684 batch_size \uff09 is typically chosen to be a relatively small number of examples, ranging from 1 to a few hundred. Crucially, m is usually held fixed as the training set size m grows. We may fit a training set with billions of examples using updates computed on only a hundred examples. The estimate\uff08\u4f30\u8ba1\uff09 of the gradient is formed as Gradient descent in general has often been regarded as slow or unreliable. In the past, the application of gradient descent to non-convex optimization problems was regarded as foolhardy or unprincipled. Today, we know that the machine learning models described in Part work very well when trained with gradient II descent. The optimization algorithm may not be guaranteed to arrive at even a local minimum in a reasonable amount of time, but it often finds a very low value of the cost function quickly enough to be useful.","title":"5.9 Stochastic Gradient Descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Gradient-descent/","text":"Gradient descent \u68af\u5ea6\u4e0b\u964d\u3002 Gradient descent Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point. If, instead, one takes steps proportional to the positive of the gradient, one approaches a local maximum of that function; the procedure is then known as gradient ascent . SUMMARY : \u68af\u5ea6\u4e0a\u5347\u4e0e\u68af\u5ea6\u4e0b\u964d Gradient descent is also known as steepest descent \uff08\u6781\u901f\u4e0b\u964d\uff09. However, gradient descent should not be confused with the method of steepest descent for approximating integrals. Description Gradient descent is based on the observation that if the multi-variable function $ F(\\mathbf {x} ) $ is defined and differentiable in a neighborhood of a point $ \\mathbf {a} $, then $ F(\\mathbf {x} ) $ decreases fastest if one goes from $ \\mathbf {a} $ in the direction of the negative gradient of $ F $ at $ \\mathbf {a} ,-\\nabla F(\\mathbf {a} ) $. It follows that, if $ \\mathbf {a} _{n+1}=\\mathbf {a} _{n}-\\gamma \\nabla F(\\mathbf {a} _{n}) $ for $ \\gamma \\in \\mathbb {R} {+} $ small enough, then $ F(\\mathbf {a {n}} )\\geq F(\\mathbf {a_{n+1}} ) $. In other words, the term $ \\gamma \\nabla F(\\mathbf {a} ) $ is subtracted from $ \\mathbf {a} $ because we want to move against the gradient, toward the minimum. With this observation in mind, one starts with a guess $ \\mathbf {x} _{0} $ for a local minimum of $ F $, and considers the sequence $ \\mathbf {x} _{0},\\mathbf {x} _{1},\\mathbf {x} _{2},\\ldots $ such that $ \\mathbf {x} _{n+1}=\\mathbf {x} _{n}-\\gamma _{n}\\nabla F(\\mathbf {x} _{n}), n\\geq 0. $ We have a monotonic sequence $ F(\\mathbf {x} _{0})\\geq F(\\mathbf {x} _{1})\\geq F(\\mathbf {x} _{2})\\geq \\cdots , $ so hopefully the sequence $ (\\mathbf {x} _{n}) $ converges to the desired local minimum. Note that the value of the step size $ \\gamma $ is allowed to change at every iteration. With certain assumptions on the function $ F $ (for example, $ F $ convex and $ \\nabla F $ Lipschitz ) and particular choices of $ \\gamma $ (e.g., chosen either via a line search that satisfies the Wolfe conditions or the Barzilai-Borwein[ 1] method shown as following), $ \\gamma _{n}={\\frac {\\left|\\left(\\mathbf {x} _{n}-\\mathbf {x} _{n-1}\\right)^{T}\\left[\\nabla F(\\mathbf {x} _{n})-\\nabla F(\\mathbf {x} _{n-1})\\right]\\right|}{\\left|\\nabla F(\\mathbf {x} _{n})-\\nabla F(\\mathbf {x} _{n-1})\\right|^{2}}} $ convergence to a local minimum can be guaranteed. When the function $ F $ is convex , all local minima are also global minima , so in this case gradient descent can converge to the global solution. This process is illustrated in the adjacent picture. Here $ F $ is assumed to be defined on the plane, and that its graph has a bowl shape. The blue curves are the contour lines , that is, the regions on which the value of $ F $ is constant. A red arrow originating at a point shows the direction of the negative gradient at that point. Note that the (negative) gradient at a point is orthogonal to the contour line going through that point. We see that gradient descent leads us to the bottom of the bowl, that is, to the point where the value of the function $ F $ is minimal. Illustration of gradient descent on a series of level sets. Examples Gradient descent has problems with pathological\uff08\u75c5\u6001\uff09 functions such as the Rosenbrock function shown here. $ f(x_{1},x_{2})=(1-x_{1}) {2}+100(x_{2}-{x_{1}} {2})^{2}. $ The Rosenbrock function has a narrow curved valley which contains the minimum. The bottom of the valley is very flat. Because of the curved flat valley the optimization is zigzagging slowly with small step sizes towards the minimum. The zigzagging nature of the method is also evident below, where the gradient descent method is applied to $ F(x,y)=\\sin \\left({\\frac {1}{2}}x^{2}-{\\frac {1}{4}}y^{2}+3\\right)\\cos \\left(2x+1-e^{y}\\right). $ machinelearningmastery Gradient Descent For Machine Learning","title":"Gradient-descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Gradient-descent/#gradient#descent","text":"\u68af\u5ea6\u4e0b\u964d\u3002","title":"Gradient descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Gradient-descent/#gradient#descent_1","text":"Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point. If, instead, one takes steps proportional to the positive of the gradient, one approaches a local maximum of that function; the procedure is then known as gradient ascent . SUMMARY : \u68af\u5ea6\u4e0a\u5347\u4e0e\u68af\u5ea6\u4e0b\u964d Gradient descent is also known as steepest descent \uff08\u6781\u901f\u4e0b\u964d\uff09. However, gradient descent should not be confused with the method of steepest descent for approximating integrals.","title":"Gradient descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Gradient-descent/#description","text":"Gradient descent is based on the observation that if the multi-variable function $ F(\\mathbf {x} ) $ is defined and differentiable in a neighborhood of a point $ \\mathbf {a} $, then $ F(\\mathbf {x} ) $ decreases fastest if one goes from $ \\mathbf {a} $ in the direction of the negative gradient of $ F $ at $ \\mathbf {a} ,-\\nabla F(\\mathbf {a} ) $. It follows that, if $ \\mathbf {a} _{n+1}=\\mathbf {a} _{n}-\\gamma \\nabla F(\\mathbf {a} _{n}) $ for $ \\gamma \\in \\mathbb {R} {+} $ small enough, then $ F(\\mathbf {a {n}} )\\geq F(\\mathbf {a_{n+1}} ) $. In other words, the term $ \\gamma \\nabla F(\\mathbf {a} ) $ is subtracted from $ \\mathbf {a} $ because we want to move against the gradient, toward the minimum. With this observation in mind, one starts with a guess $ \\mathbf {x} _{0} $ for a local minimum of $ F $, and considers the sequence $ \\mathbf {x} _{0},\\mathbf {x} _{1},\\mathbf {x} _{2},\\ldots $ such that $ \\mathbf {x} _{n+1}=\\mathbf {x} _{n}-\\gamma _{n}\\nabla F(\\mathbf {x} _{n}), n\\geq 0. $ We have a monotonic sequence $ F(\\mathbf {x} _{0})\\geq F(\\mathbf {x} _{1})\\geq F(\\mathbf {x} _{2})\\geq \\cdots , $ so hopefully the sequence $ (\\mathbf {x} _{n}) $ converges to the desired local minimum. Note that the value of the step size $ \\gamma $ is allowed to change at every iteration. With certain assumptions on the function $ F $ (for example, $ F $ convex and $ \\nabla F $ Lipschitz ) and particular choices of $ \\gamma $ (e.g., chosen either via a line search that satisfies the Wolfe conditions or the Barzilai-Borwein[ 1] method shown as following), $ \\gamma _{n}={\\frac {\\left|\\left(\\mathbf {x} _{n}-\\mathbf {x} _{n-1}\\right)^{T}\\left[\\nabla F(\\mathbf {x} _{n})-\\nabla F(\\mathbf {x} _{n-1})\\right]\\right|}{\\left|\\nabla F(\\mathbf {x} _{n})-\\nabla F(\\mathbf {x} _{n-1})\\right|^{2}}} $ convergence to a local minimum can be guaranteed. When the function $ F $ is convex , all local minima are also global minima , so in this case gradient descent can converge to the global solution. This process is illustrated in the adjacent picture. Here $ F $ is assumed to be defined on the plane, and that its graph has a bowl shape. The blue curves are the contour lines , that is, the regions on which the value of $ F $ is constant. A red arrow originating at a point shows the direction of the negative gradient at that point. Note that the (negative) gradient at a point is orthogonal to the contour line going through that point. We see that gradient descent leads us to the bottom of the bowl, that is, to the point where the value of the function $ F $ is minimal. Illustration of gradient descent on a series of level sets.","title":"Description"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Gradient-descent/#examples","text":"Gradient descent has problems with pathological\uff08\u75c5\u6001\uff09 functions such as the Rosenbrock function shown here. $ f(x_{1},x_{2})=(1-x_{1}) {2}+100(x_{2}-{x_{1}} {2})^{2}. $ The Rosenbrock function has a narrow curved valley which contains the minimum. The bottom of the valley is very flat. Because of the curved flat valley the optimization is zigzagging slowly with small step sizes towards the minimum. The zigzagging nature of the method is also evident below, where the gradient descent method is applied to $ F(x,y)=\\sin \\left({\\frac {1}{2}}x^{2}-{\\frac {1}{4}}y^{2}+3\\right)\\cos \\left(2x+1-e^{y}\\right). $","title":"Examples"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Gradient-descent/#machinelearningmastery#gradient#descent#for#machine#learning","text":"","title":"machinelearningmastery Gradient Descent For Machine Learning"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Stochastic-gradient-descent/","text":"Stochastic gradient descent Background Stochastic gradient descent Stochastic gradient descent (often abbreviated SGD ) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable ). It is called stochastic because the method uses randomly selected (or shuffled) samples to evaluate the gradients, hence SGD can be regarded as a stochastic approximation of gradient descent optimization. The ideas can be traced back[ 1] at least to the 1951 article titled \"A Stochastic Approximation Method\" by Herbert Robbins and Sutton Monro , who proposed with detailed analysis a root-finding method now called the Robbins\u2013Monro algorithm . Background Main article: M-estimation See also: Estimating equation Both statistical estimation and machine learning consider the problem of minimizing an objective function that has the form of a sum: $ Q(w)={\\frac {1}{n}}\\sum {i=1}^{n}Q {i}(w), $ where the parameter $ w $ that minimizes $ Q(w) $ is to be estimated . Each summand function $ Q_{i} $ is typically associated with the $ i $-th observation in the data set (used for training). In classical statistics, sum-minimization problems arise in least squares and in maximum-likelihood estimation (for independent observations). The general class of estimators that arise as minimizers of sums are called M-estimators . However, in statistics, it has been long recognized that requiring even local minimization is too restrictive for some problems of maximum-likelihood estimation.[ 2] Therefore, contemporary statistical theorists often consider stationary points of the likelihood function (or zeros of its derivative, the score function , and other estimating equations ). The sum-minimization problem also arises for empirical risk minimization . In this case, $ Q_{i}(w) $ is the value of the loss function at $ i $-th example, and $ Q(w) $ is the empirical risk. When used to minimize the above function, a standard (or \"batch\") gradient descent method would perform the following iterations : where $ \\eta $ is a step size (sometimes called the learning rate in machine learning). In many cases, the summand functions have a simple form that enables inexpensive evaluations of the sum-function and the sum gradient. For example, in statistics, one-parameter exponential families allow economical function-evaluations and gradient-evaluations. However, in other cases, evaluating the sum-gradient may require expensive evaluations of the gradients from all summand functions. When the training set is enormous and no simple formulas exist, evaluating the sums of gradients becomes very expensive, because evaluating the gradient requires evaluating all the summand functions' gradients. To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step. This is very effective in the case of large-scale machine learning problems.[ 3]","title":"Stochastic-gradient-descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Stochastic-gradient-descent/#stochastic#gradient#descent","text":"Stochastic gradient descent (often abbreviated SGD ) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable ). It is called stochastic because the method uses randomly selected (or shuffled) samples to evaluate the gradients, hence SGD can be regarded as a stochastic approximation of gradient descent optimization. The ideas can be traced back[ 1] at least to the 1951 article titled \"A Stochastic Approximation Method\" by Herbert Robbins and Sutton Monro , who proposed with detailed analysis a root-finding method now called the Robbins\u2013Monro algorithm .","title":"Stochastic gradient descent"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/8-Optimization-for-Training-Deep-Models/SGD/Stochastic-gradient-descent/#background","text":"Main article: M-estimation See also: Estimating equation Both statistical estimation and machine learning consider the problem of minimizing an objective function that has the form of a sum: $ Q(w)={\\frac {1}{n}}\\sum {i=1}^{n}Q {i}(w), $ where the parameter $ w $ that minimizes $ Q(w) $ is to be estimated . Each summand function $ Q_{i} $ is typically associated with the $ i $-th observation in the data set (used for training). In classical statistics, sum-minimization problems arise in least squares and in maximum-likelihood estimation (for independent observations). The general class of estimators that arise as minimizers of sums are called M-estimators . However, in statistics, it has been long recognized that requiring even local minimization is too restrictive for some problems of maximum-likelihood estimation.[ 2] Therefore, contemporary statistical theorists often consider stationary points of the likelihood function (or zeros of its derivative, the score function , and other estimating equations ). The sum-minimization problem also arises for empirical risk minimization . In this case, $ Q_{i}(w) $ is the value of the loss function at $ i $-th example, and $ Q(w) $ is the empirical risk. When used to minimize the above function, a standard (or \"batch\") gradient descent method would perform the following iterations : where $ \\eta $ is a step size (sometimes called the learning rate in machine learning). In many cases, the summand functions have a simple form that enables inexpensive evaluations of the sum-function and the sum gradient. For example, in statistics, one-parameter exponential families allow economical function-evaluations and gradient-evaluations. However, in other cases, evaluating the sum-gradient may require expensive evaluations of the gradients from all summand functions. When the training set is enormous and no simple formulas exist, evaluating the sums of gradients becomes very expensive, because evaluating the gradient requires evaluating all the summand functions' gradients. To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step. This is very effective in the case of large-scale machine learning problems.[ 3]","title":"Background"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/9-Convolutional-Networks/","text":"Chapter 9 Convolutional Networks","title":"9-Convolutional-Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/9-Convolutional-Networks/#chapter#9#convolutional#networks","text":"","title":"Chapter 9 Convolutional Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/9.3-Pooling/","text":"9.3 Pooling A typical layer of a convolutional network consists of three stages (see figure 9.7). In the first stage, the layer performs several convolutions in parallel to produce a set of linear activations . In the second stage, each linear activation is run through a nonlinear activation function , such as the rectified linear activation function . This stage is sometimes called the detector stage. In the third stage, we use a pooling function to modify the output of the layer further. A pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, the max pooling (Zhou and Chellappa, 1988 ) operation reports the maximum output within a rectangular neighborhood . Other popular pooling functions include the average of a rectangular neighborhood , the L^2 L^2 norm of a rectangular neighborhood , or a weighted average based on the distance from the central pixel. In all cases, pooling helps to make the representation become approximately invariant to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change\uff08\u66f4\u52a0robust\uff09. See figure 9.8 for an example of how this works. Invariance to local translation can be a very useful property if we care more about whether some feature is present than exactly where it is \uff08\u4e0d\u5173\u5fc3\u4f4d\u7f6e\uff0c\u800c\u4ec5\u4ec5\u5173\u6ce8\u8fd9\u4e2afeature\u662f\u5426\u51fa\u73b0\uff09.For example, when determining whether an image contains a face, we need not know the location of the eyes with pixel-perfect accuracy, we just need to know that there is an eye on the left side of the face and an eye on the right side of the face. In other contexts, it is more important to preserve the location of a feature. For example, if we want to find a corner defined by two edges meeting at a specific orientation, we need to preserve the location of the edges well enough to test whether they meet. The use of pooling can be viewed as adding an infinitely strong prior that the function the layer learns must be invariant to small translations. When this assumption is correct, it can greatly improve the statistical efficiency of the network.","title":"9.3-Pooling"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/9.3-Pooling/#93#pooling","text":"A typical layer of a convolutional network consists of three stages (see figure 9.7). In the first stage, the layer performs several convolutions in parallel to produce a set of linear activations . In the second stage, each linear activation is run through a nonlinear activation function , such as the rectified linear activation function . This stage is sometimes called the detector stage. In the third stage, we use a pooling function to modify the output of the layer further. A pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, the max pooling (Zhou and Chellappa, 1988 ) operation reports the maximum output within a rectangular neighborhood . Other popular pooling functions include the average of a rectangular neighborhood , the L^2 L^2 norm of a rectangular neighborhood , or a weighted average based on the distance from the central pixel. In all cases, pooling helps to make the representation become approximately invariant to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change\uff08\u66f4\u52a0robust\uff09. See figure 9.8 for an example of how this works. Invariance to local translation can be a very useful property if we care more about whether some feature is present than exactly where it is \uff08\u4e0d\u5173\u5fc3\u4f4d\u7f6e\uff0c\u800c\u4ec5\u4ec5\u5173\u6ce8\u8fd9\u4e2afeature\u662f\u5426\u51fa\u73b0\uff09.For example, when determining whether an image contains a face, we need not know the location of the eyes with pixel-perfect accuracy, we just need to know that there is an eye on the left side of the face and an eye on the right side of the face. In other contexts, it is more important to preserve the location of a feature. For example, if we want to find a corner defined by two edges meeting at a specific orientation, we need to preserve the location of the edges well enough to test whether they meet. The use of pooling can be viewed as adding an infinitely strong prior that the function the layer learns must be invariant to small translations. When this assumption is correct, it can greatly improve the statistical efficiency of the network.","title":"9.3 Pooling"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-pooling-layer/","text":"Max-pooling / Pooling Introduction Max pooling is a sample-based discretization process \uff08\u57fa\u4e8e\u6837\u4f8b\u7684\u964d\u91c7\u6837\u8fc7\u7a0b\uff09. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.[ 2] How does it work and why This is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation. SUMMARY : **translation invariance**\u662fCNN\u7684\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u7279\u6027 Max pooling is done by applying a max filter to (usually) non-overlapping subregions of the initial representation. Examples Let's say we have a 4x4 matrix representing our initial input. Let's say, as well, that we have a 2x2 filter that we'll run over our input. We'll have a stride \uff08\u8de8\u5ea6\uff09 of 2 (meaning the (dx, dy) for stepping over our input will be (2, 2)) and won't overlap regions. For each of the regions represented by the filter, we will take the max of that region and create a new, output matrix where each element is the max of a region in the original input. Pictorial representation: Real-life example: References http://www.flaticon.com/ Jump up\u2191 https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks A Gentle Introduction to Pooling Layers for Convolutional Neural Networks Convolutional layers in a convolutional neural network summarize the presence of features in an input image. A problem with the output feature maps is that they are sensitive to the location of the features in the input. One approach to address this sensitivity is to down sample the feature maps . This has the effect of making the resulting down sampled feature maps more robust to changes in the position of the feature in the image, referred to by the technical phrase \u201c local translation invariance .\u201d Pooling layers provide an approach to down sampling feature maps by summarizing the presence of features in patches of the feature map. Two common pooling methods are average pooling and max pooling that summarize the average presence of a feature and the most activated presence of a feature respectively. In this tutorial, you will discover how the pooling operation works and how to implement it in convolutional neural networks . After completing this tutorial, you will know: Pooling is required to down sample the detection of features in feature maps. How to calculate and implement average and maximum pooling in a convolutional neural network. How to use global pooling in a convolutional neural network. Discover how to build models for photo classification, object detection, face recognition, and more in my new computer vision book , with 30 step-by-step tutorials and full source code. Let\u2019s get started.","title":"CNN-pooling-layer"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-pooling-layer/#max-pooling#pooling","text":"","title":"Max-pooling / Pooling"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-pooling-layer/#introduction","text":"Max pooling is a sample-based discretization process \uff08\u57fa\u4e8e\u6837\u4f8b\u7684\u964d\u91c7\u6837\u8fc7\u7a0b\uff09. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.[ 2]","title":"Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-pooling-layer/#how#does#it#work#and#why","text":"This is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation. SUMMARY : **translation invariance**\u662fCNN\u7684\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u7279\u6027 Max pooling is done by applying a max filter to (usually) non-overlapping subregions of the initial representation.","title":"How does it work and why"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-pooling-layer/#examples","text":"Let's say we have a 4x4 matrix representing our initial input. Let's say, as well, that we have a 2x2 filter that we'll run over our input. We'll have a stride \uff08\u8de8\u5ea6\uff09 of 2 (meaning the (dx, dy) for stepping over our input will be (2, 2)) and won't overlap regions. For each of the regions represented by the filter, we will take the max of that region and create a new, output matrix where each element is the max of a region in the original input. Pictorial representation: Real-life example:","title":"Examples"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-pooling-layer/#references","text":"http://www.flaticon.com/ Jump up\u2191 https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks","title":"References"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-pooling-layer/#a#gentle#introduction#to#pooling#layers#for#convolutional#neural#networks","text":"Convolutional layers in a convolutional neural network summarize the presence of features in an input image. A problem with the output feature maps is that they are sensitive to the location of the features in the input. One approach to address this sensitivity is to down sample the feature maps . This has the effect of making the resulting down sampled feature maps more robust to changes in the position of the feature in the image, referred to by the technical phrase \u201c local translation invariance .\u201d Pooling layers provide an approach to down sampling feature maps by summarizing the presence of features in patches of the feature map. Two common pooling methods are average pooling and max pooling that summarize the average presence of a feature and the most activated presence of a feature respectively. In this tutorial, you will discover how the pooling operation works and how to implement it in convolutional neural networks . After completing this tutorial, you will know: Pooling is required to down sample the detection of features in feature maps. How to calculate and implement average and maximum pooling in a convolutional neural network. How to use global pooling in a convolutional neural network. Discover how to build models for photo classification, object detection, face recognition, and more in my new computer vision book , with 30 step-by-step tutorials and full source code. Let\u2019s get started.","title":"A Gentle Introduction to Pooling Layers for Convolutional Neural Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-translation-invariance/","text":"What is translation invariance in computer vision and convolutional neural network? \u7ffb\u8bd1\u4e0d\u53d8\u6027 I don't have computer vision background, yet when I read some image processing and convolutional neural networks related articles and papers, I constantly face the term, translation invariance , or translation invariant . Or I read a lot that the convolution operation provides translation invariance ?!! what does this mean? I myself always translated it to myself as if it means if we change an image in any shape, the actual concept of the image doesn't change. For example if I rotate an image of a lets say tree, it's again a tree no matter what I do to that picture. And I myself consider all operations that can happen to an image and transform it in a way (crop it, resize it, gray-scale it,color it etc...) to be this way. I have no idea if this is true so I would be grateful if anyone could explain this to me . A You're on the right track. Invariance means that you can recognize an object as an object, even when its appearance varies in some way. This is generally a good thing, because it preserves the object's identity, category, (etc) across changes in the specifics of the visual input, like relative positions of the viewer/camera and the object. The image below contains many views of the same statue. You (and well-trained neural networks) can recognize that the same object appears in every picture, even though the actual pixel values are quite different. Note that translation here has a specific meaning in vision, borrowed from geometry. It does not refer to any type of conversion, unlike say, a translation from French to English or between file formats. Instead, it means that each point/pixel in the image has been moved the same amount in the same direction . Alternately, you can think of the origin as having been shifted an equal amount in the opposite direction. For example, we can generate the 2 nd and 3 rd images in the first row from the first by moving each pixel 50 or 100 pixels to the right. One can show that the convolution operator commutes with respect to translation. If you convolve f f with g g , it doesn't matter if you translate the convolved output f \\star g f \\star g , or if you translate f f or g g first, then convolve them. Wikipedia has a bit more . One approach to translation-invariant object recognition is to take a \"template\" of the object and convolve it with every possible location of the object in the image. If you get a large response at a location, it suggests that an object resembling the template is located at that location. This approach is often called template-matching . Invariance vs. Equivariance Santanu_Pattanayak's answer ( here ) points out that there is a difference between translation invariance and translation equivariance . Translation invariance means that the system produces exactly the same response, regardless of how its input is shifted. For example, a face-detector might report \"FACE FOUND\" for all three images in the top row. Equivariance means that the system works equally well across positions, but its response shifts with the position of the target. For example, a heat map of \"face-iness\" would have similar bumps at the left, center, and right when it processes the first row of images. This is is sometimes an important distinction, but many people call both phenomena \"invariance\", especially since it is usually trivial to convert an equivariant response into an invariant one--just disregard all the position information). 2 Glad I could help. This is one of my big research interests so if there's anything else that would be useful, I'll see what I can do. \u2013 Matt Krause Apr 25 '16 at 10:18 Could you clarify how translation invariance is achieved with CNN? The activations of a convolutional layer in a CNN are not invariant under translations : they move around as the image moves around (i.e., they are equivariant, rather than invarianct, to translations). Those activations are usually fed into a pooling layer , which also isn't invariant to translations. And pooling layer may feed into a fully connected layer . Do the weights in a fully connected layer somehow change transalation equivariant to translation invariant behavior? \u2013 max Oct 16 '17 at 8:39 @max , Pooling does increase translation invariance , especially max-pooling(!), which completely disregards\uff08\u5ffd\u89c6\uff09 spatial\uff08\u7a7a\u95f4\uff09 information within the pooling neighborhood . See Chapter 9 of Deep Learning deeplearningbook.org/contents/convnets.html (starting on p. 335). This idea is also popular in neuroscience--the HMAX model (e.g., here: maxlab.neuro.georgetown.edu/docs/publications/nn99.pdf ) uses a combination of averaging and max-pooling to generate translation (and other kinds of ) invariance. \u2013 Matt Krause Oct 16 '17 at 17:16 1 Oh right, pooling provides invariance over small translations (I was thinking about larger shifts, but perhaps each successive layer of pooling can handle progressively larger shifts). But what about the fully convolutional networks ? Without pooling, what provides (at least approximate) invariance? \u2013 max Oct 16 '17 at 23:10 How do one explain that \"speech is translational invariant only along time-axis, but not frequency axis\", what does it mean? \u2013 Gene Nov 14 '17 at 15:04 1 @Fredom , that might be better as a new question, but in brief--the audio signal sounds the same even when you shift it forwards in time (e.g., by adding a bunch of silence at the beginning). However, if you shift it in the frequency domain, it sounds different: not only is the spectrum shifted, but relationships between frequencies (e.g., harmonics) are also distorted. \u2013 Matt Krause Nov 14 '17 at 17:24 Ways of implementing Translation invariance","title":"CNN-translation-invariance"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-translation-invariance/#what#is#translation#invariance#in#computer#vision#and#convolutional#neural#network","text":"\u7ffb\u8bd1\u4e0d\u53d8\u6027 I don't have computer vision background, yet when I read some image processing and convolutional neural networks related articles and papers, I constantly face the term, translation invariance , or translation invariant . Or I read a lot that the convolution operation provides translation invariance ?!! what does this mean? I myself always translated it to myself as if it means if we change an image in any shape, the actual concept of the image doesn't change. For example if I rotate an image of a lets say tree, it's again a tree no matter what I do to that picture. And I myself consider all operations that can happen to an image and transform it in a way (crop it, resize it, gray-scale it,color it etc...) to be this way. I have no idea if this is true so I would be grateful if anyone could explain this to me .","title":"What is translation invariance in computer vision and convolutional neural network?"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-translation-invariance/#a","text":"You're on the right track. Invariance means that you can recognize an object as an object, even when its appearance varies in some way. This is generally a good thing, because it preserves the object's identity, category, (etc) across changes in the specifics of the visual input, like relative positions of the viewer/camera and the object. The image below contains many views of the same statue. You (and well-trained neural networks) can recognize that the same object appears in every picture, even though the actual pixel values are quite different. Note that translation here has a specific meaning in vision, borrowed from geometry. It does not refer to any type of conversion, unlike say, a translation from French to English or between file formats. Instead, it means that each point/pixel in the image has been moved the same amount in the same direction . Alternately, you can think of the origin as having been shifted an equal amount in the opposite direction. For example, we can generate the 2 nd and 3 rd images in the first row from the first by moving each pixel 50 or 100 pixels to the right. One can show that the convolution operator commutes with respect to translation. If you convolve f f with g g , it doesn't matter if you translate the convolved output f \\star g f \\star g , or if you translate f f or g g first, then convolve them. Wikipedia has a bit more . One approach to translation-invariant object recognition is to take a \"template\" of the object and convolve it with every possible location of the object in the image. If you get a large response at a location, it suggests that an object resembling the template is located at that location. This approach is often called template-matching .","title":"A"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-translation-invariance/#invariance#vs#equivariance","text":"Santanu_Pattanayak's answer ( here ) points out that there is a difference between translation invariance and translation equivariance . Translation invariance means that the system produces exactly the same response, regardless of how its input is shifted. For example, a face-detector might report \"FACE FOUND\" for all three images in the top row. Equivariance means that the system works equally well across positions, but its response shifts with the position of the target. For example, a heat map of \"face-iness\" would have similar bumps at the left, center, and right when it processes the first row of images. This is is sometimes an important distinction, but many people call both phenomena \"invariance\", especially since it is usually trivial to convert an equivariant response into an invariant one--just disregard all the position information). 2 Glad I could help. This is one of my big research interests so if there's anything else that would be useful, I'll see what I can do. \u2013 Matt Krause Apr 25 '16 at 10:18 Could you clarify how translation invariance is achieved with CNN? The activations of a convolutional layer in a CNN are not invariant under translations : they move around as the image moves around (i.e., they are equivariant, rather than invarianct, to translations). Those activations are usually fed into a pooling layer , which also isn't invariant to translations. And pooling layer may feed into a fully connected layer . Do the weights in a fully connected layer somehow change transalation equivariant to translation invariant behavior? \u2013 max Oct 16 '17 at 8:39 @max , Pooling does increase translation invariance , especially max-pooling(!), which completely disregards\uff08\u5ffd\u89c6\uff09 spatial\uff08\u7a7a\u95f4\uff09 information within the pooling neighborhood . See Chapter 9 of Deep Learning deeplearningbook.org/contents/convnets.html (starting on p. 335). This idea is also popular in neuroscience--the HMAX model (e.g., here: maxlab.neuro.georgetown.edu/docs/publications/nn99.pdf ) uses a combination of averaging and max-pooling to generate translation (and other kinds of ) invariance. \u2013 Matt Krause Oct 16 '17 at 17:16 1 Oh right, pooling provides invariance over small translations (I was thinking about larger shifts, but perhaps each successive layer of pooling can handle progressively larger shifts). But what about the fully convolutional networks ? Without pooling, what provides (at least approximate) invariance? \u2013 max Oct 16 '17 at 23:10 How do one explain that \"speech is translational invariant only along time-axis, but not frequency axis\", what does it mean? \u2013 Gene Nov 14 '17 at 15:04 1 @Fredom , that might be better as a new question, but in brief--the audio signal sounds the same even when you shift it forwards in time (e.g., by adding a bunch of silence at the beginning). However, if you shift it in the frequency domain, it sounds different: not only is the spectrum shifted, but relationships between frequencies (e.g., harmonics) are also distorted. \u2013 Matt Krause Nov 14 '17 at 17:24","title":"Invariance vs. Equivariance"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CNN-translation-invariance/#ways#of#implementing#translation#invariance","text":"","title":"Ways of implementing Translation invariance"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/Fei-Fei-Li/","text":"Fei-Fei Li https://profiles.stanford.edu/fei-fei-li wikipedia Fei-Fei Li","title":"Fei-Fei-Li"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/Fei-Fei-Li/#fei-fei#li","text":"https://profiles.stanford.edu/fei-fei-li","title":"Fei-Fei Li"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/Fei-Fei-Li/#wikipedia#fei-fei#li","text":"","title":"wikipedia Fei-Fei Li"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/ImageNet/","text":"","title":"ImageNet"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/Tutorial/","text":"A Beginner's Guide To Understanding Convolutional Neural Networks","title":"[A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/Tutorial/#a#beginners#guide#to#understanding#convolutional#neural#networks","text":"","title":"A Beginner's Guide To Understanding Convolutional Neural Networks"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/paper-Convolutional-Sequence-to-Sequence-Learning/","text":"Convolutional Sequence to Sequence Learning","title":"paper-Convolutional-Sequence-to-Sequence-Learning"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/paper-Convolutional-Sequence-to-Sequence-Learning/#convolutional#sequence#to#sequence#learning","text":"","title":"Convolutional Sequence to Sequence Learning"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/AlexNet/AlexNet/","text":"AlexNet baike AlexNet wikipedia AlexNet","title":"AlexNet"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/AlexNet/AlexNet/#alexnet","text":"","title":"AlexNet"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/AlexNet/AlexNet/#baike#alexnet","text":"","title":"baike AlexNet"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/AlexNet/AlexNet/#wikipedia#alexnet","text":"","title":"wikipedia AlexNet"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/","text":"\u5173\u4e8e\u672c\u7ae0 stanford CS231n: Convolutional Neural Networks for Visual Recognition CS231n Convolutional Neural Networks for Visual Recognition Note These notes accompany the Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition . For questions/concerns/bug reports contact Justin Johnson regarding the assignments, or contact Andrej Karpathy regarding the course notes. You can also submit a pull request directly to our git repo . We encourage the use of the hypothes.is extension to annote comments and discuss these notes inline.","title":"Introduction"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/#_1","text":"stanford CS231n: Convolutional Neural Networks for Visual Recognition","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/#cs231n#convolutional#neural#networks#for#visual#recognition#note","text":"These notes accompany the Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition . For questions/concerns/bug reports contact Justin Johnson regarding the assignments, or contact Andrej Karpathy regarding the course notes. You can also submit a pull request directly to our git repo . We encourage the use of the hypothes.is extension to annote comments and discuss these notes inline.","title":"CS231n Convolutional Neural Networks for Visual Recognition Note"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/","text":"Convolutional Neural Networks (CNNs / ConvNets) Convolutional Neural Networks are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases . Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function : from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply. SUMMARY : dot product\u610f\u5473\u7740\u7ed3\u679c\u662f\u4e00\u4e2a\u5f20\u91cf\uff1b\u610f\u5473\u7740filter\u7684shape\u548c\u5b83\u6240\u626b\u8fc7\u7684\u533a\u57df\u7684shape\u76f8\u540c\uff1b SUMMARY : score function vs loss function SUMMARY : The whole network still expresses a single differentiable score function So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network. Architecture Overview Recall: Regular Neural Nets. As we saw in the previous chapter, Neural Networks receive an input (a single vector), and transform it through a series of hidden layers . Each hidden layer is made up of a set of neurons, where each neuron is fully connected to all neurons in the previous layer, and where neurons in a single layer function completely independently and do not share any connections. The last fully-connected layer is called the \u201coutput layer\u201d and in classification settings it represents the class scores . Regular Neural Nets don\u2019t scale well to full images . In CIFAR-10, images are only of size 32x32x3 (32 wide, 32 high, 3 color channels), so a single fully-connected neuron in a first hidden layer of a regular Neural Network would have 32*32*3 = 3072 32*32*3 = 3072 weights. This amount still seems manageable, but clearly this fully-connected structure does not scale to larger images. For example, an image of more respectable size, e.g. 200 * 200 * 3 200 * 200 * 3 , would lead to neurons that have 200*200*3 = 120,000 200*200*3 = 120,000 weights. Moreover, we would almost certainly want to have several such neurons, so the parameters would add up quickly! Clearly, this full connectivity is wasteful and the huge number of parameters would quickly lead to overfitting. 3D volumes of neurons . Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth . (Note that the word depth here refers to the third dimension of an activation volume, not to the depth of a full Neural Network, which can refer to the total number of layers in a network.) For example, the input images in CIFAR-10 are an input volume of activations, and the volume has dimensions 32x32x3\u200b (width, height, depth respectively). As we will soon see, the neurons in a layer will only be connected to a small region of the layer before it, instead of all of the neurons in a fully-connected manner . Moreover, the final output layer would for CIFAR-10 have dimensions 1x1x10\u200b, because by the end of the ConvNet architecture we will reduce the full image into a single vector of class scores , arranged along the depth dimension. Here is a visualization: Left: A regular 3-layer Neural Network. Right: A ConvNet arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels). A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters. Layers used to build ConvNets As we described above, a simple ConvNet is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through a differentiable function . We use three main types of layers to build ConvNet architectures: Convolutional Layer , Pooling Layer , and Fully-Connected Layer (exactly as seen in regular Neural Networks). We will stack these layers to form a full ConvNet architecture . Example Architecture: Overview . We will go into more details below, but a simple ConvNet for CIFAR-10 classification could have the architecture [INPUT - CONV - RELU - POOL - FC]. In more detail: INPUT [32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R,G,B. CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. This may result in volume such as [32x32x12] if we decided to use 12 filters . RELU layer will apply an elementwise activation function, such as the max(0,x) max(0,x) thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]). POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]. FC (i.e. fully-connected) layer will compute the class scores , resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score, such as among the 10 categories of CIFAR-10. As with ordinary Neural Networks and as the name implies, each neuron in this layer will be connected to all the numbers in the previous volume. In this way, ConvNets transform the original image layer by layer from the original pixel values to the final class scores . Note that some layers contain parameters and other don\u2019t. In particular, the CONV/FC layers perform transformations that are a function of not only the activations in the input volume, but also of the parameters (the weights and biases of the neurons). On the other hand, the RELU/POOL layers will implement a fixed function. The parameters in the CONV/FC layers will be trained with gradient descent so that the class scores that the ConvNet computes are consistent with the labels in the training set for each image. In summary: A ConvNet architecture is in the simplest case a list of Layers that transform the image volume into an output volume (e.g. holding the class scores) There are a few distinct types of Layers (e.g. CONV/FC/RELU/POOL are by far the most popular) Each Layer accepts an input 3D volume and transforms it to an output 3D volume through a differentiable function Each Layer may or may not have parameters (e.g. CONV/FC do, RELU/POOL don\u2019t) Each Layer may or may not have additional hyperparameters (e.g. CONV/FC/POOL do, RELU doesn\u2019t) The activations of an example ConvNet architecture. The initial volume stores the raw image pixels (left) and the last volume stores the class scores (right). Each volume of activations along the processing path is shown as a column. Since it's difficult to visualize 3D volumes, we lay out each volume's slices in rows. The last layer volume holds the scores for each class, but here we only visualize the sorted top 5 scores, and print the labels of each one. The full web-based demo is shown in the header of our website. The architecture shown here is a tiny VGG Net, which we will discuss later. We now describe the individual layers and the details of their hyperparameters and their connectivities. Convolutional Layer The Conv layer is the core building block of a Convolutional Network that does most of the computational heavy lifting. Conv\u5c42\u662f\u5377\u79ef\u7f51\u7edc\u7684\u6838\u5fc3\u6784\u4ef6\uff0c\u5b83\u627f\u62c5\u4e86\u5927\u90e8\u5206\u8ba1\u7b97\u91cf\u3002 SUMMARY : \u4e0b\u9762\u51e0\u6bb5\uff0c\u4ece\u4e0d\u540c\u7684\u89d2\u5ea6\u5bf9CNN\u8fdb\u884c\u4e86\u63cf\u8ff0\uff0c**Overview and intuition without brain stuff**\u6bb5\u662f\u4ece\u6570\u5b66\uff08\u5377\u79ef\u8fd0\u7b97\uff09\u7684\u89d2\u5ea6\u8fdb\u884c\u7684\u63cf\u8ff0\uff0c**The brain view**\u6bb5\u5219\u662f\u4eceneuron\u7684\u89d2\u5ea6\u6765\u8fdb\u884c\u7684\u63cf\u8ff0\uff1b\u5176\u5b9e\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c\u6211\u4eec\u6240\u4f7f\u7528\u7684network topology\u5176\u5b9e\u662f\u5bf9\u6570\u5b66\u8fd0\u7b97\u7684\u5f62\u8c61\u5316\uff1aMLP\u4e2d\u6240\u8c13\u7684\u5168\u8fde\u63a5\uff0c\u5176\u5b9e\u662f\u5bf9\u77e9\u9635\u4e58\u6cd5\u7684\u5f62\u8c61\u5316\uff1bCNN\u4e2d\u7684\u60c5\u51b5\u5728\u4e0b\u9762\u7ed9\u51fa\u4e86\u975e\u5e38\u8be6\u7ec6\u7684\u4ecb\u7ecd\uff1b\u90a3\u8fd9\u4e24\u8005\u5230\u5e95\u662f\u5148\u6709\u7684\u6570\u5b66\uff0c\u7136\u540e\u6709\u7684\u5bf9\u5b83\u7684\u5f62\u8c61\u5316\u7684\u63cf\u8ff0\u5462\uff1f\u8fd8\u662f\u5148\u6709\u7684\u540e\u8005\u518d\u6709\u7684\u524d\u8005\uff1f Overview and intuition without brain stuff. Lets first discuss what the CONV layer computes without brain/neuron analogies. The CONV layer\u2019s parameters consist of a set of learnable filters . Every filter is small spatially (along width and height), but extends through the full depth of the input volume. For example, a typical filter on a first layer of a ConvNet might have size 5x5x3 (i.e. 5 pixels width and height, and 3 because images have depth 3, the color channels). During the forward pass, we slide\uff08\u6ed1\u52a8\uff09 (more precisely, convolve\uff08\u5377\u79ef\uff09) each filter across the width and height of the input volume and compute dot products between the entries of the filter and the input at any position. As we slide the filter over the width and height of the input volume we will produce a 2-dimensional activation map that gives the responses of that filter at every spatial position. Intuitively, the network will learn filters that activate when they see some type of visual feature such as an edge\uff08\u8fb9\u7f18\uff09 of some orientation or a blotch\uff08\u6591\u70b9\uff09 of some color on the first layer, or eventually entire honeycomb or wheel-like patterns on higher layers of the network. Now, we will have an entire set of filters in each CONV layer (e.g. 12 filters), and each of them will produce a separate 2-dimensional activation map. We will stack these activation maps along the depth dimension and produce the output volume. \u6ca1\u6709\u5927\u8111\u7684\u6982\u8ff0\u548c\u76f4\u89c9\u3002\u8ba9\u6211\u4eec\u9996\u5148\u8ba8\u8bbaCONV\u5c42\u5728\u6ca1\u6709\u8111/\u795e\u7ecf\u5143\u7c7b\u6bd4\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\u7684\u5185\u5bb9\u3002 CONV\u5c42\u7684\u53c2\u6570\u7531\u4e00\u7ec4\u53ef\u5b66\u4e60\u7684\u8fc7\u6ee4\u5668\u7ec4\u6210\u3002\u6bcf\u4e2a\u8fc7\u6ee4\u5668\u5728\u7a7a\u95f4\u4e0a\u90fd\u5f88\u5c0f\uff08\u6cbf\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff09\uff0c\u4f46\u5ef6\u4f38\u5230\u8f93\u5165\u4f53\u79ef\u7684\u6574\u4e2a\u6df1\u5ea6\u3002\u4f8b\u5982\uff0cConvNet\u7b2c\u4e00\u5c42\u4e0a\u7684\u5178\u578b\u6ee4\u6ce2\u5668\u53ef\u80fd\u5177\u67095x5x3\u7684\u5c3a\u5bf8\uff08\u53735\u50cf\u7d20\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u4ee5\u53ca3\uff0c\u56e0\u4e3a\u56fe\u50cf\u5177\u6709\u6df1\u5ea63\uff0c\u989c\u8272\u901a\u9053\uff09\u3002\u5728\u524d\u5411\u4f20\u9012\u671f\u95f4\uff0c\u6211\u4eec\u5728\u8f93\u5165\u4f53\u79ef\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0a\u6ed1\u52a8\uff08\u6ed1\u52a8\uff09\uff08\u66f4\u51c6\u786e\u5730\u8bf4\uff0c\u5377\u79ef\uff08\u5377\u79ef\uff09\uff09\u6bcf\u4e2a\u6ee4\u6ce2\u5668\uff0c\u5e76\u8ba1\u7b97\u6ee4\u6ce2\u5668\u7684\u6761\u76ee\u548c\u4efb\u4f55\u4f4d\u7f6e\u5904\u7684\u8f93\u5165\u4e4b\u95f4\u7684\u70b9\u79ef\u3002\u5f53\u6211\u4eec\u5728\u8f93\u5165\u4f53\u79ef\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0a\u6ed1\u52a8\u6ee4\u955c\u65f6\uff0c\u6211\u4eec\u5c06\u751f\u6210\u4e00\u4e2a\u4e8c\u7ef4\u6fc0\u6d3b\u8d34\u56fe\uff0c\u8be5\u8d34\u56fe\u5728\u6bcf\u4e2a\u7a7a\u95f4\u4f4d\u7f6e\u7ed9\u51fa\u8be5\u6ee4\u955c\u7684\u54cd\u5e94\u3002\u76f4\u89c2\u5730\uff0c\u7f51\u7edc\u5c06\u5b66\u4e60\u5f53\u4ed6\u4eec\u770b\u5230\u67d0\u79cd\u7c7b\u578b\u7684\u89c6\u89c9\u7279\u5f81\u65f6\u6fc0\u6d3b\u7684\u8fc7\u6ee4\u5668\uff0c\u4f8b\u5982\u67d0\u4e2a\u65b9\u5411\u7684\u8fb9\u7f18\u6216\u7b2c\u4e00\u5c42\u4e0a\u67d0\u79cd\u989c\u8272\u7684\u6591\u70b9\uff0c\u6216\u6700\u7ec8\u5728\u7f51\u7edc\u7684\u66f4\u9ad8\u5c42\u4e0a\u7684\u6574\u4e2a\u8702\u7a9d\u6216\u8f6e\u72b6\u56fe\u6848\u3002\u73b0\u5728\uff0c\u6211\u4eec\u5c06\u5728\u6bcf\u4e2aCONV\u5c42\u4e2d\u6709\u4e00\u6574\u5957\u8fc7\u6ee4\u5668\uff08\u4f8b\u598212\u4e2a\u8fc7\u6ee4\u5668\uff09\uff0c\u5e76\u4e14\u6bcf\u4e2a\u8fc7\u6ee4\u5668\u5c06\u4ea7\u751f\u5355\u72ec\u76842\u7ef4\u6fc0\u6d3b\u56fe\u3002\u6211\u4eec\u5c06\u6cbf\u6df1\u5ea6\u7ef4\u5ea6\u5806\u53e0\u8fd9\u4e9b\u6fc0\u6d3b\u56fe\u5e76\u751f\u6210\u8f93\u51fa\u91cf\u3002 THINKING : \u6bcf\u4e2afilter\u662f\u5426\u9700\u8981\u626b\u63cf\u5b8c\u6574\u4e2a**input volume**\uff1f\u6bcf\u4e2afilter\u7684\u8f93\u51fa\u662f\u4ec0\u4e48\uff1f entries of the filter\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u8fd9\u4e9b\u95ee\u9898\u5728\u4e0a\u9762\u8fd9\u4e00\u6bb5\u4e2d\u90fd\u5df2\u7ecf\u63cf\u8ff0\u6e05\u695a\u4e86\uff1b THINKING : \u6240\u8c13\u7684filter\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u5377\u79ef\u8fd0\u7b97\u5b50\uff1b The brain view . If you\u2019re a fan of the brain/neuron analogies, every entry in the 3D output volume can also be interpreted as an output of a neuron that looks at only a small region in the input and shares parameters with all neurons to the left and right spatially (since these numbers all result from applying the same filter). We now discuss the details of the neuron connectivities, their arrangement in space, and their parameter sharing scheme. THINKING : neuron\u548cfilter\u4e4b\u95f4\u7684\u5173\u7cfb\uff1f\uff1f\u6309\u7167MLP\u4e2d\u7684\u7406\u89e3\uff0c\u6bcf\u4e00\u5c42\u4e2d\u7684\u4e00\u4e2aneuron\u90fd\u6267\u884c\u4e86\u4e00\u4e2afunction\uff0c\u90a3\u5728CNN\u4e2d\uff0c\u662f\u5426\u4e5f\u662f\u5982\u6b64\u5462\uff1f\u5728\u4e0b\u9762\u8fd9\u4e00\u6bb5\u4e2d\u5c31\u4f1a\u4ecb\u7ecd\u8fd9\u4e2a\u5185\u5bb9\uff0c\u5176\u5b9e\u901a\u8fc7\u8fd9\u4e2a\u5185\u5bb9\u4e5f\u53ef\u4ee5\u5f97\u77e5\uff1a\u5728CNN\u4e2d\uff0c\u6bcf\u4e2aneuron\u6240\u6267\u884c\u7684\u90fd\u662f\u4e00\u4e2afilter\u7684\u64cd\u4f5c\uff1b Local Connectivity. When dealing with high-dimensional inputs such as images, as we saw above it is impractical to connect neurons to all neurons in the previous volume. Instead, we will connect each neuron to only a local region of the input volume. The spatial extent of this connectivity is a hyperparameter called the receptive field of the neuron (equivalently\uff08\u76f8\u5f53\u4e8e\uff09 this is the filter size ). The extent of the connectivity along the depth axis is always equal to the depth of the input volume. It is important to emphasize again this asymmetry in how we treat the spatial dimensions (width and height) and the depth dimension: The connections are local in space (along width and height), but always full along the entire depth of the input volume. Example 1 . For example, suppose that the input volume has size [32x32x3], (e.g. an RGB CIFAR-10 image). If the receptive field (or the filter size) is 5x5, then each neuron in the Conv Layer will have weights to a [5x5x3] region in the input volume, for a total of 5*5*3 = 75 5*5*3 = 75 weights (and +1 bias parameter). Notice that the extent of the connectivity along the depth axis must be 3, since this is the depth of the input volume. Example 2 . Suppose an input volume had size [16x16x20]. Then using an example receptive field size of 3x3, every neuron in the Conv Layer would now have a total of 3*3*20 = 180 3*3*20 = 180 connections to the input volume. Notice that, again, the connectivity is local in space (e.g. 3x3), but full along the input depth (20). Left: An example input volume in red (e.g. a 32x32x3 CIFAR-10 image), and an example volume of neurons in the first Convolutional layer . Each neuron in the convolutional layer is connected only to a local region in the input volume spatially, but to the full depth (i.e. all color channels). Note, there are multiple neurons (5 in this example) along the depth, all looking at the same region in the input - see discussion of depth columns in text below. Right: The neurons from the Neural Network chapter remain unchanged: They still compute a dot product of their weights with the input followed by a non-linearity, but their connectivity is now restricted to be local spatially. Spatial arrangement . We have explained the connectivity of each neuron in the Conv Layer to the input volume, but we haven\u2019t yet discussed how many neurons there are in the output volume or how they are arranged. Three hyperparameters control the size of the output volume : the depth, stride and zero-padding . We discuss these next: First, the depth of the output volume is a hyperparameter: it corresponds to the number of filters we would like to use, each learning to look for something different in the input. For example, if the first Convolutional Layer takes as input the raw image, then different neurons along the depth dimension may activate in presence of various oriented edges, or blobs of color. We will refer to a set of neurons that are all looking at the same region of the input as a depth column (some people also prefer the term fibre ). Second, we must specify the stride with which we slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more, though this is rare in practice) then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially. As we will soon see, sometimes it will be convenient to pad the input volume with zeros around the border. The size of this zero-padding is a hyperparameter. The nice feature of zero padding is that it will allow us to control the spatial size of the output volumes (most commonly as we\u2019ll see soon we will use it to exactly preserve the spatial size of the input volume so the input and output width and height are the same). We can compute the spatial size of the output volume as a function of the input volume size ( W W ), the receptive field size of the Conv Layer neurons ( F F ), the stride with which they are applied ( S S ), and the amount of zero padding used ( P P ) on the border. You can convince yourself that the correct formula for calculating how many neurons \u201cfit\u201d is given by (W - F + 2P)/S + 1 (W - F + 2P)/S + 1 . For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output. Lets also see one more graphical example: Illustration of spatial arrangement. In this example there is only one spatial dimension (x-axis), one neuron with a receptive field size of F = 3, the input size is W = 5, and there is zero padding of P = 1. Left: The neuron strided across the input in stride of S = 1, giving output of size (5 - 3 + 2)/1+1 = 5. Right: The neuron uses stride of S = 2, giving output of size (5 - 3 + 2)/2+1 = 3. Notice that stride S = 3 could not be used since it wouldn't fit neatly across the volume. In terms of the equation, this can be determined since (5 - 3 + 2) = 4 is not divisible by 3. The neuron weights are in this example [1,0,-1] (shown on very right), and its bias is zero. These weights are shared across all yellow neurons (see parameter sharing below). Use of zero-padding . In the example above on left, note that the input dimension was 5 and the output dimension was equal: also 5. This worked out so because our receptive fields were 3 and we used zero padding of 1. If there was no zero-padding used, then the output volume would have had spatial dimension of only 3, because that it is how many neurons would have \u201cfit\u201d across the original input. In general, setting zero padding to be P=(F\u22121)/2 P=(F\u22121)/2 when the stride is S=1 S=1 ensures that the input volume and output volume will have the same size spatially. It is very common to use zero-padding in this way and we will discuss the full reasons when we talk more about ConvNet architectures. Constraints on strides . Note again that the spatial arrangement hyperparameters have mutual constraints. For example, when the input has size W=10 W=10 , no zero-padding is used P=0 P=0 , and the filter size is F=3 F=3 , then it would be impossible to use stride S=2 S=2 , since , i.e. not an integer, indicating that the neurons don\u2019t \u201cfit\u201d neatly and symmetrically across the input. Therefore, this setting of the hyperparameters is considered to be invalid, and a ConvNet library could throw an exception or zero pad the rest to make it fit, or crop the input to make it fit, or something. As we will see in the ConvNet architectures section, sizing the ConvNets appropriately so that all the dimensions \u201cwork out\u201d can be a real headache, which the use of zero-padding and some design guidelines will significantly alleviate. Real-world example . The Krizhevsky et al. architecture that won the ImageNet challenge in 2012 accepted images of size [227x227x3]. On the first Convolutional Layer, it used neurons with receptive field size F=11 F=11 , stride S=4 S=4 and no zero padding P=0 P=0 . Since (227 - 11)/4 + 1 = 55, and since the Conv layer had a depth of K=96 K=96 , the Conv layer output volume had size [55x55x96]. Each of the 55*55*96 neurons in this volume was connected to a region of size [11x11x3] in the input volume. Moreover, all 96 neurons in each depth column are connected to the same [11x11x3] region of the input, but of course with different weights. As a fun aside, if you read the actual paper it claims that the input images were 224x224, which is surely incorrect because (224 - 11)/4 + 1 is quite clearly not an integer. This has confused many people in the history of ConvNets and little is known about what happened. My own best guess is that Alex used zero-padding of 3 extra pixels that he does not mention in the paper. Parameter Sharing. Parameter sharing scheme is used in Convolutional Layers to control the number of parameters. Using the real-world example above, we see that there are 55*55*96 = 290,400 neurons in the first Conv Layer, and each has 11*11*3 = 363 weights and 1 bias. Together, this adds up to 290400 * 364 = 105,705,600 parameters on the first layer of the ConvNet alone. Clearly, this number is very high. It turns out that we can dramatically reduce the number of parameters by making one reasonable assumption: That if one feature is useful to compute at some spatial position (x,y), then it should also be useful to compute at a different position (x2,y2). In other words, denoting a single 2-dimensional slice of depth as a depth slice (e.g. a volume of size [55x55x96] has 96 depth slices, each of size [55x55]), we are going to constrain the neurons in each depth slice to use the same weights and bias. With this parameter sharing scheme, the first Conv Layer in our example would now have only 96 unique set of weights (one for each depth slice), for a total of 96*11*11*3 = 34,848 unique weights, or 34,944 parameters (+96 biases). Alternatively, all 55*55 neurons in each depth slice will now be using the same parameters. In practice during backpropagation, every neuron in the volume will compute the gradient for its weights, but these gradients will be added up across each depth slice and only update a single set of weights per slice. Notice that if all neurons in a single depth slice are using the same weight vector, then the forward pass of the CONV layer can in each depth slice be computed as a convolution of the neuron\u2019s weights with the input volume (Hence the name: Convolutional Layer). This is why it is common to refer to the sets of weights as a filter (or a kernel ), that is convolved with the input. Example filters learned by Krizhevsky et al. Each of the 96 filters shown here is of size [11x11x3], and each one is shared by the 55*55 neurons in one depth slice. Notice that the parameter sharing assumption is relatively reasonable: If detecting a horizontal edge is important at some location in the image, it should intuitively be useful at some other location as well due to the translationally-invariant structure of images. There is therefore no need to relearn to detect a horizontal edge at every one of the 55*55 distinct locations in the Conv layer output volume. Note that sometimes the parameter sharing assumption may not make sense. This is especially the case when the input images to a ConvNet have some specific centered structure, where we should expect, for example, that completely different features should be learned on one side of the image than another. One practical example is when the input are faces that have been centered in the image. You might expect that different eye-specific or hair-specific features could (and should) be learned in different spatial locations. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a Locally-Connected Layer . Numpy examples. To make the discussion above more concrete, lets express the same ideas but in code and with a specific example. Suppose that the input volume is a numpy array X . Then: A depth column (or a fibre ) at position (x,y) would be the activations X[x,y,:] . A depth slice , or equivalently an activation map at depth d would be the activations X[:,:,d] . Conv Layer Example . Suppose that the input volume X has shape X.shape: (11,11,4) . Suppose further that we use no zero padding (P=0P=0), that the filter size is F=5F=5, and that the stride is S=2S=2. The output volume would therefore have spatial size (11-5)/2+1 = 4, giving a volume with width and height of 4. The activation map in the output volume (call it V ), would then look as follows (only some of the elements are computed in this example): V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0 V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0 V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0 V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0 Remember that in numpy, the operation * above denotes elementwise multiplication between the arrays. Notice also that the weight vector W0 is the weight vector of that neuron and b0 is the bias. Here, W0 is assumed to be of shape W0.shape: (5,5,4) , since the filter size is 5 and the depth of the input volume is 4. Notice that at each point, we are computing the dot product as seen before in ordinary neural networks. Also, we see that we are using the same weight and bias (due to parameter sharing), and where the dimensions along the width are increasing in steps of 2 (i.e. the stride). To construct a second activation map in the output volume, we would have: V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1 V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1 V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1 V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1 V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 (example of going along y) V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 (or along both) where we see that we are indexing into the second depth dimension in V (at index 1) because we are computing the second activation map, and that a different set of parameters ( W1 ) is now used. In the example above, we are for brevity leaving out some of the other operations the Conv Layer would perform to fill the other parts of the output array V . Additionally, recall that these activation maps are often followed elementwise through an activation function such as ReLU, but this is not shown here. Summary . To summarize, the Conv Layer: Accepts a volume of size W1\u00d7H1\u00d7D1W1\u00d7H1\u00d7D1 Requires four hyperparameters: Number of filters KK, their spatial extent FF, the stride SS, the amount of zero padding PP. Produces a volume of size W2\u00d7H2\u00d7D2W2\u00d7H2\u00d7D2 where: W2=(W1\u2212F+2P)/S+1W2=(W1\u2212F+2P)/S+1 H2=(H1\u2212F+2P)/S+1H2=(H1\u2212F+2P)/S+1 (i.e. width and height are computed equally by symmetry) D2=KD2=K With parameter sharing, it introduces F\u22c5F\u22c5D1F\u22c5F\u22c5D1 weights per filter, for a total of (F\u22c5F\u22c5D1)\u22c5K(F\u22c5F\u22c5D1)\u22c5K weights and KK biases. In the output volume, the dd-th depth slice (of size W2\u00d7H2W2\u00d7H2) is the result of performing a valid convolution of the dd-th filter over the input volume with a stride of SS, and then offset by dd-th bias. A common setting of the hyperparameters is F=3,S=1,P=1F=3,S=1,P=1. However, there are common conventions and rules of thumb that motivate these hyperparameters. See the ConvNet architectures section below. Convolution Demo . Below is a running demo of a CONV layer. Since 3D volumes are hard to visualize, all the volumes (the input volume (in blue), the weight volumes (in red), the output volume (in green)) are visualized with each depth slice stacked in rows. The input volume is of size W_1 = 5, H_1 = 5, D_1 = 3 W_1 = 5, H_1 = 5, D_1 = 3 , and the CONV layer parameters are K = 2, F = 3, S = 2, P = 1 K = 2, F = 3, S = 2, P = 1 . That is, we have two filters of size 3\u00d733\u00d73, and they are applied with a stride of 2. Therefore, the output volume size has spatial size (5 - 3 + 2)/2 + 1 = 3. Moreover, notice that a padding of P=1 P=1 is applied to the input volume, making the outer border of the input volume zero. The visualization below iterates over the output activations (green), and shows that each element is computed by elementwise multiplying the highlighted input (blue) with the filter (red), summing it up, and then offsetting the result by the bias. Implementation as Matrix Multiplication . Note that the convolution operation essentially performs dot products between the filters and local regions of the input. A common implementation pattern of the CONV layer is to take advantage of this fact and formulate the forward pass of a convolutional layer as one big matrix multiply as follows: The local regions in the input image are stretched out into columns in an operation commonly called im2col . For example, if the input is [227x227x3] and it is to be convolved with 11x11x3 filters at stride 4, then we would take [11x11x3] blocks of pixels in the input and stretch each block into a column vector of size 11*11*3 = 363. Iterating this process in the input at stride of 4 gives (227-11)/4+1 = 55 locations along both width and height, leading to an output matrix X_col of im2col of size [363 x 3025], where every column is a stretched out receptive field and there are 55*55 = 3025 of them in total. Note that since the receptive fields overlap, every number in the input volume may be duplicated in multiple distinct columns. The weights of the CONV layer are similarly stretched out into rows. For example, if there are 96 filters of size [11x11x3] this would give a matrix W_row of size [96 x 363]. The result of a convolution is now equivalent to performing one large matrix multiply np.dot(W_row, X_col) , which evaluates the dot product between every filter and every receptive field location. In our example, the output of this operation would be [96 x 3025], giving the output of the dot product of each filter at each location. The result must finally be reshaped back to its proper output dimension [55x55x96]. This approach has the downside that it can use a lot of memory, since some values in the input volume are replicated multiple times in X_col . However, the benefit is that there are many very efficient implementations of Matrix Multiplication that we can take advantage of (for example, in the commonly used BLAS API). Moreover, the same im2col idea can be reused to perform the pooling operation, which we discuss next. Backpropagation. The backward pass for a convolution operation (for both the data and the weights) is also a convolution (but with spatially-flipped filters). This is easy to derive in the 1-dimensional case with a toy example (not expanded on for now). 1x1 convolution . As an aside, several papers use 1x1 convolutions, as first investigated by Network in Network . Some people are at first confused to see 1x1 convolutions especially when they come from signal processing background. Normally signals are 2-dimensional so 1x1 convolutions do not make sense (it\u2019s just pointwise scaling). However, in ConvNets this is not the case because one must remember that we operate over 3-dimensional volumes, and that the filters always extend through the full depth of the input volume. For example, if the input is [32x32x3] then doing 1x1 convolutions would effectively be doing 3-dimensional dot products (since the input depth is 3 channels). Dilated convolutions. A recent development (e.g. see paper by Fisher Yu and Vladlen Koltun ) is to introduce one more hyperparameter to the CONV layer called the dilation . So far we\u2019ve only discussed CONV filters that are contiguous. However, it\u2019s possible to have filters that have spaces between each cell, called dilation. As an example, in one dimension a filter w of size 3 would compute over input x the following: w[0]*x[0] + w[1]*x[1] + w[2]*x[2] . This is dilation of 0. For dilation 1 the filter would instead compute w[0]*x[0] + w[1]*x[2] + w[2]*x[4] ; In other words there is a gap of 1 between the applications. This can be very useful in some settings to use in conjunction with 0-dilated filters because it allows you to merge spatial information across the inputs much more agressively with fewer layers. For example, if you stack two 3x3 CONV layers on top of each other then you can convince yourself that the neurons on the 2 nd layer are a function of a 5x5 patch of the input (we would say that the effective receptive field of these neurons is 5x5). If we use dilated convolutions then this effective receptive field would grow much quicker. Pooling Layer It is common to periodically insert a Pooling layer in-between successive Conv layers in a ConvNet architecture. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. The Pooling Layer operates independently on every depth slice of the input and resizes it spatially, using the MAX operation . The most common form is a pooling layer with filters of size 2x2 applied with a stride of 2 downsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations. Every MAX operation would in this case be taking a max over 4 numbers (little 2x2 region in some depth slice). The depth dimension remains unchanged. More generally, the pooling layer: Accepts a volume of size W_1 \\times H_1 \\times D_1 W_1 \\times H_1 \\times D_1 Requires two hyperparameters: their spatial extent F F , the stride S S , Produces a volume of size W_2 \\times H_2 \\times D_2 W_2 \\times H_2 \\times D_2 where: W_2 = (W_1 - F)/S + 1 W_2 = (W_1 - F)/S + 1 H_2 = (H_1 - F)/S + 1 H_2 = (H_1 - F)/S + 1 D_2 = D_1 D_2 = D_1 Introduces zero parameters since it computes a fixed function of the input For Pooling layers, it is not common to pad the input using zero-padding. It is worth noting that there are only two commonly seen variations of the max pooling layer found in practice: A pooling layer with F=3,S=2 F=3,S=2 (also called overlapping pooling ), and more commonly F=2,S=2 F=2,S=2 . Pooling sizes with larger receptive fields are too destructive. General pooling . In addition to max pooling , the pooling units can also perform other functions, such as average pooling or even L2-norm pooling . Average pooling was often used historically but has recently fallen out of favor compared to the max pooling operation, which has been shown to work better in practice. Pooling layer downsamples the volume spatially, independently in each depth slice of the input volume. Left: In this example, the input volume of size [224x224x64] is pooled with filter size 2, stride 2 into output volume of size [112x112x64]. Notice that the volume depth is preserved. Right: The most common downsampling operation is max, giving rise to max pooling, here shown with a stride of 2. That is, each max is taken over 4 numbers (little 2x2 square). Backpropagation . Recall from the backpropagation chapter that the backward pass for a max(x, y) operation has a simple interpretation as only routing the gradient to the input that had the highest value in the forward pass. Hence, during the forward pass of a pooling layer it is common to keep track of the index of the max activation (sometimes also called the switches ) so that gradient routing is efficient during backpropagation. Getting rid of pooling . Many people dislike the pooling operation and think that we can get away without it. For example, Striving for Simplicity: The All Convolutional Net proposes to discard the pooling layer in favor of architecture that only consists of repeated CONV layers. To reduce the size of the representation they suggest using larger stride in CONV layer once in a while. Discarding pooling layers has also been found to be important in training good generative models, such as variational autoencoders (VAEs) or generative adversarial networks (GANs). It seems likely that future architectures will feature very few to no pooling layers. Normalization Layer Many types of normalization layers have been proposed for use in ConvNet architectures, sometimes with the intentions of implementing inhibition schemes observed in the biological brain. However, these layers have since fallen out of favor because in practice their contribution has been shown to be minimal, if any. For various types of normalizations, see the discussion in Alex Krizhevsky\u2019s cuda-convnet library API . Fully-connected layer Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can hence be computed with a matrix multiplication followed by a bias offset . See the Neural Network section of the notes for more information. Converting FC layers to CONV layers It is worth noting that the only difference between FC and CONV layers is that the neurons in the CONV layer are connected only to a local region in the input, and that many of the neurons in a CONV volume share parameters. However, the neurons in both layers still compute dot products, so their functional form is identical. Therefore, it turns out that it\u2019s possible to convert between FC and CONV layers: For any CONV layer there is an FC layer that implements the same forward function. The weight matrix would be a large matrix that is mostly zero except for at certain blocks (due to local connectivity) where the weights in many of the blocks are equal (due to parameter sharing). Conversely, any FC layer can be converted to a CONV layer . For example, an FC layer with K=4096 K=4096 that is looking at some input volume of size 7\u00d77\u00d7512 7\u00d77\u00d7512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096 F=7,P=0,S=1,K=4096 . In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1\u00d71\u00d74096 1\u00d71\u00d74096 since only a single depth column \u201cfits\u201d across the input volume, giving identical result as the initial FC layer. SUMMARY : \u4e0a\u8ff0 FC layer with K=4096 K=4096 \u4e2d\u7684 K K \u662f\u4ec0\u4e48\u610f\u601d\uff1fneuron\u4e2a\u6570\uff1f\u5e94\u8be5\u662f\u7684\uff0c\u53ef\u4ee5\u8fdb\u884c\u5012\u63a8\uff0c\u65e2\u7136FC layer\u53ef\u4ee5\u7b49\u4ef7\u7684\u8f6c\u6362\u4e3a**CONV layer** with F=7,P=0,S=1,K=4096 F=7,P=0,S=1,K=4096 \uff0c\u8fd9\u4e2a**CONV layer**\u9501\u6267\u884c\u7684\u64cd\u4f5c\u662f\u975e\u5e38\u7b80\u5355\u7684\uff1a\u5b83\u67094096\u4e2a filter\uff0c\u6bcf\u4e2afilter\u90fd\u4f1a\u548c input volume of size 7\u00d77\u00d7512 7\u00d77\u00d7512 \u6267\u884cdot product\uff0c\u663e\u7136\u8fd9\u5176\u5b9e\u5c31\u662fMLP\u4e2d\u7684\u5168\u8fde\u63a5\u5c42\u4e86\uff0c\u663e\u7136\uff0c\u6bcf\u4e2afilter\u5c31\u76f8\u5f53\u4e8eMLP\u4e2d\u7684\u4e00\u4e2aneuron\uff1b\u8fd9\u4e2a\u63a8\u6d4b\u5728\u4e0b\u9762\u7684**FC->CONV conversion**\u4e2d\u662f\u53ef\u4ee5\u9a8c\u8bc1\u7684\uff1b SUMMARY : CONV layer with F=7,P=0,S=1,K=4096 F=7,P=0,S=1,K=4096 . \u4e2d\u7684 K K \u6307\u7684\u662ffilter\u7684\u4e2a\u6570\u3002 FC->CONV conversion . Of these two conversions, the ability to convert an FC layer to a CONV layer is particularly useful in practice. Consider a ConvNet architecture that takes a 224x224x3 image, and then uses a series of CONV layers and POOL layers to reduce the image to an activations volume of size 7x7x512 (in an AlexNet architecture that we\u2019ll see later, this is done by use of 5 pooling layers that downsample the input spatially by a factor of two each time, making the final spatial size 224/2/2/2/2/2 = 7). From there, an AlexNet uses two FC layers of size 4096 and finally the last FC layers with 1000 neurons that compute the class scores. We can convert each of these three FC layers to CONV layers as described above: Replace the first FC layer that looks at [7x7x512] volume with a CONV layer that uses filter size F=7 F=7 , giving output volume [1x1x4096]. Replace the second FC layer with a CONV layer that uses filter size F=1 F=1 , giving output volume [1x1x4096] Replace the last FC layer similarly, with F=1 F=1 , giving final output [1x1x1000] Each of these conversions could in practice involve manipulating (e.g. reshaping) the weight matrix W W in each FC layer into CONV layer filters . It turns out that this conversion allows us to \u201cslide\u201d the original ConvNet very efficiently across many spatial positions in a larger image, in a single forward pass. For example, if 224x224 image gives a volume of size [7x7x512] - i.e. a reduction by 32, then forwarding an image of size 384x384 through the converted architecture would give the equivalent volume in size [12x12x512], since 384/32 = 12. Following through with the next 3 CONV layers that we just converted from FC layers would now give the final volume of size [6x6x1000], since (12 - 7)/1 + 1 = 6. Note that instead of a single vector of class scores of size [1x1x1000], we\u2019re now getting an entire 6x6 array of class scores across the 384x384 image. Evaluating the original ConvNet (with FC layers) independently across 224x224 crops of the 384x384 image in strides of 32 pixels gives an identical result to forwarding the converted ConvNet one time. Naturally, forwarding the converted ConvNet a single time is much more efficient than iterating the original ConvNet over all those 36 locations, since the 36 evaluations share computation. This trick is often used in practice to get better performance, where for example, it is common to resize an image to make it bigger, use a converted ConvNet to evaluate the class scores at many spatial positions and then average the class scores. Lastly, what if we wanted to efficiently apply the original ConvNet over the image but at a stride smaller than 32 pixels? We could achieve this with multiple forward passes. For example, note that if we wanted to use a stride of 16 pixels we could do so by combining the volumes received by forwarding the converted ConvNet twice: First over the original image and second over the image but with the image shifted spatially by 16 pixels along both width and height. An IPython Notebook on Net Surgery shows how to perform the conversion in practice, in code (using Caffe) ConvNet Architectures We have seen that Convolutional Networks are commonly made up of only three layer types: CONV, POOL (we assume Max pool unless stated otherwise) and FC (short for fully-connected). We will also explicitly write the RELU activation function as a layer, which applies elementwise non-linearity. In this section we discuss how these are commonly stacked together to form entire ConvNets. Layer Patterns The most common form of a ConvNet architecture stacks a few CONV-RELU layers, follows them with POOL layers, and repeats this pattern until the image has been merged spatially to a small size. At some point, it is common to transition to fully-connected layers. The last fully-connected layer holds the output, such as the class scores. In other words, the most common ConvNet architecture follows the pattern: INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC where the * indicates repetition, and the POOL? indicates an optional pooling layer. Moreover, N >= 0 (and usually N <= 3 ), M >= 0 , K >= 0 (and usually K < 3 ). For example, here are some common ConvNet architectures you may see that follow this pattern: INPUT -> FC , implements a linear classifier. Here N = M = K = 0 . INPUT -> CONV -> RELU -> FC INPUT -> [CONV -> RELU -> POOL]*2 -> FC -> RELU -> FC . Here we see that there is a single CONV layer between every POOL layer. INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> FC Here we see two CONV layers stacked before every POOL layer. This is generally a good idea for larger and deeper networks, because multiple stacked CONV layers can develop more complex features of the input volume before the destructive pooling operation. Additional Resources Additional resources related to implementation: Soumith benchmarks for CONV performance ConvNetJS CIFAR-10 demo allows you to play with ConvNet architectures and see the results and computations in real time, in the browser. Caffe , one of the popular ConvNet libraries. State of the art ResNets in Torch7","title":"Convolutional-Neural-Networks(CNNs-or-ConvNets)"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#convolutional#neural#networks#cnns#convnets","text":"Convolutional Neural Networks are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases . Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function : from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply. SUMMARY : dot product\u610f\u5473\u7740\u7ed3\u679c\u662f\u4e00\u4e2a\u5f20\u91cf\uff1b\u610f\u5473\u7740filter\u7684shape\u548c\u5b83\u6240\u626b\u8fc7\u7684\u533a\u57df\u7684shape\u76f8\u540c\uff1b SUMMARY : score function vs loss function SUMMARY : The whole network still expresses a single differentiable score function So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.","title":"Convolutional Neural Networks (CNNs / ConvNets)"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#architecture#overview","text":"Recall: Regular Neural Nets. As we saw in the previous chapter, Neural Networks receive an input (a single vector), and transform it through a series of hidden layers . Each hidden layer is made up of a set of neurons, where each neuron is fully connected to all neurons in the previous layer, and where neurons in a single layer function completely independently and do not share any connections. The last fully-connected layer is called the \u201coutput layer\u201d and in classification settings it represents the class scores . Regular Neural Nets don\u2019t scale well to full images . In CIFAR-10, images are only of size 32x32x3 (32 wide, 32 high, 3 color channels), so a single fully-connected neuron in a first hidden layer of a regular Neural Network would have 32*32*3 = 3072 32*32*3 = 3072 weights. This amount still seems manageable, but clearly this fully-connected structure does not scale to larger images. For example, an image of more respectable size, e.g. 200 * 200 * 3 200 * 200 * 3 , would lead to neurons that have 200*200*3 = 120,000 200*200*3 = 120,000 weights. Moreover, we would almost certainly want to have several such neurons, so the parameters would add up quickly! Clearly, this full connectivity is wasteful and the huge number of parameters would quickly lead to overfitting. 3D volumes of neurons . Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth . (Note that the word depth here refers to the third dimension of an activation volume, not to the depth of a full Neural Network, which can refer to the total number of layers in a network.) For example, the input images in CIFAR-10 are an input volume of activations, and the volume has dimensions 32x32x3\u200b (width, height, depth respectively). As we will soon see, the neurons in a layer will only be connected to a small region of the layer before it, instead of all of the neurons in a fully-connected manner . Moreover, the final output layer would for CIFAR-10 have dimensions 1x1x10\u200b, because by the end of the ConvNet architecture we will reduce the full image into a single vector of class scores , arranged along the depth dimension. Here is a visualization: Left: A regular 3-layer Neural Network. Right: A ConvNet arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels). A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.","title":"Architecture Overview"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#layers#used#to#build#convnets","text":"As we described above, a simple ConvNet is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through a differentiable function . We use three main types of layers to build ConvNet architectures: Convolutional Layer , Pooling Layer , and Fully-Connected Layer (exactly as seen in regular Neural Networks). We will stack these layers to form a full ConvNet architecture . Example Architecture: Overview . We will go into more details below, but a simple ConvNet for CIFAR-10 classification could have the architecture [INPUT - CONV - RELU - POOL - FC]. In more detail: INPUT [32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R,G,B. CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. This may result in volume such as [32x32x12] if we decided to use 12 filters . RELU layer will apply an elementwise activation function, such as the max(0,x) max(0,x) thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]). POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]. FC (i.e. fully-connected) layer will compute the class scores , resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score, such as among the 10 categories of CIFAR-10. As with ordinary Neural Networks and as the name implies, each neuron in this layer will be connected to all the numbers in the previous volume. In this way, ConvNets transform the original image layer by layer from the original pixel values to the final class scores . Note that some layers contain parameters and other don\u2019t. In particular, the CONV/FC layers perform transformations that are a function of not only the activations in the input volume, but also of the parameters (the weights and biases of the neurons). On the other hand, the RELU/POOL layers will implement a fixed function. The parameters in the CONV/FC layers will be trained with gradient descent so that the class scores that the ConvNet computes are consistent with the labels in the training set for each image. In summary: A ConvNet architecture is in the simplest case a list of Layers that transform the image volume into an output volume (e.g. holding the class scores) There are a few distinct types of Layers (e.g. CONV/FC/RELU/POOL are by far the most popular) Each Layer accepts an input 3D volume and transforms it to an output 3D volume through a differentiable function Each Layer may or may not have parameters (e.g. CONV/FC do, RELU/POOL don\u2019t) Each Layer may or may not have additional hyperparameters (e.g. CONV/FC/POOL do, RELU doesn\u2019t) The activations of an example ConvNet architecture. The initial volume stores the raw image pixels (left) and the last volume stores the class scores (right). Each volume of activations along the processing path is shown as a column. Since it's difficult to visualize 3D volumes, we lay out each volume's slices in rows. The last layer volume holds the scores for each class, but here we only visualize the sorted top 5 scores, and print the labels of each one. The full web-based demo is shown in the header of our website. The architecture shown here is a tiny VGG Net, which we will discuss later. We now describe the individual layers and the details of their hyperparameters and their connectivities.","title":"Layers used to build ConvNets"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#convolutional#layer","text":"The Conv layer is the core building block of a Convolutional Network that does most of the computational heavy lifting. Conv\u5c42\u662f\u5377\u79ef\u7f51\u7edc\u7684\u6838\u5fc3\u6784\u4ef6\uff0c\u5b83\u627f\u62c5\u4e86\u5927\u90e8\u5206\u8ba1\u7b97\u91cf\u3002 SUMMARY : \u4e0b\u9762\u51e0\u6bb5\uff0c\u4ece\u4e0d\u540c\u7684\u89d2\u5ea6\u5bf9CNN\u8fdb\u884c\u4e86\u63cf\u8ff0\uff0c**Overview and intuition without brain stuff**\u6bb5\u662f\u4ece\u6570\u5b66\uff08\u5377\u79ef\u8fd0\u7b97\uff09\u7684\u89d2\u5ea6\u8fdb\u884c\u7684\u63cf\u8ff0\uff0c**The brain view**\u6bb5\u5219\u662f\u4eceneuron\u7684\u89d2\u5ea6\u6765\u8fdb\u884c\u7684\u63cf\u8ff0\uff1b\u5176\u5b9e\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c\u6211\u4eec\u6240\u4f7f\u7528\u7684network topology\u5176\u5b9e\u662f\u5bf9\u6570\u5b66\u8fd0\u7b97\u7684\u5f62\u8c61\u5316\uff1aMLP\u4e2d\u6240\u8c13\u7684\u5168\u8fde\u63a5\uff0c\u5176\u5b9e\u662f\u5bf9\u77e9\u9635\u4e58\u6cd5\u7684\u5f62\u8c61\u5316\uff1bCNN\u4e2d\u7684\u60c5\u51b5\u5728\u4e0b\u9762\u7ed9\u51fa\u4e86\u975e\u5e38\u8be6\u7ec6\u7684\u4ecb\u7ecd\uff1b\u90a3\u8fd9\u4e24\u8005\u5230\u5e95\u662f\u5148\u6709\u7684\u6570\u5b66\uff0c\u7136\u540e\u6709\u7684\u5bf9\u5b83\u7684\u5f62\u8c61\u5316\u7684\u63cf\u8ff0\u5462\uff1f\u8fd8\u662f\u5148\u6709\u7684\u540e\u8005\u518d\u6709\u7684\u524d\u8005\uff1f","title":"Convolutional Layer"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#overview#and#intuition#without#brain#stuff","text":"Lets first discuss what the CONV layer computes without brain/neuron analogies. The CONV layer\u2019s parameters consist of a set of learnable filters . Every filter is small spatially (along width and height), but extends through the full depth of the input volume. For example, a typical filter on a first layer of a ConvNet might have size 5x5x3 (i.e. 5 pixels width and height, and 3 because images have depth 3, the color channels). During the forward pass, we slide\uff08\u6ed1\u52a8\uff09 (more precisely, convolve\uff08\u5377\u79ef\uff09) each filter across the width and height of the input volume and compute dot products between the entries of the filter and the input at any position. As we slide the filter over the width and height of the input volume we will produce a 2-dimensional activation map that gives the responses of that filter at every spatial position. Intuitively, the network will learn filters that activate when they see some type of visual feature such as an edge\uff08\u8fb9\u7f18\uff09 of some orientation or a blotch\uff08\u6591\u70b9\uff09 of some color on the first layer, or eventually entire honeycomb or wheel-like patterns on higher layers of the network. Now, we will have an entire set of filters in each CONV layer (e.g. 12 filters), and each of them will produce a separate 2-dimensional activation map. We will stack these activation maps along the depth dimension and produce the output volume. \u6ca1\u6709\u5927\u8111\u7684\u6982\u8ff0\u548c\u76f4\u89c9\u3002\u8ba9\u6211\u4eec\u9996\u5148\u8ba8\u8bbaCONV\u5c42\u5728\u6ca1\u6709\u8111/\u795e\u7ecf\u5143\u7c7b\u6bd4\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\u7684\u5185\u5bb9\u3002 CONV\u5c42\u7684\u53c2\u6570\u7531\u4e00\u7ec4\u53ef\u5b66\u4e60\u7684\u8fc7\u6ee4\u5668\u7ec4\u6210\u3002\u6bcf\u4e2a\u8fc7\u6ee4\u5668\u5728\u7a7a\u95f4\u4e0a\u90fd\u5f88\u5c0f\uff08\u6cbf\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff09\uff0c\u4f46\u5ef6\u4f38\u5230\u8f93\u5165\u4f53\u79ef\u7684\u6574\u4e2a\u6df1\u5ea6\u3002\u4f8b\u5982\uff0cConvNet\u7b2c\u4e00\u5c42\u4e0a\u7684\u5178\u578b\u6ee4\u6ce2\u5668\u53ef\u80fd\u5177\u67095x5x3\u7684\u5c3a\u5bf8\uff08\u53735\u50cf\u7d20\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u4ee5\u53ca3\uff0c\u56e0\u4e3a\u56fe\u50cf\u5177\u6709\u6df1\u5ea63\uff0c\u989c\u8272\u901a\u9053\uff09\u3002\u5728\u524d\u5411\u4f20\u9012\u671f\u95f4\uff0c\u6211\u4eec\u5728\u8f93\u5165\u4f53\u79ef\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0a\u6ed1\u52a8\uff08\u6ed1\u52a8\uff09\uff08\u66f4\u51c6\u786e\u5730\u8bf4\uff0c\u5377\u79ef\uff08\u5377\u79ef\uff09\uff09\u6bcf\u4e2a\u6ee4\u6ce2\u5668\uff0c\u5e76\u8ba1\u7b97\u6ee4\u6ce2\u5668\u7684\u6761\u76ee\u548c\u4efb\u4f55\u4f4d\u7f6e\u5904\u7684\u8f93\u5165\u4e4b\u95f4\u7684\u70b9\u79ef\u3002\u5f53\u6211\u4eec\u5728\u8f93\u5165\u4f53\u79ef\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0a\u6ed1\u52a8\u6ee4\u955c\u65f6\uff0c\u6211\u4eec\u5c06\u751f\u6210\u4e00\u4e2a\u4e8c\u7ef4\u6fc0\u6d3b\u8d34\u56fe\uff0c\u8be5\u8d34\u56fe\u5728\u6bcf\u4e2a\u7a7a\u95f4\u4f4d\u7f6e\u7ed9\u51fa\u8be5\u6ee4\u955c\u7684\u54cd\u5e94\u3002\u76f4\u89c2\u5730\uff0c\u7f51\u7edc\u5c06\u5b66\u4e60\u5f53\u4ed6\u4eec\u770b\u5230\u67d0\u79cd\u7c7b\u578b\u7684\u89c6\u89c9\u7279\u5f81\u65f6\u6fc0\u6d3b\u7684\u8fc7\u6ee4\u5668\uff0c\u4f8b\u5982\u67d0\u4e2a\u65b9\u5411\u7684\u8fb9\u7f18\u6216\u7b2c\u4e00\u5c42\u4e0a\u67d0\u79cd\u989c\u8272\u7684\u6591\u70b9\uff0c\u6216\u6700\u7ec8\u5728\u7f51\u7edc\u7684\u66f4\u9ad8\u5c42\u4e0a\u7684\u6574\u4e2a\u8702\u7a9d\u6216\u8f6e\u72b6\u56fe\u6848\u3002\u73b0\u5728\uff0c\u6211\u4eec\u5c06\u5728\u6bcf\u4e2aCONV\u5c42\u4e2d\u6709\u4e00\u6574\u5957\u8fc7\u6ee4\u5668\uff08\u4f8b\u598212\u4e2a\u8fc7\u6ee4\u5668\uff09\uff0c\u5e76\u4e14\u6bcf\u4e2a\u8fc7\u6ee4\u5668\u5c06\u4ea7\u751f\u5355\u72ec\u76842\u7ef4\u6fc0\u6d3b\u56fe\u3002\u6211\u4eec\u5c06\u6cbf\u6df1\u5ea6\u7ef4\u5ea6\u5806\u53e0\u8fd9\u4e9b\u6fc0\u6d3b\u56fe\u5e76\u751f\u6210\u8f93\u51fa\u91cf\u3002 THINKING : \u6bcf\u4e2afilter\u662f\u5426\u9700\u8981\u626b\u63cf\u5b8c\u6574\u4e2a**input volume**\uff1f\u6bcf\u4e2afilter\u7684\u8f93\u51fa\u662f\u4ec0\u4e48\uff1f entries of the filter\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u8fd9\u4e9b\u95ee\u9898\u5728\u4e0a\u9762\u8fd9\u4e00\u6bb5\u4e2d\u90fd\u5df2\u7ecf\u63cf\u8ff0\u6e05\u695a\u4e86\uff1b THINKING : \u6240\u8c13\u7684filter\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u5377\u79ef\u8fd0\u7b97\u5b50\uff1b","title":"Overview and intuition without brain stuff."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#the#brain#view","text":"If you\u2019re a fan of the brain/neuron analogies, every entry in the 3D output volume can also be interpreted as an output of a neuron that looks at only a small region in the input and shares parameters with all neurons to the left and right spatially (since these numbers all result from applying the same filter). We now discuss the details of the neuron connectivities, their arrangement in space, and their parameter sharing scheme. THINKING : neuron\u548cfilter\u4e4b\u95f4\u7684\u5173\u7cfb\uff1f\uff1f\u6309\u7167MLP\u4e2d\u7684\u7406\u89e3\uff0c\u6bcf\u4e00\u5c42\u4e2d\u7684\u4e00\u4e2aneuron\u90fd\u6267\u884c\u4e86\u4e00\u4e2afunction\uff0c\u90a3\u5728CNN\u4e2d\uff0c\u662f\u5426\u4e5f\u662f\u5982\u6b64\u5462\uff1f\u5728\u4e0b\u9762\u8fd9\u4e00\u6bb5\u4e2d\u5c31\u4f1a\u4ecb\u7ecd\u8fd9\u4e2a\u5185\u5bb9\uff0c\u5176\u5b9e\u901a\u8fc7\u8fd9\u4e2a\u5185\u5bb9\u4e5f\u53ef\u4ee5\u5f97\u77e5\uff1a\u5728CNN\u4e2d\uff0c\u6bcf\u4e2aneuron\u6240\u6267\u884c\u7684\u90fd\u662f\u4e00\u4e2afilter\u7684\u64cd\u4f5c\uff1b","title":"The brain view."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#local#connectivity","text":"When dealing with high-dimensional inputs such as images, as we saw above it is impractical to connect neurons to all neurons in the previous volume. Instead, we will connect each neuron to only a local region of the input volume. The spatial extent of this connectivity is a hyperparameter called the receptive field of the neuron (equivalently\uff08\u76f8\u5f53\u4e8e\uff09 this is the filter size ). The extent of the connectivity along the depth axis is always equal to the depth of the input volume. It is important to emphasize again this asymmetry in how we treat the spatial dimensions (width and height) and the depth dimension: The connections are local in space (along width and height), but always full along the entire depth of the input volume. Example 1 . For example, suppose that the input volume has size [32x32x3], (e.g. an RGB CIFAR-10 image). If the receptive field (or the filter size) is 5x5, then each neuron in the Conv Layer will have weights to a [5x5x3] region in the input volume, for a total of 5*5*3 = 75 5*5*3 = 75 weights (and +1 bias parameter). Notice that the extent of the connectivity along the depth axis must be 3, since this is the depth of the input volume. Example 2 . Suppose an input volume had size [16x16x20]. Then using an example receptive field size of 3x3, every neuron in the Conv Layer would now have a total of 3*3*20 = 180 3*3*20 = 180 connections to the input volume. Notice that, again, the connectivity is local in space (e.g. 3x3), but full along the input depth (20). Left: An example input volume in red (e.g. a 32x32x3 CIFAR-10 image), and an example volume of neurons in the first Convolutional layer . Each neuron in the convolutional layer is connected only to a local region in the input volume spatially, but to the full depth (i.e. all color channels). Note, there are multiple neurons (5 in this example) along the depth, all looking at the same region in the input - see discussion of depth columns in text below. Right: The neurons from the Neural Network chapter remain unchanged: They still compute a dot product of their weights with the input followed by a non-linearity, but their connectivity is now restricted to be local spatially.","title":"Local Connectivity."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#spatial#arrangement","text":"We have explained the connectivity of each neuron in the Conv Layer to the input volume, but we haven\u2019t yet discussed how many neurons there are in the output volume or how they are arranged. Three hyperparameters control the size of the output volume : the depth, stride and zero-padding . We discuss these next: First, the depth of the output volume is a hyperparameter: it corresponds to the number of filters we would like to use, each learning to look for something different in the input. For example, if the first Convolutional Layer takes as input the raw image, then different neurons along the depth dimension may activate in presence of various oriented edges, or blobs of color. We will refer to a set of neurons that are all looking at the same region of the input as a depth column (some people also prefer the term fibre ). Second, we must specify the stride with which we slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more, though this is rare in practice) then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially. As we will soon see, sometimes it will be convenient to pad the input volume with zeros around the border. The size of this zero-padding is a hyperparameter. The nice feature of zero padding is that it will allow us to control the spatial size of the output volumes (most commonly as we\u2019ll see soon we will use it to exactly preserve the spatial size of the input volume so the input and output width and height are the same). We can compute the spatial size of the output volume as a function of the input volume size ( W W ), the receptive field size of the Conv Layer neurons ( F F ), the stride with which they are applied ( S S ), and the amount of zero padding used ( P P ) on the border. You can convince yourself that the correct formula for calculating how many neurons \u201cfit\u201d is given by (W - F + 2P)/S + 1 (W - F + 2P)/S + 1 . For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output. Lets also see one more graphical example: Illustration of spatial arrangement. In this example there is only one spatial dimension (x-axis), one neuron with a receptive field size of F = 3, the input size is W = 5, and there is zero padding of P = 1. Left: The neuron strided across the input in stride of S = 1, giving output of size (5 - 3 + 2)/1+1 = 5. Right: The neuron uses stride of S = 2, giving output of size (5 - 3 + 2)/2+1 = 3. Notice that stride S = 3 could not be used since it wouldn't fit neatly across the volume. In terms of the equation, this can be determined since (5 - 3 + 2) = 4 is not divisible by 3. The neuron weights are in this example [1,0,-1] (shown on very right), and its bias is zero. These weights are shared across all yellow neurons (see parameter sharing below). Use of zero-padding . In the example above on left, note that the input dimension was 5 and the output dimension was equal: also 5. This worked out so because our receptive fields were 3 and we used zero padding of 1. If there was no zero-padding used, then the output volume would have had spatial dimension of only 3, because that it is how many neurons would have \u201cfit\u201d across the original input. In general, setting zero padding to be P=(F\u22121)/2 P=(F\u22121)/2 when the stride is S=1 S=1 ensures that the input volume and output volume will have the same size spatially. It is very common to use zero-padding in this way and we will discuss the full reasons when we talk more about ConvNet architectures. Constraints on strides . Note again that the spatial arrangement hyperparameters have mutual constraints. For example, when the input has size W=10 W=10 , no zero-padding is used P=0 P=0 , and the filter size is F=3 F=3 , then it would be impossible to use stride S=2 S=2 , since , i.e. not an integer, indicating that the neurons don\u2019t \u201cfit\u201d neatly and symmetrically across the input. Therefore, this setting of the hyperparameters is considered to be invalid, and a ConvNet library could throw an exception or zero pad the rest to make it fit, or crop the input to make it fit, or something. As we will see in the ConvNet architectures section, sizing the ConvNets appropriately so that all the dimensions \u201cwork out\u201d can be a real headache, which the use of zero-padding and some design guidelines will significantly alleviate. Real-world example . The Krizhevsky et al. architecture that won the ImageNet challenge in 2012 accepted images of size [227x227x3]. On the first Convolutional Layer, it used neurons with receptive field size F=11 F=11 , stride S=4 S=4 and no zero padding P=0 P=0 . Since (227 - 11)/4 + 1 = 55, and since the Conv layer had a depth of K=96 K=96 , the Conv layer output volume had size [55x55x96]. Each of the 55*55*96 neurons in this volume was connected to a region of size [11x11x3] in the input volume. Moreover, all 96 neurons in each depth column are connected to the same [11x11x3] region of the input, but of course with different weights. As a fun aside, if you read the actual paper it claims that the input images were 224x224, which is surely incorrect because (224 - 11)/4 + 1 is quite clearly not an integer. This has confused many people in the history of ConvNets and little is known about what happened. My own best guess is that Alex used zero-padding of 3 extra pixels that he does not mention in the paper.","title":"Spatial arrangement."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#parameter#sharing","text":"Parameter sharing scheme is used in Convolutional Layers to control the number of parameters. Using the real-world example above, we see that there are 55*55*96 = 290,400 neurons in the first Conv Layer, and each has 11*11*3 = 363 weights and 1 bias. Together, this adds up to 290400 * 364 = 105,705,600 parameters on the first layer of the ConvNet alone. Clearly, this number is very high. It turns out that we can dramatically reduce the number of parameters by making one reasonable assumption: That if one feature is useful to compute at some spatial position (x,y), then it should also be useful to compute at a different position (x2,y2). In other words, denoting a single 2-dimensional slice of depth as a depth slice (e.g. a volume of size [55x55x96] has 96 depth slices, each of size [55x55]), we are going to constrain the neurons in each depth slice to use the same weights and bias. With this parameter sharing scheme, the first Conv Layer in our example would now have only 96 unique set of weights (one for each depth slice), for a total of 96*11*11*3 = 34,848 unique weights, or 34,944 parameters (+96 biases). Alternatively, all 55*55 neurons in each depth slice will now be using the same parameters. In practice during backpropagation, every neuron in the volume will compute the gradient for its weights, but these gradients will be added up across each depth slice and only update a single set of weights per slice. Notice that if all neurons in a single depth slice are using the same weight vector, then the forward pass of the CONV layer can in each depth slice be computed as a convolution of the neuron\u2019s weights with the input volume (Hence the name: Convolutional Layer). This is why it is common to refer to the sets of weights as a filter (or a kernel ), that is convolved with the input. Example filters learned by Krizhevsky et al. Each of the 96 filters shown here is of size [11x11x3], and each one is shared by the 55*55 neurons in one depth slice. Notice that the parameter sharing assumption is relatively reasonable: If detecting a horizontal edge is important at some location in the image, it should intuitively be useful at some other location as well due to the translationally-invariant structure of images. There is therefore no need to relearn to detect a horizontal edge at every one of the 55*55 distinct locations in the Conv layer output volume. Note that sometimes the parameter sharing assumption may not make sense. This is especially the case when the input images to a ConvNet have some specific centered structure, where we should expect, for example, that completely different features should be learned on one side of the image than another. One practical example is when the input are faces that have been centered in the image. You might expect that different eye-specific or hair-specific features could (and should) be learned in different spatial locations. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a Locally-Connected Layer .","title":"Parameter Sharing."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#numpy#examples","text":"To make the discussion above more concrete, lets express the same ideas but in code and with a specific example. Suppose that the input volume is a numpy array X . Then: A depth column (or a fibre ) at position (x,y) would be the activations X[x,y,:] . A depth slice , or equivalently an activation map at depth d would be the activations X[:,:,d] . Conv Layer Example . Suppose that the input volume X has shape X.shape: (11,11,4) . Suppose further that we use no zero padding (P=0P=0), that the filter size is F=5F=5, and that the stride is S=2S=2. The output volume would therefore have spatial size (11-5)/2+1 = 4, giving a volume with width and height of 4. The activation map in the output volume (call it V ), would then look as follows (only some of the elements are computed in this example): V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0 V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0 V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0 V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0 Remember that in numpy, the operation * above denotes elementwise multiplication between the arrays. Notice also that the weight vector W0 is the weight vector of that neuron and b0 is the bias. Here, W0 is assumed to be of shape W0.shape: (5,5,4) , since the filter size is 5 and the depth of the input volume is 4. Notice that at each point, we are computing the dot product as seen before in ordinary neural networks. Also, we see that we are using the same weight and bias (due to parameter sharing), and where the dimensions along the width are increasing in steps of 2 (i.e. the stride). To construct a second activation map in the output volume, we would have: V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1 V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1 V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1 V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1 V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 (example of going along y) V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 (or along both) where we see that we are indexing into the second depth dimension in V (at index 1) because we are computing the second activation map, and that a different set of parameters ( W1 ) is now used. In the example above, we are for brevity leaving out some of the other operations the Conv Layer would perform to fill the other parts of the output array V . Additionally, recall that these activation maps are often followed elementwise through an activation function such as ReLU, but this is not shown here. Summary . To summarize, the Conv Layer: Accepts a volume of size W1\u00d7H1\u00d7D1W1\u00d7H1\u00d7D1 Requires four hyperparameters: Number of filters KK, their spatial extent FF, the stride SS, the amount of zero padding PP. Produces a volume of size W2\u00d7H2\u00d7D2W2\u00d7H2\u00d7D2 where: W2=(W1\u2212F+2P)/S+1W2=(W1\u2212F+2P)/S+1 H2=(H1\u2212F+2P)/S+1H2=(H1\u2212F+2P)/S+1 (i.e. width and height are computed equally by symmetry) D2=KD2=K With parameter sharing, it introduces F\u22c5F\u22c5D1F\u22c5F\u22c5D1 weights per filter, for a total of (F\u22c5F\u22c5D1)\u22c5K(F\u22c5F\u22c5D1)\u22c5K weights and KK biases. In the output volume, the dd-th depth slice (of size W2\u00d7H2W2\u00d7H2) is the result of performing a valid convolution of the dd-th filter over the input volume with a stride of SS, and then offset by dd-th bias. A common setting of the hyperparameters is F=3,S=1,P=1F=3,S=1,P=1. However, there are common conventions and rules of thumb that motivate these hyperparameters. See the ConvNet architectures section below.","title":"Numpy examples."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#convolution#demo","text":"Below is a running demo of a CONV layer. Since 3D volumes are hard to visualize, all the volumes (the input volume (in blue), the weight volumes (in red), the output volume (in green)) are visualized with each depth slice stacked in rows. The input volume is of size W_1 = 5, H_1 = 5, D_1 = 3 W_1 = 5, H_1 = 5, D_1 = 3 , and the CONV layer parameters are K = 2, F = 3, S = 2, P = 1 K = 2, F = 3, S = 2, P = 1 . That is, we have two filters of size 3\u00d733\u00d73, and they are applied with a stride of 2. Therefore, the output volume size has spatial size (5 - 3 + 2)/2 + 1 = 3. Moreover, notice that a padding of P=1 P=1 is applied to the input volume, making the outer border of the input volume zero. The visualization below iterates over the output activations (green), and shows that each element is computed by elementwise multiplying the highlighted input (blue) with the filter (red), summing it up, and then offsetting the result by the bias.","title":"Convolution Demo."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#implementation#as#matrix#multiplication","text":"Note that the convolution operation essentially performs dot products between the filters and local regions of the input. A common implementation pattern of the CONV layer is to take advantage of this fact and formulate the forward pass of a convolutional layer as one big matrix multiply as follows: The local regions in the input image are stretched out into columns in an operation commonly called im2col . For example, if the input is [227x227x3] and it is to be convolved with 11x11x3 filters at stride 4, then we would take [11x11x3] blocks of pixels in the input and stretch each block into a column vector of size 11*11*3 = 363. Iterating this process in the input at stride of 4 gives (227-11)/4+1 = 55 locations along both width and height, leading to an output matrix X_col of im2col of size [363 x 3025], where every column is a stretched out receptive field and there are 55*55 = 3025 of them in total. Note that since the receptive fields overlap, every number in the input volume may be duplicated in multiple distinct columns. The weights of the CONV layer are similarly stretched out into rows. For example, if there are 96 filters of size [11x11x3] this would give a matrix W_row of size [96 x 363]. The result of a convolution is now equivalent to performing one large matrix multiply np.dot(W_row, X_col) , which evaluates the dot product between every filter and every receptive field location. In our example, the output of this operation would be [96 x 3025], giving the output of the dot product of each filter at each location. The result must finally be reshaped back to its proper output dimension [55x55x96]. This approach has the downside that it can use a lot of memory, since some values in the input volume are replicated multiple times in X_col . However, the benefit is that there are many very efficient implementations of Matrix Multiplication that we can take advantage of (for example, in the commonly used BLAS API). Moreover, the same im2col idea can be reused to perform the pooling operation, which we discuss next.","title":"Implementation as Matrix Multiplication."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#backpropagation","text":"The backward pass for a convolution operation (for both the data and the weights) is also a convolution (but with spatially-flipped filters). This is easy to derive in the 1-dimensional case with a toy example (not expanded on for now).","title":"Backpropagation."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#1x1#convolution","text":"As an aside, several papers use 1x1 convolutions, as first investigated by Network in Network . Some people are at first confused to see 1x1 convolutions especially when they come from signal processing background. Normally signals are 2-dimensional so 1x1 convolutions do not make sense (it\u2019s just pointwise scaling). However, in ConvNets this is not the case because one must remember that we operate over 3-dimensional volumes, and that the filters always extend through the full depth of the input volume. For example, if the input is [32x32x3] then doing 1x1 convolutions would effectively be doing 3-dimensional dot products (since the input depth is 3 channels).","title":"1x1 convolution."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#dilated#convolutions","text":"A recent development (e.g. see paper by Fisher Yu and Vladlen Koltun ) is to introduce one more hyperparameter to the CONV layer called the dilation . So far we\u2019ve only discussed CONV filters that are contiguous. However, it\u2019s possible to have filters that have spaces between each cell, called dilation. As an example, in one dimension a filter w of size 3 would compute over input x the following: w[0]*x[0] + w[1]*x[1] + w[2]*x[2] . This is dilation of 0. For dilation 1 the filter would instead compute w[0]*x[0] + w[1]*x[2] + w[2]*x[4] ; In other words there is a gap of 1 between the applications. This can be very useful in some settings to use in conjunction with 0-dilated filters because it allows you to merge spatial information across the inputs much more agressively with fewer layers. For example, if you stack two 3x3 CONV layers on top of each other then you can convince yourself that the neurons on the 2 nd layer are a function of a 5x5 patch of the input (we would say that the effective receptive field of these neurons is 5x5). If we use dilated convolutions then this effective receptive field would grow much quicker.","title":"Dilated convolutions."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#pooling#layer","text":"It is common to periodically insert a Pooling layer in-between successive Conv layers in a ConvNet architecture. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. The Pooling Layer operates independently on every depth slice of the input and resizes it spatially, using the MAX operation . The most common form is a pooling layer with filters of size 2x2 applied with a stride of 2 downsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations. Every MAX operation would in this case be taking a max over 4 numbers (little 2x2 region in some depth slice). The depth dimension remains unchanged. More generally, the pooling layer: Accepts a volume of size W_1 \\times H_1 \\times D_1 W_1 \\times H_1 \\times D_1 Requires two hyperparameters: their spatial extent F F , the stride S S , Produces a volume of size W_2 \\times H_2 \\times D_2 W_2 \\times H_2 \\times D_2 where: W_2 = (W_1 - F)/S + 1 W_2 = (W_1 - F)/S + 1 H_2 = (H_1 - F)/S + 1 H_2 = (H_1 - F)/S + 1 D_2 = D_1 D_2 = D_1 Introduces zero parameters since it computes a fixed function of the input For Pooling layers, it is not common to pad the input using zero-padding. It is worth noting that there are only two commonly seen variations of the max pooling layer found in practice: A pooling layer with F=3,S=2 F=3,S=2 (also called overlapping pooling ), and more commonly F=2,S=2 F=2,S=2 . Pooling sizes with larger receptive fields are too destructive.","title":"Pooling Layer"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#general#pooling","text":"In addition to max pooling , the pooling units can also perform other functions, such as average pooling or even L2-norm pooling . Average pooling was often used historically but has recently fallen out of favor compared to the max pooling operation, which has been shown to work better in practice. Pooling layer downsamples the volume spatially, independently in each depth slice of the input volume. Left: In this example, the input volume of size [224x224x64] is pooled with filter size 2, stride 2 into output volume of size [112x112x64]. Notice that the volume depth is preserved. Right: The most common downsampling operation is max, giving rise to max pooling, here shown with a stride of 2. That is, each max is taken over 4 numbers (little 2x2 square).","title":"General pooling."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#backpropagation_1","text":"Recall from the backpropagation chapter that the backward pass for a max(x, y) operation has a simple interpretation as only routing the gradient to the input that had the highest value in the forward pass. Hence, during the forward pass of a pooling layer it is common to keep track of the index of the max activation (sometimes also called the switches ) so that gradient routing is efficient during backpropagation.","title":"Backpropagation."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#getting#rid#of#pooling","text":"Many people dislike the pooling operation and think that we can get away without it. For example, Striving for Simplicity: The All Convolutional Net proposes to discard the pooling layer in favor of architecture that only consists of repeated CONV layers. To reduce the size of the representation they suggest using larger stride in CONV layer once in a while. Discarding pooling layers has also been found to be important in training good generative models, such as variational autoencoders (VAEs) or generative adversarial networks (GANs). It seems likely that future architectures will feature very few to no pooling layers.","title":"Getting rid of pooling."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#normalization#layer","text":"Many types of normalization layers have been proposed for use in ConvNet architectures, sometimes with the intentions of implementing inhibition schemes observed in the biological brain. However, these layers have since fallen out of favor because in practice their contribution has been shown to be minimal, if any. For various types of normalizations, see the discussion in Alex Krizhevsky\u2019s cuda-convnet library API .","title":"Normalization Layer"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#fully-connected#layer","text":"Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can hence be computed with a matrix multiplication followed by a bias offset . See the Neural Network section of the notes for more information.","title":"Fully-connected layer"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#converting#fc#layers#to#conv#layers","text":"It is worth noting that the only difference between FC and CONV layers is that the neurons in the CONV layer are connected only to a local region in the input, and that many of the neurons in a CONV volume share parameters. However, the neurons in both layers still compute dot products, so their functional form is identical. Therefore, it turns out that it\u2019s possible to convert between FC and CONV layers: For any CONV layer there is an FC layer that implements the same forward function. The weight matrix would be a large matrix that is mostly zero except for at certain blocks (due to local connectivity) where the weights in many of the blocks are equal (due to parameter sharing). Conversely, any FC layer can be converted to a CONV layer . For example, an FC layer with K=4096 K=4096 that is looking at some input volume of size 7\u00d77\u00d7512 7\u00d77\u00d7512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096 F=7,P=0,S=1,K=4096 . In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1\u00d71\u00d74096 1\u00d71\u00d74096 since only a single depth column \u201cfits\u201d across the input volume, giving identical result as the initial FC layer. SUMMARY : \u4e0a\u8ff0 FC layer with K=4096 K=4096 \u4e2d\u7684 K K \u662f\u4ec0\u4e48\u610f\u601d\uff1fneuron\u4e2a\u6570\uff1f\u5e94\u8be5\u662f\u7684\uff0c\u53ef\u4ee5\u8fdb\u884c\u5012\u63a8\uff0c\u65e2\u7136FC layer\u53ef\u4ee5\u7b49\u4ef7\u7684\u8f6c\u6362\u4e3a**CONV layer** with F=7,P=0,S=1,K=4096 F=7,P=0,S=1,K=4096 \uff0c\u8fd9\u4e2a**CONV layer**\u9501\u6267\u884c\u7684\u64cd\u4f5c\u662f\u975e\u5e38\u7b80\u5355\u7684\uff1a\u5b83\u67094096\u4e2a filter\uff0c\u6bcf\u4e2afilter\u90fd\u4f1a\u548c input volume of size 7\u00d77\u00d7512 7\u00d77\u00d7512 \u6267\u884cdot product\uff0c\u663e\u7136\u8fd9\u5176\u5b9e\u5c31\u662fMLP\u4e2d\u7684\u5168\u8fde\u63a5\u5c42\u4e86\uff0c\u663e\u7136\uff0c\u6bcf\u4e2afilter\u5c31\u76f8\u5f53\u4e8eMLP\u4e2d\u7684\u4e00\u4e2aneuron\uff1b\u8fd9\u4e2a\u63a8\u6d4b\u5728\u4e0b\u9762\u7684**FC->CONV conversion**\u4e2d\u662f\u53ef\u4ee5\u9a8c\u8bc1\u7684\uff1b SUMMARY : CONV layer with F=7,P=0,S=1,K=4096 F=7,P=0,S=1,K=4096 . \u4e2d\u7684 K K \u6307\u7684\u662ffilter\u7684\u4e2a\u6570\u3002","title":"Converting FC layers to CONV layers"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#fc-conv#conversion","text":"Of these two conversions, the ability to convert an FC layer to a CONV layer is particularly useful in practice. Consider a ConvNet architecture that takes a 224x224x3 image, and then uses a series of CONV layers and POOL layers to reduce the image to an activations volume of size 7x7x512 (in an AlexNet architecture that we\u2019ll see later, this is done by use of 5 pooling layers that downsample the input spatially by a factor of two each time, making the final spatial size 224/2/2/2/2/2 = 7). From there, an AlexNet uses two FC layers of size 4096 and finally the last FC layers with 1000 neurons that compute the class scores. We can convert each of these three FC layers to CONV layers as described above: Replace the first FC layer that looks at [7x7x512] volume with a CONV layer that uses filter size F=7 F=7 , giving output volume [1x1x4096]. Replace the second FC layer with a CONV layer that uses filter size F=1 F=1 , giving output volume [1x1x4096] Replace the last FC layer similarly, with F=1 F=1 , giving final output [1x1x1000] Each of these conversions could in practice involve manipulating (e.g. reshaping) the weight matrix W W in each FC layer into CONV layer filters . It turns out that this conversion allows us to \u201cslide\u201d the original ConvNet very efficiently across many spatial positions in a larger image, in a single forward pass. For example, if 224x224 image gives a volume of size [7x7x512] - i.e. a reduction by 32, then forwarding an image of size 384x384 through the converted architecture would give the equivalent volume in size [12x12x512], since 384/32 = 12. Following through with the next 3 CONV layers that we just converted from FC layers would now give the final volume of size [6x6x1000], since (12 - 7)/1 + 1 = 6. Note that instead of a single vector of class scores of size [1x1x1000], we\u2019re now getting an entire 6x6 array of class scores across the 384x384 image. Evaluating the original ConvNet (with FC layers) independently across 224x224 crops of the 384x384 image in strides of 32 pixels gives an identical result to forwarding the converted ConvNet one time. Naturally, forwarding the converted ConvNet a single time is much more efficient than iterating the original ConvNet over all those 36 locations, since the 36 evaluations share computation. This trick is often used in practice to get better performance, where for example, it is common to resize an image to make it bigger, use a converted ConvNet to evaluate the class scores at many spatial positions and then average the class scores. Lastly, what if we wanted to efficiently apply the original ConvNet over the image but at a stride smaller than 32 pixels? We could achieve this with multiple forward passes. For example, note that if we wanted to use a stride of 16 pixels we could do so by combining the volumes received by forwarding the converted ConvNet twice: First over the original image and second over the image but with the image shifted spatially by 16 pixels along both width and height. An IPython Notebook on Net Surgery shows how to perform the conversion in practice, in code (using Caffe)","title":"FC-&gt;CONV conversion."},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#convnet#architectures","text":"We have seen that Convolutional Networks are commonly made up of only three layer types: CONV, POOL (we assume Max pool unless stated otherwise) and FC (short for fully-connected). We will also explicitly write the RELU activation function as a layer, which applies elementwise non-linearity. In this section we discuss how these are commonly stacked together to form entire ConvNets.","title":"ConvNet Architectures"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#layer#patterns","text":"The most common form of a ConvNet architecture stacks a few CONV-RELU layers, follows them with POOL layers, and repeats this pattern until the image has been merged spatially to a small size. At some point, it is common to transition to fully-connected layers. The last fully-connected layer holds the output, such as the class scores. In other words, the most common ConvNet architecture follows the pattern: INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC where the * indicates repetition, and the POOL? indicates an optional pooling layer. Moreover, N >= 0 (and usually N <= 3 ), M >= 0 , K >= 0 (and usually K < 3 ). For example, here are some common ConvNet architectures you may see that follow this pattern: INPUT -> FC , implements a linear classifier. Here N = M = K = 0 . INPUT -> CONV -> RELU -> FC INPUT -> [CONV -> RELU -> POOL]*2 -> FC -> RELU -> FC . Here we see that there is a single CONV layer between every POOL layer. INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> FC Here we see two CONV layers stacked before every POOL layer. This is generally a good idea for larger and deeper networks, because multiple stacked CONV layers can develop more complex features of the input volume before the destructive pooling operation.","title":"Layer Patterns"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/CS231n/Convolutional-Neural-Networks%28CNNs-or-ConvNets%29/#additional#resources","text":"Additional resources related to implementation: Soumith benchmarks for CONV performance ConvNetJS CIFAR-10 demo allows you to play with ConvNet architectures and see the results and computations in real time, in the browser. Caffe , one of the popular ConvNet libraries. State of the art ResNets in Torch7","title":"Additional Resources"},{"location":"Theory/Deep-learning/Book-deep-learning/Part-II-Deep-Networks-Modern-Practices/9-Convolutional-Networks/VGG/VGG/","text":"https://towardsdatascience.com/vgg-neural-networks-the-next-step-after-alexnet-3f91fa9ffe2c https://neurohive.io/en/popular-networks/vgg16/","title":"VGG"},{"location":"Theory/Deep-learning/Guide/Design-neural-network/","text":"\u9886\u57df\u77e5\u8bc6 \u5728 Convolutional Neural Networks (CNNs / ConvNets) \u4e2d\u63d0\u53ca\uff1a ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network. \u5229\u7528\u9886\u57df\u77e5\u8bc6\u6765\u5bf9\u6a21\u578b\u8fdb\u884c\u6539\u8fdb\uff1b\u65e0\u8bba\u662fCNN\u8fd8\u662fRNN\uff0c\u90fd\u8fd0\u7528\u4e86\u9886\u57df\u76f8\u5173\u7684\u77e5\u8bc6\u5bf9\u6a21\u578b\u8fdb\u884c\u4e86\u6539\u8fdb\uff0c\u56e0\u6b64\u5b83\u4eec\u80fd\u591f\u975e\u5e38\u597d\u7684\u89e3\u51b3\u5b83\u7684\u76ee\u6807\u9886\u57df\u7684\u95ee\u9898\uff1b parameter sharing\u5728neural network\u4e2d\u7684\u8fd0\u7528 CNN \u53c2\u89c1 Convolutional Neural Networks (CNNs / ConvNets) RNN \u53c2\u89c1deep learning book\uff1aChapter 10 Sequence Modeling: Recurrent and Recursive Nets \u5728deep learning book\uff1aChapter 10 Sequence Modeling: Recurrent and Recursive Nets\u7684\u5bfc\u8bed\u4e2d\u5bf9\u6bd4\u4e86CNN\u548cRNN\u5728parameter sharing\u4e2d\u7684\u5dee\u5f02\uff1b A related idea is the use of convolution across a 1-D temporal sequence. This convolutional approach is the basis for time-delay neural networks (Lang and Hinton 1988 Waibel 1989 Lang 1990 , ; et al., ; et al., ). The convolution operation allows a network to share parameters across time, but is shallow. The output of convolution is a sequence where each member of the output is a function of a small number of neighboring members of the input. The idea of parameter sharing manifests in the application of the same convolution kernel at each time step. Recurrent networks share parameters in a different way. Each member of the output is a function of the previous members of the output. Each member of the output is produced using the same update rule applied to the previous outputs. This recurrent formulation results in the sharing of parameters through a very deep computational graph.","title":"Design-neural-network"},{"location":"Theory/Deep-learning/Guide/Design-neural-network/#_1","text":"\u5728 Convolutional Neural Networks (CNNs / ConvNets) \u4e2d\u63d0\u53ca\uff1a ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network. \u5229\u7528\u9886\u57df\u77e5\u8bc6\u6765\u5bf9\u6a21\u578b\u8fdb\u884c\u6539\u8fdb\uff1b\u65e0\u8bba\u662fCNN\u8fd8\u662fRNN\uff0c\u90fd\u8fd0\u7528\u4e86\u9886\u57df\u76f8\u5173\u7684\u77e5\u8bc6\u5bf9\u6a21\u578b\u8fdb\u884c\u4e86\u6539\u8fdb\uff0c\u56e0\u6b64\u5b83\u4eec\u80fd\u591f\u975e\u5e38\u597d\u7684\u89e3\u51b3\u5b83\u7684\u76ee\u6807\u9886\u57df\u7684\u95ee\u9898\uff1b","title":"\u9886\u57df\u77e5\u8bc6"},{"location":"Theory/Deep-learning/Guide/Design-neural-network/#parameter#sharingneural#network","text":"CNN \u53c2\u89c1 Convolutional Neural Networks (CNNs / ConvNets) RNN \u53c2\u89c1deep learning book\uff1aChapter 10 Sequence Modeling: Recurrent and Recursive Nets \u5728deep learning book\uff1aChapter 10 Sequence Modeling: Recurrent and Recursive Nets\u7684\u5bfc\u8bed\u4e2d\u5bf9\u6bd4\u4e86CNN\u548cRNN\u5728parameter sharing\u4e2d\u7684\u5dee\u5f02\uff1b A related idea is the use of convolution across a 1-D temporal sequence. This convolutional approach is the basis for time-delay neural networks (Lang and Hinton 1988 Waibel 1989 Lang 1990 , ; et al., ; et al., ). The convolution operation allows a network to share parameters across time, but is shallow. The output of convolution is a sequence where each member of the output is a function of a small number of neighboring members of the input. The idea of parameter sharing manifests in the application of the same convolution kernel at each time step. Recurrent networks share parameters in a different way. Each member of the output is a function of the previous members of the output. Each member of the output is produced using the same update rule applied to the previous outputs. This recurrent formulation results in the sharing of parameters through a very deep computational graph.","title":"parameter sharing\u5728neural network\u4e2d\u7684\u8fd0\u7528"},{"location":"Theory/Deep-learning/Guide/Activation-function/Activation-function/","text":"Activation function In artificial neural networks , the activation function of a node defines the output of that node given an input or set of inputs. A standard computer chip circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input. This is similar to the behavior of the linear perceptron in neural networks . However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes.[ 1] In artificial neural networks , this function is also called the transfer function .","title":"Activation-function"},{"location":"Theory/Deep-learning/Guide/Activation-function/Activation-function/#activation#function","text":"In artificial neural networks , the activation function of a node defines the output of that node given an input or set of inputs. A standard computer chip circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input. This is similar to the behavior of the linear perceptron in neural networks . However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes.[ 1] In artificial neural networks , this function is also called the transfer function .","title":"Activation function"},{"location":"Theory/Deep-learning/Guide/Activation-function/ReLU-VS-sigmoid-VS-softmax/","text":"Softmax vs Sigmoid function in Logistic classifier? What decides the choice of function ( Softmax vs Sigmoid ) in a Logistic classifier ? Suppose there are 4 output classes . Each of the above function gives the probabilities of each class being the correct output . So which one to take for a classifier ? A The sigmoid function is used for the two-class logistic regression , whereas the softmax function is used for the multiclass logistic regression (a.k.a. MaxEnt, multinomial logistic regression, softmax Regression, Maximum Entropy Classifier). In the two-class logistic regression , the predicted probablies are as follows, using the sigmoid function: $$ \\begin{align} \\Pr(Y_i=0) &= \\frac{e^{-\\boldsymbol\\beta_ \\cdot \\mathbf{X} i}} {1 +e^{-\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i}} \\, \\ \\Pr(Y_i=1) &= 1 - \\Pr(Y_i=0) = \\frac{1} {1 +e^{-\\boldsymbol\\beta \\cdot \\mathbf{X} i}} \\end{align} $$ In the multiclass logistic regression, with KK classes, the predicted probabilities are as follows, using the softmax function: $$ \\begin{align} \\Pr(Y_i=k) &= \\frac{e^{\\boldsymbol\\beta_k \\cdot \\mathbf{X}_i}} {~\\sum {0 \\leq c \\leq K} {}{e {\\boldsymbol\\beta_c \\cdot \\mathbf{X}_i}}} \\, \\ \\end{align} $$ One can observe that the softmax function is an extension of the sigmoid function to the multiclass case, as explained below. Let's look at the multiclass logistic regression, with K=2 K=2 classes: $$ \\begin{align} \\Pr(Y_i=0) &= \\frac{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X} i}} {~\\sum {0 \\leq c \\leq K} {}{e {\\boldsymbol\\beta_c \\cdot \\mathbf{X} i}}} = \\frac{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i}}{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i} + e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}} = \\frac{e^{(\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) \\cdot \\mathbf{X}_i}}{e^{(\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) \\cdot \\mathbf{X}_i} + 1} = \\frac{e^{-\\boldsymbol\\beta \\cdot \\mathbf{X} i}} {1 +e^{-\\boldsymbol\\beta \\cdot \\mathbf{X}_i}} \\ \\, \\ \\Pr(Y_i=1) &= \\frac{e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}} {~\\sum {0 \\leq c \\leq K} {}{e {\\boldsymbol\\beta_c \\cdot \\mathbf{X} i}}} = \\frac{e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}}{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i} + e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}} = \\frac{1}{e^{(\\boldsymbol\\beta_0-\\boldsymbol\\beta_1) \\cdot \\mathbf{X}_i} + 1} = \\frac{1} {1 +e^{-\\boldsymbol\\beta \\cdot \\mathbf{X}_i}} \\, \\ \\end{align} $$ with \\boldsymbol\\beta = - (\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) \\boldsymbol\\beta = - (\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) We see that we obtain the same probabilities as in the two-class logistic regression using the sigmoid function. Wikipedia expands a bit more on that. \u6df1\u5ea6\u5b66\u4e60\u5e38\u7528\u6fc0\u6d3b\u51fd\u6570\u4e4b\u2014 Sigmoid & ReLU & Softmax https://blog.csdn.net/zahuopuboss/article/details/70056231","title":"ReLU-VS-sigmoid-VS-softmax"},{"location":"Theory/Deep-learning/Guide/Activation-function/ReLU-VS-sigmoid-VS-softmax/#softmax#vs#sigmoid#function#in#logistic#classifier","text":"What decides the choice of function ( Softmax vs Sigmoid ) in a Logistic classifier ? Suppose there are 4 output classes . Each of the above function gives the probabilities of each class being the correct output . So which one to take for a classifier ?","title":"Softmax vs Sigmoid function in Logistic classifier?"},{"location":"Theory/Deep-learning/Guide/Activation-function/ReLU-VS-sigmoid-VS-softmax/#a","text":"The sigmoid function is used for the two-class logistic regression , whereas the softmax function is used for the multiclass logistic regression (a.k.a. MaxEnt, multinomial logistic regression, softmax Regression, Maximum Entropy Classifier). In the two-class logistic regression , the predicted probablies are as follows, using the sigmoid function: $$ \\begin{align} \\Pr(Y_i=0) &= \\frac{e^{-\\boldsymbol\\beta_ \\cdot \\mathbf{X} i}} {1 +e^{-\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i}} \\, \\ \\Pr(Y_i=1) &= 1 - \\Pr(Y_i=0) = \\frac{1} {1 +e^{-\\boldsymbol\\beta \\cdot \\mathbf{X} i}} \\end{align} $$ In the multiclass logistic regression, with KK classes, the predicted probabilities are as follows, using the softmax function: $$ \\begin{align} \\Pr(Y_i=k) &= \\frac{e^{\\boldsymbol\\beta_k \\cdot \\mathbf{X}_i}} {~\\sum {0 \\leq c \\leq K} {}{e {\\boldsymbol\\beta_c \\cdot \\mathbf{X}_i}}} \\, \\ \\end{align} $$ One can observe that the softmax function is an extension of the sigmoid function to the multiclass case, as explained below. Let's look at the multiclass logistic regression, with K=2 K=2 classes: $$ \\begin{align} \\Pr(Y_i=0) &= \\frac{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X} i}} {~\\sum {0 \\leq c \\leq K} {}{e {\\boldsymbol\\beta_c \\cdot \\mathbf{X} i}}} = \\frac{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i}}{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i} + e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}} = \\frac{e^{(\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) \\cdot \\mathbf{X}_i}}{e^{(\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) \\cdot \\mathbf{X}_i} + 1} = \\frac{e^{-\\boldsymbol\\beta \\cdot \\mathbf{X} i}} {1 +e^{-\\boldsymbol\\beta \\cdot \\mathbf{X}_i}} \\ \\, \\ \\Pr(Y_i=1) &= \\frac{e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}} {~\\sum {0 \\leq c \\leq K} {}{e {\\boldsymbol\\beta_c \\cdot \\mathbf{X} i}}} = \\frac{e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}}{e^{\\boldsymbol\\beta_0 \\cdot \\mathbf{X}_i} + e^{\\boldsymbol\\beta_1 \\cdot \\mathbf{X}_i}} = \\frac{1}{e^{(\\boldsymbol\\beta_0-\\boldsymbol\\beta_1) \\cdot \\mathbf{X}_i} + 1} = \\frac{1} {1 +e^{-\\boldsymbol\\beta \\cdot \\mathbf{X}_i}} \\, \\ \\end{align} $$ with \\boldsymbol\\beta = - (\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) \\boldsymbol\\beta = - (\\boldsymbol\\beta_0 - \\boldsymbol\\beta_1) We see that we obtain the same probabilities as in the two-class logistic regression using the sigmoid function. Wikipedia expands a bit more on that.","title":"A"},{"location":"Theory/Deep-learning/Guide/Activation-function/ReLU-VS-sigmoid-VS-softmax/#sigmoid#relu#softmax","text":"https://blog.csdn.net/zahuopuboss/article/details/70056231","title":"\u6df1\u5ea6\u5b66\u4e60\u5e38\u7528\u6fc0\u6d3b\u51fd\u6570\u4e4b\u2014 Sigmoid &amp; ReLU &amp; Softmax"},{"location":"Theory/Deep-learning/Guide/Activation-function/sigmoid-in-deep-learning/","text":"sigmoid in deep learning LSTM \u5728LSTM\u4e2d\uff0c\u4f7f\u7528 sigmoid \u5b9e\u73b0gate\u3002","title":"sigmoid-in-deep-learning"},{"location":"Theory/Deep-learning/Guide/Activation-function/sigmoid-in-deep-learning/#sigmoid#in#deep#learning","text":"","title":"sigmoid in deep learning"},{"location":"Theory/Deep-learning/Guide/Activation-function/sigmoid-in-deep-learning/#lstm","text":"\u5728LSTM\u4e2d\uff0c\u4f7f\u7528 sigmoid \u5b9e\u73b0gate\u3002","title":"LSTM"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/","text":"What is the Difference Between a Batch and an Epoch in a Neural Network? Stochastic gradient descent is a learning algorithm that has a number of hyperparameters. Two hyperparameters that often confuse beginners are the batch size and number of epochs . They are both integer values and seem to do the same thing. In this post, you will discover the difference between batches and epochs in stochastic gradient descent. After reading this post, you will know: Stochastic gradient descent is an iterative learning algorithm that uses a training dataset to update a model . The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model\u2019s internal parameters are updated. The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset . Discover how to develop deep learning models for a range of predictive modeling problems with just a few lines of code in my new book , with 18 step-by-step tutorials and 9 projects. Let\u2019s get started. Overview This post is divided into five parts; they are: Stochastic Gradient Descent What Is a Sample? What Is a Batch? What Is an Epoch? What Is the Difference Between Batch and Epoch? Stochastic Gradient Descent Stochastic Gradient Descent, or SGD for short, is an optimization algorithm used to train machine learning algorithms, most notably artificial neural networks used in deep learning. The job of the algorithm is to find a set of internal model parameters that perform well against some performance measure such as logarithmic loss or mean squared error . Optimization is a type of searching process and you can think of this search as learning. The optimization algorithm is called \u201c gradient descent \u201c, where \u201c gradient \u201d refers to the calculation of an error gradient or slope\uff08\u503e\u659c\uff09 of error and \u201cdescent\u201d refers to the moving down along that slope towards some minimum level of error. The algorithm is iterative . This means that the search process occurs over multiple discrete steps, each step hopefully slightly improving the model parameters . Each step involves using the model with the current set of internal parameters to make predictions on some samples, comparing the predictions to the real expected outcomes, calculating the error , and using the error to update the internal model parameters . This update procedure is different for different algorithms, but in the case of artificial neural networks, the backpropagation update algorithm is used. Before we dive into batches and epochs, let\u2019s take a look at what we mean by sample. Learn more about gradient descent here: Gradient Descent For Machine Learning What Is a Sample? A sample is a single row of data. It contains inputs that are fed into the algorithm and an output that is used to compare to the prediction and calculate an error. A training dataset is comprised of many rows of data, e.g. many samples. A sample may also be called an instance, an observation, an input vector, or a feature vector. Now that we know what a sample is, let\u2019s define a batch . What Is a Batch? The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters. Think of a batch as a for-loop iterating over one or more samples and making predictions. At the end of the batch, the predictions are compared to the expected output variables and an error is calculated. From this error , the update algorithm is used to improve the model , e.g. move down along the error gradient . SUMMARY : \u5178\u578b\u7684update algorithm\u5c31\u662f backpropagation update algorithm A training dataset can be divided into one or more batches. When all training samples are used to create one batch, the learning algorithm is called batch gradient descent . When the batch is the size of one sample, the learning algorithm is called stochastic gradient descent . When the batch size is more than one sample and less than the size of the training dataset, the learning algorithm is called mini-batch gradient descent . Batch Gradient Descent . Batch Size = Size of Training Set Stochastic Gradient Descent . Batch Size = 1 Mini-Batch Gradient Descent . 1 < Batch Size < Size of Training Set In the case of mini-batch gradient descent, popular batch sizes include 32, 64, and 128 samples. You may see these values used in models in the literature and in tutorials. What if the dataset does not divide evenly by the batch size? This can and does happen often when training a model. It simply means that the final batch has fewer samples than the other batches. Alternately, you can remove some samples from the dataset or change the batch size such that the number of samples in the dataset does divide evenly by the batch size. For more on the differences between these variations of gradient descent, see the post: A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size For more on the effect of batch size on the learning process, see the post: How to Control the Speed and Stability of Training Neural Networks Batch Size A batch involves an update to the model using samples; next, let\u2019s look at an epoch. What Is an Epoch? The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset . One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters . An epoch is comprised of one or more batches. For example, as above, an epoch that has one batch is called the batch gradient descent learning algorithm . You can think of a for-loop over the number of epochs where each loop proceeds over the training dataset. Within this for-loop is another nested for-loop that iterates over each batch of samples, where one batch has the specified \u201cbatch size\u201d number of samples. The number of epochs is traditionally large, often hundreds or thousands, allowing the learning algorithm to run until the error from the model has been sufficiently minimized. You may see examples of the number of epochs in the literature and in tutorials set to 10, 100, 500, 1000, and larger. It is common to create line plots that show epochs along the x-axis as time and the error or skill of the model on the y-axis. These plots are sometimes called learning curves . These plots can help to diagnose whether the model has over learned, under learned, or is suitably fit to the training dataset. For more on diagnostics via learning curves with LSTM networks, see the post: A Gentle Introduction to Learning Curves for Diagnosing Model Performance In case it is still not clear, let\u2019s look at the differences between batches and epochs. What Is the Difference Between Batch and Epoch? The batch size is a number of samples processed before the model is updated. The number of epochs is the number of complete passes through the training dataset. The size of a batch must be more than or equal to one and less than or equal to the number of samples in the training dataset. The number of epochs can be set to an integer value between one and infinity. You can run the algorithm for as long as you like and even stop it using other criteria besides a fixed number of epochs, such as a change (or lack of change) in model error over time. They are both integer values and they are both hyperparameters for the learning algorithm , e.g. parameters for the learning process , not internal model parameters found by the learning process . You must specify the batch size and number of epochs for a learning algorithm. There are no magic rules for how to configure these parameters. You must try different values and see what works best for your problem. Worked Example Finally, let\u2019s make this concrete with a small example. Assume you have a dataset with 200 samples (rows of data) and you choose a batch size of 5 and 1,000 epochs. This means that the dataset will be divided into 40 batches, each with five samples. The model weights will be updated after each batch of five samples. This also means that one epoch will involve 40 batches or 40 updates to the model. With 1,000 epochs, the model will be exposed to or pass through the whole dataset 1,000 times. That is a total of 40,000 batches during the entire training process. Further Reading This section provides more resources on the topic if you are looking to go deeper. Gradient Descent For Machine Learning How to Control the Speed and Stability of Training Neural Networks Batch Size A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size A Gentle Introduction to Learning Curves for Diagnosing Model Performance Stochastic gradient descent on Wikipedia Backpropagation on Wikipedia Summary In this post, you discovered the difference between batches and epochs in stochastic gradient descent. Specifically, you learned: Stochastic gradient descent is an iterative learning algorithm that uses a training dataset to update a model. The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model\u2019s internal parameters are updated. The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset. Do you have any questions? Ask your questions in the comments below and I will do my best to answer.","title":"Batch-VS-epoch"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#what#is#the#difference#between#a#batch#and#an#epoch#in#a#neural#network","text":"Stochastic gradient descent is a learning algorithm that has a number of hyperparameters. Two hyperparameters that often confuse beginners are the batch size and number of epochs . They are both integer values and seem to do the same thing. In this post, you will discover the difference between batches and epochs in stochastic gradient descent. After reading this post, you will know: Stochastic gradient descent is an iterative learning algorithm that uses a training dataset to update a model . The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model\u2019s internal parameters are updated. The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset . Discover how to develop deep learning models for a range of predictive modeling problems with just a few lines of code in my new book , with 18 step-by-step tutorials and 9 projects. Let\u2019s get started.","title":"What is the Difference Between a Batch and an Epoch in a Neural Network?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#overview","text":"This post is divided into five parts; they are: Stochastic Gradient Descent What Is a Sample? What Is a Batch? What Is an Epoch? What Is the Difference Between Batch and Epoch?","title":"Overview"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#stochastic#gradient#descent","text":"Stochastic Gradient Descent, or SGD for short, is an optimization algorithm used to train machine learning algorithms, most notably artificial neural networks used in deep learning. The job of the algorithm is to find a set of internal model parameters that perform well against some performance measure such as logarithmic loss or mean squared error . Optimization is a type of searching process and you can think of this search as learning. The optimization algorithm is called \u201c gradient descent \u201c, where \u201c gradient \u201d refers to the calculation of an error gradient or slope\uff08\u503e\u659c\uff09 of error and \u201cdescent\u201d refers to the moving down along that slope towards some minimum level of error. The algorithm is iterative . This means that the search process occurs over multiple discrete steps, each step hopefully slightly improving the model parameters . Each step involves using the model with the current set of internal parameters to make predictions on some samples, comparing the predictions to the real expected outcomes, calculating the error , and using the error to update the internal model parameters . This update procedure is different for different algorithms, but in the case of artificial neural networks, the backpropagation update algorithm is used. Before we dive into batches and epochs, let\u2019s take a look at what we mean by sample. Learn more about gradient descent here: Gradient Descent For Machine Learning","title":"Stochastic Gradient Descent"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#what#is#a#sample","text":"A sample is a single row of data. It contains inputs that are fed into the algorithm and an output that is used to compare to the prediction and calculate an error. A training dataset is comprised of many rows of data, e.g. many samples. A sample may also be called an instance, an observation, an input vector, or a feature vector. Now that we know what a sample is, let\u2019s define a batch .","title":"What Is a Sample?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#what#is#a#batch","text":"The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters. Think of a batch as a for-loop iterating over one or more samples and making predictions. At the end of the batch, the predictions are compared to the expected output variables and an error is calculated. From this error , the update algorithm is used to improve the model , e.g. move down along the error gradient . SUMMARY : \u5178\u578b\u7684update algorithm\u5c31\u662f backpropagation update algorithm A training dataset can be divided into one or more batches. When all training samples are used to create one batch, the learning algorithm is called batch gradient descent . When the batch is the size of one sample, the learning algorithm is called stochastic gradient descent . When the batch size is more than one sample and less than the size of the training dataset, the learning algorithm is called mini-batch gradient descent . Batch Gradient Descent . Batch Size = Size of Training Set Stochastic Gradient Descent . Batch Size = 1 Mini-Batch Gradient Descent . 1 < Batch Size < Size of Training Set In the case of mini-batch gradient descent, popular batch sizes include 32, 64, and 128 samples. You may see these values used in models in the literature and in tutorials.","title":"What Is a Batch?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#what#if#the#dataset#does#not#divide#evenly#by#the#batch#size","text":"This can and does happen often when training a model. It simply means that the final batch has fewer samples than the other batches. Alternately, you can remove some samples from the dataset or change the batch size such that the number of samples in the dataset does divide evenly by the batch size. For more on the differences between these variations of gradient descent, see the post: A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size For more on the effect of batch size on the learning process, see the post: How to Control the Speed and Stability of Training Neural Networks Batch Size A batch involves an update to the model using samples; next, let\u2019s look at an epoch.","title":"What if the dataset does not divide evenly by the batch size?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#what#is#an#epoch","text":"The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset . One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters . An epoch is comprised of one or more batches. For example, as above, an epoch that has one batch is called the batch gradient descent learning algorithm . You can think of a for-loop over the number of epochs where each loop proceeds over the training dataset. Within this for-loop is another nested for-loop that iterates over each batch of samples, where one batch has the specified \u201cbatch size\u201d number of samples. The number of epochs is traditionally large, often hundreds or thousands, allowing the learning algorithm to run until the error from the model has been sufficiently minimized. You may see examples of the number of epochs in the literature and in tutorials set to 10, 100, 500, 1000, and larger. It is common to create line plots that show epochs along the x-axis as time and the error or skill of the model on the y-axis. These plots are sometimes called learning curves . These plots can help to diagnose whether the model has over learned, under learned, or is suitably fit to the training dataset. For more on diagnostics via learning curves with LSTM networks, see the post: A Gentle Introduction to Learning Curves for Diagnosing Model Performance In case it is still not clear, let\u2019s look at the differences between batches and epochs.","title":"What Is an Epoch?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#what#is#the#difference#between#batch#and#epoch","text":"The batch size is a number of samples processed before the model is updated. The number of epochs is the number of complete passes through the training dataset. The size of a batch must be more than or equal to one and less than or equal to the number of samples in the training dataset. The number of epochs can be set to an integer value between one and infinity. You can run the algorithm for as long as you like and even stop it using other criteria besides a fixed number of epochs, such as a change (or lack of change) in model error over time. They are both integer values and they are both hyperparameters for the learning algorithm , e.g. parameters for the learning process , not internal model parameters found by the learning process . You must specify the batch size and number of epochs for a learning algorithm. There are no magic rules for how to configure these parameters. You must try different values and see what works best for your problem.","title":"What Is the Difference Between Batch and Epoch?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#worked#example","text":"Finally, let\u2019s make this concrete with a small example. Assume you have a dataset with 200 samples (rows of data) and you choose a batch size of 5 and 1,000 epochs. This means that the dataset will be divided into 40 batches, each with five samples. The model weights will be updated after each batch of five samples. This also means that one epoch will involve 40 batches or 40 updates to the model. With 1,000 epochs, the model will be exposed to or pass through the whole dataset 1,000 times. That is a total of 40,000 batches during the entire training process.","title":"Worked Example"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#further#reading","text":"This section provides more resources on the topic if you are looking to go deeper. Gradient Descent For Machine Learning How to Control the Speed and Stability of Training Neural Networks Batch Size A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size A Gentle Introduction to Learning Curves for Diagnosing Model Performance Stochastic gradient descent on Wikipedia Backpropagation on Wikipedia","title":"Further Reading"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Batch-VS-epoch/#summary","text":"In this post, you discovered the difference between batches and epochs in stochastic gradient descent. Specifically, you learned: Stochastic gradient descent is an iterative learning algorithm that uses a training dataset to update a model. The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model\u2019s internal parameters are updated. The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset. Do you have any questions? Ask your questions in the comments below and I will do my best to answer.","title":"Summary"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Steps-VS-epochs/","text":"What is the difference between steps and epochs in TensorFlow? In most of the models, there is a steps parameter indicating the number of steps to run over data . But yet I see in most practical usage, we also execute the fit function N epochs . What is the difference between running 1000 steps with 1 epoch and running 100 steps with 10 epoch? Which one is better in practice? Any logic changes between consecutive epochs? Data shuffling? COMMENTS : Jason Brownlee at machinelearningmastery.com has a very nice, detailed answer to exactly that question. \u2013 BmyGuest Apr 16 at 20:12 A An epoch usually means one iteration over all of the training data. For instance if you have 20,000 images and a batch size of 100 then the epoch should contain 20,000 / 100 = 200 steps . However I usually just set a fixed number of steps like 1000 per epoch even though I have a much larger data set. At the end of the epoch I check the average cost and if it improved I save a checkpoint. There is no difference between steps from one epoch to another. I just treat them as checkpoints. People often shuffle around the data set between epochs. I prefer to use the random.sample function to choose the data to process in my epochs. So say I want to do 1000 steps with a batch size of 32. I will just randomly pick 32,000 samples from the pool of training data. A A training step is one gradient update. In one step batch_size many examples are processed. An epoch consists of one full cycle through the training data. This is usually many steps. As an example, if you have 2,000 images and use a batch size of 10 an epoch consists of 2,000 images / (10 images / step) = 200 steps. If you choose our training image randomly (and independent) in each step, you normally do not call it epoch. [This is where my answer differs from the previous one. Also see my comment.]","title":"Steps-VS-epochs"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Steps-VS-epochs/#what#is#the#difference#between#steps#and#epochs#in#tensorflow","text":"In most of the models, there is a steps parameter indicating the number of steps to run over data . But yet I see in most practical usage, we also execute the fit function N epochs . What is the difference between running 1000 steps with 1 epoch and running 100 steps with 10 epoch? Which one is better in practice? Any logic changes between consecutive epochs? Data shuffling? COMMENTS : Jason Brownlee at machinelearningmastery.com has a very nice, detailed answer to exactly that question. \u2013 BmyGuest Apr 16 at 20:12","title":"What is the difference between steps and epochs in TensorFlow?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Steps-VS-epochs/#a","text":"An epoch usually means one iteration over all of the training data. For instance if you have 20,000 images and a batch size of 100 then the epoch should contain 20,000 / 100 = 200 steps . However I usually just set a fixed number of steps like 1000 per epoch even though I have a much larger data set. At the end of the epoch I check the average cost and if it improved I save a checkpoint. There is no difference between steps from one epoch to another. I just treat them as checkpoints. People often shuffle around the data set between epochs. I prefer to use the random.sample function to choose the data to process in my epochs. So say I want to do 1000 steps with a batch size of 32. I will just randomly pick 32,000 samples from the pool of training data.","title":"A"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/Steps-VS-epochs/#a_1","text":"A training step is one gradient update. In one step batch_size many examples are processed. An epoch consists of one full cycle through the training data. This is usually many steps. As an example, if you have 2,000 images and use a batch size of 10 an epoch consists of 2,000 images / (10 images / step) = 200 steps. If you choose our training image randomly (and independent) in each step, you normally do not call it epoch. [This is where my answer differs from the previous one. Also see my comment.]","title":"A"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/buzz-word-batch-size/","text":"stackexchange What is batch size in neural network? I'm using Python Keras package for neural network. This is the link . Is batch_size equals to number of test samples? From Wikipedia we have this information: However, in other cases, evaluating the sum-gradient may require expensive evaluations of the gradients from all summand functions. When the training set is enormous and no simple formulas exist, evaluating the sums of gradients becomes very expensive, because evaluating the gradient requires evaluating all the summand functions' gradients. To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step. This is very effective in the case of large-scale machine learning problems. Above information is describing test data? Is this same as batch_size in keras (Number of samples per gradient update)? A The batch size defines the number of samples that will be propagated through the network. For instance, let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1 st to 100 th ) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101 st to 200 th ) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network. Problem might happen with the last set of samples. In our example, we've used 1050 which is not divisible by 100 without remainder. The simplest solution is just to get the final 50 samples and train the network. Advantages of using a batch size < number of all samples: It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory. Typically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter. Disadvantages of using a batch size < number of all samples: The smaller the batch the less accurate the estimate of the gradient will be. In the figure below, you can see that the direction of the mini-batch gradient (green color) fluctuates much more in comparison to the direction of the full batch gradient (blue color). Stochastic is just a mini-batch with batch_size equal to 1. In that case, the gradient changes its direction even more often than a mini-batch gradient.","title":"stackexchange [What is batch size in neural network?](https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network)"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/buzz-word-batch-size/#stackexchange#what#is#batch#size#in#neural#network","text":"I'm using Python Keras package for neural network. This is the link . Is batch_size equals to number of test samples? From Wikipedia we have this information: However, in other cases, evaluating the sum-gradient may require expensive evaluations of the gradients from all summand functions. When the training set is enormous and no simple formulas exist, evaluating the sums of gradients becomes very expensive, because evaluating the gradient requires evaluating all the summand functions' gradients. To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step. This is very effective in the case of large-scale machine learning problems. Above information is describing test data? Is this same as batch_size in keras (Number of samples per gradient update)?","title":"stackexchange What is batch size in neural network?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/buzz-word-batch-size/#a","text":"The batch size defines the number of samples that will be propagated through the network. For instance, let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1 st to 100 th ) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101 st to 200 th ) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network. Problem might happen with the last set of samples. In our example, we've used 1050 which is not divisible by 100 without remainder. The simplest solution is just to get the final 50 samples and train the network. Advantages of using a batch size < number of all samples: It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory. Typically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter. Disadvantages of using a batch size < number of all samples: The smaller the batch the less accurate the estimate of the gradient will be. In the figure below, you can see that the direction of the mini-batch gradient (green color) fluctuates much more in comparison to the direction of the full batch gradient (blue color). Stochastic is just a mini-batch with batch_size equal to 1. In that case, the gradient changes its direction even more often than a mini-batch gradient.","title":"A"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/word-epoch/","text":"What is \u201cepoch\u201d in keras.models.Model.fit? A Here is how Keras documentation defines an epoch: Epoch : an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation. So, in other words, a number of epochs means how many times you go through your training set. The model is updated each time a batch is processed, which means that it can be updated multiple times during one epoch. If batch_size is set equal to the length of x , then the model will be updated once per epoch. Meaning of an Epoch in Neural Networks Training while I'm reading in how to build ANN in pybrain , they say: Train the network for some epochs. Usually you would set something like 5 here, trainer.trainEpochs( 1 ) I looked for what is that mean , then I conclude that we use an epoch of data to update weights, If I choose to train the data with 5 epochs as pybrain advice, the dataset will be divided into 5 subsets, and the wights will update 5 times as maximum. I'm familiar with online training where the wights are updated after each sample data or feature vector, My question is how to be sure that 5 epochs will be enough to build a model and setting the weights probably? what is the advantage of this way on online training? Also the term \"epoch\" is used on online training, does it mean one feature vector? A One epoch consists of one full training cycle on the training set. Once every sample in the set is seen, you start again - marking the beginning of the 2 nd epoch. This has nothing to do with batch or online training per se. Batch means that you update once at the end of the epoch (after every sample is seen, i.e. #epoch updates) and online that you update after each sample (#samples * #epoch updates). You can't be sure if 5 epochs or 500 is enough for convergence\uff08\u6536\u655b\uff09 since it will vary from data to data. You can stop training when the error converges or gets lower than a certain threshold. This also goes into the territory of preventing overfitting. You can read up on early stopping and cross-validation regarding that.","title":"[What is \u201cepoch\u201d in keras.models.Model.fit?](https://stackoverflow.com/questions/44907377/what-is-epoch-in-keras-models-model-fit)"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/word-epoch/#what#is#epoch#in#kerasmodelsmodelfit","text":"","title":"What is \u201cepoch\u201d in keras.models.Model.fit?"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/word-epoch/#a","text":"Here is how Keras documentation defines an epoch: Epoch : an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation. So, in other words, a number of epochs means how many times you go through your training set. The model is updated each time a batch is processed, which means that it can be updated multiple times during one epoch. If batch_size is set equal to the length of x , then the model will be updated once per epoch.","title":"A"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/word-epoch/#meaning#of#an#epoch#in#neural#networks#training","text":"while I'm reading in how to build ANN in pybrain , they say: Train the network for some epochs. Usually you would set something like 5 here, trainer.trainEpochs( 1 ) I looked for what is that mean , then I conclude that we use an epoch of data to update weights, If I choose to train the data with 5 epochs as pybrain advice, the dataset will be divided into 5 subsets, and the wights will update 5 times as maximum. I'm familiar with online training where the wights are updated after each sample data or feature vector, My question is how to be sure that 5 epochs will be enough to build a model and setting the weights probably? what is the advantage of this way on online training? Also the term \"epoch\" is used on online training, does it mean one feature vector?","title":"Meaning of an Epoch in Neural Networks Training"},{"location":"Theory/Deep-learning/Guide/Batch-epoch-step/word-epoch/#a_1","text":"One epoch consists of one full training cycle on the training set. Once every sample in the set is seen, you start again - marking the beginning of the 2 nd epoch. This has nothing to do with batch or online training per se. Batch means that you update once at the end of the epoch (after every sample is seen, i.e. #epoch updates) and online that you update after each sample (#samples * #epoch updates). You can't be sure if 5 epochs or 500 is enough for convergence\uff08\u6536\u655b\uff09 since it will vary from data to data. You can stop training when the error converges or gets lower than a certain threshold. This also goes into the territory of preventing overfitting. You can read up on early stopping and cross-validation regarding that.","title":"A"},{"location":"Theory/Deep-learning/Guide/Compiler/","text":"Compiler NNVM compiler 1) \u6700\u65b0 | NNVM \u7f16\u8bd1\u5668\u5bfc\u8bba\uff1a\u7528\u4e8eAI\u6846\u67b6\u7684\u4e00\u79cd\u65b0\u5f0f\u7aef\u5230\u7aef\u7f16\u8bd1\u5668 2) \u9648\u5929\u5947\u56e2\u961f\u53d1\u5e03NNVM\u7f16\u8bd1\u5668\uff0c\u6027\u80fd\u4f18\u4e8eMXNet\uff0c\u674e\u6c90\u64b0\u6587\u4ecb\u7ecd 3) \u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u4e2d\u95f4\u4ef6\u4e4bNNVM(\u4e00)\u4ecb\u7ecd 4) \u7406\u89e3\u4e00\u4e0bnnvm \u548c tvm\u7684\u533a\u522b 5) \u4e00\u79cd\u5f00\u6e90\u3001\u7aef\u5230\u7aef\u7684\u65b0\u578b\u4eba\u5de5\u667a\u80fd\u6846\u67b6\u7f16\u8bd1\u5668\u2014\u2014NNVM\u7f16\u8bd1\u5668 apache Apache TVM amazon Introducing NNVM Compiler: A New Open End-to-End Compiler for AI Frameworks IR \u65b0\u667a\u5143 \u6df1\u5ea6\u5b66\u4e60\u7684IR\u201c\u4e4b\u4e89\u201d \u3010\u65b0\u667a\u5143\u5bfc\u8bfb\u3011**\u719f\u6089**\u7f16\u8bd1\u5668**\u7684\u540c\u5b66\u5e94\u8be5\u5bf9\u4e0a\u56fe\u5e76\u4e0d\u964c\u751f\u3002\u5b83\u5c31\u662f\u5927\u540d\u9f0e\u9f0e\u7684LLVM\u7684logo\u3002Google Tensorflow **XLA (Accelerated Linear Algebra)\u5c31\u4f7f\u7528\u4e86**LLVM IR**\uff08 Intermediate Representation \uff09\u3002\u800c\u5b83\u7684\u201c\u7ade\u4e89\u5bf9\u624b\u201d\uff0c\u521a\u521a\u53d1\u5e03\u7684**TVM/NNVM**\uff0c\u5219\u662f\u201cTensor IR Stack for Deep Learning Systems\u201d\u3002IR\u662f\u4ec0\u4e48\uff1f\u4e3a\u4ec0\u4e48\u91cd\u8981\uff1f\u6211\u4eec\u4e00\u8d77\u6765\u770b\u770b\u3002 \u4e0a\u5468\uff0c\u6211\u4eec\u770b\u5230\u8fd9\u6837\u7684\u65b0\u95fb\u201cFacebook and Microsoft introduce new open ecosystem for interchangeable AI frameworks\u201d\u3002\u8fd9\u4e5f\u8ba9Framework\u4e4b\u4e89\u66f4\u52a0\u70ed\u95f9\u3002\u7b80\u5355\u6765\u8bf4\uff0cONNX\u4e5f\u662f\u4e3a\u4e86\u89e3\u51b3\u76ee\u524d\u591a\u4e2aFramework\u4e92\u64cd\u4f5c\u7684\u95ee\u9898\u3002\u4f46\u6709\u8da3\u7684\u662f\uff0c\u8fd9\u4e2a\u201c\u5f00\u653e\u201d\u7684\u7cfb\u7edf\u770b\u8d77\u6765\u66f4\u50cf\u662f\u5fae\u8f6f\u548cFB\u8fde\u5408\u5bf9\u6297Google\u3002\u76ee\u524dTensorflow\u7684\u5360\u6709\u7387\u5df2\u7ecf\u9886\u5148\u4e0d\u5c11\uff0c\u5176\u5b83\u7684Framework\u80af\u5b9a\u4e5f\u4e0d\u5e0c\u671b\u770b\u5230Tensorflow\u4e00\u5bb6\u72ec\u5927\uff0c\u6bd5\u7adfFramework\u662f\u505adeep learning\u7684\u4e00\u4e2a\u201c\u5165\u53e3\u201d\u3002\u6700\u8fd1PyTorch\u7684\u52bf\u5934\u4e0d\u9519\uff0cCaffe2, PyTorch\u548cCognitive Toolkit\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u201c\u8054\u5408\u201d\uff0c\u4f3c\u4e4e\u4e5f\u662f\u4e2a\u4e0d\u9519\u7684\u9009\u62e9\u3002 \u201cAn Intermediate representation (IR) is the data structure or code used internally by a compiler or virtual machine to represent source code.**An IR is designed to be conducive for further processing, such as optimization and translation. A \"**good \" IR must be accurate \u2013 capable of representing the source code without loss of information \u2013 and independent of any particular source or target language. An IR may take one of several forms: an in-memory data structure, or a special tuple- or stack-based code readable by the program. In the latter case it is also called an intermediate language.\u201d - Wikipedia \u6211\u4eec\u8fd8\u662f\u4ece\u76ee\u524dDeep Learning\u7684\u4e00\u4e2a\u73b0\u5b9e\u95ee\u9898\u8bf4\u8d77\u5427\u3002 \u4e0a\u56fe\u6765\u81ea\u4ecb\u7ecdNNVM\u7684\u4e00\u7bc7\u6587\u7ae0[1]\u3002\u6587\u4e2d\u5728\u8c08\u5230NNVM\u7684\u76ee\u6807\u7684\u65f6\u5019\uff0c\u662f\u8fd9\u4e48\u8bf4\u7684\uff1a \u201cThis is a new interesting era of deep learning, with emergence trend of new system, hardware and computational model. The usecase for deep learning is more heterogeneous , and we need tailored(\u526a\u88c1) learning system for our cars, mobiles and cloud services. The future of deep learning system is going to be more heterogeneous, and we will find emergence need of different front-ends, backends and optimization techniques . Instead of building a monolithic(\u96c6\u6210\u7684) solution to solve all these problems, how about adopt unix philosophy, build effective modules for learning system, and assemble them together to build minimum and effective systems?\u201d \u7b80\u5355\u6765\u8bf4\uff0c \u73b0\u5728Deep Learning\u6709\u8fd9\u4e48\u591a\u4e0d\u540c\u524d\u7aef\uff08framework\uff09\uff0c\u6709\u8fd9\u4e48\u591a\u4e0d\u540c\u7684\u540e\u7aef\uff08hardware\uff09\uff0c\u662f\u5426\u80fd\u627e\u5230\u4e00\u4e2a\u6865\u6881\u66f4\u6709\u6548\u5b9e\u73b0\u4ed6\u4eec\u4e4b\u95f4\u7684\u4f18\u5316\u548c\u5f71\u5c04\u5462\uff1f \u5b9e\u9645\u4e0a\u8fd9\u4e2a\u95ee\u9898\u5e76\u4e0d\u65b0\u9c9c\u3002\u5f53\u5e74\uff0c\u968f\u7740\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\u548c\u9700\u6c42\uff0c\u51fa\u73b0\u4e86\u5927\u91cf\u4e0d\u540c\u7684\u7f16\u7a0b\u8bed\u8a00\u548c\u4e0d\u540c\u7684\u5904\u7406\u5668\u67b6\u6784\uff0c\u8f6f\u4ef6\u4ea7\u4e1a\u4e5f\u9047\u5230\u8fc7\u7c7b\u4f3c\u7684\u95ee\u9898\u3002 \u6362\u53e5\u8bdd\u8bf4\uff0c\u8fd9\u4e5f\u6b63\u662f\u91cd\u6f14\u4e86LLVM\u51fa\u73b0\u65f6\u7684\u573a\u666f\uff1a \u5927\u91cf\u4e0d\u540c\u7684\u7f16\u7a0b\u8bed\u8a00\u548c\u8d8a\u6765\u8d8a\u591a\u7684\u786c\u4ef6\u67b6\u6784\u4e4b\u95f4\u9700\u8981\u4e00\u4e2a\u6865\u6881 \u3002LLVM\u7684\u51fa\u73b0\uff0c\u8ba9\u4e0d\u540c\u7684\u524d\u7aef\u540e\u7aef\u4f7f\u7528\u7edf\u4e00\u7684 LLVM IR ,\u5982\u679c\u9700\u8981\u652f\u6301\u65b0\u7684\u7f16\u7a0b\u8bed\u8a00\u6216\u8005\u65b0\u7684\u8bbe\u5907\u5e73\u53f0\uff0c\u53ea\u9700\u8981\u5f00\u53d1\u5bf9\u5e94\u7684\u524d\u7aef\u548c\u540e\u7aef\u5373\u53ef\u3002\u540c\u65f6\u57fa\u4e8e LLVM IR \u6211\u4eec\u53ef\u4ee5\u5f88\u5feb\u7684\u5f00\u53d1\u81ea\u5df1\u7684\u7f16\u7a0b\u8bed\u8a00\u3002\u6bd4\u5982\uff0cLLVM\u521b\u5efa\u8005Chris Lattner\u540e\u6765\u52a0\u5165\u4e86Apple\uff0c\u53c8\u521b\u5efa\u4e86Swift\u8bed\u8a00\uff0c\u53ef\u4ee5\u770b\u4f5c\u662fLLVM\u7684\u524d\u7aef\u3002 \u7531\u6b64\u4e5f\u53ef\u4ee5\u770b\u51fa\uff0cLLVM\u7edf\u4e00\u7684IR\u662f\u5b83\u6210\u529f\u7684\u5173\u952e\u4e4b\u4e00\uff0c\u4e5f\u5145\u5206\u8bf4\u660e\u4e86\u4e00\u4e2a\u4f18\u79c0IR\u7684\u91cd\u8981\u6027\u3002 \u5f53\u7136\uff0cIR\u672c\u8d28\u4e0a\u662f\u4e00\u79cd\u4e2d\u95f4\u8868\u793a\u5f62\u5f0f\uff0c\u662f\u4e00\u4e2a\u5b8c\u6574\u7f16\u8bd1\u5de5\u5177\u7684\u4e00\u90e8\u5206\u3002\u800c\u6211\u4eec\u4e0b\u9762\u8ba8\u8bba\u7684TVM\uff0cXLA\u90fd\u662f\u56f4\u7ed5\u7279\u5b9aIR\u6784\u5efa\u7684\u4f18\u5316\u548c\u7f16\u8bd1\u5de5\u5177\u3002 \u9648\u5929\u5947\u5728\u53e6\u4e00\u7bc7\u6587\u7ae0\u4e2d\u63d0\u5230\uff1a\u201c...\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff0c\u6211\u4eec\u9700\u8981\u7c7b\u4f3c\u7684\u9879\u76ee\u3002\u5b66\u4e60 LL**VM** \u7684\u601d\u60f3\uff0c\u6211\u4eec\u5c06\u5176\u53d6\u540d NN**VM**\u201d\u3002(2016\u5e7410\u6708) 8\u670817\u53f7\uff0c\u9648\u5929\u5947\u7684\u56e2\u961f\u53c8\u53d1\u5e03\u4e86T**VM**\uff1aAn End to End IR Stack for Deploying the Deep Learning Workloads to Hardwares[2]\uff0c\u5176\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a We adopt **a common philosophy from the compiler community**and **provide two intermediate representation layers**to efficiently lower high-level deep learning algorithms down to a multitude of hardware back-ends. \u53ef\u4ee5\u770b\u51fa\uff0c\u4ed6\u4eec\u5728\u4e4b\u524d\u7684NNVM\u4e4b\u5916\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u65b0\u7684IR Stack\uff0cTVM\uff0c\u8bd5\u56fe\u89e3\u51b3\u4e0b\u56fe\u6240\u793a\u7684Gap,\u201cA lot of powerful optimizations can be supported by the graph optimization framework. ... However we find that the computational graph based IR alone is not enough to solve the challenge of supporting different hardware backends. \u201d\u8fd9\u91cc\u7684graph based IR\u5219\u662f\u6307NNVM\u3002 \u6211\u4eec\u77e5\u9053\uff0c\u5728LLVM\u73af\u5883\u4e2d\uff0c\u53ea\u6709\u4e00\u4e2a\u7edf\u4e00\u7684IR\u3002 \u90a3\u4e48\uff0c\u4e3a\u4ec0\u4e48Deep Learning\u73af\u5883\u4e2dgraph based IR\u8fd8\u4e0d\u591f\u5462 \uff1f\u5728\u968f\u540e\u7684\u4e00\u7bc7\u77e5\u4e4e\u6587\u7ae0\u4e2d[3]\uff0c\u9648\u5929\u5947\u63d0\u5230\u4e86\u53bb\u5e7410\u6708\u77e5\u4e4e\u4e0a\u5173\u4e8e\u201c \u5982\u4f55\u8bc4\u4ef7\u9648\u5929\u5947\u7684\u6a21\u5757\u5316\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edfNNVM\uff1f \u201d\u7684\u8ba8\u8bba[4]\u3002\u800c\u8fd9\u4e2a\u8ba8\u8bba\u4e2d\u738b\u5065\u98de\u7684\u56de\u7b54\u4f3c\u4e4e\u662fTVM\u4ea7\u751f\u7684\u7075\u611f\u4e4b\u4e00\u3002 \u540c\u6837\u5728\u8fd9\u7bc7\u6587\u7ae0\u5f53\u4e2d\uff0c\u9648\u5929\u5947\u8fd8\u63d0\u5230\uff0c\u201cTVM\u548c\u5df2\u6709\u7684\u89e3\u51b3\u65b9\u6848\u4e0d\u540c\uff0c \u4ee5XLA\u4f5c\u4e3a\u4f8b\u5b50\uff0cTVM\u8d70\u4e86\u548c\u76ee\u524d\u7684XLA\u6bd4\u66f4\u52a0\u6fc0\u8fdb\u7684\u6280\u672f\u8def\u7ebf\uff0cTVM\u53ef\u4ee5\u7528\u6765\u4f7f\u5f97\u5b9e\u73b0XLA\u9700\u8981\u7684\u529f\u80fd\u66f4\u52a0\u5bb9\u6613 \u201d\u3002 \u65e2\u7136TVM\u7684\u4f5c\u8005\u70b9\u4e86\u5bf9\u624b\u7684\u540d\uff0c\u6211\u4eec\u5c31\u6765\u770b\u770bGoogle\u7684XLA\u5427\u3002 XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that optimizes TensorFlow computations. The results are improvements in speed, memory usage, and portability on server and mobile platforms. Initially, most users will not see large benefits from XLA, but are welcome to experiment by using XLA via just-in-time (JIT) compilation or ahead-of-time (AOT) compilation. Developers targeting new hardware accelerators are especially encouraged to try out XLA. \u4e0b\u56fe\u5de6\u534a\u90e8\u5206\u6765\u81ea\u201c2017 EuroLLVM Deveopers\u2019 Meeting\u201d\u4e0a\u7684\u4e00\u4e2a\u62a5\u544a[6]\uff0c\u6bd4\u8f83\u6e05\u695a\u4ecb\u7ecd\u4e86XLA\u7684\u76ee\u6807\uff0c\u5176\u57fa\u672c\u529f\u80fd\u4e5f\u662f\u4f18\u5316\u548c\u4ee3\u7801\u751f\u6210\u3002 XLA\u5177\u4f53\u7684\u67b6\u6784\u5982\u56fe\u53f3\u534a\u90e8\u5206\u6240\u793a\uff0c\u53ef\u4ee5\u770b\u51fa\uff0c\u5b83\u4e5f\u662f**\u4e24\u5c42\u4f18\u5316**\u7684\u7ed3\u6784[5]\uff0c\u4f7f\u7528LLVM\u7528\u4f5clow-level IR, optimization, and code-generation\u3002\u7531\u4e8e\u4f7f\u7528\u4e86LLVM IR, \u4ed6\u53ef\u4ee5\u6bd4\u8f83\u5bb9\u6613\u7684\u652f\u6301\u4e0d\u540c\u7684\u540e\u7aef\uff08Backend\uff09\u3002\u4e0b\u56fe\u5c31\u662f\u4f7f\u7528GPU Backend\u7684\u4f8b\u5b50\u3002 \u5bf9\u4e8e\u76ee\u524d\u4e0d\u76f4\u63a5\u652f\u6301\u7684\u540e\u7aef\uff0cXLA\u7ed9\u51fa\u4e86\u4e09\u79cd\u573a\u666f\u7684\u5f00\u53d1\u65b9\u6cd5\u3002\u5305\u62ec\uff1a \\1. Existing CPU architecture not yet officially supported by XLA, with or without an existing LLVM backend. \\2. Non-CPU-like hardware with an existing LLVM backend. \\3. Non-CPU-like hardware without an existing LLVM backend. \u603b\u7684\u6765\u8bf4\uff0cXLA\u548cTVM\u8bd5\u56fe\u89e3\u51b3\u7684\u95ee\u9898\u7c7b\u4f3c\u3002\u4f46XLA\u53ea\u662f\u9488\u5bf9Google\u7684Tensorflow\u7684\u3002\u800cTVM/NNVM\u867d\u7136\u662fMxNe\u9635\u8425\uff0c\u4f46\u8bd5\u56fe\u4f5c\u4e3a\u4e00\u4e2a\u5f00\u53d1\u548c\u516c\u5171\u7684\u63a5\u53e3\u3002 \u8fd9\u91cc\u63d2\u64ad\u4e00\u4e2a\u65b0\u95fb\uff0cChris Lattner\u6700\u8fd1\u52a0\u5165\u4e86Google Brain\u3002\u867d\u7136\u8fd8\u4e0d\u77e5\u9053\u4ed6\u7684\u4e3b\u8981\u5de5\u4f5c\u662f\u4e0d\u662f\u4f1a\u653e\u5728XLA\u8fd9\u91cc\uff0c\u4f46\u662f\u4ed6\u548cJeff Dean\u914d\u5408\uff0c\u786e\u5b9e\u662f\u4ee4\u4eba\u751f\u754f\u3002 \u5176\u5b9e\uff0c\u7c7b\u4f3c\u7684\u60f3\u6cd5\u8fd8\u5305\u62ec\uff1aIntel\u2019s NGraph\uff08\u5982\u4e0b\u56fe\uff09\uff0cHP\u7684Cognitive Computing Toolkit (CCT)\uff0c IBM\u7684SystemML\u3002 \u800c\u5728\u521a\u521a\u7ed3\u675f\u7684Hot Chips\u4f1a\u8bae\u4e0a\uff0cMicrosoft\u53d1\u5e03\u4e86Project Brainwave\uff0cCloud\u7684AI FPGA\u52a0\u901f\u5e73\u53f0\u3002\u5b83\u7684\u5de5\u5177\u94fe\u662f\u8fd9\u6837\u7684\uff0c\u662f\u4e0d\u662f\u53c8\u770b\u5230\u4e86\u4e24\u5c42IR\uff1f \u6700\u540e\uff0c\u6700\u8fd1\u8fd8\u770b\u5230\u53e6\u4e00\u4e2a\u6709\u8da3\u7684\u5c1d\u8bd5\uff1aKhronos Neural Network Exchange Format (NNEF)\uff0c\u8bd5\u56fe\u5b9a\u4e49\u4e00\u79cd\u6807\u51c6\u7684\u6570\u636e\u4ea4\u6362\u683c\u5f0f\u3002\u201cThe NNEF standard encapsulates neural network structure, data formats, commonly used operations (such as convolution, pooling, normalization, etc.) and formal network semantics. \u201d T.S.\uff1a \u968f\u7740Deep Learning\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\uff0c\u5927\u5bb6\u8d8a\u6765\u8d8a\u5173\u5fc3DNN(deep nerual network)\u5728\u4e0d\u540c\u786c\u4ef6\u67b6\u6784\u4e0aTraining\u548cInference\u7684\u5b9e\u73b0\u6548\u7387\u3002\u53c2\u8003\u4f20\u7edf\u7f16\u8bd1\u5668\uff08compiler\uff09\u8bbe\u8ba1\u7684\u7ecf\u9a8c\uff0cXLA\u548cTVM/NNVM\u90fd\u5f00\u59cb\u4e86\u5f88\u597d\u7684\u5c1d\u8bd5\u3002\u800c\u201cIR\u201d\u7684\u7ade\u4e89\uff0c\u5c06\u662f\u672a\u6765Framework\u4e4b\u4e89\u7684\u91cd\u8981\u4e00\u73af\u3002 Reference\uff1a [1]\u9648\u5929\u5947, \"Build your own TensorFlow with NNVM and Torch\", http://tqchen.github.io/2016/10/01/build-your-own-tensorflow-with-nnvm-and-torch.html [2]\u9648\u5929\u5947, \"TVM: An End to End IR Stack for Deploying the Deep Learning Workloads to Hardwares\", http://tvmlang.org/2017/08/17/tvm-release-announcement.html [3]\u9648\u5929\u5947, \"\u5982\u4f55\u8bc4\u4ef7\u9648\u5929\u5947\u56e2\u961f\u65b0\u5f00\u6e90\u7684TVM\uff1f\", https://www.zhihu.com/question/64091792/answer/217722459 [4] \u738b\u5065\u98de\uff0c\u201c\u5982\u4f55\u8bc4\u4ef7\u9648\u5929\u5947\u7684\u6a21\u5757\u5316\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edfNNVM\uff1f\u201d\uff0c https://www.zhihu.com/question/51216952/answer/124708405 [5]\"XLA Overview\", https://www.tensorflow.org/performance/xla/ [6]\"2017 EuroLLVM Developers\u2019 Meeting: D. Majnemer \u201cXLA: Accelerated Linear Algebra\u201d\", https://www.youtube.com/watch?v=2IOPpyyuLkc [7]\"A Brief Introduction to LLVM\", https://www.youtube.com/watch?v=a5-WaD8VV38 \" [8]\"XLA: TensorFlow Compiled!\", https://www.youtube.com/watch?v=kAOanJczHA0","title":"Compiler"},{"location":"Theory/Deep-learning/Guide/Compiler/#compiler","text":"","title":"Compiler"},{"location":"Theory/Deep-learning/Guide/Compiler/#nnvm#compiler","text":"1) \u6700\u65b0 | NNVM \u7f16\u8bd1\u5668\u5bfc\u8bba\uff1a\u7528\u4e8eAI\u6846\u67b6\u7684\u4e00\u79cd\u65b0\u5f0f\u7aef\u5230\u7aef\u7f16\u8bd1\u5668 2) \u9648\u5929\u5947\u56e2\u961f\u53d1\u5e03NNVM\u7f16\u8bd1\u5668\uff0c\u6027\u80fd\u4f18\u4e8eMXNet\uff0c\u674e\u6c90\u64b0\u6587\u4ecb\u7ecd 3) \u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u4e2d\u95f4\u4ef6\u4e4bNNVM(\u4e00)\u4ecb\u7ecd 4) \u7406\u89e3\u4e00\u4e0bnnvm \u548c tvm\u7684\u533a\u522b 5) \u4e00\u79cd\u5f00\u6e90\u3001\u7aef\u5230\u7aef\u7684\u65b0\u578b\u4eba\u5de5\u667a\u80fd\u6846\u67b6\u7f16\u8bd1\u5668\u2014\u2014NNVM\u7f16\u8bd1\u5668","title":"NNVM compiler"},{"location":"Theory/Deep-learning/Guide/Compiler/#apache#apache#tvm","text":"","title":"apache Apache TVM"},{"location":"Theory/Deep-learning/Guide/Compiler/#amazon#introducing#nnvm#compiler#a#new#open#end-to-end#compiler#for#ai#frameworks","text":"","title":"amazon Introducing NNVM Compiler: A New Open End-to-End Compiler for AI Frameworks"},{"location":"Theory/Deep-learning/Guide/Compiler/#ir","text":"","title":"IR"},{"location":"Theory/Deep-learning/Guide/Compiler/#ir_1","text":"\u3010\u65b0\u667a\u5143\u5bfc\u8bfb\u3011**\u719f\u6089**\u7f16\u8bd1\u5668**\u7684\u540c\u5b66\u5e94\u8be5\u5bf9\u4e0a\u56fe\u5e76\u4e0d\u964c\u751f\u3002\u5b83\u5c31\u662f\u5927\u540d\u9f0e\u9f0e\u7684LLVM\u7684logo\u3002Google Tensorflow **XLA (Accelerated Linear Algebra)\u5c31\u4f7f\u7528\u4e86**LLVM IR**\uff08 Intermediate Representation \uff09\u3002\u800c\u5b83\u7684\u201c\u7ade\u4e89\u5bf9\u624b\u201d\uff0c\u521a\u521a\u53d1\u5e03\u7684**TVM/NNVM**\uff0c\u5219\u662f\u201cTensor IR Stack for Deep Learning Systems\u201d\u3002IR\u662f\u4ec0\u4e48\uff1f\u4e3a\u4ec0\u4e48\u91cd\u8981\uff1f\u6211\u4eec\u4e00\u8d77\u6765\u770b\u770b\u3002 \u4e0a\u5468\uff0c\u6211\u4eec\u770b\u5230\u8fd9\u6837\u7684\u65b0\u95fb\u201cFacebook and Microsoft introduce new open ecosystem for interchangeable AI frameworks\u201d\u3002\u8fd9\u4e5f\u8ba9Framework\u4e4b\u4e89\u66f4\u52a0\u70ed\u95f9\u3002\u7b80\u5355\u6765\u8bf4\uff0cONNX\u4e5f\u662f\u4e3a\u4e86\u89e3\u51b3\u76ee\u524d\u591a\u4e2aFramework\u4e92\u64cd\u4f5c\u7684\u95ee\u9898\u3002\u4f46\u6709\u8da3\u7684\u662f\uff0c\u8fd9\u4e2a\u201c\u5f00\u653e\u201d\u7684\u7cfb\u7edf\u770b\u8d77\u6765\u66f4\u50cf\u662f\u5fae\u8f6f\u548cFB\u8fde\u5408\u5bf9\u6297Google\u3002\u76ee\u524dTensorflow\u7684\u5360\u6709\u7387\u5df2\u7ecf\u9886\u5148\u4e0d\u5c11\uff0c\u5176\u5b83\u7684Framework\u80af\u5b9a\u4e5f\u4e0d\u5e0c\u671b\u770b\u5230Tensorflow\u4e00\u5bb6\u72ec\u5927\uff0c\u6bd5\u7adfFramework\u662f\u505adeep learning\u7684\u4e00\u4e2a\u201c\u5165\u53e3\u201d\u3002\u6700\u8fd1PyTorch\u7684\u52bf\u5934\u4e0d\u9519\uff0cCaffe2, PyTorch\u548cCognitive Toolkit\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u201c\u8054\u5408\u201d\uff0c\u4f3c\u4e4e\u4e5f\u662f\u4e2a\u4e0d\u9519\u7684\u9009\u62e9\u3002 \u201cAn Intermediate representation (IR) is the data structure or code used internally by a compiler or virtual machine to represent source code.**An IR is designed to be conducive for further processing, such as optimization and translation. A \"**good \" IR must be accurate \u2013 capable of representing the source code without loss of information \u2013 and independent of any particular source or target language. An IR may take one of several forms: an in-memory data structure, or a special tuple- or stack-based code readable by the program. In the latter case it is also called an intermediate language.\u201d - Wikipedia \u6211\u4eec\u8fd8\u662f\u4ece\u76ee\u524dDeep Learning\u7684\u4e00\u4e2a\u73b0\u5b9e\u95ee\u9898\u8bf4\u8d77\u5427\u3002 \u4e0a\u56fe\u6765\u81ea\u4ecb\u7ecdNNVM\u7684\u4e00\u7bc7\u6587\u7ae0[1]\u3002\u6587\u4e2d\u5728\u8c08\u5230NNVM\u7684\u76ee\u6807\u7684\u65f6\u5019\uff0c\u662f\u8fd9\u4e48\u8bf4\u7684\uff1a \u201cThis is a new interesting era of deep learning, with emergence trend of new system, hardware and computational model. The usecase for deep learning is more heterogeneous , and we need tailored(\u526a\u88c1) learning system for our cars, mobiles and cloud services. The future of deep learning system is going to be more heterogeneous, and we will find emergence need of different front-ends, backends and optimization techniques . Instead of building a monolithic(\u96c6\u6210\u7684) solution to solve all these problems, how about adopt unix philosophy, build effective modules for learning system, and assemble them together to build minimum and effective systems?\u201d \u7b80\u5355\u6765\u8bf4\uff0c \u73b0\u5728Deep Learning\u6709\u8fd9\u4e48\u591a\u4e0d\u540c\u524d\u7aef\uff08framework\uff09\uff0c\u6709\u8fd9\u4e48\u591a\u4e0d\u540c\u7684\u540e\u7aef\uff08hardware\uff09\uff0c\u662f\u5426\u80fd\u627e\u5230\u4e00\u4e2a\u6865\u6881\u66f4\u6709\u6548\u5b9e\u73b0\u4ed6\u4eec\u4e4b\u95f4\u7684\u4f18\u5316\u548c\u5f71\u5c04\u5462\uff1f \u5b9e\u9645\u4e0a\u8fd9\u4e2a\u95ee\u9898\u5e76\u4e0d\u65b0\u9c9c\u3002\u5f53\u5e74\uff0c\u968f\u7740\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\u548c\u9700\u6c42\uff0c\u51fa\u73b0\u4e86\u5927\u91cf\u4e0d\u540c\u7684\u7f16\u7a0b\u8bed\u8a00\u548c\u4e0d\u540c\u7684\u5904\u7406\u5668\u67b6\u6784\uff0c\u8f6f\u4ef6\u4ea7\u4e1a\u4e5f\u9047\u5230\u8fc7\u7c7b\u4f3c\u7684\u95ee\u9898\u3002 \u6362\u53e5\u8bdd\u8bf4\uff0c\u8fd9\u4e5f\u6b63\u662f\u91cd\u6f14\u4e86LLVM\u51fa\u73b0\u65f6\u7684\u573a\u666f\uff1a \u5927\u91cf\u4e0d\u540c\u7684\u7f16\u7a0b\u8bed\u8a00\u548c\u8d8a\u6765\u8d8a\u591a\u7684\u786c\u4ef6\u67b6\u6784\u4e4b\u95f4\u9700\u8981\u4e00\u4e2a\u6865\u6881 \u3002LLVM\u7684\u51fa\u73b0\uff0c\u8ba9\u4e0d\u540c\u7684\u524d\u7aef\u540e\u7aef\u4f7f\u7528\u7edf\u4e00\u7684 LLVM IR ,\u5982\u679c\u9700\u8981\u652f\u6301\u65b0\u7684\u7f16\u7a0b\u8bed\u8a00\u6216\u8005\u65b0\u7684\u8bbe\u5907\u5e73\u53f0\uff0c\u53ea\u9700\u8981\u5f00\u53d1\u5bf9\u5e94\u7684\u524d\u7aef\u548c\u540e\u7aef\u5373\u53ef\u3002\u540c\u65f6\u57fa\u4e8e LLVM IR \u6211\u4eec\u53ef\u4ee5\u5f88\u5feb\u7684\u5f00\u53d1\u81ea\u5df1\u7684\u7f16\u7a0b\u8bed\u8a00\u3002\u6bd4\u5982\uff0cLLVM\u521b\u5efa\u8005Chris Lattner\u540e\u6765\u52a0\u5165\u4e86Apple\uff0c\u53c8\u521b\u5efa\u4e86Swift\u8bed\u8a00\uff0c\u53ef\u4ee5\u770b\u4f5c\u662fLLVM\u7684\u524d\u7aef\u3002 \u7531\u6b64\u4e5f\u53ef\u4ee5\u770b\u51fa\uff0cLLVM\u7edf\u4e00\u7684IR\u662f\u5b83\u6210\u529f\u7684\u5173\u952e\u4e4b\u4e00\uff0c\u4e5f\u5145\u5206\u8bf4\u660e\u4e86\u4e00\u4e2a\u4f18\u79c0IR\u7684\u91cd\u8981\u6027\u3002 \u5f53\u7136\uff0cIR\u672c\u8d28\u4e0a\u662f\u4e00\u79cd\u4e2d\u95f4\u8868\u793a\u5f62\u5f0f\uff0c\u662f\u4e00\u4e2a\u5b8c\u6574\u7f16\u8bd1\u5de5\u5177\u7684\u4e00\u90e8\u5206\u3002\u800c\u6211\u4eec\u4e0b\u9762\u8ba8\u8bba\u7684TVM\uff0cXLA\u90fd\u662f\u56f4\u7ed5\u7279\u5b9aIR\u6784\u5efa\u7684\u4f18\u5316\u548c\u7f16\u8bd1\u5de5\u5177\u3002 \u9648\u5929\u5947\u5728\u53e6\u4e00\u7bc7\u6587\u7ae0\u4e2d\u63d0\u5230\uff1a\u201c...\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff0c\u6211\u4eec\u9700\u8981\u7c7b\u4f3c\u7684\u9879\u76ee\u3002\u5b66\u4e60 LL**VM** \u7684\u601d\u60f3\uff0c\u6211\u4eec\u5c06\u5176\u53d6\u540d NN**VM**\u201d\u3002(2016\u5e7410\u6708) 8\u670817\u53f7\uff0c\u9648\u5929\u5947\u7684\u56e2\u961f\u53c8\u53d1\u5e03\u4e86T**VM**\uff1aAn End to End IR Stack for Deploying the Deep Learning Workloads to Hardwares[2]\uff0c\u5176\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a We adopt **a common philosophy from the compiler community**and **provide two intermediate representation layers**to efficiently lower high-level deep learning algorithms down to a multitude of hardware back-ends. \u53ef\u4ee5\u770b\u51fa\uff0c\u4ed6\u4eec\u5728\u4e4b\u524d\u7684NNVM\u4e4b\u5916\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u65b0\u7684IR Stack\uff0cTVM\uff0c\u8bd5\u56fe\u89e3\u51b3\u4e0b\u56fe\u6240\u793a\u7684Gap,\u201cA lot of powerful optimizations can be supported by the graph optimization framework. ... However we find that the computational graph based IR alone is not enough to solve the challenge of supporting different hardware backends. \u201d\u8fd9\u91cc\u7684graph based IR\u5219\u662f\u6307NNVM\u3002 \u6211\u4eec\u77e5\u9053\uff0c\u5728LLVM\u73af\u5883\u4e2d\uff0c\u53ea\u6709\u4e00\u4e2a\u7edf\u4e00\u7684IR\u3002 \u90a3\u4e48\uff0c\u4e3a\u4ec0\u4e48Deep Learning\u73af\u5883\u4e2dgraph based IR\u8fd8\u4e0d\u591f\u5462 \uff1f\u5728\u968f\u540e\u7684\u4e00\u7bc7\u77e5\u4e4e\u6587\u7ae0\u4e2d[3]\uff0c\u9648\u5929\u5947\u63d0\u5230\u4e86\u53bb\u5e7410\u6708\u77e5\u4e4e\u4e0a\u5173\u4e8e\u201c \u5982\u4f55\u8bc4\u4ef7\u9648\u5929\u5947\u7684\u6a21\u5757\u5316\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edfNNVM\uff1f \u201d\u7684\u8ba8\u8bba[4]\u3002\u800c\u8fd9\u4e2a\u8ba8\u8bba\u4e2d\u738b\u5065\u98de\u7684\u56de\u7b54\u4f3c\u4e4e\u662fTVM\u4ea7\u751f\u7684\u7075\u611f\u4e4b\u4e00\u3002 \u540c\u6837\u5728\u8fd9\u7bc7\u6587\u7ae0\u5f53\u4e2d\uff0c\u9648\u5929\u5947\u8fd8\u63d0\u5230\uff0c\u201cTVM\u548c\u5df2\u6709\u7684\u89e3\u51b3\u65b9\u6848\u4e0d\u540c\uff0c \u4ee5XLA\u4f5c\u4e3a\u4f8b\u5b50\uff0cTVM\u8d70\u4e86\u548c\u76ee\u524d\u7684XLA\u6bd4\u66f4\u52a0\u6fc0\u8fdb\u7684\u6280\u672f\u8def\u7ebf\uff0cTVM\u53ef\u4ee5\u7528\u6765\u4f7f\u5f97\u5b9e\u73b0XLA\u9700\u8981\u7684\u529f\u80fd\u66f4\u52a0\u5bb9\u6613 \u201d\u3002 \u65e2\u7136TVM\u7684\u4f5c\u8005\u70b9\u4e86\u5bf9\u624b\u7684\u540d\uff0c\u6211\u4eec\u5c31\u6765\u770b\u770bGoogle\u7684XLA\u5427\u3002 XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that optimizes TensorFlow computations. The results are improvements in speed, memory usage, and portability on server and mobile platforms. Initially, most users will not see large benefits from XLA, but are welcome to experiment by using XLA via just-in-time (JIT) compilation or ahead-of-time (AOT) compilation. Developers targeting new hardware accelerators are especially encouraged to try out XLA. \u4e0b\u56fe\u5de6\u534a\u90e8\u5206\u6765\u81ea\u201c2017 EuroLLVM Deveopers\u2019 Meeting\u201d\u4e0a\u7684\u4e00\u4e2a\u62a5\u544a[6]\uff0c\u6bd4\u8f83\u6e05\u695a\u4ecb\u7ecd\u4e86XLA\u7684\u76ee\u6807\uff0c\u5176\u57fa\u672c\u529f\u80fd\u4e5f\u662f\u4f18\u5316\u548c\u4ee3\u7801\u751f\u6210\u3002 XLA\u5177\u4f53\u7684\u67b6\u6784\u5982\u56fe\u53f3\u534a\u90e8\u5206\u6240\u793a\uff0c\u53ef\u4ee5\u770b\u51fa\uff0c\u5b83\u4e5f\u662f**\u4e24\u5c42\u4f18\u5316**\u7684\u7ed3\u6784[5]\uff0c\u4f7f\u7528LLVM\u7528\u4f5clow-level IR, optimization, and code-generation\u3002\u7531\u4e8e\u4f7f\u7528\u4e86LLVM IR, \u4ed6\u53ef\u4ee5\u6bd4\u8f83\u5bb9\u6613\u7684\u652f\u6301\u4e0d\u540c\u7684\u540e\u7aef\uff08Backend\uff09\u3002\u4e0b\u56fe\u5c31\u662f\u4f7f\u7528GPU Backend\u7684\u4f8b\u5b50\u3002 \u5bf9\u4e8e\u76ee\u524d\u4e0d\u76f4\u63a5\u652f\u6301\u7684\u540e\u7aef\uff0cXLA\u7ed9\u51fa\u4e86\u4e09\u79cd\u573a\u666f\u7684\u5f00\u53d1\u65b9\u6cd5\u3002\u5305\u62ec\uff1a \\1. Existing CPU architecture not yet officially supported by XLA, with or without an existing LLVM backend. \\2. Non-CPU-like hardware with an existing LLVM backend. \\3. Non-CPU-like hardware without an existing LLVM backend. \u603b\u7684\u6765\u8bf4\uff0cXLA\u548cTVM\u8bd5\u56fe\u89e3\u51b3\u7684\u95ee\u9898\u7c7b\u4f3c\u3002\u4f46XLA\u53ea\u662f\u9488\u5bf9Google\u7684Tensorflow\u7684\u3002\u800cTVM/NNVM\u867d\u7136\u662fMxNe\u9635\u8425\uff0c\u4f46\u8bd5\u56fe\u4f5c\u4e3a\u4e00\u4e2a\u5f00\u53d1\u548c\u516c\u5171\u7684\u63a5\u53e3\u3002 \u8fd9\u91cc\u63d2\u64ad\u4e00\u4e2a\u65b0\u95fb\uff0cChris Lattner\u6700\u8fd1\u52a0\u5165\u4e86Google Brain\u3002\u867d\u7136\u8fd8\u4e0d\u77e5\u9053\u4ed6\u7684\u4e3b\u8981\u5de5\u4f5c\u662f\u4e0d\u662f\u4f1a\u653e\u5728XLA\u8fd9\u91cc\uff0c\u4f46\u662f\u4ed6\u548cJeff Dean\u914d\u5408\uff0c\u786e\u5b9e\u662f\u4ee4\u4eba\u751f\u754f\u3002 \u5176\u5b9e\uff0c\u7c7b\u4f3c\u7684\u60f3\u6cd5\u8fd8\u5305\u62ec\uff1aIntel\u2019s NGraph\uff08\u5982\u4e0b\u56fe\uff09\uff0cHP\u7684Cognitive Computing Toolkit (CCT)\uff0c IBM\u7684SystemML\u3002 \u800c\u5728\u521a\u521a\u7ed3\u675f\u7684Hot Chips\u4f1a\u8bae\u4e0a\uff0cMicrosoft\u53d1\u5e03\u4e86Project Brainwave\uff0cCloud\u7684AI FPGA\u52a0\u901f\u5e73\u53f0\u3002\u5b83\u7684\u5de5\u5177\u94fe\u662f\u8fd9\u6837\u7684\uff0c\u662f\u4e0d\u662f\u53c8\u770b\u5230\u4e86\u4e24\u5c42IR\uff1f \u6700\u540e\uff0c\u6700\u8fd1\u8fd8\u770b\u5230\u53e6\u4e00\u4e2a\u6709\u8da3\u7684\u5c1d\u8bd5\uff1aKhronos Neural Network Exchange Format (NNEF)\uff0c\u8bd5\u56fe\u5b9a\u4e49\u4e00\u79cd\u6807\u51c6\u7684\u6570\u636e\u4ea4\u6362\u683c\u5f0f\u3002\u201cThe NNEF standard encapsulates neural network structure, data formats, commonly used operations (such as convolution, pooling, normalization, etc.) and formal network semantics. \u201d T.S.\uff1a \u968f\u7740Deep Learning\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\uff0c\u5927\u5bb6\u8d8a\u6765\u8d8a\u5173\u5fc3DNN(deep nerual network)\u5728\u4e0d\u540c\u786c\u4ef6\u67b6\u6784\u4e0aTraining\u548cInference\u7684\u5b9e\u73b0\u6548\u7387\u3002\u53c2\u8003\u4f20\u7edf\u7f16\u8bd1\u5668\uff08compiler\uff09\u8bbe\u8ba1\u7684\u7ecf\u9a8c\uff0cXLA\u548cTVM/NNVM\u90fd\u5f00\u59cb\u4e86\u5f88\u597d\u7684\u5c1d\u8bd5\u3002\u800c\u201cIR\u201d\u7684\u7ade\u4e89\uff0c\u5c06\u662f\u672a\u6765Framework\u4e4b\u4e89\u7684\u91cd\u8981\u4e00\u73af\u3002 Reference\uff1a [1]\u9648\u5929\u5947, \"Build your own TensorFlow with NNVM and Torch\", http://tqchen.github.io/2016/10/01/build-your-own-tensorflow-with-nnvm-and-torch.html [2]\u9648\u5929\u5947, \"TVM: An End to End IR Stack for Deploying the Deep Learning Workloads to Hardwares\", http://tvmlang.org/2017/08/17/tvm-release-announcement.html [3]\u9648\u5929\u5947, \"\u5982\u4f55\u8bc4\u4ef7\u9648\u5929\u5947\u56e2\u961f\u65b0\u5f00\u6e90\u7684TVM\uff1f\", https://www.zhihu.com/question/64091792/answer/217722459 [4] \u738b\u5065\u98de\uff0c\u201c\u5982\u4f55\u8bc4\u4ef7\u9648\u5929\u5947\u7684\u6a21\u5757\u5316\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edfNNVM\uff1f\u201d\uff0c https://www.zhihu.com/question/51216952/answer/124708405 [5]\"XLA Overview\", https://www.tensorflow.org/performance/xla/ [6]\"2017 EuroLLVM Developers\u2019 Meeting: D. Majnemer \u201cXLA: Accelerated Linear Algebra\u201d\", https://www.youtube.com/watch?v=2IOPpyyuLkc [7]\"A Brief Introduction to LLVM\", https://www.youtube.com/watch?v=a5-WaD8VV38 \" [8]\"XLA: TensorFlow Compiled!\", https://www.youtube.com/watch?v=kAOanJczHA0","title":"\u65b0\u667a\u5143 \u6df1\u5ea6\u5b66\u4e60\u7684IR\u201c\u4e4b\u4e89\u201d"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/","text":"\u524d\u8a00 model \u76ee\u524d\u5df2\u7ecf\u4f7f\u7528\u4e86\u4e09\u79cdmodel\uff1a MLP CNN RNN \u6bcf\u79cdmodel\u90fd\u8868\u793a\u4e00\u79cdcomputation\uff08\u8fd9\u662fmodel\u7684\u672c\u8d28\uff09\uff0c\u5728\u8bba\u6587\u4e2d\uff0c\u4e5f\u662f\u901a\u8fc7computation\uff08\u5404\u79cd\u5404\u6837\u7684\u516c\u5f0f\uff09\u6765\u63cf\u8ff0\u4e00\u4e2a\u6a21\u578b\u7684\uff1b\u800c\u5728\u5404\u79cdblog\u548ctutorial\u4e2d\uff0c\u5f80\u5f80\u559c\u6b22\u4f7f\u7528model\u7684topology\u6765\u4ecb\u7ecd\u5b83\uff1b\u663e\u7136model\u7684topology\u53ef\u4ee5\u770b\u505a\u662f\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u8868\u793a\uff0c\u5b83\u4eec\u80fd\u591f\u5e2e\u52a9\u5b66\u4e60\u8005\u66f4\u5feb\u5730\u5b66\u4e60model\uff0c\u5e2e\u52a9\u5b66\u4e60\u8005\u7406\u89e3model\u7684computation\uff1b \u5728deep learning book\u76846.5.1 Computational Graphs\u4e2d\u4ecb\u7ecd\uff0c\u6211\u4eec\u53ef\u4ee5computationaln graph\u6765formalizing computation as graph\u3002\u5728TensorFlow\u7684low API\u4e2d\u6307\u51fa\uff1aTensorFlow\u4e5f\u662f\u4f7f\u7528 computational graph \u6765\u5b9e\u73b0\u5e95\u5c42\u8ba1\u7b97\u7684\u63cf\u8ff0\u7684\uff08 A TensorFlow computation, represented as a dataflow graph. tensorflow\u4e2d\u662f\u4f7f\u7528\u7684dataflow graph\u6765\u8868\u793acomputation\u7684\uff09 \u8981\u60f3\u5b8c\u6574\u5730\u638c\u63e1\u4e00\u4e2a\u6a21\u578b\uff0c\u9700\u8981\u4ececomputation\uff0cmodel topology\uff0ccomputation graph\u8fd9\u4e09\u4e2a\u65b9\u9762\u5165\u624b\uff1b\u5176\u5b9ecomputation\u624d\u662f\u672c\u8d28\u6240\u5728\uff0cmodel topology\uff0ccomputation graph\u90fd\u662f\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u5c55\u793a\uff1b\u9664\u6b64\u4e4b\u5916\uff0c\u76ee\u524d\u5927\u591a\u6570deep learning framework\u7684\u5b9e\u73b0\u90fd\u662f\u91c7\u7528\u7684\u57fa\u4e8etensor\u7684\u6570\u636e\u8868\u793a\u3001\u57fa\u4e8etensor\u7684computation\uff0c\u4ece\u6574\u4f53\u6765\u770b\u8fd9\u4e2amodel\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u51fd\u6570 f(input_tensor)= outout_tensor \uff0c input_tensor \u6d41\u7ecfmodel\u5f97\u5230 output_tensor \uff0c\u6240\u4ee5\u638c\u63e1tensor\u5728model\u4e2d\u7684\u6d41\u52a8\u8fc7\u7a0b\uff08\u6d41\u52a8\u8fc7\u7a0b\u4e2dtensor\u7684shape\u7684\u53d8\u5316\u7b49\uff09\u4e5f\u662f\u638c\u63e1model\u7684computation\u7684\u4e00\u4e2a\u6377\u5f84\uff1b\u66f4\u52a0\u51c6\u786e\u5730\u8bf4\u4ed6\u4eec\u662f\u4f7f\u7528 dataflow graph \u6765\u8868\u793acomputation\uff0c\u6bd4\u5982tensorflow\uff1b \u5728\u6a21\u578b\u8bbe\u8ba1\u4e2d\u6240\u8bbe\u8ba1\u5730\u5404\u79cd\u601d\u60f3\uff0c\u5982parameter sharing\u7b49\uff0c\u90fd\u662f\u6709\u5bf9\u5e94\u7684computation\u7684\uff1b Neural Networks, Manifolds, and Topology layer \u6309\u7167\u76ee\u524d\u7684\u5927\u591a\u6570\u6df1\u5ea6\u5b66\u4e60\u5e93\uff0c\u5982tensorflow\uff0cKeras\uff0c\u90fd\u662f\u5c06model\u62bd\u8c61\u6210\u7531\u591a\u4e2alayer\u53e0\u52a0\u800c\u6210\u7684\uff0c\u6240\u4ee5\u5728\u8fdb\u884c\u5b9e\u73b0\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u662f\u5148\u4ece\u5b9e\u73b0\u5c42\u5165\u624b\uff1b\u5e76\u4e14\u5f88\u591a\u7684\u8bba\u6587\u4e2d\u4e5f\u662f\u8fd9\u6837\u63cf\u8ff0\u7684\uff1b\u4ecedeep learning book\u7684chapter 6\u4e2d\uff0c\u4e5f\u5c06\u8fd9\u4e2amodel\u63cf\u8ff0\u4e3a\u4e00\u4e2a\u590d\u5408\u51fd\u6570\uff0c\u590d\u5408\u51fd\u6570\u4e2d\u7684\u6bcf\u4e00\u4e2a\u90fd\u5bf9\u5e94\u4e86\u4e00\u5c42\uff1b computational graph \u5176\u5b9ecomputation graph\u5e76\u6ca1\u6709\u4e25\u683c\u7684\u5b9a\u4e49\uff0c\u5728deep learning book\u4e2d\u7684computation graph\u5c31\u548cTensorFlow\u7684computation graph\u662f\u5b9a\u4e49\u5c31\u662f\u4e0d\u540c\u7684\uff1b deep learning book\u4e2d\u7684computation graph\u4fa7\u91cd\u70b9\u5728\u4e8e\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u5c55\u793a\uff0c\u5b83\u7684\u89c4\u5219\u5982\u4e0b\uff1a - node in the graph to indicate a variable TensorFlow\u7684 computational graph \u7684\u5b9a\u4e49\u5982\u4e0b\uff1a tf.Operation (or \"ops\"): The nodes of the graph. Operations describe calculations that consume and produce tensors. tf.Tensor : The edges in the graph. These represent the values that will flow through the graph. Most TensorFlow functions return tf.Tensors . \u663e\u7136\uff0cTensorFlow\u4e2d\u7684\u5b9a\u4e49\u548cdeep learning book\u4e2d\u7684\u5b9a\u4e49\u662f\u4e0d\u540c\u7684\uff0c\u76f4\u89c2\u662f\u89c9\u5f97TensorFlow\u4e2d computational graph \u7684\u5b9a\u4e49\u662f\u6bd4\u8f83\u9002\u5408\u4e8e\u7f16\u7801\u5b9e\u73b0\u7684\uff0c\u800cdeep learning book\u4e2d\u7684\u5b9a\u4e49\u662f\u4fbf\u4e8e\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u5c55\u793a\uff08\u5f53\u7136TensorFlow\u7684computational graph\u4e5f\u80fd\u591f\u8fbe\u5230\u8fd9\u4e2a\u76ee\u7684\uff09\uff1b \u5728\u4e0b\u9762\u7684\u63cf\u8ff0\u4e2d\uff0ccomputational graph\u7684\u63cf\u8ff0\u90fd\u662f\u6309\u7167TensorFlow\u4e2d\u7684\u5b9a\u4e49\uff1b Computational graph\u7684\u8865\u51fa\u5185\u5bb9\uff1a \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f - YE Y\u7684\u56de\u7b54 - \u77e5\u4e4e \uff1a Computational graph\u3002\u6700\u9ad8\u7968\u7b54\u6848\u548c @\u9f9a\u79b9pangolulu \u7684\u7b54\u6848\u4e2d\u90fd\u6709\u63d0\u5230\uff0c\u5c31\u4e0d\u8d58\u8ff0\uff0c\u5176\u5b9e\u5c31\u662f\u8ba1\u7b97\u4ee3\u6570\u4e2d\u7684\u4e00\u4e2a\u6700\u57fa\u7840\u529e\u6cd5\uff0c\u4ece\u8ba1\u7b97\u673a\u7684\u89d2\u5ea6\u6765\u770b\u8fd8\u6709\u70b9\u52a8\u6001\u89c4\u5212\u7684\u610f\u601d\u3002\u5176\u4f18\u70b9\u662f\u8868\u8fbe\u5f0f\u7ed9\u5b9a\u7684\u60c5\u51b5\u4e0b\u5bf9\u590d\u5408\u51fd\u6570\u4e2d\u6240\u6709\u53d8\u91cf\u8fdb\u884c\u5feb\u901f\u6c42\u5bfc\uff0c\u8fd9\u6b63\u597d\u662f\u795e\u7ecf\u7f51\u7edc\u5c24\u5176\u662f\u6df1\u5ea6\u5b66\u4e60\u7684\u573a\u666f\u3002\u73b0\u5728\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u91cc\u7684\u6c42\u5bfc\u4e5f\u90fd\u662f\u57fa\u4e8eComputational Graph\uff0c\u6bd4\u5982theano\uff0ctorch\u548ctensorflow\uff0cCaffe\u4e5f\u53ef\u4ee5\u770b\u505a\u662fcomputaiona graph\uff0c\u53ea\u4e0d\u8fc7node\u662flayer\u3002 \u7ed3\u6784\u5316\u601d\u7ef4\uff1a \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f - Anonymous\u7684\u56de\u7b54 - \u77e5\u4e4e https://www.zhihu.com/question/27239198/answer/89853077 \uff1a\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u591a\u5c42\u590d\u5408\u51fd\u6570 \u6570\u5b66\u662f\u4e00\u95e8\u7b80\u6d01\u4f46\u662f\u542b\u4e49\u4e30\u5bcc\u7684\u539f\u56e0\uff0c\u7b80\u5355\u7684\u516c\u5f0f\uff0c\u4f46\u662f\u80fd\u591f\u8868\u8fbe\u5f3a\u5927\u7684\u7ed3\u6784 MLP MLP\u7684model topology\uff1a full connected\uff08\u8f93\u5165\u5c42\u4e0e\u9690\u85cf\u5c42\u4e4b\u95f4\uff0c\u9690\u85cf\u5c42\u4e0e\u9690\u85cf\u5c42\u4e4b\u95f4\uff0c\u9690\u85cf\u5c42\u4e0e\u8f93\u51fa\u5c42\u4e4b\u95f4\uff0c\u90fd\u662f\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u8fde\u63a5\u7684\uff09 MLP\u7684computation\uff1a matrix multiplication \u4e0b\u9762\u7684\u4ee3\u7801\u662f\u6458\u81ea Getting started with the Keras Sequential model \u7684Multilayer Perceptron (MLP) for multi-class softmax classification: import keras from keras.models import Sequential from keras.layers import Dense , Dropout , Activation from keras.optimizers import SGD # Generate dummy data import numpy as np x_train = np . random . random (( 1000 , 20 )) y_train = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 1000 , 1 )), num_classes = 10 ) x_test = np . random . random (( 100 , 20 )) y_test = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 100 , 1 )), num_classes = 10 ) model = Sequential () # Dense(64) is a fully-connected layer with 64 hidden units. # in the first layer, you must specify the expected input data shape: # here, 20-dimensional vectors. model . add ( Dense ( 64 , activation = 'relu' , input_dim = 20 )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 64 , activation = 'relu' )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 10 , activation = 'softmax' )) sgd = SGD ( lr = 0.01 , decay = 1e-6 , momentum = 0.9 , nesterov = True ) model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'accuracy' ]) model . fit ( x_train , y_train , epochs = 20 , batch_size = 128 ) score = model . evaluate ( x_test , y_test , batch_size = 128 ) \u601d\u8003\uff1a\u4e0a\u8ff0\u4ee3\u7801\u6240\u6784\u5efa\u7684\u6a21\u578b\u7684\u6743\u91cd\u77e9\u9635\u662f\u4ec0\u4e48\uff1f \u7b54\uff1a\u4e00\u822c**\u8f93\u5165\u77e9\u9635**\u7684shape\u662f [batch_size, feature_num] \uff0c\u5219\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f [feature_num, hidden_layer_node_num_1] \uff0c\u5373\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\u548c batch_size \u65e0\u5173\u7684\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u7279\u6027\uff1a\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u5728\u4e0d\u77e5\u9053 batch_size \u7684\u60c5\u51b5\u4e0b\u5c31\u53ef\u4ee5\u6784\u5efa\u6a21\u578b\u4e86\uff0c\u65e0\u8bba\u5bf9\u4e8e\u4ec0\u4e48\u6a21\u578b\uff0c\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684**\u8282\u70b9\u6570**\u548c**\u7279\u5f81\u7684\u4e2a\u6570**\u3001 batch_size \u90fd\u662f\u6ca1\u6709\u5173\u8054\u7684\uff08\u5f53\u6d89\u53caLSTM\u7684\u65f6\u5019\uff0cLSTM\u4e2d\u6bcf\u4e00\u5c42\u7684neuron\u7684\u4e2a\u6570\u548c time_step \u4e5f\u662f\u6ca1\u6709\u5173\u8054\u7684\uff09\uff0c**\u7279\u5f81\u7684\u4e2a\u6570**\u4f1a\u5f71\u54cdneuron\u4e2d\u7684\u53c2\u6570\u4e2a\u6570\u6709\u5173\uff1b \u7531\u4e8eMLP\u8981\u6c42full connected\uff0c\u4f7f\u7528**\u77e9\u9635\u4e58\u6cd5**\u662f\u80fd\u591f\u975e\u5e38\u597d\u5730\u5b9e\u73b0\u8fd9\u79cd\u9700\u6c42\u7684\uff0c\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b\uff1a [ [1,1,1], [1,1,1], [1,1,1], [1,1,1], [1,1,1], ] 4*3 \u7b2c\u4e00\u9690\u85cf\u5c42\u670910\u4e2anode\uff0c\u5219\u5b83\u7684\u6743\u91cd\u77e9\u9635\u662f[3 * 10] [ [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], ] \u6bcf\u4e00\u5217\u8868\u793a\u7684\u662f \u7b2c\u4e8c\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\uff1a [hidden_layer_node_num_1, hidden_layer_node_num_2] \uff0c\u4f9d\u6b21\u7c7b\u63a8\uff0c\u6240\u4ee5\u6700\u7ec8\u6700\u540e\u4e00\u5c42\u5373\u8f93\u51fa\u5c42\u7684\u4e0e\u524d\u4e00\u5c42\u4e4b\u95f4\u7684\u6743\u91cd\u77e9\u9635 [hidden_layer_node_num_-1, n_class] \uff08 -1 \u8868\u793a\u6700\u540e\u4e00\u5c42\uff09\u3002 \u6240\u4ee5\uff0c\u4e00\u4e2abatch_size\u7684\u6570\u636e\u6d41\u7ecfMLP\u4e4b\u540e\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u6570\u636e\u7684shape\u662f [batch_size, n_classes] \u3002 \u5176\u5b9e\u4ece\u8fd9\u4e2a\u6570\u5b66\u5173\u7cfb\u4e5f\u53ef\u4ee5\u770b\u51fa\u4e3a\u4ec0\u4e48\u8981\u5c06label\u4ee5one-hot\u7684\u65b9\u5f0f\u8868\u793a\u4e86\uff1b \u4e0b\u9762\u7684\u4ee3\u7801\u662fTensorFlow\u4e2d\u6784\u5efaMLP\u7684\u4e00\u4e2ademo\uff1a with tf . name_scope ( 'input' ): self . x_in = tf . placeholder ( tf . float32 , [ None , self . feature_num ], name = 'x_in' ) # self.y_in = tf.placeholder(tf.float32, [None, self.time_step, self.n_classes], name='y_in') # \u6bcf\u4e2asequence\u90fd\u53d6\u6700\u540e\u4e00\u6761\u8bb0\u5f55\u7684target\u6765\u4f5c\u4e3a\u8fd9\u4e2asequence\u7684target self . y_in = tf . placeholder ( tf . float32 , [ None , self . n_classes ], name = 'y_in' ) self . keep_prob = tf . placeholder ( tf . float32 , name = 'dropout_in' ) with tf . name_scope ( 'layer1' ): w_in = self . __weight_variable__ ([ self . feature_num , self . num_lstm_units ]) b_in = self . __bias_variable__ ([ self . num_lstm_units ]) lstm_input_layer = tf . reshape ( self . x_in , [ - 1 , self . feature_num ]) # input layer lstm_input_layer = tf . nn . relu ( tf . matmul ( lstm_input_layer , w_in ) + b_in ) \u4e00\u822c\uff0c\u6211\u4eec\u5728\u9605\u8bfb\u4e66\u7c4d\u7684\u65f6\u5019\uff0c\u4e66\u4e2d\u6240\u63cf\u8ff0\u7684\u6d41\u7a0b\u90fd\u662f\u4e00\u6b21\u8f93\u5165\u4e00\u6761\u8bb0\u5f55\uff0c\u8fd9\u79cd\u505a\u6cd5\u662f\u7406\u8bba\u4e0a\u7684\uff0c\u5b9e\u9645\u4e0a\u5982\u679c\u771f\u6ef4\u4e00\u6b21\u4ec5\u4ec5\u5582\u5165\u4e00\u6761\u6570\u636e\u7684\u8bdd\uff0c\u4f1a\u975e\u5e38\u7f13\u6162\uff1b\u5b9e\u9645\u7684\u5b9e\u73b0\u662f\u4e00\u6b21\u5582\u5165\u4e00\u4e2abatch\u7684\uff0c\u5373\u662f\u4e0a\u9762\u6240\u63cf\u8ff0\u7684**\u8f93\u5165\u77e9\u9635**\uff0c\u73b0\u4ee3\u7684GPU\u5904\u7406\u77e9\u9635\u8fd0\u7b97\u7684\u901f\u5ea6\u975e\u5e38\u5feb\uff1b\u5176\u5b9e\u4e00\u6b21\u5582\u5165\u4e00\u6761\u8bb0\u5f55\u4e5f\u53ef\u4ee5\u5957\u7528\u4e0a\u9762\u7684\u77e9\u9635\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u5373 batch_size=1 \uff1b \u4eceTensorFlow\u7684\u4ee3\u7801\u53ef\u4ee5\u770b\u51fa\uff0c\u8f93\u5165\u77e9\u9635\u548c\u7b2c\u4e00\u5c42\u7684\u6743\u91cd\u77e9\u9635\u6267\u884c\u77e9\u9635\u4e58\u6cd5\uff0c\u6839\u636e\u77e9\u9635**\u4e58\u6cd5\u539f\u7406**\u53ef\u4ee5\u77e5\u9053\u6bcf\u4e00\u6761\u6570\u636e\u4f1a\u6d41\u5165\u5230\u7b2c\u4e00\u9690\u85cf\u5c42\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8282\u70b9\uff0c\u4e00\u6761\u8bb0\u5f55\u6d41\u5165\u4e00\u4e2a\u8282\u70b9\u4ea7\u751f\u7684\u8f93\u51fa\u5176\u5b9e\u662f\u4e00\u4e2a\u6807\u91cf\uff1b\u5176\u5b9e\u8fd9\u4e5f\u662ffull connected\u7684\u542b\u4e49\u6240\u5728\uff1b CNN \u5173\u4e8eCNN\u7684computation\u548cmodel topology\u53c2\u8003\u4e0b\u9762\u4e24\u7bc7\u6587\u7ae0\uff0c\u5176\u4e2d\u7ed9\u51fa\u4e86\u975e\u5e38\u597d\u7684\u89e3\u91ca\uff1a Convolutional Neural Networks (CNNs / ConvNets) A Beginner's Guide To Understanding Convolutional Neural Networks \u5168\u8fde\u63a5\u5bf9\u5e94\u7684\u662f\u77e9\u9635\u4e58\u6cd5\uff0cCNN\u4e2d\u7684filter\u5219\u5bf9\u5e94\u7684\u5377\u79ef\u8fd0\u7b97\uff0c\u5377\u79ef\u5c42\u4e2d\u7684\u795e\u7ecf\u5143\u53ea\u4f1a\u548cinput\u7684\u4e00\u90e8\u5206\u8fdb\u884c\u8fde\u63a5\uff0c\u800c\u4e0d\u662f\u5168\u8fde\u63a5\uff1b RNN LSTM Understanding LSTM Networks Bi-RNN encoder-decoder/seq2seq encoder-align model-decoder paper Neural Machine Translation by Jointly Learning to Align and Translate \u5c31\u662f\u91c7\u7528\u7684\u8fd9\u79cd\u67b6\u6784\uff0c\u5b83\u7684model topology\u5728blog Attention mechanism \u8fd9\u7ed9\u51fa\u4e86\uff0c\u4e24\u8005\u7ed3\u5408\u8d77\u6765\u80fd\u591f\u66f4\u52a0\u6df1\u523b\u7406\u89e3\u5b83\u7684\u672c\u8d28\uff1b \u601d\u8003 model\u662f\u5426\u662f\u4e00\u79cdcomputational graph\uff0c\u5373\u5b83\u662f\u5bf9\u6570\u5b66\u516c\u5f0f\u7684\u4e00\u79cd\u5c55\u793a\u3002 model\u662f\u4e00\u79cd\u66f4\u9ad8\u5c42\u6b21\u7684\u62bd\u8c61\uff0cmodel\u662f\u5efa\u7acb\u5728computational graph\u4e4b\u4e0a\u7684\uff0c\u5373model\u662f\u57fa\u4e8ecomputational graph\u800c\u6784\u5efa\u7684\uff1b \u5728\u5404\u79cd\u5b9e\u73b0\uff0c\u6bd4\u5982tensorflow\u3001torch\u90fd\u662f\u91c7\u7528\u7684\u8fd9\u79cd\u7b56\u7565\uff0c\u5373\u5b83\u4eec\u6240\u63d0\u4f9b \u7684\u5404\u79cdmodel\u662f\u57fa\u4e8e\u5b83\u4eec\u7684computational graph\u800c\u5b9e\u73b0\u7684\u3002","title":"Introduction"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#_1","text":"","title":"\u524d\u8a00"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#model","text":"\u76ee\u524d\u5df2\u7ecf\u4f7f\u7528\u4e86\u4e09\u79cdmodel\uff1a MLP CNN RNN \u6bcf\u79cdmodel\u90fd\u8868\u793a\u4e00\u79cdcomputation\uff08\u8fd9\u662fmodel\u7684\u672c\u8d28\uff09\uff0c\u5728\u8bba\u6587\u4e2d\uff0c\u4e5f\u662f\u901a\u8fc7computation\uff08\u5404\u79cd\u5404\u6837\u7684\u516c\u5f0f\uff09\u6765\u63cf\u8ff0\u4e00\u4e2a\u6a21\u578b\u7684\uff1b\u800c\u5728\u5404\u79cdblog\u548ctutorial\u4e2d\uff0c\u5f80\u5f80\u559c\u6b22\u4f7f\u7528model\u7684topology\u6765\u4ecb\u7ecd\u5b83\uff1b\u663e\u7136model\u7684topology\u53ef\u4ee5\u770b\u505a\u662f\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u8868\u793a\uff0c\u5b83\u4eec\u80fd\u591f\u5e2e\u52a9\u5b66\u4e60\u8005\u66f4\u5feb\u5730\u5b66\u4e60model\uff0c\u5e2e\u52a9\u5b66\u4e60\u8005\u7406\u89e3model\u7684computation\uff1b \u5728deep learning book\u76846.5.1 Computational Graphs\u4e2d\u4ecb\u7ecd\uff0c\u6211\u4eec\u53ef\u4ee5computationaln graph\u6765formalizing computation as graph\u3002\u5728TensorFlow\u7684low API\u4e2d\u6307\u51fa\uff1aTensorFlow\u4e5f\u662f\u4f7f\u7528 computational graph \u6765\u5b9e\u73b0\u5e95\u5c42\u8ba1\u7b97\u7684\u63cf\u8ff0\u7684\uff08 A TensorFlow computation, represented as a dataflow graph. tensorflow\u4e2d\u662f\u4f7f\u7528\u7684dataflow graph\u6765\u8868\u793acomputation\u7684\uff09 \u8981\u60f3\u5b8c\u6574\u5730\u638c\u63e1\u4e00\u4e2a\u6a21\u578b\uff0c\u9700\u8981\u4ececomputation\uff0cmodel topology\uff0ccomputation graph\u8fd9\u4e09\u4e2a\u65b9\u9762\u5165\u624b\uff1b\u5176\u5b9ecomputation\u624d\u662f\u672c\u8d28\u6240\u5728\uff0cmodel topology\uff0ccomputation graph\u90fd\u662f\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u5c55\u793a\uff1b\u9664\u6b64\u4e4b\u5916\uff0c\u76ee\u524d\u5927\u591a\u6570deep learning framework\u7684\u5b9e\u73b0\u90fd\u662f\u91c7\u7528\u7684\u57fa\u4e8etensor\u7684\u6570\u636e\u8868\u793a\u3001\u57fa\u4e8etensor\u7684computation\uff0c\u4ece\u6574\u4f53\u6765\u770b\u8fd9\u4e2amodel\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u51fd\u6570 f(input_tensor)= outout_tensor \uff0c input_tensor \u6d41\u7ecfmodel\u5f97\u5230 output_tensor \uff0c\u6240\u4ee5\u638c\u63e1tensor\u5728model\u4e2d\u7684\u6d41\u52a8\u8fc7\u7a0b\uff08\u6d41\u52a8\u8fc7\u7a0b\u4e2dtensor\u7684shape\u7684\u53d8\u5316\u7b49\uff09\u4e5f\u662f\u638c\u63e1model\u7684computation\u7684\u4e00\u4e2a\u6377\u5f84\uff1b\u66f4\u52a0\u51c6\u786e\u5730\u8bf4\u4ed6\u4eec\u662f\u4f7f\u7528 dataflow graph \u6765\u8868\u793acomputation\uff0c\u6bd4\u5982tensorflow\uff1b \u5728\u6a21\u578b\u8bbe\u8ba1\u4e2d\u6240\u8bbe\u8ba1\u5730\u5404\u79cd\u601d\u60f3\uff0c\u5982parameter sharing\u7b49\uff0c\u90fd\u662f\u6709\u5bf9\u5e94\u7684computation\u7684\uff1b Neural Networks, Manifolds, and Topology","title":"model"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#layer","text":"\u6309\u7167\u76ee\u524d\u7684\u5927\u591a\u6570\u6df1\u5ea6\u5b66\u4e60\u5e93\uff0c\u5982tensorflow\uff0cKeras\uff0c\u90fd\u662f\u5c06model\u62bd\u8c61\u6210\u7531\u591a\u4e2alayer\u53e0\u52a0\u800c\u6210\u7684\uff0c\u6240\u4ee5\u5728\u8fdb\u884c\u5b9e\u73b0\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u662f\u5148\u4ece\u5b9e\u73b0\u5c42\u5165\u624b\uff1b\u5e76\u4e14\u5f88\u591a\u7684\u8bba\u6587\u4e2d\u4e5f\u662f\u8fd9\u6837\u63cf\u8ff0\u7684\uff1b\u4ecedeep learning book\u7684chapter 6\u4e2d\uff0c\u4e5f\u5c06\u8fd9\u4e2amodel\u63cf\u8ff0\u4e3a\u4e00\u4e2a\u590d\u5408\u51fd\u6570\uff0c\u590d\u5408\u51fd\u6570\u4e2d\u7684\u6bcf\u4e00\u4e2a\u90fd\u5bf9\u5e94\u4e86\u4e00\u5c42\uff1b","title":"layer"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#computational#graph","text":"\u5176\u5b9ecomputation graph\u5e76\u6ca1\u6709\u4e25\u683c\u7684\u5b9a\u4e49\uff0c\u5728deep learning book\u4e2d\u7684computation graph\u5c31\u548cTensorFlow\u7684computation graph\u662f\u5b9a\u4e49\u5c31\u662f\u4e0d\u540c\u7684\uff1b deep learning book\u4e2d\u7684computation graph\u4fa7\u91cd\u70b9\u5728\u4e8e\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u5c55\u793a\uff0c\u5b83\u7684\u89c4\u5219\u5982\u4e0b\uff1a - node in the graph to indicate a variable TensorFlow\u7684 computational graph \u7684\u5b9a\u4e49\u5982\u4e0b\uff1a tf.Operation (or \"ops\"): The nodes of the graph. Operations describe calculations that consume and produce tensors. tf.Tensor : The edges in the graph. These represent the values that will flow through the graph. Most TensorFlow functions return tf.Tensors . \u663e\u7136\uff0cTensorFlow\u4e2d\u7684\u5b9a\u4e49\u548cdeep learning book\u4e2d\u7684\u5b9a\u4e49\u662f\u4e0d\u540c\u7684\uff0c\u76f4\u89c2\u662f\u89c9\u5f97TensorFlow\u4e2d computational graph \u7684\u5b9a\u4e49\u662f\u6bd4\u8f83\u9002\u5408\u4e8e\u7f16\u7801\u5b9e\u73b0\u7684\uff0c\u800cdeep learning book\u4e2d\u7684\u5b9a\u4e49\u662f\u4fbf\u4e8e\u5bf9computation\u7684\u5f62\u5f0f\u5316\u5730\u5c55\u793a\uff08\u5f53\u7136TensorFlow\u7684computational graph\u4e5f\u80fd\u591f\u8fbe\u5230\u8fd9\u4e2a\u76ee\u7684\uff09\uff1b \u5728\u4e0b\u9762\u7684\u63cf\u8ff0\u4e2d\uff0ccomputational graph\u7684\u63cf\u8ff0\u90fd\u662f\u6309\u7167TensorFlow\u4e2d\u7684\u5b9a\u4e49\uff1b Computational graph\u7684\u8865\u51fa\u5185\u5bb9\uff1a \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f - YE Y\u7684\u56de\u7b54 - \u77e5\u4e4e \uff1a Computational graph\u3002\u6700\u9ad8\u7968\u7b54\u6848\u548c @\u9f9a\u79b9pangolulu \u7684\u7b54\u6848\u4e2d\u90fd\u6709\u63d0\u5230\uff0c\u5c31\u4e0d\u8d58\u8ff0\uff0c\u5176\u5b9e\u5c31\u662f\u8ba1\u7b97\u4ee3\u6570\u4e2d\u7684\u4e00\u4e2a\u6700\u57fa\u7840\u529e\u6cd5\uff0c\u4ece\u8ba1\u7b97\u673a\u7684\u89d2\u5ea6\u6765\u770b\u8fd8\u6709\u70b9\u52a8\u6001\u89c4\u5212\u7684\u610f\u601d\u3002\u5176\u4f18\u70b9\u662f\u8868\u8fbe\u5f0f\u7ed9\u5b9a\u7684\u60c5\u51b5\u4e0b\u5bf9\u590d\u5408\u51fd\u6570\u4e2d\u6240\u6709\u53d8\u91cf\u8fdb\u884c\u5feb\u901f\u6c42\u5bfc\uff0c\u8fd9\u6b63\u597d\u662f\u795e\u7ecf\u7f51\u7edc\u5c24\u5176\u662f\u6df1\u5ea6\u5b66\u4e60\u7684\u573a\u666f\u3002\u73b0\u5728\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u91cc\u7684\u6c42\u5bfc\u4e5f\u90fd\u662f\u57fa\u4e8eComputational Graph\uff0c\u6bd4\u5982theano\uff0ctorch\u548ctensorflow\uff0cCaffe\u4e5f\u53ef\u4ee5\u770b\u505a\u662fcomputaiona graph\uff0c\u53ea\u4e0d\u8fc7node\u662flayer\u3002 \u7ed3\u6784\u5316\u601d\u7ef4\uff1a \u5982\u4f55\u76f4\u89c2\u5730\u89e3\u91ca backpropagation \u7b97\u6cd5\uff1f - Anonymous\u7684\u56de\u7b54 - \u77e5\u4e4e https://www.zhihu.com/question/27239198/answer/89853077 \uff1a\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u591a\u5c42\u590d\u5408\u51fd\u6570 \u6570\u5b66\u662f\u4e00\u95e8\u7b80\u6d01\u4f46\u662f\u542b\u4e49\u4e30\u5bcc\u7684\u539f\u56e0\uff0c\u7b80\u5355\u7684\u516c\u5f0f\uff0c\u4f46\u662f\u80fd\u591f\u8868\u8fbe\u5f3a\u5927\u7684\u7ed3\u6784","title":"computational graph"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#mlp","text":"MLP\u7684model topology\uff1a full connected\uff08\u8f93\u5165\u5c42\u4e0e\u9690\u85cf\u5c42\u4e4b\u95f4\uff0c\u9690\u85cf\u5c42\u4e0e\u9690\u85cf\u5c42\u4e4b\u95f4\uff0c\u9690\u85cf\u5c42\u4e0e\u8f93\u51fa\u5c42\u4e4b\u95f4\uff0c\u90fd\u662f\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u8fde\u63a5\u7684\uff09 MLP\u7684computation\uff1a matrix multiplication \u4e0b\u9762\u7684\u4ee3\u7801\u662f\u6458\u81ea Getting started with the Keras Sequential model \u7684Multilayer Perceptron (MLP) for multi-class softmax classification: import keras from keras.models import Sequential from keras.layers import Dense , Dropout , Activation from keras.optimizers import SGD # Generate dummy data import numpy as np x_train = np . random . random (( 1000 , 20 )) y_train = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 1000 , 1 )), num_classes = 10 ) x_test = np . random . random (( 100 , 20 )) y_test = keras . utils . to_categorical ( np . random . randint ( 10 , size = ( 100 , 1 )), num_classes = 10 ) model = Sequential () # Dense(64) is a fully-connected layer with 64 hidden units. # in the first layer, you must specify the expected input data shape: # here, 20-dimensional vectors. model . add ( Dense ( 64 , activation = 'relu' , input_dim = 20 )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 64 , activation = 'relu' )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 10 , activation = 'softmax' )) sgd = SGD ( lr = 0.01 , decay = 1e-6 , momentum = 0.9 , nesterov = True ) model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'accuracy' ]) model . fit ( x_train , y_train , epochs = 20 , batch_size = 128 ) score = model . evaluate ( x_test , y_test , batch_size = 128 ) \u601d\u8003\uff1a\u4e0a\u8ff0\u4ee3\u7801\u6240\u6784\u5efa\u7684\u6a21\u578b\u7684\u6743\u91cd\u77e9\u9635\u662f\u4ec0\u4e48\uff1f \u7b54\uff1a\u4e00\u822c**\u8f93\u5165\u77e9\u9635**\u7684shape\u662f [batch_size, feature_num] \uff0c\u5219\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f [feature_num, hidden_layer_node_num_1] \uff0c\u5373\u7b2c\u4e00\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\u548c batch_size \u65e0\u5173\u7684\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u7279\u6027\uff1a\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u5728\u4e0d\u77e5\u9053 batch_size \u7684\u60c5\u51b5\u4e0b\u5c31\u53ef\u4ee5\u6784\u5efa\u6a21\u578b\u4e86\uff0c\u65e0\u8bba\u5bf9\u4e8e\u4ec0\u4e48\u6a21\u578b\uff0c\u6a21\u578b\u4e2d\u6bcf\u4e00\u5c42\u7684**\u8282\u70b9\u6570**\u548c**\u7279\u5f81\u7684\u4e2a\u6570**\u3001 batch_size \u90fd\u662f\u6ca1\u6709\u5173\u8054\u7684\uff08\u5f53\u6d89\u53caLSTM\u7684\u65f6\u5019\uff0cLSTM\u4e2d\u6bcf\u4e00\u5c42\u7684neuron\u7684\u4e2a\u6570\u548c time_step \u4e5f\u662f\u6ca1\u6709\u5173\u8054\u7684\uff09\uff0c**\u7279\u5f81\u7684\u4e2a\u6570**\u4f1a\u5f71\u54cdneuron\u4e2d\u7684\u53c2\u6570\u4e2a\u6570\u6709\u5173\uff1b \u7531\u4e8eMLP\u8981\u6c42full connected\uff0c\u4f7f\u7528**\u77e9\u9635\u4e58\u6cd5**\u662f\u80fd\u591f\u975e\u5e38\u597d\u5730\u5b9e\u73b0\u8fd9\u79cd\u9700\u6c42\u7684\uff0c\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b\uff1a [ [1,1,1], [1,1,1], [1,1,1], [1,1,1], [1,1,1], ] 4*3 \u7b2c\u4e00\u9690\u85cf\u5c42\u670910\u4e2anode\uff0c\u5219\u5b83\u7684\u6743\u91cd\u77e9\u9635\u662f[3 * 10] [ [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2], ] \u6bcf\u4e00\u5217\u8868\u793a\u7684\u662f \u7b2c\u4e8c\u9690\u85cf\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684shape\u662f\uff1a [hidden_layer_node_num_1, hidden_layer_node_num_2] \uff0c\u4f9d\u6b21\u7c7b\u63a8\uff0c\u6240\u4ee5\u6700\u7ec8\u6700\u540e\u4e00\u5c42\u5373\u8f93\u51fa\u5c42\u7684\u4e0e\u524d\u4e00\u5c42\u4e4b\u95f4\u7684\u6743\u91cd\u77e9\u9635 [hidden_layer_node_num_-1, n_class] \uff08 -1 \u8868\u793a\u6700\u540e\u4e00\u5c42\uff09\u3002 \u6240\u4ee5\uff0c\u4e00\u4e2abatch_size\u7684\u6570\u636e\u6d41\u7ecfMLP\u4e4b\u540e\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u6570\u636e\u7684shape\u662f [batch_size, n_classes] \u3002 \u5176\u5b9e\u4ece\u8fd9\u4e2a\u6570\u5b66\u5173\u7cfb\u4e5f\u53ef\u4ee5\u770b\u51fa\u4e3a\u4ec0\u4e48\u8981\u5c06label\u4ee5one-hot\u7684\u65b9\u5f0f\u8868\u793a\u4e86\uff1b \u4e0b\u9762\u7684\u4ee3\u7801\u662fTensorFlow\u4e2d\u6784\u5efaMLP\u7684\u4e00\u4e2ademo\uff1a with tf . name_scope ( 'input' ): self . x_in = tf . placeholder ( tf . float32 , [ None , self . feature_num ], name = 'x_in' ) # self.y_in = tf.placeholder(tf.float32, [None, self.time_step, self.n_classes], name='y_in') # \u6bcf\u4e2asequence\u90fd\u53d6\u6700\u540e\u4e00\u6761\u8bb0\u5f55\u7684target\u6765\u4f5c\u4e3a\u8fd9\u4e2asequence\u7684target self . y_in = tf . placeholder ( tf . float32 , [ None , self . n_classes ], name = 'y_in' ) self . keep_prob = tf . placeholder ( tf . float32 , name = 'dropout_in' ) with tf . name_scope ( 'layer1' ): w_in = self . __weight_variable__ ([ self . feature_num , self . num_lstm_units ]) b_in = self . __bias_variable__ ([ self . num_lstm_units ]) lstm_input_layer = tf . reshape ( self . x_in , [ - 1 , self . feature_num ]) # input layer lstm_input_layer = tf . nn . relu ( tf . matmul ( lstm_input_layer , w_in ) + b_in ) \u4e00\u822c\uff0c\u6211\u4eec\u5728\u9605\u8bfb\u4e66\u7c4d\u7684\u65f6\u5019\uff0c\u4e66\u4e2d\u6240\u63cf\u8ff0\u7684\u6d41\u7a0b\u90fd\u662f\u4e00\u6b21\u8f93\u5165\u4e00\u6761\u8bb0\u5f55\uff0c\u8fd9\u79cd\u505a\u6cd5\u662f\u7406\u8bba\u4e0a\u7684\uff0c\u5b9e\u9645\u4e0a\u5982\u679c\u771f\u6ef4\u4e00\u6b21\u4ec5\u4ec5\u5582\u5165\u4e00\u6761\u6570\u636e\u7684\u8bdd\uff0c\u4f1a\u975e\u5e38\u7f13\u6162\uff1b\u5b9e\u9645\u7684\u5b9e\u73b0\u662f\u4e00\u6b21\u5582\u5165\u4e00\u4e2abatch\u7684\uff0c\u5373\u662f\u4e0a\u9762\u6240\u63cf\u8ff0\u7684**\u8f93\u5165\u77e9\u9635**\uff0c\u73b0\u4ee3\u7684GPU\u5904\u7406\u77e9\u9635\u8fd0\u7b97\u7684\u901f\u5ea6\u975e\u5e38\u5feb\uff1b\u5176\u5b9e\u4e00\u6b21\u5582\u5165\u4e00\u6761\u8bb0\u5f55\u4e5f\u53ef\u4ee5\u5957\u7528\u4e0a\u9762\u7684\u77e9\u9635\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u5373 batch_size=1 \uff1b \u4eceTensorFlow\u7684\u4ee3\u7801\u53ef\u4ee5\u770b\u51fa\uff0c\u8f93\u5165\u77e9\u9635\u548c\u7b2c\u4e00\u5c42\u7684\u6743\u91cd\u77e9\u9635\u6267\u884c\u77e9\u9635\u4e58\u6cd5\uff0c\u6839\u636e\u77e9\u9635**\u4e58\u6cd5\u539f\u7406**\u53ef\u4ee5\u77e5\u9053\u6bcf\u4e00\u6761\u6570\u636e\u4f1a\u6d41\u5165\u5230\u7b2c\u4e00\u9690\u85cf\u5c42\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8282\u70b9\uff0c\u4e00\u6761\u8bb0\u5f55\u6d41\u5165\u4e00\u4e2a\u8282\u70b9\u4ea7\u751f\u7684\u8f93\u51fa\u5176\u5b9e\u662f\u4e00\u4e2a\u6807\u91cf\uff1b\u5176\u5b9e\u8fd9\u4e5f\u662ffull connected\u7684\u542b\u4e49\u6240\u5728\uff1b","title":"MLP"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#cnn","text":"\u5173\u4e8eCNN\u7684computation\u548cmodel topology\u53c2\u8003\u4e0b\u9762\u4e24\u7bc7\u6587\u7ae0\uff0c\u5176\u4e2d\u7ed9\u51fa\u4e86\u975e\u5e38\u597d\u7684\u89e3\u91ca\uff1a Convolutional Neural Networks (CNNs / ConvNets) A Beginner's Guide To Understanding Convolutional Neural Networks \u5168\u8fde\u63a5\u5bf9\u5e94\u7684\u662f\u77e9\u9635\u4e58\u6cd5\uff0cCNN\u4e2d\u7684filter\u5219\u5bf9\u5e94\u7684\u5377\u79ef\u8fd0\u7b97\uff0c\u5377\u79ef\u5c42\u4e2d\u7684\u795e\u7ecf\u5143\u53ea\u4f1a\u548cinput\u7684\u4e00\u90e8\u5206\u8fdb\u884c\u8fde\u63a5\uff0c\u800c\u4e0d\u662f\u5168\u8fde\u63a5\uff1b","title":"CNN"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#rnn","text":"","title":"RNN"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#lstm","text":"Understanding LSTM Networks","title":"LSTM"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#bi-rnn","text":"","title":"Bi-RNN"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#encoder-decoderseq2seq","text":"","title":"encoder-decoder/seq2seq"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#encoder-align#model-decoder","text":"paper Neural Machine Translation by Jointly Learning to Align and Translate \u5c31\u662f\u91c7\u7528\u7684\u8fd9\u79cd\u67b6\u6784\uff0c\u5b83\u7684model topology\u5728blog Attention mechanism \u8fd9\u7ed9\u51fa\u4e86\uff0c\u4e24\u8005\u7ed3\u5408\u8d77\u6765\u80fd\u591f\u66f4\u52a0\u6df1\u523b\u7406\u89e3\u5b83\u7684\u672c\u8d28\uff1b","title":"encoder-align model-decoder"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/#_2","text":"model\u662f\u5426\u662f\u4e00\u79cdcomputational graph\uff0c\u5373\u5b83\u662f\u5bf9\u6570\u5b66\u516c\u5f0f\u7684\u4e00\u79cd\u5c55\u793a\u3002 model\u662f\u4e00\u79cd\u66f4\u9ad8\u5c42\u6b21\u7684\u62bd\u8c61\uff0cmodel\u662f\u5efa\u7acb\u5728computational graph\u4e4b\u4e0a\u7684\uff0c\u5373model\u662f\u57fa\u4e8ecomputational graph\u800c\u6784\u5efa\u7684\uff1b \u5728\u5404\u79cd\u5b9e\u73b0\uff0c\u6bd4\u5982tensorflow\u3001torch\u90fd\u662f\u91c7\u7528\u7684\u8fd9\u79cd\u7b56\u7565\uff0c\u5373\u5b83\u4eec\u6240\u63d0\u4f9b \u7684\u5404\u79cdmodel\u662f\u57fa\u4e8e\u5b83\u4eec\u7684computational graph\u800c\u5b9e\u73b0\u7684\u3002","title":"\u601d\u8003"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/Computational-graph/","text":"Computational graph \u5728wikipedia Computer algebra \u201c Computer science aspects#Expressions \u201d\u6bb5\u4e2d\uff0c\u8ba9\u6211\u60f3\u8d77\u4e86\u5728compiler principle\u4e2d\u63cf\u8ff0\u7684\u5bf9expression\u7684\u8868\u793a\uff1asyntax tree\u3001grammar tree\uff0c\u663e\u7136computational graph\u4e5f\u662f\u4e00\u79cd\u8868\u8fbe\u65b9\u5f0f\uff1b\u663e\u7136\u5728\u8ba1\u7b97\u4ee3\u6570\u4e2d\uff0c\u975e\u5e38\u91cd\u8981\u7684\u4e00\u4e2a\u8bfe\u9898\u5c31\u662f\u5982\u4f55\u6765\u8868\u793acomputation\uff0c\u663e\u7136computational graph\u662f\u4e00\u79cd\u975e\u5e38\u5f3a\u5927\u7684\u5de5\u5177\uff1b\u5404\u79cd\u5404\u6837\u7684\u95ee\u9898\uff0c\u5982\u679c\u8981\u4f7f\u7528computer\u6765\u8fdb\u884c\u89e3\u51b3\uff0c\u90a3\u4e48\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u8bfe\u9898\u5c31\u662f\uff1a\u5982\u4f55\u6765\u8868\u793a\uff1f\u663e\u7136\u8fd9\u662f\u5404\u79cddata structure\u6392\u4e0a\u7528\u573a\u7684\u65f6\u5019\u4e86\u3002 symbolic computation: computational graph\u662f\u5c31\u662f\u4e00\u79cd\u5178\u578b\u7684symbolic computation\uff0c\u5b83\u57286.5.5 Symbol-to-Symbol Derivatives\u30016.5.4 Back-Propagation Computation in Fully-Connected MLP \u4e2d\u6709\u63cf\u8ff0 \u5173\u4e8ecomputational graph\uff0c\u53c2\u89c1\uff1a https://www.zhihu.com/question/27239198/answer/734273315 https://zhuanlan.zhihu.com/p/69175484 https://zhuanlan.zhihu.com/p/70075944 https://zhuanlan.zhihu.com/p/71869192","title":"Computational-graph"},{"location":"Theory/Deep-learning/Guide/Computation-And-model-And-computational-graph/Computational-graph/#computational#graph","text":"\u5728wikipedia Computer algebra \u201c Computer science aspects#Expressions \u201d\u6bb5\u4e2d\uff0c\u8ba9\u6211\u60f3\u8d77\u4e86\u5728compiler principle\u4e2d\u63cf\u8ff0\u7684\u5bf9expression\u7684\u8868\u793a\uff1asyntax tree\u3001grammar tree\uff0c\u663e\u7136computational graph\u4e5f\u662f\u4e00\u79cd\u8868\u8fbe\u65b9\u5f0f\uff1b\u663e\u7136\u5728\u8ba1\u7b97\u4ee3\u6570\u4e2d\uff0c\u975e\u5e38\u91cd\u8981\u7684\u4e00\u4e2a\u8bfe\u9898\u5c31\u662f\u5982\u4f55\u6765\u8868\u793acomputation\uff0c\u663e\u7136computational graph\u662f\u4e00\u79cd\u975e\u5e38\u5f3a\u5927\u7684\u5de5\u5177\uff1b\u5404\u79cd\u5404\u6837\u7684\u95ee\u9898\uff0c\u5982\u679c\u8981\u4f7f\u7528computer\u6765\u8fdb\u884c\u89e3\u51b3\uff0c\u90a3\u4e48\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u8bfe\u9898\u5c31\u662f\uff1a\u5982\u4f55\u6765\u8868\u793a\uff1f\u663e\u7136\u8fd9\u662f\u5404\u79cddata structure\u6392\u4e0a\u7528\u573a\u7684\u65f6\u5019\u4e86\u3002 symbolic computation: computational graph\u662f\u5c31\u662f\u4e00\u79cd\u5178\u578b\u7684symbolic computation\uff0c\u5b83\u57286.5.5 Symbol-to-Symbol Derivatives\u30016.5.4 Back-Propagation Computation in Fully-Connected MLP \u4e2d\u6709\u63cf\u8ff0 \u5173\u4e8ecomputational graph\uff0c\u53c2\u89c1\uff1a https://www.zhihu.com/question/27239198/answer/734273315 https://zhuanlan.zhihu.com/p/69175484 https://zhuanlan.zhihu.com/p/70075944 https://zhuanlan.zhihu.com/p/71869192","title":"Computational graph"},{"location":"Theory/Deep-learning/Guide/End-to-end/End-to-end/","text":"What does \u201cend to end\u201d mean in deep learning methods? I want to know what it is, and how it is any different from ensembling? Suppose, I want to achieve high accuracy in classification and segmentation, for a specific task, if I use different networks, such as CNN, RNN, etc to achieve this, is this called an end to end model? (architecture?) or not? A end-to-end = all parameters are trained jointly (vs. step-by-step ) ensembling = several classifiers are trained independently, each classifier makes a prediction, and all predictions are combined into one using some strategy (e.g., take the most common prediction across all classifiers). Limits of End-to-End Learning Abstract End-to-end learning refers to training a possibly complex learning system by applying gradient-based learning to the system as a whole. End-to-end learning systems are specifically designed so that all modules are differentiable\uff08\u53ef\u5fae\u7684\uff09. In effect, not only a central learning machine , but also all \u201cperipheral\u201d modules like representation learning and memory formation are covered by a holistic\uff08\u6574\u4f53\u7684\uff09 learning process. The power of end-to-end learning has been demonstrated on many tasks, like playing a whole array of Atari video games with a single architecture. While pushing for solutions to more challenging tasks, network architectures keep growing more and more complex. In this paper we ask the question whether and to what extent end-to-end learning is a future-proof technique in the sense of scaling to complex and diverse data processing architectures. We point out potential inefficiencies, and we argue in particular that end-to-end learning does not make optimal use of the modular design of present neural networks. Our surprisingly simple experiments demonstrate these inefficiencies, up to the complete breakdown of learning. Keywords: end-to-end machine learning Introduction We are today in the position to train rather deep and complex neural networks in an end-to-end (e2e) fashion, by gradient descent. In a nutshell, this amounts to\uff08\u76f8\u5f53\u4e8e\uff09 scaling up the good old backpropagation algorithm (see Schmidhuber, 2015 and references therein) to immensely rich and complex models. However, the end-to-end learning philosophy goes one step further: carefully ensuring that all modules of a learning systems are differentiable with respect to all adjustable parameters (weights) and training this system as a whole are lifted to the status of principles. This elegant although straightforward and somewhat brute-force technique has been popularized in the context of deep learning. It is a seemingly natural consequence of deep neural architectures blurring the classic boundaries between learning machine and other processing components by casting a possibly complex processing pipeline into the coherent and flexible modeling language of neural networks.1 The approach yields state-of-the-art results (Collobert et al., 2011; Krizhevsky et al., 2012; Mnih et al., 2015). Its appeal is a unified training scheme that makes most of the available information by taking labels (supervised learning) and rewards (reinforcement learning) into account, instead of relying only on the input distribution (unsupervised pre-training). Excellent recent examples of studies TO READ https://www.zhihu.com/question/51435499","title":"Introduction"},{"location":"Theory/Deep-learning/Guide/End-to-end/End-to-end/#what#does#end#to#end#mean#in#deep#learning#methods","text":"I want to know what it is, and how it is any different from ensembling? Suppose, I want to achieve high accuracy in classification and segmentation, for a specific task, if I use different networks, such as CNN, RNN, etc to achieve this, is this called an end to end model? (architecture?) or not?","title":"What does \u201cend to end\u201d mean in deep learning methods?"},{"location":"Theory/Deep-learning/Guide/End-to-end/End-to-end/#a","text":"end-to-end = all parameters are trained jointly (vs. step-by-step ) ensembling = several classifiers are trained independently, each classifier makes a prediction, and all predictions are combined into one using some strategy (e.g., take the most common prediction across all classifiers).","title":"A"},{"location":"Theory/Deep-learning/Guide/End-to-end/End-to-end/#limits#of#end-to-end#learning","text":"","title":"Limits of End-to-End Learning"},{"location":"Theory/Deep-learning/Guide/End-to-end/End-to-end/#abstract","text":"End-to-end learning refers to training a possibly complex learning system by applying gradient-based learning to the system as a whole. End-to-end learning systems are specifically designed so that all modules are differentiable\uff08\u53ef\u5fae\u7684\uff09. In effect, not only a central learning machine , but also all \u201cperipheral\u201d modules like representation learning and memory formation are covered by a holistic\uff08\u6574\u4f53\u7684\uff09 learning process. The power of end-to-end learning has been demonstrated on many tasks, like playing a whole array of Atari video games with a single architecture. While pushing for solutions to more challenging tasks, network architectures keep growing more and more complex. In this paper we ask the question whether and to what extent end-to-end learning is a future-proof technique in the sense of scaling to complex and diverse data processing architectures. We point out potential inefficiencies, and we argue in particular that end-to-end learning does not make optimal use of the modular design of present neural networks. Our surprisingly simple experiments demonstrate these inefficiencies, up to the complete breakdown of learning. Keywords: end-to-end machine learning","title":"Abstract"},{"location":"Theory/Deep-learning/Guide/End-to-end/End-to-end/#introduction","text":"We are today in the position to train rather deep and complex neural networks in an end-to-end (e2e) fashion, by gradient descent. In a nutshell, this amounts to\uff08\u76f8\u5f53\u4e8e\uff09 scaling up the good old backpropagation algorithm (see Schmidhuber, 2015 and references therein) to immensely rich and complex models. However, the end-to-end learning philosophy goes one step further: carefully ensuring that all modules of a learning systems are differentiable with respect to all adjustable parameters (weights) and training this system as a whole are lifted to the status of principles. This elegant although straightforward and somewhat brute-force technique has been popularized in the context of deep learning. It is a seemingly natural consequence of deep neural architectures blurring the classic boundaries between learning machine and other processing components by casting a possibly complex processing pipeline into the coherent and flexible modeling language of neural networks.1 The approach yields state-of-the-art results (Collobert et al., 2011; Krizhevsky et al., 2012; Mnih et al., 2015). Its appeal is a unified training scheme that makes most of the available information by taking labels (supervised learning) and rewards (reinforcement learning) into account, instead of relying only on the input distribution (unsupervised pre-training). Excellent recent examples of studies","title":"Introduction"},{"location":"Theory/Deep-learning/Guide/End-to-end/End-to-end/#to#read","text":"https://www.zhihu.com/question/51435499","title":"TO READ"},{"location":"Theory/Deep-learning/Guide/End-to-end/wikipedia-End-to-end-reinforcement-learning/","text":"End-to-end reinforcement learning End-to-end reinforcement learning","title":"End-to-end-reinforcement-learning"},{"location":"Theory/Deep-learning/Guide/End-to-end/wikipedia-End-to-end-reinforcement-learning/#end-to-end#reinforcement#learning","text":"","title":"End-to-end reinforcement learning"},{"location":"Theory/Deep-learning/Guide/Model-capacity/Model-capacity/","text":"Model capacity \u57285.2 Capacity, Overfitting and Underfitting\u4e2d\u4ecb\u7ecd\u4e86capacity\u7684\u6982\u5ff5\uff0c\u73b0\u5728\u5f00\u59cb\u4ecb\u7ecddeep learning model\u7684capacity\u3002 How to Control Neural Network Model Capacity With Nodes and Layers The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit , whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers . In this tutorial, you will discover how to control the capacity of a neural network model and how capacity impacts what a model is capable of learning. After completing this tutorial, you will know: Neural network model capacity is controlled both by the number of nodes and the number of layers in the model. A model with a single hidden layer and sufficient number of nodes has the capability of learning any mapping function, but the chosen learning algorithm may or may not be able to realize this capability. Increasing the number of layers provides a short-cut to increasing the capacity of the model with fewer resources, and modern techniques allow learning algorithms to successfully train deep models. Discover how to train faster, reduce overfitting, and make better predictions with deep learning models in my new book , with 26 step-by-step tutorials and full source code. Tutorial Overview his tutorial is divided into five parts; they are: Controlling Neural Network Model Capacity Configure Nodes and Layers in Keras Multi-Class Classification Problem Change Model Capacity With Nodes Change Model Capacity With Layers Controlling Neural Network Model Capacity The goal of a neural network is to learn how to map input examples to output examples. Neural networks learn mapping functions. The capacity of a network refers to the range or scope of the types of functions that the model can approximate. Informally, a model\u2019s capacity is its ability to fit a wide variety of functions. \u2014 Pages 111-112, Deep Learning , 2016. A model with less capacity may not be able to sufficiently learn the training dataset. A model with more capacity can model more different types of functions and may be able to learn a function to sufficiently map inputs to outputs in the training dataset. Whereas a model with too much capacity may memorize the training dataset and fail to generalize or get lost or stuck in the search for a suitable mapping function. Generally, we can think of model capacity as a control over whether the model is likely to underfit or overfit a training dataset. We can control whether a model is more likely to overfit or underfit by altering its capacity. \u2014 Pages 111, Deep Learning , 2016. The capacity of a neural network can be controlled by two aspects of the model: Number of Nodes. Number of Layers. A model with more nodes or more layers has a greater capacity and, in turn, is potentially capable of learning a larger set of mapping functions. A model with more layers and more hidden units per layer has higher representational capacity \u2014 it is capable of representing more complicated functions. \u2014 Pages 428, Deep Learning , 2016. The number of nodes in a layer is referred to as the width . Developing wide networks with one layer and many nodes was relatively straightforward. In theory, a network with enough nodes in the single hidden layer can learn to approximate any mapping function, although in practice, we don\u2019t know how many nodes are sufficient or how to train such a model. The number of layers in a model is referred to as its depth . Increasing the depth increases the capacity of the model. Training deep models, e.g. those with many hidden layers, can be computationally more efficient than training a single layer network with a vast number of nodes. Modern deep learning provides a very powerful framework for supervised learning. By adding more layers and more units within a layer, a deep network can represent functions of increasing complexity. \u2014 Pages 167, Deep Learning , 2016. Traditionally, it has been challenging to train neural network models with more than a few layers due to problems such as vanishing gradients\uff08\u68af\u5ea6\u6d88\u5931\uff09. More recently, modern methods have allowed the training of deep network models, allowing the developing of models of surprising depth that are capable of achieving impressive performance on challenging problems in a wide range of domains. How to decide the number of hidden layers and nodes in a hidden layer? I have 18 input features for a prediction network, so how many hidden layers should I take and what number of nodes are there in those hidden layers? Is there any formula for deciding this, or it is trial and error?","title":"Model-capacity"},{"location":"Theory/Deep-learning/Guide/Model-capacity/Model-capacity/#model#capacity","text":"\u57285.2 Capacity, Overfitting and Underfitting\u4e2d\u4ecb\u7ecd\u4e86capacity\u7684\u6982\u5ff5\uff0c\u73b0\u5728\u5f00\u59cb\u4ecb\u7ecddeep learning model\u7684capacity\u3002","title":"Model capacity"},{"location":"Theory/Deep-learning/Guide/Model-capacity/Model-capacity/#how#to#control#neural#network#model#capacity#with#nodes#and#layers","text":"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit , whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers . In this tutorial, you will discover how to control the capacity of a neural network model and how capacity impacts what a model is capable of learning. After completing this tutorial, you will know: Neural network model capacity is controlled both by the number of nodes and the number of layers in the model. A model with a single hidden layer and sufficient number of nodes has the capability of learning any mapping function, but the chosen learning algorithm may or may not be able to realize this capability. Increasing the number of layers provides a short-cut to increasing the capacity of the model with fewer resources, and modern techniques allow learning algorithms to successfully train deep models. Discover how to train faster, reduce overfitting, and make better predictions with deep learning models in my new book , with 26 step-by-step tutorials and full source code.","title":"How to Control Neural Network Model Capacity With Nodes and Layers"},{"location":"Theory/Deep-learning/Guide/Model-capacity/Model-capacity/#tutorial#overview","text":"his tutorial is divided into five parts; they are: Controlling Neural Network Model Capacity Configure Nodes and Layers in Keras Multi-Class Classification Problem Change Model Capacity With Nodes Change Model Capacity With Layers","title":"Tutorial Overview"},{"location":"Theory/Deep-learning/Guide/Model-capacity/Model-capacity/#controlling#neural#network#model#capacity","text":"The goal of a neural network is to learn how to map input examples to output examples. Neural networks learn mapping functions. The capacity of a network refers to the range or scope of the types of functions that the model can approximate. Informally, a model\u2019s capacity is its ability to fit a wide variety of functions. \u2014 Pages 111-112, Deep Learning , 2016. A model with less capacity may not be able to sufficiently learn the training dataset. A model with more capacity can model more different types of functions and may be able to learn a function to sufficiently map inputs to outputs in the training dataset. Whereas a model with too much capacity may memorize the training dataset and fail to generalize or get lost or stuck in the search for a suitable mapping function. Generally, we can think of model capacity as a control over whether the model is likely to underfit or overfit a training dataset. We can control whether a model is more likely to overfit or underfit by altering its capacity. \u2014 Pages 111, Deep Learning , 2016. The capacity of a neural network can be controlled by two aspects of the model: Number of Nodes. Number of Layers. A model with more nodes or more layers has a greater capacity and, in turn, is potentially capable of learning a larger set of mapping functions. A model with more layers and more hidden units per layer has higher representational capacity \u2014 it is capable of representing more complicated functions. \u2014 Pages 428, Deep Learning , 2016. The number of nodes in a layer is referred to as the width . Developing wide networks with one layer and many nodes was relatively straightforward. In theory, a network with enough nodes in the single hidden layer can learn to approximate any mapping function, although in practice, we don\u2019t know how many nodes are sufficient or how to train such a model. The number of layers in a model is referred to as its depth . Increasing the depth increases the capacity of the model. Training deep models, e.g. those with many hidden layers, can be computationally more efficient than training a single layer network with a vast number of nodes. Modern deep learning provides a very powerful framework for supervised learning. By adding more layers and more units within a layer, a deep network can represent functions of increasing complexity. \u2014 Pages 167, Deep Learning , 2016. Traditionally, it has been challenging to train neural network models with more than a few layers due to problems such as vanishing gradients\uff08\u68af\u5ea6\u6d88\u5931\uff09. More recently, modern methods have allowed the training of deep network models, allowing the developing of models of surprising depth that are capable of achieving impressive performance on challenging problems in a wide range of domains.","title":"Controlling Neural Network Model Capacity"},{"location":"Theory/Deep-learning/Guide/Model-capacity/Model-capacity/#how#to#decide#the#number#of#hidden#layers#and#nodes#in#a#hidden#layer","text":"I have 18 input features for a prediction network, so how many hidden layers should I take and what number of nodes are there in those hidden layers? Is there any formula for deciding this, or it is trial and error?","title":"How to decide the number of hidden layers and nodes in a hidden layer?"},{"location":"Theory/Deep-learning/Guide/Model-initialization/Model-initialization/","text":"Why Initialize a Neural Network with Random Weights?","title":"Model-initialization"},{"location":"Theory/Deep-learning/Guide/Model-initialization/Model-initialization/#why#initialize#a#neural#network#with#random#weights","text":"","title":"Why Initialize a Neural Network with Random Weights?"},{"location":"Theory/Deep-learning/Guide/Transformer-and-attention/Papers/","text":"\u57fa\u4e8etransformer\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff1a - GPT -BERT","title":"Papers"},{"location":"Theory/Deep-learning/Guide/Tutorial/Artificial-neural-network/","text":"Artificial neural network","title":"Artificial-neural-network"},{"location":"Theory/Deep-learning/Guide/Tutorial/Artificial-neural-network/#artificial#neural#network","text":"","title":"Artificial neural network"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/","text":"Neural Networks Tutorial \u2013 A Pathway to Deep Learning Chances are, if you are searching for a tutorial on artificial neural networks (ANN) you already have some idea of what they are, and what they are capable of doing. But did you know that neural networks are the foundation of the new and exciting field of deep learning? Deep learning is the field of machine learning that is making many state-of-the-art advancements, from beating players at Go and Poker ( reinforcement learning ), to speeding up drug discovery and assisting self-driving cars . If these types of cutting edge applications excite you like they excite me, then you will be interesting in learning as much as you can about deep learning. However, that requires you to know quite a bit about how neural networks work. This tutorial article is designed to help you get up to speed in neural networks as quickly as possible. In this tutorial I\u2019ll be presenting some concepts, code and maths that will enable you to build and understand a simple neural network. Some tutorials focus only on the code and skip the maths \u2013 but this impedes understanding. I\u2019ll take things as slowly as possible, but it might help to brush up on your matrices and differentiation if you need to. The code will be in Python, so it will be beneficial if you have a basic understanding of how Python works. You\u2019ll pretty much get away with knowing about Python functions, loops and the basics of the numpy library. By the end of this neural networks tutorial you\u2019ll be able to build an ANN in Python that will correctly classify handwritten digits in images with a fair degree of accuracy. Once you\u2019re done with this tutorial, you can dive a little deeper with the following posts: Python TensorFlow Tutorial \u2013 Build a Neural Network Improve your neural networks \u2013 Part 1 [TIPS AND TRICKS] Stochastic Gradient Descent \u2013 Mini-batch and more All of the relevant code in this tutorial can be found here . Here\u2019s an outline of the tutorial, with links, so you can easily navigate to the parts you want: 1 What are artificial neural networks? 2 The structure of an ANN 2.1 The artificial neuron 2.2 Nodes 2.3 The bias 2.4 Putting together the structure 2.5 The notation 3 The feed-forward pass 3.1 A feed-forward example 3.2 Our first attempt at a feed-forward function 3.3 A more efficient implementation 3.4 Vectorisation in neural networks 3.5 Matrix multiplication 4 Gradient descent and optimisation 4.1 A simple example in code 4.2 The cost function 4.3 Gradient descent in neural networks 4.4 A two dimensional gradient descent example 4.5 Backpropagation in depth 4.6 Propagating into the hidden layers 4.7 Vectorisation of backpropagation 4.8 Implementing the gradient descent step 4.9 The final gradient descent algorithm 5 Implementing the neural network in Python 5.1 Scaling data 5.2 Creating test and training datasets 5.3 Setting up the output layer 5.4 Creating the neural network 5.5 Assessing the accuracy of the trained model 1 What are artificial neural networks? Artificial neural networks (ANNs) are software implementations of the neuronal structure of our brains. We don\u2019t need to talk about the complex biology of our brain structures, but suffice to say, the brain contains neurons which are kind of like organic switches . These can change their output state depending on the strength of their electrical or chemical input. The neural network in a person\u2019s brain is a hugely interconnected network of neurons , where the output of any given neuron may be the input to thousands of other neurons. Learning occurs by repeatedly activating certain neural connections over others, and this reinforces\uff08\u52a0\u5f3a\uff09 those connections. This makes them more likely to produce a desired outcome given a specified input. This learning involves feedback \u2013 when the desired outcome occurs, the neural connections causing that outcome become strengthened. Artificial neural networks attempt to simplify and mimic\uff08\u6a21\u4eff\uff09 this brain behaviour. They can be trained in a supervised or unsupervised manner. In a supervised ANN, the network is trained by providing matched input and output data samples, with the intention of getting the ANN to provide a desired output for a given input. An example is an e-mail spam filter \u2013 the input training data could be the count of various words in the body of the e-mail, and the output training data would be a classification of whether the e-mail was truly spam or not. If many examples of e-mails are passed through the neural network this allows the network to learn what input data makes it likely that an e-mail is spam or not. This learning takes place be adjusting the weights of the ANN connections, but this will be discussed further in the next section. Unsupervised learning in an ANN is an attempt to get the ANN to \u201cunderstand\u201d the structure of the provided input data \u201con its own\u201d. This type of ANN will not be discussed in this post. 2 The structure of an ANN 2.1 The artificial neuron The biological neuron is simulated in an ANN by an activation function . In classification tasks (e.g. identifying spam e-mails) this activation function has to have a \u201cswitch on\u201d characteristic \u2013 in other words, once the input is greater than a certain value, the output should change state i.e. from 0 to 1, from -1 to 1 or from 0 to >0. This simulates the \u201cturning on\u201d of a biological neuron . A common activation function that is used is the sigmoid function: $$ \\begin{equation*} f(z) = \\frac{1}{1+exp(-z)} \\end{equation*} $$ Which looks like this: As can be seen in the figure above, the function is \u201cactivated\u201d i.e. it moves from 0 to 1 when the input x is greater than a certain value. The sigmoid function isn\u2019t a step function however, the edge is \u201csoft\u201d, and the output doesn\u2019t change instantaneously. This means that there is a derivative\uff08\u5bfc\u6570\uff09 of the function and this is important for the training algorithm which is discussed more in Section 4 . 2.2 Nodes As mentioned previously, biological neurons are connected hierarchical networks , with the outputs of some neurons being the inputs to others. We can represent these networks as connected layers of nodes. Each node takes multiple weighted inputs , applies the activation function to the summation of these inputs, and in doing so generates an output. I\u2019ll break this down further, but to help things along, consider the diagram below: Figure 2. Node with inputs The circle in the image above represents the node. The node is the \u201cseat\u201d of the activation function , and takes the weighted inputs, sums them, then inputs them to the activation function. The output of the activation function is shown as h in the above diagram. Note: a node as I have shown above is also called a perceptron \uff08\u611f\u77e5\u673a\uff09 in some literature. What about this \u201cweight\u201d idea that has been mentioned? The weights are real valued numbers (i.e. not binary 1s or 0s), which are multiplied by the inputs and then summed up in the node. So, in other words, the weighted input to the node above would be: $$ \\begin{equation*} x_1w_1 + x_2w_2 + x_3w_3 + b \\end{equation*} $$ Here the w_i w_i values are weights (ignore the b b for the moment). What are these weights all about? Well, they are the variables that are changed during the learning process, and, along with the input, determine the output of the node. The b b is the weight of the +1 bias element \u2013 the inclusion of this bias enhances the flexibility of the node, which is best demonstrated in an example. 2.3 The bias Let\u2019s take an extremely simple node, with only one input and one output: Figure 2. Simple node The input to the activation function of the node in this case is simply x_1w_1 x_1w_1 . What does changing w_1 w_1 do in this simple network? w1 = 0.5 w2 = 1.0 w3 = 2.0 l1 = 'w = 0.5' l2 = 'w = 1.0' l3 = 'w = 2.0' for w , l in [( w1 , l1 ), ( w2 , l2 ), ( w3 , l3 )]: f = 1 / ( 1 + np . exp ( - x * w )) plt . plot ( x , f , label = l ) plt . xlabel ( 'x' ) plt . ylabel ( 'h_w(x)' ) plt . legend ( loc = 2 ) plt . show () Figure 4. Effect of adjusting weights Here we can see that changing the weight changes the slope\uff08\u659c\u7387\uff09 of the output of the sigmoid activation function , which is obviously useful if we want to model different strengths of relationships between the input and output variables. However, what if we only want the output to change when x is greater than 1? This is where the bias comes in \u2013 let\u2019s consider the same network with a bias input: Figure 5. Effect of bias w = 5.0 b1 = - 8.0 b2 = 0.0 b3 = 8.0 l1 = 'b = -8.0' l2 = 'b = 0.0' l3 = 'b = 8.0' for b , l in [( b1 , l1 ), ( b2 , l2 ), ( b3 , l3 )]: f = 1 / ( 1 + np . exp ( - ( x * w + b ))) plt . plot ( x , f , label = l ) plt . xlabel ( 'x' ) plt . ylabel ( 'h_wb(x)' ) plt . legend ( loc = 2 ) plt . show () Figure 6. Effect of bias adjusments In this case, the w_1 w_1 has been increased to simulate a more defined \u201cturn on\u201d function. As you can see, by varying the bias \u201cweight\u201d b b , you can change when the node activates. Therefore, by adding a bias term, you can make the node simulate a generic if function, i.e. if (x > z) then 1 else 0 . Without a bias term, you are unable to vary the z in that if statement, it will be always stuck around 0. This is obviously very useful if you are trying to simulate conditional relationships . 2.4 Putting together the structure Hopefully the previous explanations have given you a good overview of how a given node/neuron/perceptron in a neural network operates. However, as you are probably aware, there are many such interconnected nodes in a fully fledged\uff08\u6210\u719f\u7684\uff09 neural network. These structures can come in a myriad of different forms, but the most common simple neural network structure consists of an input layer , a hidden layer and an output layer . An example of such a structure can be seen below: Figure 10. Three layer neural network The three layers of the network can be seen in the above figure \u2013 Layer 1 represents the input layer , where the external input data enters the network. Layer 2 is called the hidden layer as this layer is not part of the input or output. Note: neural networks can have many hidden layers, but in this case for simplicity I have just included one. Finally, Layer 3 is the output layer . You can observe the many connections between the layers, in particular between Layer 1 (L1) and Layer 2 (L2). As can be seen, each node in L1 has a connection to all the nodes in L2. Likewise for the nodes in L2 to the single output node L3. Each of these connections will have an associated weight. 2.5 The notation The maths below requires some fairly precise notation so that we know what we are talking about. The notation I am using here is similar to that used in the Stanford deep learning tutorial. In the upcoming equations, each of these weights are identified with the following notation: {w_{ij}}^{(l)} {w_{ij}}^{(l)} . i i refers to the node number of the connection in layer l+1 l+1 and j j refers to the node number of the connection in layer l l . Take special note of this order. So, for the connection between node 1 in layer 1 and node 2 in layer 2, the weight notation would be {w_{21}}^{(1)} {w_{21}}^{(1)} . This notation may seem a bit odd, as you would expect the i and j to refer the node numbers in layers l l and l+1 l+1 respectively (i.e. in the direction of input to output), rather than the opposite. However, this notation makes more sense when you add the bias. As you can observe in the figure above \u2013 the (+1) bias is connected to each of the nodes in the subsequent layer. So the bias in layer 1 is connected to the all the nodes in layer two. Because the bias is not a true node with an activation function , it has no inputs (it always outputs the value +1). The notation of the bias weight is {b_i}^{(l)} {b_i}^{(l)} , where i is the node number in the layer l+1 l+1 \u2013 the same as used for the normal weight notation {w_{21}}^{(1)} {w_{21}}^{(1)} . So, the weight on the connection between the bias in layer 1 and the second node in layer 2 is given by {b_2}^{(1)} {b_2}^{(1)} . Remember, these values \u2013 {w_{ji}}^{(1)} {w_{ji}}^{(1)} and {b_i}^{(l)} {b_i}^{(l)} \u2013 all need to be calculated in the training phase of the ANN. Finally, the node output notation is {h_j}^{(l)} {h_j}^{(l)} , where j j denotes the node number in layer l l of the network. As can be observed in the three layer network above, the output of node 2 in layer 2 has the notation of {h_2}^{(2)} {h_2}^{(2)} . Now that we have the notation all sorted out, it is now time to look at how you calculate the output of the network when the input and the weights are known. The process of calculating the output of the neural network given these values is called the feed-forward pass or process. 3 The feed-forward pass To demonstrate how to calculate the output from the input in neural networks, let\u2019s start with the specific case of the three layer neural network that was presented above. Below it is presented in equation form, then it will be demonstrated with a concrete example and some Python code: $$ \\begin{align} h_1^{(2)} &= f(w_{11}^{(1)}x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_1^{(1)}) \\ h_2^{(2)} &= f(w_{21}^{(1)}x_1 + w_{22}^{(1)} x_2 + w_{23}^{(1)} x_3 + b_2^{(1)}) \\ h_3^{(2)} &= f(w_{31}^{(1)}x_1 + w_{32}^{(1)} x_2 + w_{33}^{(1)} x_3 + b_3^{(1)}) \\ h_{W,b}(x) &= h_1^{(3)} = f(w_{11} {(2)}h_1 {(2)} + w_{12}^{(2)} h_2^{(2)} + w_{13}^{(2)} h_3^{(2)} + b_1^{(2)}) \\end{align} $$ SUMMARY : $$ \\begin{align} h_1^{(2)} &= f(w_{11}^{(1)}x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_1^{(1)}) \\ \\end{align} $$ \u7b2c\u4e00\u5c42\u8282\u70b91\u5230\u7b2c\u4e8c\u5c42\u8282\u70b91\uff0c\u7b2c\u4e00\u5c42\u8282\u70b92\u5230\u7b2c\u4e8c\u5c42\u8282\u70b91\uff0c\u7b2c\u4e00\u5c42\u8282\u70b93\u5230\u7b2c\u4e8c\u5c42\u8282\u70b91\uff1b In the equation above f(\\bullet) f(\\bullet) refers to the node activation function , in this case the sigmoid function. The first line, {h_1}^{(2)} {h_1}^{(2)} is the output of the first node in the second layer, and its inputs are w_{11}^{(1)} x_1 w_{11}^{(1)} x_1 w_{12}^{(1)} x_2 w_{12}^{(1)} x_2 w_{13}^{(1)} x_3 w_{13}^{(1)} x_3 and b_1^{(1)} b_1^{(1)} . These inputs can be traced in the three-layer connection diagram above. They are simply summed and then passed through the activation function to calculate the output of the first node. Likewise, for the other two nodes in the second layer. The final line is the output of the only node in the third and final layer, which is ultimate output of the neural network. As can be observed, rather than taking the weighted input variables ( x_1, x_2, x_3 x_1, x_2, x_3 ), the final node takes as input the weighted output of the nodes of the second layer ( h_{1}^{(1)} h_{1}^{(1)} , h_{2}^{(2)} h_{2}^{(2)} , h_{3}^{(3)} h_{3}^{(3)} ), plus the weighted bias. Therefore, you can see in equation form the hierarchical nature of artificial neural networks. 3.1 A feed-forward example Now, let\u2019s do a simple first example of the output of this neural network in Python. First things first, notice that the weights between layer 1 and 2 ( w_{11}^{(1)} w_{11}^{(1)} , w_{12}^{(1)} w_{12}^{(1)} ,\u2026) are ideally suited to matrix representation? Observe: $$ \\begin{equation} W^{(1)} = \\begin{pmatrix} w_{11}^{(1)} & w_{12}^{(1)} & w_{13}^{(1)} \\ w_{21}^{(1)} & w_{22}^{(1)} & w_{23}^{(1)} \\ w_{31}^{(1)} & w_{32}^{(1)} & w_{33}^{(1)} \\ \\end{pmatrix} \\end{equation} $$ This matrix can be easily represented using numpy arrays: import numpy as np w1 = np . array ([[ 0.2 , 0.2 , 0.2 ], [ 0.4 , 0.4 , 0.4 ], [ 0.6 , 0.6 , 0.6 ]]) Here I have just filled up the layer 1 weight array with some example weights. We can do the same for the layer 2 weight array: $$ \\begin{equation} W^{(2)} = \\begin{pmatrix} w_{11}^{(2)} & w_{12}^{(2)} & w_{13}^{(2)} \\end{pmatrix} \\end{equation} $$ w2 = np . zeros (( 1 , 3 )) w2 [ 0 ,:] = np . array ([ 0.5 , 0.5 , 0.5 ]) We can also setup some dummy values in the layer 1 bias weight array/vector, and the layer 2 bias weight (which is only a single value in this neural network structure \u2013 i.e. a scalar): b1 = np . array ([ 0.8 , 0.8 , 0.8 ]) b2 = np . array ([ 0.2 ]) Finally, before we write the main program to calculate the output from the neural network, it\u2019s handy to setup a separate Python function for the activation function : def f ( x ): return 1 / ( 1 + np . exp ( - x )) 3.2 Our first attempt at a feed-forward function Below is a simple way of calculating the output of the neural network, using nested loops in python. We\u2019ll look at more efficient ways of calculating the output shortly. def simple_looped_nn_calc ( n_layers , x , w , b ): for l in range ( n_layers - 1 ): #Setup the input array which the weights will be multiplied by for each layer #If it's the first layer, the input array will be the x input vector #If it's not the first layer, the input to the next layer will be the #output of the previous layer if l == 0 : node_in = x else : node_in = h #Setup the output array for the nodes in layer l + 1 h = np . zeros (( w [ l ] . shape [ 0 ],)) #loop through the rows of the weight array for i in range ( w [ l ] . shape [ 0 ]): #setup the sum inside the activation function f_sum = 0 #loop through the columns of the weight array for j in range ( w [ l ] . shape [ 1 ]): f_sum += w [ l ][ i ][ j ] * node_in [ j ] #add the bias f_sum += b [ l ][ i ] #finally use the activation function to calculate the #i-th output i.e. h1, h2, h3 h [ i ] = f ( f_sum ) return h This function takes as input the number of layers in the neural network, the x input array/vector, then Python tuples or lists of the weights and bias weights of the network, with each element in the tuple/list representing a layer ll in the network. In other words, the inputs are setup in the following: w = [ w1 , w2 ] b = [ b1 , b2 ] #a dummy x input vector x = [ 1.5 , 2.0 , 3.0 ] The function first checks what the input is to the layer of nodes/weights being considered. If we are looking at the first layer, the input to the second layer nodes is the input vector xx multiplied by the relevant weights. After the first layer though, the inputs to subsequent layers are the output of the previous layers. Finally, there is a nested loop through the relevant ii and jj values of the weight vectors and the bias. The function uses the dimensions of the weights for each layer to figure out the number of nodes and therefore the structure of the network. Calling the function: simple_looped_nn_calc ( 3 , x , w , b ) gives the output of 0.8354. We can confirm this results by manually performing the calculations in the original equations: $$ \\begin{align} h_1^{(2)} &= f(0.2*1.5 + 0.2*2.0 + 0.2*3.0 + 0.8) = 0.8909 \\ h_2^{(2)} &= f(0.4*1.5 + 0.4*2.0 + 0.4*3.0 + 0.8) = 0.9677 \\ h_3^{(2)} &= f(0.6*1.5 + 0.6*2.0 + 0.6*3.0 + 0.8) = 0.9909 \\ h_{W,b}(x) &= h_1^{(3)} = f(0.5*0.8909 + 0.5*0.9677 + 0.5*0.9909 + 0.2) = 0.8354 \\end{align} $$ 3.3 A more efficient implementation As was stated earlier \u2013 using loops isn\u2019t the most efficient way of calculating the feed forward step in Python. This is because the loops in Python are notoriously slow. An alternative, more efficient mechanism of doing the feed forward step in Python and numpy will be discussed shortly. We can benchmark how efficient the algorithm is by using the %timeit function in IPython, which runs the function a number of times and returns the average time that the function takes to run: % timeit simple_looped_nn_calc ( 3 , x , w , b ) Running this tells us that the looped feed forward takes 40\\mu s 40\\mu s . A result in the tens of microseconds sounds very fast, but when applied to very large practical NNs with 100s of nodes per layer, this speed will become prohibitive, especially when training the network, as will become clear later in this tutorial. If we try a four layer neural network using the same code, we get significantly worse performance \u2013 70\\mu s 70\\mu s in fact. 3.4 Vectorisation in neural networks There is a way to write the equations even more compactly, and to calculate the feed forward process in neural networks more efficiently, from a computational perspective. Firstly, we can introduce a new variable z_{i}^{(l)} z_{i}^{(l)} which is the summated input into node i i of layer l l , including the bias term. So in the case of the first node in layer 2, z z is equal to: $$ z_{1}^{(2)} = w_{11}^{(1)}x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_1^{(1)} = \\sum_{j=1}^{n} w_{ij}^{(1)}x_i + b_{i}^{(1)} $$ where n is the number of nodes in layer 1. Using this notation, the unwieldy previous set of equations for the example three layer network can be reduced to: \\begin{align} z^{(2)} &= W^{(1)} x + b^{(1)} \\\\ h^{(2)} &= f(z^{(2)}) \\\\ z^{(3)} &= W^{(2)} h^{(2)} + b^{(2)} \\\\ h_{W,b}(x) &= h^{(3)} = f(z^{(3)}) \\end{align} \\begin{align} z^{(2)} &= W^{(1)} x + b^{(1)} \\\\ h^{(2)} &= f(z^{(2)}) \\\\ z^{(3)} &= W^{(2)} h^{(2)} + b^{(2)} \\\\ h_{W,b}(x) &= h^{(3)} = f(z^{(3)}) \\end{align} 4 Gradient descent and optimisation 4.1 A simple example in code Below is an example of a simple Python implementation of gradient descent for solving the minimum of the equation f(x) = x^4 \u2013 3x^3 + 2 f(x) = x^4 \u2013 3x^3 + 2 taken from Wikipedia. The gradient of this function is able to be calculated analytically (i.e. we can do it easily using calculus, which we can\u2019t do with many real world applications) and is f'(x) = 4x^3 \u2013 9x^2 f'(x) = 4x^3 \u2013 9x^2 . This means at every value of xx, we can calculate the gradient of the function by using a simple equation. Again, using calculus we can know that the exact minimum of this equation is x=2.25 x=2.25 . Previously, we\u2019ve talked about iteratively minimising the error of the output of the neural network by varying the weights in gradient descent . However, as it turns out, there is a mathematically more generalised way of looking at things that allows us to reduce the error while also preventing things like overfitting (this will be discussed more in later articles). This more general optimisation formulation revolves around minimising what\u2019s called the cost function . The equivalent cost function of a single training pair ( x^z x^z , y^z y^z ) in a neural network is: x_old = 0 # The value does not matter as long as abs(x_new - x_old) > precision x_new = 6 # The algorithm starts at x=6 gamma = 0.01 # step size precision = 0.00001 def df ( x ): y = 4 * x ** 3 - 9 * x ** 2 return y while abs ( x_new - x_old ) > precision : x_old = x_new x_new += - gamma * df ( x_old ) print ( \"The local minimum occurs at %f \" % x_new ) This function prints \u201cThe local minimum occurs at 2.249965\u201d, which agrees with the exact solution within the precision. This code implements the weight adjustment algorithm that I showed above, and can be seen to find the minimum of the function correctly within the given precision. This is a very simple example of gradient descent , and finding the gradient works quite differently when training neural networks . However, the main idea remains \u2013 we figure out the gradient of the neural network then adjust the weights in a step to try to get closer to the minimum error that we are trying to find. Another difference between this toy example of gradient descent is that the weight vector is multi-dimensional, and therefore the gradient descent method must search a multi-dimensional space for the minimum point. The way we figure out the gradient of a neural network is via the famous backpropagation method, which will be discussed shortly. First however, we have to look at the error function more closely. 4.2 The cost function 4.3 Gradient descent in neural networks Gradient descent for every weight w_{(ij)}^{(l)} w_{(ij)}^{(l)} and every bias b_i^{(l)} b_i^{(l)} in the neural network looks like the following: $$ \\begin{align} w_{ij}^{(l)} &= w_{ij}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial w_{ij}^{(l)}} J(w,b) \\ b_{i}^{(l)} &= b_{i}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial b_{i}^{(l)}} J(w,b) \\end{align} $$ Basically, the equation above is similiar to the previously shown gradient descent algorithm: w_{new} = w_{old} \u2013 \\alpha * \\nabla error w_{new} = w_{old} \u2013 \\alpha * \\nabla error . The new and old subscripts are missing, but the values on the left side of the equation are new and the values on the right side are old . Again, we have an iterative process whereby the weights are updated in each iteration, this time based on the cost function J(w,b) J(w,b) . The values \\frac{\\partial}{\\partial w_{ij}^{(l)}} \\frac{\\partial}{\\partial w_{ij}^{(l)}} and \\frac{\\partial}{\\partial b_{i}^{(l)}} \\frac{\\partial}{\\partial b_{i}^{(l)}} are the partial derivatives of the single sample cost function based on the weight values. What does this mean? Recall that for the simple gradient descent example mentioned previously, each step depends on the slope of the error/cost term with respect to the weights. Another word for slope or gradient is the derivative . A normal derivative has the notation \\frac{d}{dx} \\frac{d}{dx} . If x x in this instance is a vector, then such a derivative will also be a vector, displaying the gradient in all the dimensions of x x . 4.4 A two dimensional gradient descent example 4.5 Backpropagation in depth In this section, I\u2019m going to delve into the maths a little. If you\u2019re wary of the maths of how backpropagation works, then it may be best to skip this section. The next section will show you how to implement backpropagation in code \u2013 so if you want to skip straight on to using this method, feel free to skip the rest of this section. However, if you don\u2019t mind a little bit of maths, I encourage you to push on to the end of this section as it will give you a good depth of understanding in training neural networks. This will be invaluable to understanding some of the key ideas in deep learning, rather than just being a code cruncher who doesn\u2019t really understand how the code works. SUMMARY : neural network\u7684training\uff1b First let\u2019s recall some of the foundational equations from Section 3 for the following three layer neural network: Figure 10. Three layer neural network (again) The output of this neural network can be calculated by: $$ \\begin{equation} h_{W,b}(x) = h_1^{(3)} = f(w_{11} {(2)}h_1 {(2)} + w_{12}^{(2)} h_2^{(2)} + w_{13}^{(2)} h_3^{(2)} + b_1^{(2)}) \\end{equation} $$ We can also simplify the above to h_1^{(3)} = f(z_1^{(2)}) h_1^{(3)} = f(z_1^{(2)}) by defining z_1^{(2)} z_1^{(2)} as: $$ z_{1}^{(2)} = w_{11} {(2)}h_1 {(2)} + w_{12}^{(2)} h_2^{(2)} + w_{13}^{(2)} h_3^{(2)} + b_1^{(2)} $$ SUMMARY : z_1^{(2)} z_1^{(2)} \u8868\u793a\u7684\u662f\u7b2c2\u5c42\u8f93\u5165\u5230\u7b2c2+1\u5c42\u7684\u7b2c1\u4e2a\u8282\u70b9\u7684sum\uff1b Let\u2019s say we want to find out how much a change in the weight w_{12}^{(2)} w_{12}^{(2)} has on the cost function J J . This is to evaluate \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} . To do so, we have to use something called the chain function: $$ \\frac {\\partial J}{\\partial w_{12}^{(2)}} = \\frac {\\partial J}{\\partial h_1^{(3)}} \\frac {\\partial h_1^{(3)}}{\\partial z_1^{(2)}} \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} $$ SUMMARY : \u5982\u679c\u6709\u591a\u5c42\u9690\u85cf\u5c42\u7684\u8bdd\uff0c\u4e0a\u8ff0\u516c\u5f0f\u662f\u5426\u4f9d\u7136\u9002\u7528\uff1f If you look at the terms on the right \u2013 the numerators \u201ccancel out\u201d the denominators, in the same way that \\frac {2}{5} \\frac {5}{2} = \\frac {2}{2} = 1 \\frac {2}{5} \\frac {5}{2} = \\frac {2}{2} = 1 . Therefore we can construct \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} by stringing together a few partial derivatives (which are quite easy, thankfully). Let\u2019s start with \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} $$ \\begin{align} \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} &= \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{11} {(1)}h_1 {(2)} + w_{12}^{(1)} h_2^{(2)} + w_{13}^{(1)} h_3^{(2)} + b_1^{(1)})\\ &= \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{12}^{(1)} h_2^{(2)})\\ &= h_2^{(2)} \\end{align} $$ The partial derivative of z_1^{(2)} z_1^{(2)} with respect w_{12}^{(2)} w_{12}^{(2)} only operates on one term within the parentheses, w_{12}^{(1)} h_2^{(2)} w_{12}^{(1)} h_2^{(2)} , as all the other terms don\u2019t vary at all when w_{12}^{(2)} w_{12}^{(2)} does. The derivative of a constant is 1, therefore \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{12}^{(1)} h_2^{(2)}) \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{12}^{(1)} h_2^{(2)}) collapses to just h_2^{(2)} h_2^{(2)} , which is simply the output of the second node in layer 2. The next partial derivative in the chain is \\frac {\\partial h_1^{(3)}}{\\partial z_1^{(2)}} \\frac {\\partial h_1^{(3)}}{\\partial z_1^{(2)}} , which is the partial derivative of the activation function of the h_1^{(3)} h_1^{(3)} output node . Because of the requirement to be able to derive this derivative, the activation functions in neural networks need to be differentiable . For the common sigmoid activation function (shown in Section 2.1 ), the derivative is: $$ \\frac {\\partial h}{\\partial z} = f'(z) = f(z)(1-f(z)) $$ Where f(z) f(z) is the activation function. So far so good \u2013 now we have to work out how to deal with the first term \\frac {\\partial J}{\\partial h_1^{(3)}} \\frac {\\partial J}{\\partial h_1^{(3)}} . Remember that J(w,b,x,y) J(w,b,x,y) is the mean squared error loss function, which looks like (for our case): $$ J(w,b,x,y) = \\frac{1}{2} \\parallel y_1 \u2013 h_1 {(3)}(z_1 {(2)}) \\parallel ^2 $$ Here y_1 y_1 is the training target for the output node . Again using the chain rule: $$ \\begin{align} &Let u = \\parallel y_1 \u2013 h_1 {(3)}(z_1 {(2)}) \\parallel and J = \\frac {1}{2} u^2\\ &Using \\frac {\\partial J}{\\partial h} = \\frac {\\partial J}{\\partial u} \\frac {\\partial u}{\\partial h}:\\ &\\frac {\\partial J}{\\partial h} = -(y_1 \u2013 h_1^{(3)}) \\end{align} $$ SUMMARY : \u4e0a\u8ff0\u63a8\u5bfc\u5e76\u6ca1\u6709\u641e\u6e05\u695a\uff1b So we\u2019ve now figured out how to calculate \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} , at least for the weights connecting the output layer . Before we move to any hidden layers (i.e. layer 2 in our example case), let\u2019s introduce some simplifications to tighten up our notation and introduce \\delta \\delta : $$ \\delta_i^{(n_l)} = -(y_i \u2013 h_i^{(n_l)})\\cdot f \\prime(z_i {(n_l)}) $$ Where i i is the node number of the output layer . SUMMARY : \\delta_i^{(n_l)} \\delta_i^{(n_l)} \u4e2d\u5305\u542b z_i^{(n_l)} z_i^{(n_l)} In our selected example there is only one such layer, therefore i=1 i=1 always in this case. Now we can write the complete cost function derivative as: $$ \\begin{align} \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b,x, y) &= h^{(l)}_j \\delta_i^{(l+1)} \\ \\end{align} $$ Where, for the output layer in our case, l l = 2 and i i remains the node number. SUMMARY : \u8fd9\u662f\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u94fe\u5f0f\u6cd5\u5219\u7684\u901a\u7528\u5f62\u5f0f\uff1b\u4ee5\u5f00\u5934\u6240\u63d0\u51fa\u7684\u95ee\u9898\uff1aLet\u2019s say we want to find out how much a change in the weight w_{12}^{(2)} w_{12}^{(2)} has on the cost function J J . This is to evaluate \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} . \u4f7f\u7528\u4e0a\u8ff0\u516c\u5f0f\u6765\u770b\u7684\u8bdd\uff0c \\frac {\\partial J}{\\partial w_{12}^{(2)}}= h^{(2)}_2 \\delta_1^{(2+1)} \\frac {\\partial J}{\\partial w_{12}^{(2)}}= h^{(2)}_2 \\delta_1^{(2+1)} . h^{(2)}_2 h^{(2)}_2 \u8868\u793a\u7b2c2\u5c42\u7b2c2\u4e2a\u8282\u70b9\u7684\u8f93\u51fa\u503c\uff1b \\delta_1^{(2+1)} \\delta_1^{(2+1)} \uff0c w_{12}^{(2)} w_{12}^{(2)} \u662f\u7b2c2\u5c42\u7684\u8282\u70b92\u4e0e\u7b2c\u4e09\u5c42\u7684\u8282\u70b91\u4e4b\u95f4\u7684\u8fde\u63a5\u6743\u91cd\uff1b 4.6 Propagating into the hidden layers What about for weights feeding into any hidden layers (layer 2 in our case)? For the weights connecting the output layer , the \\frac {\\partial J}{\\partial h} = -(y_i \u2013 h_i^{(n_l)}) \\frac {\\partial J}{\\partial h} = -(y_i \u2013 h_i^{(n_l)}) derivative made sense, as the cost function can be directly calculated by comparing the output layer to the training data . The output of the hidden nodes, however, have no such direct reference, rather, they are connected to the cost function only through mediating weights and potentially other layers of nodes. How can we find the variation in the cost function from changes to weights embedded deep within the neural network? As mentioned previously, we use the backpropagation method. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\u5982\u4f55\u6765\u8ba1\u7b97\u8c03\u6574\u8f93\u5165\u5230hidden layer\u7684weight\u5bf9cost function\u7684\u5f71\u54cd\uff1b\u5982\u679c\u4ee5\u4e0a\u8ff0\u4e09\u5c42\u795e\u7ecf\u7f51\u7edc\u4e3a\u4f8b\u7684\u8bdd\uff0c\u6b64\u5904\u7684weight\u5c31\u662finput layer\u5230hidden layer\u7684weight\uff1b\u5bf9\u4e8e\u8fd9\u79cdweigh\u800c\u8a00\uff0c\u56e0\u4e3a\u5b83\u4eec\u5e76\u4e0d\u662f\u76f4\u63a5\u8fde\u63a5\u5230\u8f93\u51fa\u5c42\uff0c\u6240\u4ee5\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528comparing the output layer to the training data . \u90a3\u5982\u4f55\u6765\u8ba1\u7b97\u90a3\u4e9b\u6539\u53d8\u90a3\u4e9b\u4e0d\u662f\u76f4\u63a5\u8fde\u63a5\u5230\u8f93\u51fa\u5c42\u800c\u662f\u5d4c\u5165\u5730\u6bd4\u8f83\u6df1\u7684\u5c42\u7684\u8282\u70b9\u7684\u6743\u91cd\u5bf9neural network\u7684\u5f71\u54cd\u5462\uff1f\u6b64\u5904\u5c31\u9700\u8981\u4f7f\u7528backpropagation\uff1b SUMMARY : \u4e0a\u8ff0\u7ed9\u51fa\u4e86backpropagation\u7684\u4ef7\u503c\u6240\u5728 Now that we\u2019ve done the hard work using the chain rule , we\u2019ll now take a more graphical approach. The term that needs to propagate back through the network is the \\delta_i^{(n_l)} \\delta_i^{(n_l)} term, as this is the network\u2019s ultimate connection to the cost function . What about node j in the second layer (hidden layer)? How does it contribute to \\delta_i^{(n_l)} \\delta_i^{(n_l)} in our test network? It contributes via the weight w_{ij}^{(2)} w_{ij}^{(2)} \u2013 see the diagram below for the case of j=1 j=1 and i=1 i=1 . Figure 11. Simple backpropagation illustration SUMMARY : \u4e0a\u56fe\u4e2d\uff0c\u6bd4\u8f83\u6a21\u7cca\u7684\u516c\u5f0f\u662f\uff1a $$ \\delta_i^{(2)} = \\delta_i^{(3)} w_{11}^{(2)} $$ As can be observed from above, the output layer \u03b4 \u03b4 is communicated to the hidden node by the weight of the connection. In the case where there is only one output layer node, the generalised hidden layer \u03b4 \u03b4 is defined as: $$ \\delta_j^{(l)} = \\delta_1^{(l+1)} w_{1j} {(l)} f \\prime(z_j)^{(l)} $$ SUMMARY : \u8fd9\u662f\u4e00\u4e2a\u9012\u5f52\u5173\u7cfb\uff0c\u95ee\u9898\u662f\u8fd9\u4e2a\u9012\u5f52\u5173\u7cfb\u662f\u5982\u4f55\u5f97\u5230\u7684\uff1f Where j j is the node number in layer l l . What about the case where there are multiple output nodes? In this case, the weighted sum of all the communicated errors are taken to calculate \\delta_j^{(l)} \\delta_j^{(l)} , as shown in the diagram below: Figure 12. Backpropagation illustration with multiple outputs SUMMARY : \u4e0a\u56fe\u4e2d\uff0c\u6bd4\u8f83\u6a21\u7cca\u7684\u516c\u5f0f\u662f\uff1a $$ \\delta_1^{(2)} = (\\sum_{i=1}^{3} w_{i1}^{(2)} \\delta_i {(3)}) f \\prime(z_i^{(2)}) $$ As can be observed from the above, each \\delta \\delta value from the output layer is included in the sum used to calculate \\delta_1^{(2)} \\delta_1^{(2)} , but each output \\delta \\delta is weighted according to the appropriate w_{i1}^{(2)} w_{i1}^{(2)} value. In other words, node 1 in layer 2 contributes to the error of three output nodes, therefore the measured error (or cost function value ) at each of these nodes has to be \u201c passed back \u201d\uff08\u4f20\u56de\uff09 to the \\delta \\delta value for this node. Now we can develop a generalised expression for the \\delta \\delta values for nodes in the hidden layers: $$ \\delta_j^{(l)} = (\\sum_{i=1}^{s_{(l+1)}} w_{ij}^{(l)} \\delta_i {(l+1)}) f \\prime(z_j^{(l)}) $$ Where j j is the node number in layer l l and i i is the node number in layer l+1 l+1 (which is the same notation we have used from the start). The value s_{(l+1)} s_{(l+1)} is the number of nodes in layer (l+1) (l+1) . SUMMARY : \u4e0a\u5f0f\u662f\u9012\u5f52\u516c\u5f0f\uff0c\u5728Wikipedia\u7684 Backpropagation \u6709\u76f8\u5e94\u7684\u4ecb\u7ecd\uff1b So we now know how to calculate: $$ \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b,x, y) = h^{(l)}_j \\delta_i^{(l+1)} $$ SUMMARY : \u6839\u636e\u8be5\u516c\u5f0f\u5c31\u53ef\u4ee5\u5f97\u5230\u8c03\u6574\u4efb\u610f\u7684 W_{ij}^{(l)} W_{ij}^{(l)} \u5bf9cost function\u7684\u5f71\u54cd\uff1b as shown previously. What about the bias weights ? I\u2019m not going to derive them as I did with the normal weights in the interest of saving time / space. However, the reader shouldn\u2019t have too many issues following the same steps, using the chain rule, to arrive at: $$ \\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b,x, y) = \\delta_i^{(l+1)} $$ Great \u2013 so we now know how to perform our original gradient descent problem for neural networks: $$ \\begin{align} w_{ij}^{(l)} &= w_{ij}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial w_{ij}^{(l)}} J(w,b) \\ b_{i}^{(l)} &= b_{i}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial b_{i}^{(l)}} J(w,b) \\end{align} $$ However, to perform this gradient descent training of the weights, we would have to resort to loops within loops. As previously shown in Section 3.4 of this neural network tutorial, performing such calculations in Python using loops is slow for large networks. Therefore, we need to figure out how to vectorise such calculations, which the next section will show. 4.8 Implementing the gradient descent step 4.9 The final gradient descent algorithm 5 Implementing the neural network in Python","title":"Neural-Networks-Tutorial"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#neural#networks#tutorial#a#pathway#to#deep#learning","text":"Chances are, if you are searching for a tutorial on artificial neural networks (ANN) you already have some idea of what they are, and what they are capable of doing. But did you know that neural networks are the foundation of the new and exciting field of deep learning? Deep learning is the field of machine learning that is making many state-of-the-art advancements, from beating players at Go and Poker ( reinforcement learning ), to speeding up drug discovery and assisting self-driving cars . If these types of cutting edge applications excite you like they excite me, then you will be interesting in learning as much as you can about deep learning. However, that requires you to know quite a bit about how neural networks work. This tutorial article is designed to help you get up to speed in neural networks as quickly as possible. In this tutorial I\u2019ll be presenting some concepts, code and maths that will enable you to build and understand a simple neural network. Some tutorials focus only on the code and skip the maths \u2013 but this impedes understanding. I\u2019ll take things as slowly as possible, but it might help to brush up on your matrices and differentiation if you need to. The code will be in Python, so it will be beneficial if you have a basic understanding of how Python works. You\u2019ll pretty much get away with knowing about Python functions, loops and the basics of the numpy library. By the end of this neural networks tutorial you\u2019ll be able to build an ANN in Python that will correctly classify handwritten digits in images with a fair degree of accuracy. Once you\u2019re done with this tutorial, you can dive a little deeper with the following posts: Python TensorFlow Tutorial \u2013 Build a Neural Network Improve your neural networks \u2013 Part 1 [TIPS AND TRICKS] Stochastic Gradient Descent \u2013 Mini-batch and more All of the relevant code in this tutorial can be found here . Here\u2019s an outline of the tutorial, with links, so you can easily navigate to the parts you want: 1 What are artificial neural networks? 2 The structure of an ANN 2.1 The artificial neuron 2.2 Nodes 2.3 The bias 2.4 Putting together the structure 2.5 The notation 3 The feed-forward pass 3.1 A feed-forward example 3.2 Our first attempt at a feed-forward function 3.3 A more efficient implementation 3.4 Vectorisation in neural networks 3.5 Matrix multiplication 4 Gradient descent and optimisation 4.1 A simple example in code 4.2 The cost function 4.3 Gradient descent in neural networks 4.4 A two dimensional gradient descent example 4.5 Backpropagation in depth 4.6 Propagating into the hidden layers 4.7 Vectorisation of backpropagation 4.8 Implementing the gradient descent step 4.9 The final gradient descent algorithm 5 Implementing the neural network in Python 5.1 Scaling data 5.2 Creating test and training datasets 5.3 Setting up the output layer 5.4 Creating the neural network 5.5 Assessing the accuracy of the trained model","title":"Neural Networks Tutorial \u2013 A Pathway to Deep Learning"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#1#what#are#artificial#neural#networks","text":"Artificial neural networks (ANNs) are software implementations of the neuronal structure of our brains. We don\u2019t need to talk about the complex biology of our brain structures, but suffice to say, the brain contains neurons which are kind of like organic switches . These can change their output state depending on the strength of their electrical or chemical input. The neural network in a person\u2019s brain is a hugely interconnected network of neurons , where the output of any given neuron may be the input to thousands of other neurons. Learning occurs by repeatedly activating certain neural connections over others, and this reinforces\uff08\u52a0\u5f3a\uff09 those connections. This makes them more likely to produce a desired outcome given a specified input. This learning involves feedback \u2013 when the desired outcome occurs, the neural connections causing that outcome become strengthened. Artificial neural networks attempt to simplify and mimic\uff08\u6a21\u4eff\uff09 this brain behaviour. They can be trained in a supervised or unsupervised manner. In a supervised ANN, the network is trained by providing matched input and output data samples, with the intention of getting the ANN to provide a desired output for a given input. An example is an e-mail spam filter \u2013 the input training data could be the count of various words in the body of the e-mail, and the output training data would be a classification of whether the e-mail was truly spam or not. If many examples of e-mails are passed through the neural network this allows the network to learn what input data makes it likely that an e-mail is spam or not. This learning takes place be adjusting the weights of the ANN connections, but this will be discussed further in the next section. Unsupervised learning in an ANN is an attempt to get the ANN to \u201cunderstand\u201d the structure of the provided input data \u201con its own\u201d. This type of ANN will not be discussed in this post.","title":"1 What are artificial neural networks?"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#2#the#structure#of#an#ann","text":"","title":"2 The structure of an ANN"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#21#the#artificial#neuron","text":"The biological neuron is simulated in an ANN by an activation function . In classification tasks (e.g. identifying spam e-mails) this activation function has to have a \u201cswitch on\u201d characteristic \u2013 in other words, once the input is greater than a certain value, the output should change state i.e. from 0 to 1, from -1 to 1 or from 0 to >0. This simulates the \u201cturning on\u201d of a biological neuron . A common activation function that is used is the sigmoid function: $$ \\begin{equation*} f(z) = \\frac{1}{1+exp(-z)} \\end{equation*} $$ Which looks like this: As can be seen in the figure above, the function is \u201cactivated\u201d i.e. it moves from 0 to 1 when the input x is greater than a certain value. The sigmoid function isn\u2019t a step function however, the edge is \u201csoft\u201d, and the output doesn\u2019t change instantaneously. This means that there is a derivative\uff08\u5bfc\u6570\uff09 of the function and this is important for the training algorithm which is discussed more in Section 4 .","title":"2.1 The artificial neuron"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#22#nodes","text":"As mentioned previously, biological neurons are connected hierarchical networks , with the outputs of some neurons being the inputs to others. We can represent these networks as connected layers of nodes. Each node takes multiple weighted inputs , applies the activation function to the summation of these inputs, and in doing so generates an output. I\u2019ll break this down further, but to help things along, consider the diagram below: Figure 2. Node with inputs The circle in the image above represents the node. The node is the \u201cseat\u201d of the activation function , and takes the weighted inputs, sums them, then inputs them to the activation function. The output of the activation function is shown as h in the above diagram. Note: a node as I have shown above is also called a perceptron \uff08\u611f\u77e5\u673a\uff09 in some literature. What about this \u201cweight\u201d idea that has been mentioned? The weights are real valued numbers (i.e. not binary 1s or 0s), which are multiplied by the inputs and then summed up in the node. So, in other words, the weighted input to the node above would be: $$ \\begin{equation*} x_1w_1 + x_2w_2 + x_3w_3 + b \\end{equation*} $$ Here the w_i w_i values are weights (ignore the b b for the moment). What are these weights all about? Well, they are the variables that are changed during the learning process, and, along with the input, determine the output of the node. The b b is the weight of the +1 bias element \u2013 the inclusion of this bias enhances the flexibility of the node, which is best demonstrated in an example.","title":"2.2 Nodes"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#23#the#bias","text":"Let\u2019s take an extremely simple node, with only one input and one output: Figure 2. Simple node The input to the activation function of the node in this case is simply x_1w_1 x_1w_1 . What does changing w_1 w_1 do in this simple network? w1 = 0.5 w2 = 1.0 w3 = 2.0 l1 = 'w = 0.5' l2 = 'w = 1.0' l3 = 'w = 2.0' for w , l in [( w1 , l1 ), ( w2 , l2 ), ( w3 , l3 )]: f = 1 / ( 1 + np . exp ( - x * w )) plt . plot ( x , f , label = l ) plt . xlabel ( 'x' ) plt . ylabel ( 'h_w(x)' ) plt . legend ( loc = 2 ) plt . show () Figure 4. Effect of adjusting weights Here we can see that changing the weight changes the slope\uff08\u659c\u7387\uff09 of the output of the sigmoid activation function , which is obviously useful if we want to model different strengths of relationships between the input and output variables. However, what if we only want the output to change when x is greater than 1? This is where the bias comes in \u2013 let\u2019s consider the same network with a bias input: Figure 5. Effect of bias w = 5.0 b1 = - 8.0 b2 = 0.0 b3 = 8.0 l1 = 'b = -8.0' l2 = 'b = 0.0' l3 = 'b = 8.0' for b , l in [( b1 , l1 ), ( b2 , l2 ), ( b3 , l3 )]: f = 1 / ( 1 + np . exp ( - ( x * w + b ))) plt . plot ( x , f , label = l ) plt . xlabel ( 'x' ) plt . ylabel ( 'h_wb(x)' ) plt . legend ( loc = 2 ) plt . show () Figure 6. Effect of bias adjusments In this case, the w_1 w_1 has been increased to simulate a more defined \u201cturn on\u201d function. As you can see, by varying the bias \u201cweight\u201d b b , you can change when the node activates. Therefore, by adding a bias term, you can make the node simulate a generic if function, i.e. if (x > z) then 1 else 0 . Without a bias term, you are unable to vary the z in that if statement, it will be always stuck around 0. This is obviously very useful if you are trying to simulate conditional relationships .","title":"2.3 The bias"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#24#putting#together#the#structure","text":"Hopefully the previous explanations have given you a good overview of how a given node/neuron/perceptron in a neural network operates. However, as you are probably aware, there are many such interconnected nodes in a fully fledged\uff08\u6210\u719f\u7684\uff09 neural network. These structures can come in a myriad of different forms, but the most common simple neural network structure consists of an input layer , a hidden layer and an output layer . An example of such a structure can be seen below: Figure 10. Three layer neural network The three layers of the network can be seen in the above figure \u2013 Layer 1 represents the input layer , where the external input data enters the network. Layer 2 is called the hidden layer as this layer is not part of the input or output. Note: neural networks can have many hidden layers, but in this case for simplicity I have just included one. Finally, Layer 3 is the output layer . You can observe the many connections between the layers, in particular between Layer 1 (L1) and Layer 2 (L2). As can be seen, each node in L1 has a connection to all the nodes in L2. Likewise for the nodes in L2 to the single output node L3. Each of these connections will have an associated weight.","title":"2.4 Putting together the structure"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#25#the#notation","text":"The maths below requires some fairly precise notation so that we know what we are talking about. The notation I am using here is similar to that used in the Stanford deep learning tutorial. In the upcoming equations, each of these weights are identified with the following notation: {w_{ij}}^{(l)} {w_{ij}}^{(l)} . i i refers to the node number of the connection in layer l+1 l+1 and j j refers to the node number of the connection in layer l l . Take special note of this order. So, for the connection between node 1 in layer 1 and node 2 in layer 2, the weight notation would be {w_{21}}^{(1)} {w_{21}}^{(1)} . This notation may seem a bit odd, as you would expect the i and j to refer the node numbers in layers l l and l+1 l+1 respectively (i.e. in the direction of input to output), rather than the opposite. However, this notation makes more sense when you add the bias. As you can observe in the figure above \u2013 the (+1) bias is connected to each of the nodes in the subsequent layer. So the bias in layer 1 is connected to the all the nodes in layer two. Because the bias is not a true node with an activation function , it has no inputs (it always outputs the value +1). The notation of the bias weight is {b_i}^{(l)} {b_i}^{(l)} , where i is the node number in the layer l+1 l+1 \u2013 the same as used for the normal weight notation {w_{21}}^{(1)} {w_{21}}^{(1)} . So, the weight on the connection between the bias in layer 1 and the second node in layer 2 is given by {b_2}^{(1)} {b_2}^{(1)} . Remember, these values \u2013 {w_{ji}}^{(1)} {w_{ji}}^{(1)} and {b_i}^{(l)} {b_i}^{(l)} \u2013 all need to be calculated in the training phase of the ANN. Finally, the node output notation is {h_j}^{(l)} {h_j}^{(l)} , where j j denotes the node number in layer l l of the network. As can be observed in the three layer network above, the output of node 2 in layer 2 has the notation of {h_2}^{(2)} {h_2}^{(2)} . Now that we have the notation all sorted out, it is now time to look at how you calculate the output of the network when the input and the weights are known. The process of calculating the output of the neural network given these values is called the feed-forward pass or process.","title":"2.5 The notation"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#3#the#feed-forward#pass","text":"To demonstrate how to calculate the output from the input in neural networks, let\u2019s start with the specific case of the three layer neural network that was presented above. Below it is presented in equation form, then it will be demonstrated with a concrete example and some Python code: $$ \\begin{align} h_1^{(2)} &= f(w_{11}^{(1)}x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_1^{(1)}) \\ h_2^{(2)} &= f(w_{21}^{(1)}x_1 + w_{22}^{(1)} x_2 + w_{23}^{(1)} x_3 + b_2^{(1)}) \\ h_3^{(2)} &= f(w_{31}^{(1)}x_1 + w_{32}^{(1)} x_2 + w_{33}^{(1)} x_3 + b_3^{(1)}) \\ h_{W,b}(x) &= h_1^{(3)} = f(w_{11} {(2)}h_1 {(2)} + w_{12}^{(2)} h_2^{(2)} + w_{13}^{(2)} h_3^{(2)} + b_1^{(2)}) \\end{align} $$ SUMMARY : $$ \\begin{align} h_1^{(2)} &= f(w_{11}^{(1)}x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_1^{(1)}) \\ \\end{align} $$ \u7b2c\u4e00\u5c42\u8282\u70b91\u5230\u7b2c\u4e8c\u5c42\u8282\u70b91\uff0c\u7b2c\u4e00\u5c42\u8282\u70b92\u5230\u7b2c\u4e8c\u5c42\u8282\u70b91\uff0c\u7b2c\u4e00\u5c42\u8282\u70b93\u5230\u7b2c\u4e8c\u5c42\u8282\u70b91\uff1b In the equation above f(\\bullet) f(\\bullet) refers to the node activation function , in this case the sigmoid function. The first line, {h_1}^{(2)} {h_1}^{(2)} is the output of the first node in the second layer, and its inputs are w_{11}^{(1)} x_1 w_{11}^{(1)} x_1 w_{12}^{(1)} x_2 w_{12}^{(1)} x_2 w_{13}^{(1)} x_3 w_{13}^{(1)} x_3 and b_1^{(1)} b_1^{(1)} . These inputs can be traced in the three-layer connection diagram above. They are simply summed and then passed through the activation function to calculate the output of the first node. Likewise, for the other two nodes in the second layer. The final line is the output of the only node in the third and final layer, which is ultimate output of the neural network. As can be observed, rather than taking the weighted input variables ( x_1, x_2, x_3 x_1, x_2, x_3 ), the final node takes as input the weighted output of the nodes of the second layer ( h_{1}^{(1)} h_{1}^{(1)} , h_{2}^{(2)} h_{2}^{(2)} , h_{3}^{(3)} h_{3}^{(3)} ), plus the weighted bias. Therefore, you can see in equation form the hierarchical nature of artificial neural networks.","title":"3 The feed-forward pass"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#31#a#feed-forward#example","text":"Now, let\u2019s do a simple first example of the output of this neural network in Python. First things first, notice that the weights between layer 1 and 2 ( w_{11}^{(1)} w_{11}^{(1)} , w_{12}^{(1)} w_{12}^{(1)} ,\u2026) are ideally suited to matrix representation? Observe: $$ \\begin{equation} W^{(1)} = \\begin{pmatrix} w_{11}^{(1)} & w_{12}^{(1)} & w_{13}^{(1)} \\ w_{21}^{(1)} & w_{22}^{(1)} & w_{23}^{(1)} \\ w_{31}^{(1)} & w_{32}^{(1)} & w_{33}^{(1)} \\ \\end{pmatrix} \\end{equation} $$ This matrix can be easily represented using numpy arrays: import numpy as np w1 = np . array ([[ 0.2 , 0.2 , 0.2 ], [ 0.4 , 0.4 , 0.4 ], [ 0.6 , 0.6 , 0.6 ]]) Here I have just filled up the layer 1 weight array with some example weights. We can do the same for the layer 2 weight array: $$ \\begin{equation} W^{(2)} = \\begin{pmatrix} w_{11}^{(2)} & w_{12}^{(2)} & w_{13}^{(2)} \\end{pmatrix} \\end{equation} $$ w2 = np . zeros (( 1 , 3 )) w2 [ 0 ,:] = np . array ([ 0.5 , 0.5 , 0.5 ]) We can also setup some dummy values in the layer 1 bias weight array/vector, and the layer 2 bias weight (which is only a single value in this neural network structure \u2013 i.e. a scalar): b1 = np . array ([ 0.8 , 0.8 , 0.8 ]) b2 = np . array ([ 0.2 ]) Finally, before we write the main program to calculate the output from the neural network, it\u2019s handy to setup a separate Python function for the activation function : def f ( x ): return 1 / ( 1 + np . exp ( - x ))","title":"3.1 A feed-forward example"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#32#our#first#attempt#at#a#feed-forward#function","text":"Below is a simple way of calculating the output of the neural network, using nested loops in python. We\u2019ll look at more efficient ways of calculating the output shortly. def simple_looped_nn_calc ( n_layers , x , w , b ): for l in range ( n_layers - 1 ): #Setup the input array which the weights will be multiplied by for each layer #If it's the first layer, the input array will be the x input vector #If it's not the first layer, the input to the next layer will be the #output of the previous layer if l == 0 : node_in = x else : node_in = h #Setup the output array for the nodes in layer l + 1 h = np . zeros (( w [ l ] . shape [ 0 ],)) #loop through the rows of the weight array for i in range ( w [ l ] . shape [ 0 ]): #setup the sum inside the activation function f_sum = 0 #loop through the columns of the weight array for j in range ( w [ l ] . shape [ 1 ]): f_sum += w [ l ][ i ][ j ] * node_in [ j ] #add the bias f_sum += b [ l ][ i ] #finally use the activation function to calculate the #i-th output i.e. h1, h2, h3 h [ i ] = f ( f_sum ) return h This function takes as input the number of layers in the neural network, the x input array/vector, then Python tuples or lists of the weights and bias weights of the network, with each element in the tuple/list representing a layer ll in the network. In other words, the inputs are setup in the following: w = [ w1 , w2 ] b = [ b1 , b2 ] #a dummy x input vector x = [ 1.5 , 2.0 , 3.0 ] The function first checks what the input is to the layer of nodes/weights being considered. If we are looking at the first layer, the input to the second layer nodes is the input vector xx multiplied by the relevant weights. After the first layer though, the inputs to subsequent layers are the output of the previous layers. Finally, there is a nested loop through the relevant ii and jj values of the weight vectors and the bias. The function uses the dimensions of the weights for each layer to figure out the number of nodes and therefore the structure of the network. Calling the function: simple_looped_nn_calc ( 3 , x , w , b ) gives the output of 0.8354. We can confirm this results by manually performing the calculations in the original equations: $$ \\begin{align} h_1^{(2)} &= f(0.2*1.5 + 0.2*2.0 + 0.2*3.0 + 0.8) = 0.8909 \\ h_2^{(2)} &= f(0.4*1.5 + 0.4*2.0 + 0.4*3.0 + 0.8) = 0.9677 \\ h_3^{(2)} &= f(0.6*1.5 + 0.6*2.0 + 0.6*3.0 + 0.8) = 0.9909 \\ h_{W,b}(x) &= h_1^{(3)} = f(0.5*0.8909 + 0.5*0.9677 + 0.5*0.9909 + 0.2) = 0.8354 \\end{align} $$","title":"3.2 Our first attempt at a feed-forward function"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#33#a#more#efficient#implementation","text":"As was stated earlier \u2013 using loops isn\u2019t the most efficient way of calculating the feed forward step in Python. This is because the loops in Python are notoriously slow. An alternative, more efficient mechanism of doing the feed forward step in Python and numpy will be discussed shortly. We can benchmark how efficient the algorithm is by using the %timeit function in IPython, which runs the function a number of times and returns the average time that the function takes to run: % timeit simple_looped_nn_calc ( 3 , x , w , b ) Running this tells us that the looped feed forward takes 40\\mu s 40\\mu s . A result in the tens of microseconds sounds very fast, but when applied to very large practical NNs with 100s of nodes per layer, this speed will become prohibitive, especially when training the network, as will become clear later in this tutorial. If we try a four layer neural network using the same code, we get significantly worse performance \u2013 70\\mu s 70\\mu s in fact.","title":"3.3 A more efficient implementation"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#34#vectorisation#in#neural#networks","text":"There is a way to write the equations even more compactly, and to calculate the feed forward process in neural networks more efficiently, from a computational perspective. Firstly, we can introduce a new variable z_{i}^{(l)} z_{i}^{(l)} which is the summated input into node i i of layer l l , including the bias term. So in the case of the first node in layer 2, z z is equal to: $$ z_{1}^{(2)} = w_{11}^{(1)}x_1 + w_{12}^{(1)} x_2 + w_{13}^{(1)} x_3 + b_1^{(1)} = \\sum_{j=1}^{n} w_{ij}^{(1)}x_i + b_{i}^{(1)} $$ where n is the number of nodes in layer 1. Using this notation, the unwieldy previous set of equations for the example three layer network can be reduced to: \\begin{align} z^{(2)} &= W^{(1)} x + b^{(1)} \\\\ h^{(2)} &= f(z^{(2)}) \\\\ z^{(3)} &= W^{(2)} h^{(2)} + b^{(2)} \\\\ h_{W,b}(x) &= h^{(3)} = f(z^{(3)}) \\end{align} \\begin{align} z^{(2)} &= W^{(1)} x + b^{(1)} \\\\ h^{(2)} &= f(z^{(2)}) \\\\ z^{(3)} &= W^{(2)} h^{(2)} + b^{(2)} \\\\ h_{W,b}(x) &= h^{(3)} = f(z^{(3)}) \\end{align}","title":"3.4 Vectorisation in neural networks"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#4#gradient#descent#and#optimisation","text":"","title":"4 Gradient descent and optimisation"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#41#a#simple#example#in#code","text":"Below is an example of a simple Python implementation of gradient descent for solving the minimum of the equation f(x) = x^4 \u2013 3x^3 + 2 f(x) = x^4 \u2013 3x^3 + 2 taken from Wikipedia. The gradient of this function is able to be calculated analytically (i.e. we can do it easily using calculus, which we can\u2019t do with many real world applications) and is f'(x) = 4x^3 \u2013 9x^2 f'(x) = 4x^3 \u2013 9x^2 . This means at every value of xx, we can calculate the gradient of the function by using a simple equation. Again, using calculus we can know that the exact minimum of this equation is x=2.25 x=2.25 . Previously, we\u2019ve talked about iteratively minimising the error of the output of the neural network by varying the weights in gradient descent . However, as it turns out, there is a mathematically more generalised way of looking at things that allows us to reduce the error while also preventing things like overfitting (this will be discussed more in later articles). This more general optimisation formulation revolves around minimising what\u2019s called the cost function . The equivalent cost function of a single training pair ( x^z x^z , y^z y^z ) in a neural network is: x_old = 0 # The value does not matter as long as abs(x_new - x_old) > precision x_new = 6 # The algorithm starts at x=6 gamma = 0.01 # step size precision = 0.00001 def df ( x ): y = 4 * x ** 3 - 9 * x ** 2 return y while abs ( x_new - x_old ) > precision : x_old = x_new x_new += - gamma * df ( x_old ) print ( \"The local minimum occurs at %f \" % x_new ) This function prints \u201cThe local minimum occurs at 2.249965\u201d, which agrees with the exact solution within the precision. This code implements the weight adjustment algorithm that I showed above, and can be seen to find the minimum of the function correctly within the given precision. This is a very simple example of gradient descent , and finding the gradient works quite differently when training neural networks . However, the main idea remains \u2013 we figure out the gradient of the neural network then adjust the weights in a step to try to get closer to the minimum error that we are trying to find. Another difference between this toy example of gradient descent is that the weight vector is multi-dimensional, and therefore the gradient descent method must search a multi-dimensional space for the minimum point. The way we figure out the gradient of a neural network is via the famous backpropagation method, which will be discussed shortly. First however, we have to look at the error function more closely.","title":"4.1 A simple example in code"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#42#the#cost#function","text":"","title":"4.2 The cost function"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#43#gradient#descent#in#neural#networks","text":"Gradient descent for every weight w_{(ij)}^{(l)} w_{(ij)}^{(l)} and every bias b_i^{(l)} b_i^{(l)} in the neural network looks like the following: $$ \\begin{align} w_{ij}^{(l)} &= w_{ij}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial w_{ij}^{(l)}} J(w,b) \\ b_{i}^{(l)} &= b_{i}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial b_{i}^{(l)}} J(w,b) \\end{align} $$ Basically, the equation above is similiar to the previously shown gradient descent algorithm: w_{new} = w_{old} \u2013 \\alpha * \\nabla error w_{new} = w_{old} \u2013 \\alpha * \\nabla error . The new and old subscripts are missing, but the values on the left side of the equation are new and the values on the right side are old . Again, we have an iterative process whereby the weights are updated in each iteration, this time based on the cost function J(w,b) J(w,b) . The values \\frac{\\partial}{\\partial w_{ij}^{(l)}} \\frac{\\partial}{\\partial w_{ij}^{(l)}} and \\frac{\\partial}{\\partial b_{i}^{(l)}} \\frac{\\partial}{\\partial b_{i}^{(l)}} are the partial derivatives of the single sample cost function based on the weight values. What does this mean? Recall that for the simple gradient descent example mentioned previously, each step depends on the slope of the error/cost term with respect to the weights. Another word for slope or gradient is the derivative . A normal derivative has the notation \\frac{d}{dx} \\frac{d}{dx} . If x x in this instance is a vector, then such a derivative will also be a vector, displaying the gradient in all the dimensions of x x .","title":"4.3 Gradient descent in neural networks"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#44#a#two#dimensional#gradient#descent#example","text":"","title":"4.4 A two dimensional gradient descent example"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#45#backpropagation#in#depth","text":"In this section, I\u2019m going to delve into the maths a little. If you\u2019re wary of the maths of how backpropagation works, then it may be best to skip this section. The next section will show you how to implement backpropagation in code \u2013 so if you want to skip straight on to using this method, feel free to skip the rest of this section. However, if you don\u2019t mind a little bit of maths, I encourage you to push on to the end of this section as it will give you a good depth of understanding in training neural networks. This will be invaluable to understanding some of the key ideas in deep learning, rather than just being a code cruncher who doesn\u2019t really understand how the code works. SUMMARY : neural network\u7684training\uff1b First let\u2019s recall some of the foundational equations from Section 3 for the following three layer neural network: Figure 10. Three layer neural network (again) The output of this neural network can be calculated by: $$ \\begin{equation} h_{W,b}(x) = h_1^{(3)} = f(w_{11} {(2)}h_1 {(2)} + w_{12}^{(2)} h_2^{(2)} + w_{13}^{(2)} h_3^{(2)} + b_1^{(2)}) \\end{equation} $$ We can also simplify the above to h_1^{(3)} = f(z_1^{(2)}) h_1^{(3)} = f(z_1^{(2)}) by defining z_1^{(2)} z_1^{(2)} as: $$ z_{1}^{(2)} = w_{11} {(2)}h_1 {(2)} + w_{12}^{(2)} h_2^{(2)} + w_{13}^{(2)} h_3^{(2)} + b_1^{(2)} $$ SUMMARY : z_1^{(2)} z_1^{(2)} \u8868\u793a\u7684\u662f\u7b2c2\u5c42\u8f93\u5165\u5230\u7b2c2+1\u5c42\u7684\u7b2c1\u4e2a\u8282\u70b9\u7684sum\uff1b Let\u2019s say we want to find out how much a change in the weight w_{12}^{(2)} w_{12}^{(2)} has on the cost function J J . This is to evaluate \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} . To do so, we have to use something called the chain function: $$ \\frac {\\partial J}{\\partial w_{12}^{(2)}} = \\frac {\\partial J}{\\partial h_1^{(3)}} \\frac {\\partial h_1^{(3)}}{\\partial z_1^{(2)}} \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} $$ SUMMARY : \u5982\u679c\u6709\u591a\u5c42\u9690\u85cf\u5c42\u7684\u8bdd\uff0c\u4e0a\u8ff0\u516c\u5f0f\u662f\u5426\u4f9d\u7136\u9002\u7528\uff1f If you look at the terms on the right \u2013 the numerators \u201ccancel out\u201d the denominators, in the same way that \\frac {2}{5} \\frac {5}{2} = \\frac {2}{2} = 1 \\frac {2}{5} \\frac {5}{2} = \\frac {2}{2} = 1 . Therefore we can construct \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} by stringing together a few partial derivatives (which are quite easy, thankfully). Let\u2019s start with \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} $$ \\begin{align} \\frac {\\partial z_1^{(2)}}{\\partial w_{12}^{(2)}} &= \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{11} {(1)}h_1 {(2)} + w_{12}^{(1)} h_2^{(2)} + w_{13}^{(1)} h_3^{(2)} + b_1^{(1)})\\ &= \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{12}^{(1)} h_2^{(2)})\\ &= h_2^{(2)} \\end{align} $$ The partial derivative of z_1^{(2)} z_1^{(2)} with respect w_{12}^{(2)} w_{12}^{(2)} only operates on one term within the parentheses, w_{12}^{(1)} h_2^{(2)} w_{12}^{(1)} h_2^{(2)} , as all the other terms don\u2019t vary at all when w_{12}^{(2)} w_{12}^{(2)} does. The derivative of a constant is 1, therefore \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{12}^{(1)} h_2^{(2)}) \\frac {\\partial}{\\partial w_{12}^{(2)}} (w_{12}^{(1)} h_2^{(2)}) collapses to just h_2^{(2)} h_2^{(2)} , which is simply the output of the second node in layer 2. The next partial derivative in the chain is \\frac {\\partial h_1^{(3)}}{\\partial z_1^{(2)}} \\frac {\\partial h_1^{(3)}}{\\partial z_1^{(2)}} , which is the partial derivative of the activation function of the h_1^{(3)} h_1^{(3)} output node . Because of the requirement to be able to derive this derivative, the activation functions in neural networks need to be differentiable . For the common sigmoid activation function (shown in Section 2.1 ), the derivative is: $$ \\frac {\\partial h}{\\partial z} = f'(z) = f(z)(1-f(z)) $$ Where f(z) f(z) is the activation function. So far so good \u2013 now we have to work out how to deal with the first term \\frac {\\partial J}{\\partial h_1^{(3)}} \\frac {\\partial J}{\\partial h_1^{(3)}} . Remember that J(w,b,x,y) J(w,b,x,y) is the mean squared error loss function, which looks like (for our case): $$ J(w,b,x,y) = \\frac{1}{2} \\parallel y_1 \u2013 h_1 {(3)}(z_1 {(2)}) \\parallel ^2 $$ Here y_1 y_1 is the training target for the output node . Again using the chain rule: $$ \\begin{align} &Let u = \\parallel y_1 \u2013 h_1 {(3)}(z_1 {(2)}) \\parallel and J = \\frac {1}{2} u^2\\ &Using \\frac {\\partial J}{\\partial h} = \\frac {\\partial J}{\\partial u} \\frac {\\partial u}{\\partial h}:\\ &\\frac {\\partial J}{\\partial h} = -(y_1 \u2013 h_1^{(3)}) \\end{align} $$ SUMMARY : \u4e0a\u8ff0\u63a8\u5bfc\u5e76\u6ca1\u6709\u641e\u6e05\u695a\uff1b So we\u2019ve now figured out how to calculate \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} , at least for the weights connecting the output layer . Before we move to any hidden layers (i.e. layer 2 in our example case), let\u2019s introduce some simplifications to tighten up our notation and introduce \\delta \\delta : $$ \\delta_i^{(n_l)} = -(y_i \u2013 h_i^{(n_l)})\\cdot f \\prime(z_i {(n_l)}) $$ Where i i is the node number of the output layer . SUMMARY : \\delta_i^{(n_l)} \\delta_i^{(n_l)} \u4e2d\u5305\u542b z_i^{(n_l)} z_i^{(n_l)} In our selected example there is only one such layer, therefore i=1 i=1 always in this case. Now we can write the complete cost function derivative as: $$ \\begin{align} \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b,x, y) &= h^{(l)}_j \\delta_i^{(l+1)} \\ \\end{align} $$ Where, for the output layer in our case, l l = 2 and i i remains the node number. SUMMARY : \u8fd9\u662f\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u94fe\u5f0f\u6cd5\u5219\u7684\u901a\u7528\u5f62\u5f0f\uff1b\u4ee5\u5f00\u5934\u6240\u63d0\u51fa\u7684\u95ee\u9898\uff1aLet\u2019s say we want to find out how much a change in the weight w_{12}^{(2)} w_{12}^{(2)} has on the cost function J J . This is to evaluate \\frac {\\partial J}{\\partial w_{12}^{(2)}} \\frac {\\partial J}{\\partial w_{12}^{(2)}} . \u4f7f\u7528\u4e0a\u8ff0\u516c\u5f0f\u6765\u770b\u7684\u8bdd\uff0c \\frac {\\partial J}{\\partial w_{12}^{(2)}}= h^{(2)}_2 \\delta_1^{(2+1)} \\frac {\\partial J}{\\partial w_{12}^{(2)}}= h^{(2)}_2 \\delta_1^{(2+1)} . h^{(2)}_2 h^{(2)}_2 \u8868\u793a\u7b2c2\u5c42\u7b2c2\u4e2a\u8282\u70b9\u7684\u8f93\u51fa\u503c\uff1b \\delta_1^{(2+1)} \\delta_1^{(2+1)} \uff0c w_{12}^{(2)} w_{12}^{(2)} \u662f\u7b2c2\u5c42\u7684\u8282\u70b92\u4e0e\u7b2c\u4e09\u5c42\u7684\u8282\u70b91\u4e4b\u95f4\u7684\u8fde\u63a5\u6743\u91cd\uff1b","title":"4.5 Backpropagation in depth"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#46#propagating#into#the#hidden#layers","text":"What about for weights feeding into any hidden layers (layer 2 in our case)? For the weights connecting the output layer , the \\frac {\\partial J}{\\partial h} = -(y_i \u2013 h_i^{(n_l)}) \\frac {\\partial J}{\\partial h} = -(y_i \u2013 h_i^{(n_l)}) derivative made sense, as the cost function can be directly calculated by comparing the output layer to the training data . The output of the hidden nodes, however, have no such direct reference, rather, they are connected to the cost function only through mediating weights and potentially other layers of nodes. How can we find the variation in the cost function from changes to weights embedded deep within the neural network? As mentioned previously, we use the backpropagation method. SUMMARY : \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\u5982\u4f55\u6765\u8ba1\u7b97\u8c03\u6574\u8f93\u5165\u5230hidden layer\u7684weight\u5bf9cost function\u7684\u5f71\u54cd\uff1b\u5982\u679c\u4ee5\u4e0a\u8ff0\u4e09\u5c42\u795e\u7ecf\u7f51\u7edc\u4e3a\u4f8b\u7684\u8bdd\uff0c\u6b64\u5904\u7684weight\u5c31\u662finput layer\u5230hidden layer\u7684weight\uff1b\u5bf9\u4e8e\u8fd9\u79cdweigh\u800c\u8a00\uff0c\u56e0\u4e3a\u5b83\u4eec\u5e76\u4e0d\u662f\u76f4\u63a5\u8fde\u63a5\u5230\u8f93\u51fa\u5c42\uff0c\u6240\u4ee5\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528comparing the output layer to the training data . \u90a3\u5982\u4f55\u6765\u8ba1\u7b97\u90a3\u4e9b\u6539\u53d8\u90a3\u4e9b\u4e0d\u662f\u76f4\u63a5\u8fde\u63a5\u5230\u8f93\u51fa\u5c42\u800c\u662f\u5d4c\u5165\u5730\u6bd4\u8f83\u6df1\u7684\u5c42\u7684\u8282\u70b9\u7684\u6743\u91cd\u5bf9neural network\u7684\u5f71\u54cd\u5462\uff1f\u6b64\u5904\u5c31\u9700\u8981\u4f7f\u7528backpropagation\uff1b SUMMARY : \u4e0a\u8ff0\u7ed9\u51fa\u4e86backpropagation\u7684\u4ef7\u503c\u6240\u5728 Now that we\u2019ve done the hard work using the chain rule , we\u2019ll now take a more graphical approach. The term that needs to propagate back through the network is the \\delta_i^{(n_l)} \\delta_i^{(n_l)} term, as this is the network\u2019s ultimate connection to the cost function . What about node j in the second layer (hidden layer)? How does it contribute to \\delta_i^{(n_l)} \\delta_i^{(n_l)} in our test network? It contributes via the weight w_{ij}^{(2)} w_{ij}^{(2)} \u2013 see the diagram below for the case of j=1 j=1 and i=1 i=1 . Figure 11. Simple backpropagation illustration SUMMARY : \u4e0a\u56fe\u4e2d\uff0c\u6bd4\u8f83\u6a21\u7cca\u7684\u516c\u5f0f\u662f\uff1a $$ \\delta_i^{(2)} = \\delta_i^{(3)} w_{11}^{(2)} $$ As can be observed from above, the output layer \u03b4 \u03b4 is communicated to the hidden node by the weight of the connection. In the case where there is only one output layer node, the generalised hidden layer \u03b4 \u03b4 is defined as: $$ \\delta_j^{(l)} = \\delta_1^{(l+1)} w_{1j} {(l)} f \\prime(z_j)^{(l)} $$ SUMMARY : \u8fd9\u662f\u4e00\u4e2a\u9012\u5f52\u5173\u7cfb\uff0c\u95ee\u9898\u662f\u8fd9\u4e2a\u9012\u5f52\u5173\u7cfb\u662f\u5982\u4f55\u5f97\u5230\u7684\uff1f Where j j is the node number in layer l l . What about the case where there are multiple output nodes? In this case, the weighted sum of all the communicated errors are taken to calculate \\delta_j^{(l)} \\delta_j^{(l)} , as shown in the diagram below: Figure 12. Backpropagation illustration with multiple outputs SUMMARY : \u4e0a\u56fe\u4e2d\uff0c\u6bd4\u8f83\u6a21\u7cca\u7684\u516c\u5f0f\u662f\uff1a $$ \\delta_1^{(2)} = (\\sum_{i=1}^{3} w_{i1}^{(2)} \\delta_i {(3)}) f \\prime(z_i^{(2)}) $$ As can be observed from the above, each \\delta \\delta value from the output layer is included in the sum used to calculate \\delta_1^{(2)} \\delta_1^{(2)} , but each output \\delta \\delta is weighted according to the appropriate w_{i1}^{(2)} w_{i1}^{(2)} value. In other words, node 1 in layer 2 contributes to the error of three output nodes, therefore the measured error (or cost function value ) at each of these nodes has to be \u201c passed back \u201d\uff08\u4f20\u56de\uff09 to the \\delta \\delta value for this node. Now we can develop a generalised expression for the \\delta \\delta values for nodes in the hidden layers: $$ \\delta_j^{(l)} = (\\sum_{i=1}^{s_{(l+1)}} w_{ij}^{(l)} \\delta_i {(l+1)}) f \\prime(z_j^{(l)}) $$ Where j j is the node number in layer l l and i i is the node number in layer l+1 l+1 (which is the same notation we have used from the start). The value s_{(l+1)} s_{(l+1)} is the number of nodes in layer (l+1) (l+1) . SUMMARY : \u4e0a\u5f0f\u662f\u9012\u5f52\u516c\u5f0f\uff0c\u5728Wikipedia\u7684 Backpropagation \u6709\u76f8\u5e94\u7684\u4ecb\u7ecd\uff1b So we now know how to calculate: $$ \\frac{\\partial}{\\partial W_{ij}^{(l)}} J(W,b,x, y) = h^{(l)}_j \\delta_i^{(l+1)} $$ SUMMARY : \u6839\u636e\u8be5\u516c\u5f0f\u5c31\u53ef\u4ee5\u5f97\u5230\u8c03\u6574\u4efb\u610f\u7684 W_{ij}^{(l)} W_{ij}^{(l)} \u5bf9cost function\u7684\u5f71\u54cd\uff1b as shown previously. What about the bias weights ? I\u2019m not going to derive them as I did with the normal weights in the interest of saving time / space. However, the reader shouldn\u2019t have too many issues following the same steps, using the chain rule, to arrive at: $$ \\frac{\\partial}{\\partial b_{i}^{(l)}} J(W,b,x, y) = \\delta_i^{(l+1)} $$ Great \u2013 so we now know how to perform our original gradient descent problem for neural networks: $$ \\begin{align} w_{ij}^{(l)} &= w_{ij}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial w_{ij}^{(l)}} J(w,b) \\ b_{i}^{(l)} &= b_{i}^{(l)} \u2013 \\alpha \\frac{\\partial}{\\partial b_{i}^{(l)}} J(w,b) \\end{align} $$ However, to perform this gradient descent training of the weights, we would have to resort to loops within loops. As previously shown in Section 3.4 of this neural network tutorial, performing such calculations in Python using loops is slow for large networks. Therefore, we need to figure out how to vectorise such calculations, which the next section will show.","title":"4.6 Propagating into the hidden layers"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#48#implementing#the#gradient#descent#step","text":"","title":"4.8 Implementing the gradient descent step"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#49#the#final#gradient#descent#algorithm","text":"","title":"4.9 The final gradient descent algorithm"},{"location":"Theory/Deep-learning/Guide/Tutorial/Neural-Networks-Tutorial/#5#implementing#the#neural#network#in#python","text":"","title":"5 Implementing the neural network in Python"},{"location":"Theory/Deep-learning/Guide/Tutorial/ujjwalkarn-A-Quick-Introduction-to-Neural-Networks/","text":"A Quick Introduction to Neural Networks","title":"ujjwalkarn-A-Quick-Introduction-to-Neural-Networks"},{"location":"Theory/Deep-learning/Guide/Tutorial/ujjwalkarn-A-Quick-Introduction-to-Neural-Networks/#a#quick#introduction#to#neural#networks","text":"","title":"A Quick Introduction to Neural Networks"},{"location":"Theory/Feature-engineering/Data-transformation%28statistics%29/","text":"Data transformation (statistics) Category:Statistical data transformation Data transformation (statistics) Category:Statistical data transformation","title":"Data-transformation(statistics)"},{"location":"Theory/Feature-engineering/Data-transformation%28statistics%29/#data#transformation#statistics","text":"","title":"Data transformation (statistics)"},{"location":"Theory/Feature-engineering/Data-transformation%28statistics%29/#categorystatistical#data#transformation","text":"","title":"Category:Statistical data transformation"},{"location":"Theory/Feature-engineering/Feature-scaling/","text":"Feature scaling Motivation Methods Rescaling (min-max normalization) Mean normalization Standardization (Z-score Normalization) Scaling to unit length Application Feature scaling Feature scaling is a method used to normalize\uff08\u6b63\u89c4\u5316\uff0c\u6807\u51c6\u5316\uff09 the range of independent variables or features of data. In data processing , it is also known as data normalization and is generally performed during the data preprocessing step. Motivation Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization . For example, many classifiers calculate the distance between two points by the Euclidean distance . If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance. Another reason why feature scaling is applied is that gradient descent converges much faster with feature scaling than without it.[ 1] Methods Rescaling (min-max normalization) Also known as min-max scaling or min-max normalization, is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [\u22121, 1]. Selecting the target range depends on the nature of the data. The general formula for a min-max of [0, 1] is given as: $ x'={\\frac {x-{\\text{min}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}} $ where $ x $ is an original value, $ x' $ is the normalized value. For example, suppose that we have the students' weight data, and the students' weights span [160 pounds, 200 pounds]. To rescale this data, we first subtract 160 from each student's weight and divide the result by 40 (the difference between the maximum and minimum weights). To rescale a range between an arbitrary set of values [a, b], the formula becomes: $ x'=a+{\\frac {(x-{\\text{min}}(x))(b-a)}{{\\text{max}}(x)-{\\text{min}}(x)}} $ where $ a,b $ are the min-max values. Mean normalization $ x'={\\frac {x-{\\text{average}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}} $ where $ x $ is an original value, $ x' $ is the normalized value. There is another form of the mean normalization which is when we divide by the standard deviation which is also called standardization. Standardization (Z-score Normalization) In machine learning, we can handle various types of data, e.g. audio signals and pixel values for image data, and this data can include multiple dimensions . Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance . This method is widely used for normalization in many machine learning algorithms (e.g., support vector machines , logistic regression , and artificial neural networks )[ 2] [ citation needed ]. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation\uff08\u6807\u51c6\u5dee\uff09. $ x'={\\frac {x-{\\bar {x}}}{\\sigma }} $ Where $ x $ is the original feature vector, $ {\\bar {x}}={\\text{average}}(x) $ is the mean of that feature vector, and $ \\sigma $ is its standard deviation. Scaling to unit length Another option that is widely used in machine-learning is to scale the components of a feature vector such that the complete vector has length one. This usually means dividing each component by the Euclidean length of the vector: $ x'={\\frac {x}{\\left|{x}\\right|}} $ In some applications (e.g. Histogram features) it can be more practical to use the L1 norm (i.e. Manhattan Distance, City-Block Length or Taxicab Geometry ) of the feature vector. This is especially important if in the following learning steps the Scalar Metric is used as a distance measure. Application In stochastic gradient descent , feature scaling can sometimes improve the convergence speed of the algorithm[ 2] [ citation needed ]. In support vector machines,[ 3] it can reduce the time to find support vectors. Note that feature scaling changes the SVM result[ citation needed ].","title":"Feature-scaling"},{"location":"Theory/Feature-engineering/Feature-scaling/#feature#scaling","text":"Feature scaling is a method used to normalize\uff08\u6b63\u89c4\u5316\uff0c\u6807\u51c6\u5316\uff09 the range of independent variables or features of data. In data processing , it is also known as data normalization and is generally performed during the data preprocessing step.","title":"Feature scaling"},{"location":"Theory/Feature-engineering/Feature-scaling/#motivation","text":"Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization . For example, many classifiers calculate the distance between two points by the Euclidean distance . If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance. Another reason why feature scaling is applied is that gradient descent converges much faster with feature scaling than without it.[ 1]","title":"Motivation"},{"location":"Theory/Feature-engineering/Feature-scaling/#methods","text":"","title":"Methods"},{"location":"Theory/Feature-engineering/Feature-scaling/#rescaling#min-max#normalization","text":"Also known as min-max scaling or min-max normalization, is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [\u22121, 1]. Selecting the target range depends on the nature of the data. The general formula for a min-max of [0, 1] is given as: $ x'={\\frac {x-{\\text{min}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}} $ where $ x $ is an original value, $ x' $ is the normalized value. For example, suppose that we have the students' weight data, and the students' weights span [160 pounds, 200 pounds]. To rescale this data, we first subtract 160 from each student's weight and divide the result by 40 (the difference between the maximum and minimum weights). To rescale a range between an arbitrary set of values [a, b], the formula becomes: $ x'=a+{\\frac {(x-{\\text{min}}(x))(b-a)}{{\\text{max}}(x)-{\\text{min}}(x)}} $ where $ a,b $ are the min-max values.","title":"Rescaling (min-max normalization)"},{"location":"Theory/Feature-engineering/Feature-scaling/#mean#normalization","text":"$ x'={\\frac {x-{\\text{average}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}} $ where $ x $ is an original value, $ x' $ is the normalized value. There is another form of the mean normalization which is when we divide by the standard deviation which is also called standardization.","title":"Mean normalization"},{"location":"Theory/Feature-engineering/Feature-scaling/#standardization#z-score#normalization","text":"In machine learning, we can handle various types of data, e.g. audio signals and pixel values for image data, and this data can include multiple dimensions . Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance . This method is widely used for normalization in many machine learning algorithms (e.g., support vector machines , logistic regression , and artificial neural networks )[ 2] [ citation needed ]. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation\uff08\u6807\u51c6\u5dee\uff09. $ x'={\\frac {x-{\\bar {x}}}{\\sigma }} $ Where $ x $ is the original feature vector, $ {\\bar {x}}={\\text{average}}(x) $ is the mean of that feature vector, and $ \\sigma $ is its standard deviation.","title":"Standardization (Z-score Normalization)"},{"location":"Theory/Feature-engineering/Feature-scaling/#scaling#to#unit#length","text":"Another option that is widely used in machine-learning is to scale the components of a feature vector such that the complete vector has length one. This usually means dividing each component by the Euclidean length of the vector: $ x'={\\frac {x}{\\left|{x}\\right|}} $ In some applications (e.g. Histogram features) it can be more practical to use the L1 norm (i.e. Manhattan Distance, City-Block Length or Taxicab Geometry ) of the feature vector. This is especially important if in the following learning steps the Scalar Metric is used as a distance measure.","title":"Scaling to unit length"},{"location":"Theory/Feature-engineering/Feature-scaling/#application","text":"In stochastic gradient descent , feature scaling can sometimes improve the convergence speed of the algorithm[ 2] [ citation needed ]. In support vector machines,[ 3] it can reduce the time to find support vectors. Note that feature scaling changes the SVM result[ citation needed ].","title":"Application"},{"location":"Theory/Feature-engineering/Normalization%28statistics%29/","text":"Normalization (statistics) Normalization (statistics)","title":"Normalization(statistics)"},{"location":"Theory/Feature-engineering/Normalization%28statistics%29/#normalization#statistics","text":"","title":"Normalization (statistics)"},{"location":"Theory/Machine-learning/","text":"\u5173\u4e8e\u672c\u7ae0 machine learning\u7684\u4e00\u4e9bmodel\u3002","title":"Introduction"},{"location":"Theory/Machine-learning/#_1","text":"machine learning\u7684\u4e00\u4e9bmodel\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"Theory/Machine-learning/CRF/crf/","text":"CRF Performing Sequence Labelling using CRF in Python \u7ef4\u57fa\u767e\u79d1 Conditional random field","title":"CRF"},{"location":"Theory/Machine-learning/CRF/crf/#crf","text":"","title":"CRF"},{"location":"Theory/Machine-learning/CRF/crf/#performing#sequence#labelling#using#crf#in#python","text":"","title":"Performing Sequence Labelling using CRF in Python"},{"location":"Theory/Machine-learning/CRF/crf/#conditional#random#field","text":"","title":"\u7ef4\u57fa\u767e\u79d1Conditional random field"},{"location":"Theory/Machine-learning/CRF/paper-Conditional-Random-Fields-Probabilistic-Models/","text":"Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data","title":"paper Conditional Random Fields Probabilistic Models"},{"location":"Theory/Machine-learning/CRF/paper-Conditional-Random-Fields-Probabilistic-Models/#conditional#random#fields#probabilistic#models#for#segmenting#and#labeling#sequence#data","text":"","title":"Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"},{"location":"Theory/Machine-learning/Markov-model/Forward-algorithm/","text":"Forward algorithm Forward algorithm","title":"Forward-algorithm"},{"location":"Theory/Machine-learning/Markov-model/Forward-algorithm/#forward#algorithm","text":"","title":"Forward algorithm"},{"location":"Theory/Machine-learning/Markov-model/Hidden-Markov-model/","text":"Hidden Markov model","title":"Hidden-Markov-model"},{"location":"Theory/Machine-learning/Markov-model/Hidden-Markov-model/#hidden#markov#model","text":"","title":"Hidden Markov model"},{"location":"Theory/Machine-learning/Markov-model/Markov-chain/","text":"Markov chain","title":"Markov-chain"},{"location":"Theory/Machine-learning/Markov-model/Markov-models/","text":"Category:Markov models Category:Markov models","title":"Markov-models"},{"location":"Theory/Machine-learning/Markov-model/Markov-models/#categorymarkov#models","text":"","title":"Category:Markov models"},{"location":"Theory/Machine-learning/Markov-model/Viterbi-algorithm/","text":"Viterbi algorithm application Viterbi algorithm application jieba","title":"Viterbi-algorithm"},{"location":"Theory/Machine-learning/Markov-model/Viterbi-algorithm/#viterbi#algorithm","text":"","title":"Viterbi algorithm"},{"location":"Theory/Machine-learning/Markov-model/Viterbi-algorithm/#application","text":"jieba","title":"application"},{"location":"draft/20180820/","text":"english Decouple \u89e3\u8026 machine learning decision tree The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. The deeper the tree, the more complex the decision rules and the fitter the model.\u5f80\u5f80\u662f\u6811\u8d8a\u6df1\uff0c\u5219decision rule\u8d8a\u590d\u6742\uff0c\u4e14\u62df\u5408\u6548\u679c\u8d8a\u597d\u3002 \u51b3\u7b56\u6811\u7684\u4e00\u4e9b\u7f3a\u70b9disadvantage \u5bb9\u6613\u8fc7\u62df\u5408 Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting . Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.\u901a\u8fc7\u526a\u679d\u3001\u9650\u5236\u6bcf\u4e2a\u53f6\u5b50\u8282\u70b9\u7684sample\u7684\u4e2a\u6570\u3001\u6811\u7684\u6df1\u5ea6\u6765\u9632\u6b62**overfitting**\u3002 - \u4e0d\u7a33\u5b9a Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This problem is mitigated\uff08\u51cf\u8f7b\uff09 by using decision trees within an ensemble.\u901a\u8fc7ensemble\u65b9\u6cd5\u6765\u51cf\u8f7b\u51b3\u7b56\u6811\u7684\u4e0d\u7a33\u5b9a\u6027 \u65e0\u6cd5\u8fbe\u5230\u5168\u5c40\u6700\u4f18 The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. Consequently, practical decision-tree learning algorithms are based on heuristic algorithms such as the greedy algorithm where locally optimal decisions are made at each node. Such algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.\u51b3\u7b56\u6811\u91c7\u7528\u7684\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u8fbe\u5230\u5168\u5c40\u6700\u4f18\u3002\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528ensemble\u65b9\u6cd5\u6765\u51cf\u8f7b\u6b64\u95ee\u9898\u3002 - \u65e0\u6cd5\u5904\u7406\u6570\u636e\u4e0d\u5747\u8861\u95ee\u9898 Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree.\u5f53\u67d0\u4e2a\u7c7b\u522b\u7684sample\u5360\u6bd4\u8f83\u9ad8\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u5bfc\u81f4\u521b\u5efa\u7684\u6811\u51fa\u73b0\u504f\u5dee\uff0c\u6240\u4ee5\u5728\u62df\u5408\u4e4b\u524d\u6700\u597d\u5148balance\u4e00\u4e0bdataset \u5bf9\u4e8e\u8fde\u7eed\u578b\u53d8\u91cf\uff0c\u51b3\u7b56\u6811\u5982\u4f55\u6765\u8fdb\u884c\u5212\u5206\uff1f\uff1f \u73b0\u5728\u770b\u6765\u8fd9\u4e2a\u95ee\u9898\u548c\u4e0b\u9762\u7684 in machine learning how to add discrete label to continuous data \u6709\u4e9b\u63a5\u8fd1\uff0c\u90fd\u662f\u5bf9\u8fde\u7eed\u578b\u53d8\u91cf\u8fdb\u884c\u5212\u5206\u7684\u3002\u663e\u7136\u4e24\u8005\u4f7f\u7528\u7684\u7b97\u6cd5\u662f\u4e0d\u76f8\u540c\u7684\u3002 Tips on practical use Decision trees tend to overfit on data with a large number of features. Getting the right ratio of samples to number of features is important, since a tree with few samples in high dimensional space is very likely to overfit. Consider performing dimensionality reduction (PCA, ICA, or Feature selection) beforehand to give your tree a better chance of finding features that are discriminative(\u6709\u8bc6\u522b\u529b\u7684). Balance your dataset before training to prevent the tree from being biased toward the classes that are dominant . Class balancing can be done by sampling an equal number of samples from each class, or preferably by normalizing the sum of the sample weights (sample_weight) for each class to the same value. Also note that weight-based pre-pruning criteria, such as min_weight_fraction_leaf, will then be less biased toward dominant classes than criteria that are not aware of the sample weights, like min_samples_leaf. in machine learning how to add discrete label to continuous data \u521a\u521a\u4f7f\u7528 in machine learning how to add discrete label to continuous data \u641c\u7d22\u4e86\u4e00\u4e0b\uff0c\u53d1\u73b0\u4e86\u5f88\u591a\u76f8\u5173\u7684\u5185\u5bb9: https://www.reddit.com/r/MachineLearning/comments/39ax98/converting_continuous_data_to_discrete_data_for/ https://www.analyticsvidhya.com/blog/2015/11/8-ways-deal-continuous-variables-predictive-modeling/ https://stackoverflow.com/questions/23267767/how-to-do-discretization-of-continuous-attributes-in-sklearn TODO data normalisation TODO dummy variables TODO Running a notebook server https://jupyter-notebook.readthedocs.io/en/stable/public_server.html Feature selection http://scikit-learn.org/stable/modules/feature_selection.html#feature-selection python pandas groupby transform\u7684\u4e00\u4e2a\u5751 \u5206\u7ec4\uff0c\u5e76\u7528\u524d\u503c\u6765\u8865\u7f3a\uff0c\u614e\u7528\u4e0b\u9762\u8fd9\u79cd\u5199\u6cd5\uff0c\u4f1a\u5bfc\u81f4\u6700\u540e self.data \u4e2d\u6ca1\u6709 CompanyCode \u5217 f = lambda x: x.fillna(method='pad') self.data = self.data.groupby(['CompanyCode'])[self.local_table.fields].transform(f) \u7528\u4e0b\u9762\u8fd9\u79cd\u5199\u6cd5\uff1a self.data = self.data.groupby(['CompanyCode']).ffill() qcut https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html","title":"english"},{"location":"draft/20180820/#english","text":"Decouple \u89e3\u8026","title":"english"},{"location":"draft/20180820/#machine#learning","text":"","title":"machine learning"},{"location":"draft/20180820/#decision#tree","text":"The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. The deeper the tree, the more complex the decision rules and the fitter the model.\u5f80\u5f80\u662f\u6811\u8d8a\u6df1\uff0c\u5219decision rule\u8d8a\u590d\u6742\uff0c\u4e14\u62df\u5408\u6548\u679c\u8d8a\u597d\u3002","title":"decision tree"},{"location":"draft/20180820/#disadvantage","text":"\u5bb9\u6613\u8fc7\u62df\u5408 Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting . Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.\u901a\u8fc7\u526a\u679d\u3001\u9650\u5236\u6bcf\u4e2a\u53f6\u5b50\u8282\u70b9\u7684sample\u7684\u4e2a\u6570\u3001\u6811\u7684\u6df1\u5ea6\u6765\u9632\u6b62**overfitting**\u3002 - \u4e0d\u7a33\u5b9a Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This problem is mitigated\uff08\u51cf\u8f7b\uff09 by using decision trees within an ensemble.\u901a\u8fc7ensemble\u65b9\u6cd5\u6765\u51cf\u8f7b\u51b3\u7b56\u6811\u7684\u4e0d\u7a33\u5b9a\u6027 \u65e0\u6cd5\u8fbe\u5230\u5168\u5c40\u6700\u4f18 The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. Consequently, practical decision-tree learning algorithms are based on heuristic algorithms such as the greedy algorithm where locally optimal decisions are made at each node. Such algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.\u51b3\u7b56\u6811\u91c7\u7528\u7684\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u8fbe\u5230\u5168\u5c40\u6700\u4f18\u3002\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528ensemble\u65b9\u6cd5\u6765\u51cf\u8f7b\u6b64\u95ee\u9898\u3002 - \u65e0\u6cd5\u5904\u7406\u6570\u636e\u4e0d\u5747\u8861\u95ee\u9898 Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree.\u5f53\u67d0\u4e2a\u7c7b\u522b\u7684sample\u5360\u6bd4\u8f83\u9ad8\u7684\u65f6\u5019\uff0c\u5c31\u4f1a\u5bfc\u81f4\u521b\u5efa\u7684\u6811\u51fa\u73b0\u504f\u5dee\uff0c\u6240\u4ee5\u5728\u62df\u5408\u4e4b\u524d\u6700\u597d\u5148balance\u4e00\u4e0bdataset","title":"\u51b3\u7b56\u6811\u7684\u4e00\u4e9b\u7f3a\u70b9disadvantage"},{"location":"draft/20180820/#_1","text":"\u73b0\u5728\u770b\u6765\u8fd9\u4e2a\u95ee\u9898\u548c\u4e0b\u9762\u7684 in machine learning how to add discrete label to continuous data \u6709\u4e9b\u63a5\u8fd1\uff0c\u90fd\u662f\u5bf9\u8fde\u7eed\u578b\u53d8\u91cf\u8fdb\u884c\u5212\u5206\u7684\u3002\u663e\u7136\u4e24\u8005\u4f7f\u7528\u7684\u7b97\u6cd5\u662f\u4e0d\u76f8\u540c\u7684\u3002","title":"\u5bf9\u4e8e\u8fde\u7eed\u578b\u53d8\u91cf\uff0c\u51b3\u7b56\u6811\u5982\u4f55\u6765\u8fdb\u884c\u5212\u5206\uff1f\uff1f"},{"location":"draft/20180820/#tips#on#practical#use","text":"Decision trees tend to overfit on data with a large number of features. Getting the right ratio of samples to number of features is important, since a tree with few samples in high dimensional space is very likely to overfit. Consider performing dimensionality reduction (PCA, ICA, or Feature selection) beforehand to give your tree a better chance of finding features that are discriminative(\u6709\u8bc6\u522b\u529b\u7684). Balance your dataset before training to prevent the tree from being biased toward the classes that are dominant . Class balancing can be done by sampling an equal number of samples from each class, or preferably by normalizing the sum of the sample weights (sample_weight) for each class to the same value. Also note that weight-based pre-pruning criteria, such as min_weight_fraction_leaf, will then be less biased toward dominant classes than criteria that are not aware of the sample weights, like min_samples_leaf.","title":"Tips on practical use"},{"location":"draft/20180820/#in#machine#learning#how#to#add#discrete#label#to#continuous#data","text":"\u521a\u521a\u4f7f\u7528 in machine learning how to add discrete label to continuous data \u641c\u7d22\u4e86\u4e00\u4e0b\uff0c\u53d1\u73b0\u4e86\u5f88\u591a\u76f8\u5173\u7684\u5185\u5bb9: https://www.reddit.com/r/MachineLearning/comments/39ax98/converting_continuous_data_to_discrete_data_for/ https://www.analyticsvidhya.com/blog/2015/11/8-ways-deal-continuous-variables-predictive-modeling/ https://stackoverflow.com/questions/23267767/how-to-do-discretization-of-continuous-attributes-in-sklearn","title":"in machine learning how to add discrete label to continuous data"},{"location":"draft/20180820/#todo#data#normalisation","text":"","title":"TODO data normalisation"},{"location":"draft/20180820/#todo#dummy#variables","text":"","title":"TODO dummy variables"},{"location":"draft/20180820/#todo#running#a#notebook#server","text":"https://jupyter-notebook.readthedocs.io/en/stable/public_server.html","title":"TODO Running a notebook server"},{"location":"draft/20180820/#feature#selection","text":"http://scikit-learn.org/stable/modules/feature_selection.html#feature-selection","title":"Feature selection"},{"location":"draft/20180820/#python","text":"","title":"python"},{"location":"draft/20180820/#pandas#groupby#transform","text":"\u5206\u7ec4\uff0c\u5e76\u7528\u524d\u503c\u6765\u8865\u7f3a\uff0c\u614e\u7528\u4e0b\u9762\u8fd9\u79cd\u5199\u6cd5\uff0c\u4f1a\u5bfc\u81f4\u6700\u540e self.data \u4e2d\u6ca1\u6709 CompanyCode \u5217 f = lambda x: x.fillna(method='pad') self.data = self.data.groupby(['CompanyCode'])[self.local_table.fields].transform(f) \u7528\u4e0b\u9762\u8fd9\u79cd\u5199\u6cd5\uff1a self.data = self.data.groupby(['CompanyCode']).ffill()","title":"pandas groupby transform\u7684\u4e00\u4e2a\u5751"},{"location":"draft/20180820/#qcut","text":"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html","title":"qcut"},{"location":"draft/20180824/","text":"python matplotlib _tkinter.TclError: no display name and no $DISPLAY environment variable https://stackoverflow.com/questions/2801882/generating-a-png-with-matplotlib-when-display-is-undefined \u4e0a\u9762\u8fd9\u7bc7\u6587\u7ae0\u867d\u7136\u7ed9\u51fa\u4e86\u7b54\u6848\uff0c\u4f46\u662f\u539f\u56e0\u5e76\u4e0d\u6e05\u695a\uff0c\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u4e86\u7b54\u6848\uff0c\u5e76\u4e14\u8fd8\u7ed9\u51fa\u4e86\u539f\u56e0\uff1a https://stackoverflow.com/questions/4931376/generating-matplotlib-graphs-without-a-running-x-server Matplotlib seems to require the $DISPLAY environment variable which means a running X server. Some web hosting services do not allow a running X server session. Is there a way to generate graphs using matplotlib without a running X server? \u5b83\u7684\u8fd9\u6bb5\u8bdd\u662f\u5bf9\u6211\u7684\u8fd9\u4e2a\u95ee\u9898\u66f4\u597d\uff0c\u66f4\u52a0\u4e13\u4e1a\u7684\u63cf\u8ff0\u3002 Setting different color for each series in scatter plot on matplotlib https://stackoverflow.com/questions/12236566/setting-different-color-for-each-series-in-scatter-plot-on-matplotlib Named colors in matplotlib https://stackoverflow.com/questions/22408237/named-colors-in-matplotlib matplotlib\u5982\u4f55\u753b\u51fapandas\u7684\u7d22\u5f15\u548c\u5217\u4e4b\u95f4\u7684\u5173\u7cfb\u56fe\uff1f\uff1f \u4e0b\u9762\u662f\u4e00\u4e2a\u5c0f\u4f8b\u5b50\uff1a %pylab inline ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000',periods=1000)) ts = ts.cumsum() ts.plot() \u4ece\u753b\u51fa\u7684\u56fe\u50cf\u6765\u770b\uff0c\u5b83\u7684\u786e\u80fd\u591f\u4ee5\u7d22\u5f15\u4e3a x \u8f74\uff0c\u4ee5\u5bf9\u5e94\u7684\u503c\u4e3a y \u8f74\uff0c\u753b\u51fa\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5176\u5b9e\u5bf9\u4e8e\u4e00\u4e2aDataFrame\uff0c\u5176\u7d22\u5f15\u548c\u6bcf\u4e00\u5217\u7684\u503c\u4e4b\u95f4\u662f\u4e00\u4e00\u5bf9\u5e94\u7684\u51fd\u6570\u5173\u7cfb\uff0c\u8fd9\u79cd\u5bf9\u5e94\u5173\u7cfb\u7528\u4e0a\u9762\u7684\u56fe\u50cf\u6765\u8868\u793a\u5c31\u662f\u4e00\u4e2a\u4e00\u4e2a\u7684\u70b9\u3002 \u4e5f\u5c31\u662f\u5982\u679c\u8c03\u7528 matplotlib \u7684plot\u51fd\u6570\u6765\u753b\u4e00\u4e2a Line Plots \u7684\u8bdd\uff0c\u524d\u63d0\u8981\u6c42\u5e94\u8be5\u662f x \u548c y \u7684\u957f\u5ea6\u9700\u8981\u662f\u76f8\u540c\u7684\uff0c matplotlib \u4f7f\u7528 [x,y] \u6765\u6784\u6210\u6240\u6709\u7684\u70b9\u96c6\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u70b9\u753b\u51fa\uff0c\u8fd9\u5e94\u8be5\u5c31\u662fmatplotlib\u7684\u5de5\u4f5c\u539f\u7406\u4e86\u3002 plot(x, y) pandas TODO PerformanceWarning: indexing past lexsort depth may impact performance. machine learning Support Vector Machines used for outliers detection http://scikit-learn.org/stable/modules/svm.html#support-vector-machines Support Vector Machines SVMs decision function depends on some subset of the training data, called the support vectors . Some properties of these support vectors can be found in members support_vectors_ , support_ and n_support : 1.4.1.1. Multi-class classification SVC and NuSVC implement the \u201cone-against-one\u201d approach (Knerr et al., 1990) for multi- class classification. If n_class is the number of classes, then n_class * (n_class - 1) / 2 classifiers are constructed and each one trains data from two classes. To provide a consistent interface with other classifiers, the decision_function_shape option allows to aggregate the results of the \u201cone-against-one\u201d classifiers to a decision function of shape (n_samples, n_classes) : SVC and NuSVC \u5b9e\u73b0\u591a\u5206\u7c7b\u7684\u91c7\u7528\u7684\u662f\u9012\u5f52\u7684\u65b9\u5f0f\uff0c\u5373\u5148\u5c06\u603b\u7c7b\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u7136\u540e\u518d\u5bf9\u6bcf\u4e2a\u5b50\u7c7b\u8fdb\u884c\u4e8c\u5206\u7c7b\u3002\u4e3a\u4e86\u63d0\u4f9b\u4e0e\u5176\u4ed6\u5206\u7c7b\u5668\u7684\u4e00\u81f4\u63a5\u53e3\uff0c\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570 decision_function_shape \u6765\u8fdb\u884c\u63a7\u5236\uff0c\u8be5\u53c2\u6570\u5141\u8bb8\u5c06\u201c\u4e00\u5bf9\u4e00\u201d\u5206\u7c7b\u5668\u7684\u7ed3\u679c\u805a\u5408\u5230\u5f62\u72b6\u4e3a \uff08n_samples\uff0cn_classes\uff09 \u7684\u51b3\u7b56\u51fd\u6570\u3002 X = [[0], [1], [2], [3]] Y = [0, 1, 2, 3] clf = svm.SVC(decision_function_shape='ovo') clf.fit(X, Y) dec = clf.decision_function([[1]]) dec.shape[1] # 4 classes: 4*3/2 = 6 clf.decision_function_shape = \"ovr\" dec = clf.decision_function([[1]]) dec.shape[1] # 4 classes English Versatile \u591a\u624d\u591a\u827a\u7684 \u667a\u80fd\u9009\u80a1 \u9009\u62e9\u884c\u4e1a \u516c\u53f8\u7684\u884c\u4e1a\u6027\u8d28\u73b0\u5728\u548c\u65f6\u95f4\u6709\u5173\u8054\u4e86\uff0c\u6240\u4ee5\u73b0\u5728\u5728\u67e5\u8be2\u516c\u53f8\u7684\u884c\u4e1a\u4fe1\u606f\u7684\u65f6\u5019\uff0c\u9700\u8981\u4e00\u5e76\u5c06\u65f6\u95f4\u67e5\u8be2\u51fa\u6765\u3002 \u6bcf\u4e2a\u516c\u53f8\u5c31\u6709\u4e00\u4e2a\u5bf9\u5e94\u7684\u65f6\u95f4\u8303\u56f4\u3002","title":"python"},{"location":"draft/20180824/#python","text":"","title":"python"},{"location":"draft/20180824/#matplotlib","text":"","title":"matplotlib"},{"location":"draft/20180824/#_tkintertclerror#no#display#name#and#no#display#environment#variable","text":"https://stackoverflow.com/questions/2801882/generating-a-png-with-matplotlib-when-display-is-undefined \u4e0a\u9762\u8fd9\u7bc7\u6587\u7ae0\u867d\u7136\u7ed9\u51fa\u4e86\u7b54\u6848\uff0c\u4f46\u662f\u539f\u56e0\u5e76\u4e0d\u6e05\u695a\uff0c\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u51fa\u4e86\u7b54\u6848\uff0c\u5e76\u4e14\u8fd8\u7ed9\u51fa\u4e86\u539f\u56e0\uff1a https://stackoverflow.com/questions/4931376/generating-matplotlib-graphs-without-a-running-x-server Matplotlib seems to require the $DISPLAY environment variable which means a running X server. Some web hosting services do not allow a running X server session. Is there a way to generate graphs using matplotlib without a running X server? \u5b83\u7684\u8fd9\u6bb5\u8bdd\u662f\u5bf9\u6211\u7684\u8fd9\u4e2a\u95ee\u9898\u66f4\u597d\uff0c\u66f4\u52a0\u4e13\u4e1a\u7684\u63cf\u8ff0\u3002","title":"_tkinter.TclError: no display name and no $DISPLAY environment variable"},{"location":"draft/20180824/#setting#different#color#for#each#series#in#scatter#plot#on#matplotlib","text":"https://stackoverflow.com/questions/12236566/setting-different-color-for-each-series-in-scatter-plot-on-matplotlib","title":"Setting different color for each series in scatter plot on matplotlib"},{"location":"draft/20180824/#named#colors#in#matplotlib","text":"https://stackoverflow.com/questions/22408237/named-colors-in-matplotlib","title":"Named colors in matplotlib"},{"location":"draft/20180824/#matplotlibpandas","text":"\u4e0b\u9762\u662f\u4e00\u4e2a\u5c0f\u4f8b\u5b50\uff1a %pylab inline ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000',periods=1000)) ts = ts.cumsum() ts.plot() \u4ece\u753b\u51fa\u7684\u56fe\u50cf\u6765\u770b\uff0c\u5b83\u7684\u786e\u80fd\u591f\u4ee5\u7d22\u5f15\u4e3a x \u8f74\uff0c\u4ee5\u5bf9\u5e94\u7684\u503c\u4e3a y \u8f74\uff0c\u753b\u51fa\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5176\u5b9e\u5bf9\u4e8e\u4e00\u4e2aDataFrame\uff0c\u5176\u7d22\u5f15\u548c\u6bcf\u4e00\u5217\u7684\u503c\u4e4b\u95f4\u662f\u4e00\u4e00\u5bf9\u5e94\u7684\u51fd\u6570\u5173\u7cfb\uff0c\u8fd9\u79cd\u5bf9\u5e94\u5173\u7cfb\u7528\u4e0a\u9762\u7684\u56fe\u50cf\u6765\u8868\u793a\u5c31\u662f\u4e00\u4e2a\u4e00\u4e2a\u7684\u70b9\u3002 \u4e5f\u5c31\u662f\u5982\u679c\u8c03\u7528 matplotlib \u7684plot\u51fd\u6570\u6765\u753b\u4e00\u4e2a Line Plots \u7684\u8bdd\uff0c\u524d\u63d0\u8981\u6c42\u5e94\u8be5\u662f x \u548c y \u7684\u957f\u5ea6\u9700\u8981\u662f\u76f8\u540c\u7684\uff0c matplotlib \u4f7f\u7528 [x,y] \u6765\u6784\u6210\u6240\u6709\u7684\u70b9\u96c6\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u70b9\u753b\u51fa\uff0c\u8fd9\u5e94\u8be5\u5c31\u662fmatplotlib\u7684\u5de5\u4f5c\u539f\u7406\u4e86\u3002 plot(x, y)","title":"matplotlib\u5982\u4f55\u753b\u51fapandas\u7684\u7d22\u5f15\u548c\u5217\u4e4b\u95f4\u7684\u5173\u7cfb\u56fe\uff1f\uff1f"},{"location":"draft/20180824/#pandas","text":"","title":"pandas"},{"location":"draft/20180824/#todo#performancewarning#indexing#past#lexsort#depth#may#impact#performance","text":"","title":"TODO PerformanceWarning: indexing past lexsort depth may impact performance."},{"location":"draft/20180824/#machine#learning","text":"","title":"machine learning"},{"location":"draft/20180824/#support#vector#machines#used#for#outliers#detection","text":"http://scikit-learn.org/stable/modules/svm.html#support-vector-machines","title":"Support Vector Machines used for outliers detection"},{"location":"draft/20180824/#support#vector#machines","text":"SVMs decision function depends on some subset of the training data, called the support vectors . Some properties of these support vectors can be found in members support_vectors_ , support_ and n_support :","title":"Support Vector Machines"},{"location":"draft/20180824/#1411#multi-class#classification","text":"SVC and NuSVC implement the \u201cone-against-one\u201d approach (Knerr et al., 1990) for multi- class classification. If n_class is the number of classes, then n_class * (n_class - 1) / 2 classifiers are constructed and each one trains data from two classes. To provide a consistent interface with other classifiers, the decision_function_shape option allows to aggregate the results of the \u201cone-against-one\u201d classifiers to a decision function of shape (n_samples, n_classes) : SVC and NuSVC \u5b9e\u73b0\u591a\u5206\u7c7b\u7684\u91c7\u7528\u7684\u662f\u9012\u5f52\u7684\u65b9\u5f0f\uff0c\u5373\u5148\u5c06\u603b\u7c7b\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u7136\u540e\u518d\u5bf9\u6bcf\u4e2a\u5b50\u7c7b\u8fdb\u884c\u4e8c\u5206\u7c7b\u3002\u4e3a\u4e86\u63d0\u4f9b\u4e0e\u5176\u4ed6\u5206\u7c7b\u5668\u7684\u4e00\u81f4\u63a5\u53e3\uff0c\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570 decision_function_shape \u6765\u8fdb\u884c\u63a7\u5236\uff0c\u8be5\u53c2\u6570\u5141\u8bb8\u5c06\u201c\u4e00\u5bf9\u4e00\u201d\u5206\u7c7b\u5668\u7684\u7ed3\u679c\u805a\u5408\u5230\u5f62\u72b6\u4e3a \uff08n_samples\uff0cn_classes\uff09 \u7684\u51b3\u7b56\u51fd\u6570\u3002 X = [[0], [1], [2], [3]] Y = [0, 1, 2, 3] clf = svm.SVC(decision_function_shape='ovo') clf.fit(X, Y) dec = clf.decision_function([[1]]) dec.shape[1] # 4 classes: 4*3/2 = 6 clf.decision_function_shape = \"ovr\" dec = clf.decision_function([[1]]) dec.shape[1] # 4 classes","title":"1.4.1.1. Multi-class classification"},{"location":"draft/20180824/#english","text":"Versatile \u591a\u624d\u591a\u827a\u7684","title":"English"},{"location":"draft/20180824/#_1","text":"","title":"\u667a\u80fd\u9009\u80a1"},{"location":"draft/20180824/#_2","text":"\u516c\u53f8\u7684\u884c\u4e1a\u6027\u8d28\u73b0\u5728\u548c\u65f6\u95f4\u6709\u5173\u8054\u4e86\uff0c\u6240\u4ee5\u73b0\u5728\u5728\u67e5\u8be2\u516c\u53f8\u7684\u884c\u4e1a\u4fe1\u606f\u7684\u65f6\u5019\uff0c\u9700\u8981\u4e00\u5e76\u5c06\u65f6\u95f4\u67e5\u8be2\u51fa\u6765\u3002 \u6bcf\u4e2a\u516c\u53f8\u5c31\u6709\u4e00\u4e2a\u5bf9\u5e94\u7684\u65f6\u95f4\u8303\u56f4\u3002","title":"\u9009\u62e9\u884c\u4e1a"},{"location":"draft/20180904/","text":"Reshaping and Pivot Tables Reshaping by pivoting DataFrame objects stacked, record \u4ece\u56fe\u7247\u770b\u51fa\uff0c df \u4e2d\u7684\u6570\u636e\u5b58\u5728\u5982\u4e0b\u89c4\u5f8b\uff1a - \u5217 bar \u53ef\u53d6\u503c A , B , C \uff0c\u4e14\u6bcf\u4e2a\u503c\u7684\u4e2a\u6570\u76f8\u540c - \u5217 foo \u548c\u5217 bar \u7684\u53d6\u503c\u662f\u914d\u5957\u7684 \u8981\u60f3\u4f7f\u7528 pivot \uff0c\u5219\u539fdataframe\u9700\u8981\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6: Select rows from a DataFrame based on values in a column in pandas https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas PerformanceWarning: indexing past lexsort depth may impact performance. \u5728\u8bbf\u95ee\u6570\u636e\u524d\u5148\u8c03\u7528\u4e00\u4e0b\u5982\u4e0b\u51fd\u6570: df.sort_index(inplace=True) https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.sort_values.html TODO pandas ValueError \u62a5\u9519\u4fe1\u606f\u5982\u4e0b\uff1a ValueError Traceback (most recent call last) ValueError: Buffer dtype mismatch, expected 'Python object' but got 'long' Exception ignored in: 'pandas._libs.lib.is_bool_array' ValueError: Buffer dtype mismatch, expected 'Python object' but got 'long' TODO Reshaping and Pivot Tables https://pandas.pydata.org/pandas-docs/stable/reshaping.html English methodological \u65b9\u6cd5\u8bba drastically \u5927\u5e45\u5730 confidence interval \u7f6e\u4fe1\u533a\u95f4 lasso \u7d22\u5957\uff0c\u62c9\u62e2 be amenable to \u9002\u7528\u4e8e anova \u65b9\u5dee\u5206\u6790 quad \u56db religion \u5b97\u6559\uff0c\u4fe1\u4ef0 atheism \u65e0\u795e\u8bba work around \u89e3\u51b3 ambiguity \u4e8c\u4e49\u6027 mimic \u6a21\u4eff IOW in other word compartmentalization \u5212\u5206 scikit-learn class hierarchy \u4f5c\u7528 method estimator base class fit , get_params , set_params transformer Preprocessing data predictor classifier classification regressor regression graph TB A[estimator] B[transformer]-->|is a|A C[predictor]-->|is a|A D[regressor]-->|is a|A \u4f7f\u7528Pipeline\u6765combining estimators There is often a fixed sequence of steps in processing the data, for example feature selection , normalization and classification .So we can use Pipeline to chain multiple estimators (\u57fa\u7c7b) into one. \u5176\u4e2dfeature selection\u5c5e\u4e8e Feature selection \u8303\u8f74 \u5176\u4e2dnormalization\u5219\u5c5e\u4e8e Preprocessing data \u8303\u8f74 classification\u5219\u4e3b\u8981\u5c5e\u4e8e Model selection and evaluation \uff0c\u76ee\u524d\u5305\u542b\u5982\u4e0b\u5185\u5bb9\uff1a - Cross-validation: evaluating estimator performance Tuning the hyper-parameters of an estimator \u5982\u4f55\u4f7f\u7528 Pipeline \uff1f \u4e0b\u9762\u662f\u4e00\u4e9b\u5177\u6709\u542f\u53d1\u6027\u7684\u4f8b\u5b50 Sample pipeline for text feature extraction and evaluation \u7b2c\u4e00\u4e2a\u4e00\u4e2apipeline\uff0c\u8fd9\u4e2apipeline\u7684**last** **estimator**\u662f\u4e00\u4e2aClassifier # Define a pipeline combining a text feature extractor with a simple # classifier pipeline = Pipeline([ ('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier()), ]) Pipeline\u5177\u6709\u8fd9\u79cd \u7279\u6027 : Calling fit on the pipeline is the same as calling fit on each estimator in turn, transform the input and pass it on to the next step. The pipeline has all the methods that the last estimator in the pipeline has, i.e. if the last estimator is a classifier , the Pipeline can be used as a classifier . If the last estimator is a transformer, again, so is the pipeline. \u6240\u4ee5\u5728\u4e0b\u9762\u8fd9\u79cd\u7528\u6cd5\u4e2d\uff0c\u6b64\u65f6\u7684 pipline \u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a classifier \u3002 # find the best parameters for both the feature extraction and the # classifier grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1) cross-validation \u4e00\u4e2a\u6a21\u578b\u6709\u4e24\u7c7b\u53c2\u6570\uff1a - \u5b66\u4e60\u53c2\u6570learning parameters\uff0c\u4ece\u6570\u636e\u4e2d\u5b66\u4e60 - \u8d85\u53c2\u6570hyperparameters\uff0c\u4eba\u4e3a\u8bbe\u7f6e \u663e\u7136**\u5b66\u4e60\u53c2\u6570**\u662f\u6211\u4eec\u65e0\u6cd5\u6539\u53d8\u7684\uff0c\u4f46\u662f**\u8d85\u53c2\u6570**\u662f\u9700\u8981\u4eba\u4e3a\u6765\u8fdb\u884c\u8c03\u6574\u7684\u3002learning parameters\u662f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7684\uff0c\u6211\u4eec\u4eba\u4e3a\u65e0\u6cd5\u8fdb\u884c\u66f4\u6539\uff0c\u800chyperparameters\u5219\u662f\u9700\u8981\u6211\u4eec\u624b\u52a8\u5730\u53bb\u5bfb\u627e\u6700\u4f18\u503c\u7684\uff08\u8fd9\u5c31\u662f3.2. Tuning the hyper-parameters of an estimator\u5185\u5bb9\uff09\uff0c\u53ea\u6709\u5f53\u8fd9\u4e24\u7c7b\u53c2\u6570\u90fd\u786e\u5b9a\u4e0b\u6765\uff0c\u5e76\u4e14\u90fd\u8fbe\u5230\u6700\u4f18\uff0c\u6211\u4eec\u624d\u7b97\u5bfb\u627e\u5230\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7136\u540e\u624d\u80fd\u591f\u4f7f\u7528\u6d4b\u8bd5\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002 \u5bf9\u4e8e\u8fd9\u4e24\u7c7b\u53c2\u6570\uff0c\u6211\u4eec\u90fd\u662f\u9700\u8981\u5bf9\u5b83\u4eec\u8fdb\u884c\u8bc4\u4f30\u7684\uff0c\u8fd9\u5c31\u6d89\u53ca\u5230\u5982\u4f55\u8fdb\u884c\u8bc4\u4f30\uff08\u8fd9\u5c31\u662fcross validation\u6240\u505a\u7684\u5de5\u4f5c\uff09\uff0c\u5e76\u4e14\u5bf9\u4ed6\u4eec\u7684\u8bc4\u4f30\u4e5f\u51b3\u5b9a\u4e86\u6211\u4eec\u80fd\u5426\u627e\u5230\u66f4\u597d\u7684\u89e3\u3002 \u5f53\u6211\u4eec\u6267\u884c\u5b8c\u4e00\u8f6e\u5b66\u4e60\u548c\u8c03\u53c2\u540e\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u6a21\u578b\u7684\u53c2\u6570\u6700\u7ec8\u786e\u8ba4\u4e86\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u6d4b\u8bd5\u96c6\u6765\u5bf9\u6574\u4e2a\u6a21\u578b\u7684\u6027\u80fd\u8fdb\u884c\u9a8c\u8bc1\u3002 \u4f7f\u7528\u4e00\u4e2a\u8bad\u7ec3\u96c6\u6765\u8bad\u7ec3\u51fa\u4e00\u4e2a\u6a21\u578b\uff0c\u7136\u540e\u8c03\u6574\u8d85\u53c2\u6570\uff0cvalidate whether a hyperparameter is good\u3002 \u6709\u4e00\u70b9\u662f\u53ef\u4ee5\u80af\u5b9a\u7684\uff1a\u4e0d\u80fd\u591f\u4f7f\u7528\u6d4b\u6d4b\u8bd5\u96c6\u53d6\u9a8c\u8bc1\u4e00\u4e2a\u8d85\u53c2\u6570\u7684\u503c\u662f\u5426\u662f\u597d\u7684\uff0c\u5982\u679c\u4f7f\u7528\u6d4b\u8bd5\u96c6\u6765\u8fdb\u884c\u9a8c\u8bc1\u7684\u8bdd\uff0c\u5219knowledge about the test set can \u201cleak\u201d into the model and evaluation metrics no longer report on generalization performance.\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5c31\u63d0\u51fa\u4e86validation set\u7684\u6982\u5ff5\uff0c\u5373\u4f7f\u7528validation set\u6765\u9a8c\u8bc1\u67d0\u4e2a\u8d85\u53c2\u6570\u7684\u597d\u574f\u3002 \u56e0\u6b64\uff0c\u6700\u7ec8\u6570\u636e\u96c6\u4f1a\u6210\u4e3a\u5982\u4e0b\u4e09\u4e2a\u65b9\u9762\uff1a - training set\uff0c\u7528\u4e8e\u5b66\u4e60learning parameters - validation set\uff0c\u7528\u4e8e\u9a8c\u8bc1\u6b64hyperparameters\u7684\u503c\u662f\u5426\u597d - test set \u4f46\u662f\u5982\u679c\u8fd9\u6837\u6765\u8fdb\u884c\u5212\u5206\u7684\u8bdd\uff0c\u5219\u4f1a\u5bfc\u81f4we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets. \u4e3a\u6b64\u5c31\u5f15\u5165\u4e86 cross-validation \uff0c CV\u7684\u601d\u60f3\u5982\u4e0b\uff1a A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV . In the basic approach, called k-fold CV , the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k \u201cfolds\u201d: - A model is trained using k-1 of the folds as training data ; - the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy ). \u663e\u7136\u5728cross validation\u4e2d\uff0c\u6570\u636e\u96c6\u4f1a\u88ab\u5206\u4e3a\u5982\u4e0b\u4e24\u7c7b\uff1a - training set - test set \u4ece \u8fd9\u4e2a\u4f8b\u5b50 \u4e2d\u662f\u53ef\u4ee5\u770b\u51fa\u6765\u7684 Q&A - k-fold CV\u662f\u8bad\u7ec3\u4e00\u4e2a\u660e\u7ec6k\u6b21\u8fd8\u662f\u8bad\u7ec3k\u6b21\u4ea7\u751fk\u4e2a\u6a21\u578b - cross_val_score \u6240\u8f93\u51fa\u7684score\u662f\u7528test set\u8bc4\u4f30\u7684\u8fd8\u662f\u4f7f\u7528\u7684\u8bad\u7ec3\u96c6\u4e2d\u7684\u7b2ck\u6298\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u7684\uff1f \u6839\u636e\u524d\u9762\u7684\u9605\u8bfb\u6765\u770b\uff0c\u80af\u5b9a\u4e0d\u662ftest set\u6765\u8bc4\u4f30\u7684\uff0c\u5e94\u8be5\u662f\u4f7f\u7528\u7b2ck\u6298\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u7684 Tuning the hyper-parameters of an estimator tuning the hyper-parameters\u7684\u66f4\u52a0\u51c6\u786e\u7684\u63cf\u8ff0\u662f( \u539f\u6587\u94fe\u63a5 )\uff1a search the hyper-parameter space for the best cross validation score. \u5373\u5728\u8d85\u53c2\u6570\u7a7a\u95f4\u4e2d\u5bfb\u627e\u5230\u6700\u4f73\u7684 cross validation score. \u5982\u4e0b\u662fscikit-learn\u6240\u63d0\u4f9b\u7684search\u7684 \u7ec4\u6210\u8981\u7d20 : - an estimator (regressor or classifier such as sklearn.svm.SVC() ); - a parameter space; - a method for searching or sampling candidates; - a cross-validation scheme; and - a score function . \u4e24\u4e2a\u901a\u7528\u7684sampling search candidates\u65b9\u6cd5\u5982\u4e0b\uff1a - GridSearchCV - RandomizedSearchCV \u6700\u4f73\u5b9e\u8df5 \u8fd9\u4e2a\u4f8b\u5b50 \u7b26\u5408\u6700\u4f73\u5b9e\u8df5\u7684 Model selection: development and evaluation \u539f\u5219\u3002 RandomizedSearchCV RandomizedSearchCV can sample a given number of candidates from a parameter space with a specified distribution . Q&A - \u6b64\u5904\u7684**specified distribution**\u5982\u4f55\u7406\u89e3 \u4f7f\u7528\u548c\u4e0d\u4f7f\u7528GridSearchCV\u7684\u5bf9\u6bd4 \u4e0d\u4f7f\u7528\u7684\u4f8b\u5b50 \u4f7f\u7528\u7684\u4f8b\u5b50","title":"Reshaping and Pivot Tables"},{"location":"draft/20180904/#reshaping#and#pivot#tables","text":"","title":"Reshaping and Pivot Tables"},{"location":"draft/20180904/#reshaping#by#pivoting#dataframe#objects","text":"stacked, record \u4ece\u56fe\u7247\u770b\u51fa\uff0c df \u4e2d\u7684\u6570\u636e\u5b58\u5728\u5982\u4e0b\u89c4\u5f8b\uff1a - \u5217 bar \u53ef\u53d6\u503c A , B , C \uff0c\u4e14\u6bcf\u4e2a\u503c\u7684\u4e2a\u6570\u76f8\u540c - \u5217 foo \u548c\u5217 bar \u7684\u53d6\u503c\u662f\u914d\u5957\u7684","title":"Reshaping by pivoting DataFrame objects"},{"location":"draft/20180904/#pivotdataframe","text":"","title":"\u8981\u60f3\u4f7f\u7528pivot\uff0c\u5219\u539fdataframe\u9700\u8981\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6:"},{"location":"draft/20180904/#select#rows#from#a#dataframe#based#on#values#in#a#column#in#pandas","text":"https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas","title":"Select rows from a DataFrame based on values in a column in pandas"},{"location":"draft/20180904/#performancewarning#indexing#past#lexsort#depth#may#impact#performance","text":"\u5728\u8bbf\u95ee\u6570\u636e\u524d\u5148\u8c03\u7528\u4e00\u4e0b\u5982\u4e0b\u51fd\u6570: df.sort_index(inplace=True) https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.sort_values.html","title":"PerformanceWarning: indexing past lexsort depth may impact performance."},{"location":"draft/20180904/#todo#pandas#valueerror","text":"\u62a5\u9519\u4fe1\u606f\u5982\u4e0b\uff1a ValueError Traceback (most recent call last) ValueError: Buffer dtype mismatch, expected 'Python object' but got 'long' Exception ignored in: 'pandas._libs.lib.is_bool_array' ValueError: Buffer dtype mismatch, expected 'Python object' but got 'long'","title":"TODO pandas ValueError"},{"location":"draft/20180904/#todo#reshaping#and#pivot#tables","text":"https://pandas.pydata.org/pandas-docs/stable/reshaping.html","title":"TODO Reshaping and Pivot Tables"},{"location":"draft/20180904/#english","text":"methodological \u65b9\u6cd5\u8bba drastically \u5927\u5e45\u5730 confidence interval \u7f6e\u4fe1\u533a\u95f4 lasso \u7d22\u5957\uff0c\u62c9\u62e2 be amenable to \u9002\u7528\u4e8e anova \u65b9\u5dee\u5206\u6790 quad \u56db religion \u5b97\u6559\uff0c\u4fe1\u4ef0 atheism \u65e0\u795e\u8bba work around \u89e3\u51b3 ambiguity \u4e8c\u4e49\u6027 mimic \u6a21\u4eff IOW in other word compartmentalization \u5212\u5206","title":"English"},{"location":"draft/20180904/#scikit-learn#class#hierarchy","text":"\u4f5c\u7528 method estimator base class fit , get_params , set_params transformer Preprocessing data predictor classifier classification regressor regression graph TB A[estimator] B[transformer]-->|is a|A C[predictor]-->|is a|A D[regressor]-->|is a|A","title":"scikit-learn class hierarchy"},{"location":"draft/20180904/#pipelinecombining#estimators","text":"There is often a fixed sequence of steps in processing the data, for example feature selection , normalization and classification .So we can use Pipeline to chain multiple estimators (\u57fa\u7c7b) into one. \u5176\u4e2dfeature selection\u5c5e\u4e8e Feature selection \u8303\u8f74 \u5176\u4e2dnormalization\u5219\u5c5e\u4e8e Preprocessing data \u8303\u8f74 classification\u5219\u4e3b\u8981\u5c5e\u4e8e Model selection and evaluation \uff0c\u76ee\u524d\u5305\u542b\u5982\u4e0b\u5185\u5bb9\uff1a - Cross-validation: evaluating estimator performance Tuning the hyper-parameters of an estimator","title":"\u4f7f\u7528Pipeline\u6765combining estimators"},{"location":"draft/20180904/#pipeline","text":"\u4e0b\u9762\u662f\u4e00\u4e9b\u5177\u6709\u542f\u53d1\u6027\u7684\u4f8b\u5b50","title":"\u5982\u4f55\u4f7f\u7528Pipeline\uff1f"},{"location":"draft/20180904/#sample#pipeline#for#text#feature#extraction#and#evaluation","text":"\u7b2c\u4e00\u4e2a\u4e00\u4e2apipeline\uff0c\u8fd9\u4e2apipeline\u7684**last** **estimator**\u662f\u4e00\u4e2aClassifier # Define a pipeline combining a text feature extractor with a simple # classifier pipeline = Pipeline([ ('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier()), ]) Pipeline\u5177\u6709\u8fd9\u79cd \u7279\u6027 : Calling fit on the pipeline is the same as calling fit on each estimator in turn, transform the input and pass it on to the next step. The pipeline has all the methods that the last estimator in the pipeline has, i.e. if the last estimator is a classifier , the Pipeline can be used as a classifier . If the last estimator is a transformer, again, so is the pipeline. \u6240\u4ee5\u5728\u4e0b\u9762\u8fd9\u79cd\u7528\u6cd5\u4e2d\uff0c\u6b64\u65f6\u7684 pipline \u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a classifier \u3002 # find the best parameters for both the feature extraction and the # classifier grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)","title":"Sample pipeline for text feature extraction and evaluation"},{"location":"draft/20180904/#cross-validation","text":"\u4e00\u4e2a\u6a21\u578b\u6709\u4e24\u7c7b\u53c2\u6570\uff1a - \u5b66\u4e60\u53c2\u6570learning parameters\uff0c\u4ece\u6570\u636e\u4e2d\u5b66\u4e60 - \u8d85\u53c2\u6570hyperparameters\uff0c\u4eba\u4e3a\u8bbe\u7f6e \u663e\u7136**\u5b66\u4e60\u53c2\u6570**\u662f\u6211\u4eec\u65e0\u6cd5\u6539\u53d8\u7684\uff0c\u4f46\u662f**\u8d85\u53c2\u6570**\u662f\u9700\u8981\u4eba\u4e3a\u6765\u8fdb\u884c\u8c03\u6574\u7684\u3002learning parameters\u662f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7684\uff0c\u6211\u4eec\u4eba\u4e3a\u65e0\u6cd5\u8fdb\u884c\u66f4\u6539\uff0c\u800chyperparameters\u5219\u662f\u9700\u8981\u6211\u4eec\u624b\u52a8\u5730\u53bb\u5bfb\u627e\u6700\u4f18\u503c\u7684\uff08\u8fd9\u5c31\u662f3.2. Tuning the hyper-parameters of an estimator\u5185\u5bb9\uff09\uff0c\u53ea\u6709\u5f53\u8fd9\u4e24\u7c7b\u53c2\u6570\u90fd\u786e\u5b9a\u4e0b\u6765\uff0c\u5e76\u4e14\u90fd\u8fbe\u5230\u6700\u4f18\uff0c\u6211\u4eec\u624d\u7b97\u5bfb\u627e\u5230\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7136\u540e\u624d\u80fd\u591f\u4f7f\u7528\u6d4b\u8bd5\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002 \u5bf9\u4e8e\u8fd9\u4e24\u7c7b\u53c2\u6570\uff0c\u6211\u4eec\u90fd\u662f\u9700\u8981\u5bf9\u5b83\u4eec\u8fdb\u884c\u8bc4\u4f30\u7684\uff0c\u8fd9\u5c31\u6d89\u53ca\u5230\u5982\u4f55\u8fdb\u884c\u8bc4\u4f30\uff08\u8fd9\u5c31\u662fcross validation\u6240\u505a\u7684\u5de5\u4f5c\uff09\uff0c\u5e76\u4e14\u5bf9\u4ed6\u4eec\u7684\u8bc4\u4f30\u4e5f\u51b3\u5b9a\u4e86\u6211\u4eec\u80fd\u5426\u627e\u5230\u66f4\u597d\u7684\u89e3\u3002 \u5f53\u6211\u4eec\u6267\u884c\u5b8c\u4e00\u8f6e\u5b66\u4e60\u548c\u8c03\u53c2\u540e\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u6a21\u578b\u7684\u53c2\u6570\u6700\u7ec8\u786e\u8ba4\u4e86\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u6d4b\u8bd5\u96c6\u6765\u5bf9\u6574\u4e2a\u6a21\u578b\u7684\u6027\u80fd\u8fdb\u884c\u9a8c\u8bc1\u3002 \u4f7f\u7528\u4e00\u4e2a\u8bad\u7ec3\u96c6\u6765\u8bad\u7ec3\u51fa\u4e00\u4e2a\u6a21\u578b\uff0c\u7136\u540e\u8c03\u6574\u8d85\u53c2\u6570\uff0cvalidate whether a hyperparameter is good\u3002 \u6709\u4e00\u70b9\u662f\u53ef\u4ee5\u80af\u5b9a\u7684\uff1a\u4e0d\u80fd\u591f\u4f7f\u7528\u6d4b\u6d4b\u8bd5\u96c6\u53d6\u9a8c\u8bc1\u4e00\u4e2a\u8d85\u53c2\u6570\u7684\u503c\u662f\u5426\u662f\u597d\u7684\uff0c\u5982\u679c\u4f7f\u7528\u6d4b\u8bd5\u96c6\u6765\u8fdb\u884c\u9a8c\u8bc1\u7684\u8bdd\uff0c\u5219knowledge about the test set can \u201cleak\u201d into the model and evaluation metrics no longer report on generalization performance.\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5c31\u63d0\u51fa\u4e86validation set\u7684\u6982\u5ff5\uff0c\u5373\u4f7f\u7528validation set\u6765\u9a8c\u8bc1\u67d0\u4e2a\u8d85\u53c2\u6570\u7684\u597d\u574f\u3002 \u56e0\u6b64\uff0c\u6700\u7ec8\u6570\u636e\u96c6\u4f1a\u6210\u4e3a\u5982\u4e0b\u4e09\u4e2a\u65b9\u9762\uff1a - training set\uff0c\u7528\u4e8e\u5b66\u4e60learning parameters - validation set\uff0c\u7528\u4e8e\u9a8c\u8bc1\u6b64hyperparameters\u7684\u503c\u662f\u5426\u597d - test set \u4f46\u662f\u5982\u679c\u8fd9\u6837\u6765\u8fdb\u884c\u5212\u5206\u7684\u8bdd\uff0c\u5219\u4f1a\u5bfc\u81f4we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets. \u4e3a\u6b64\u5c31\u5f15\u5165\u4e86 cross-validation \uff0c CV\u7684\u601d\u60f3\u5982\u4e0b\uff1a A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV . In the basic approach, called k-fold CV , the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k \u201cfolds\u201d: - A model is trained using k-1 of the folds as training data ; - the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy ). \u663e\u7136\u5728cross validation\u4e2d\uff0c\u6570\u636e\u96c6\u4f1a\u88ab\u5206\u4e3a\u5982\u4e0b\u4e24\u7c7b\uff1a - training set - test set \u4ece \u8fd9\u4e2a\u4f8b\u5b50 \u4e2d\u662f\u53ef\u4ee5\u770b\u51fa\u6765\u7684 Q&A - k-fold CV\u662f\u8bad\u7ec3\u4e00\u4e2a\u660e\u7ec6k\u6b21\u8fd8\u662f\u8bad\u7ec3k\u6b21\u4ea7\u751fk\u4e2a\u6a21\u578b - cross_val_score \u6240\u8f93\u51fa\u7684score\u662f\u7528test set\u8bc4\u4f30\u7684\u8fd8\u662f\u4f7f\u7528\u7684\u8bad\u7ec3\u96c6\u4e2d\u7684\u7b2ck\u6298\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u7684\uff1f \u6839\u636e\u524d\u9762\u7684\u9605\u8bfb\u6765\u770b\uff0c\u80af\u5b9a\u4e0d\u662ftest set\u6765\u8bc4\u4f30\u7684\uff0c\u5e94\u8be5\u662f\u4f7f\u7528\u7b2ck\u6298\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u7684","title":"cross-validation"},{"location":"draft/20180904/#tuning#the#hyper-parameters#of#an#estimator","text":"tuning the hyper-parameters\u7684\u66f4\u52a0\u51c6\u786e\u7684\u63cf\u8ff0\u662f( \u539f\u6587\u94fe\u63a5 )\uff1a search the hyper-parameter space for the best cross validation score. \u5373\u5728\u8d85\u53c2\u6570\u7a7a\u95f4\u4e2d\u5bfb\u627e\u5230\u6700\u4f73\u7684 cross validation score. \u5982\u4e0b\u662fscikit-learn\u6240\u63d0\u4f9b\u7684search\u7684 \u7ec4\u6210\u8981\u7d20 : - an estimator (regressor or classifier such as sklearn.svm.SVC() ); - a parameter space; - a method for searching or sampling candidates; - a cross-validation scheme; and - a score function . \u4e24\u4e2a\u901a\u7528\u7684sampling search candidates\u65b9\u6cd5\u5982\u4e0b\uff1a - GridSearchCV - RandomizedSearchCV \u6700\u4f73\u5b9e\u8df5 \u8fd9\u4e2a\u4f8b\u5b50 \u7b26\u5408\u6700\u4f73\u5b9e\u8df5\u7684 Model selection: development and evaluation \u539f\u5219\u3002","title":"Tuning the hyper-parameters of an estimator"},{"location":"draft/20180904/#randomizedsearchcv","text":"RandomizedSearchCV can sample a given number of candidates from a parameter space with a specified distribution . Q&A - \u6b64\u5904\u7684**specified distribution**\u5982\u4f55\u7406\u89e3","title":"RandomizedSearchCV"},{"location":"draft/20180904/#gridsearchcv","text":"\u4e0d\u4f7f\u7528\u7684\u4f8b\u5b50 \u4f7f\u7528\u7684\u4f8b\u5b50","title":"\u4f7f\u7528\u548c\u4e0d\u4f7f\u7528GridSearchCV\u7684\u5bf9\u6bd4"}]}